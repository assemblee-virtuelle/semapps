{"version":3,"file":"index.cjs.js","sources":["../../../node_modules/url-join/lib/url-join.js","../src/dataProvider/utils/fetchResource.js","../src/dataProvider/methods/getOne.js","../src/dataProvider/utils/uploadAllFiles.js","../src/dataProvider/utils/getServerKeyFromType.js","../src/dataProvider/utils/parseServerKeys.js","../src/dataProvider/utils/findContainersWithTypes.js","../src/dataProvider/methods/create.js","../src/dataProvider/methods/delete.js","../src/dataProvider/methods/deleteMany.js","../src/dataProvider/methods/getDataServers.js","../src/dataProvider/methods/getDataModels.js","../src/dataProvider/utils/fetchContainers.js","../node_modules/isobject/index.js","../src/dataProvider/utils/getEmbedFrame.js","../src/dataProvider/utils/resolvePrefix.js","../src/dataProvider/utils/buildBaseQuery.js","../../../node_modules/crypto-js/core.js","../../../node_modules/crypto-js/md5.js","../src/dataProvider/utils/buildBlankNodesQuery.js","../src/dataProvider/utils/buildSparqlQuery.js","../src/dataProvider/utils/getBlankNodesFromDataServers.js","../src/dataProvider/utils/fetchSparqlEndpoints.js","../src/dataProvider/utils/findContainersWithPath.js","../src/dataProvider/methods/getList.js","../src/dataProvider/methods/getMany.js","../src/dataProvider/methods/getManyReference.js","../src/dataProvider/methods/update.js","../../../node_modules/jwt-decode/build/jwt-decode.esm.js","../src/dataProvider/utils/fetchUserConfig.js","../src/dataProvider/utils/fetchVoidEndpoints.js","../src/dataProvider/utils/getServerKeyFromUri.js","../src/hooks/useGetExternalLink.js","../src/hooks/useDataModel.js","../src/hooks/useDataServers.js","../src/dataProvider/utils/findCreateContainerWithTypes.js","../src/reification/FilterHandler.js","../src/reification/ReificationArrayInput.js","../src/reification/GroupedReferenceHandler.js","../src/dataProvider/dataProvider.js","../src/dataProvider/httpClient.js","../src/hooks/useContainers.js","../src/hooks/useCreateContainer.js","../src/hooks/useDataModels.js"],"sourcesContent":["(function (name, context, definition) {\n  if (typeof module !== 'undefined' && module.exports) module.exports = definition();\n  else if (typeof define === 'function' && define.amd) define(definition);\n  else context[name] = definition();\n})('urljoin', this, function () {\n\n  function normalize (strArray) {\n    var resultArray = [];\n    if (strArray.length === 0) { return ''; }\n\n    if (typeof strArray[0] !== 'string') {\n      throw new TypeError('Url must be a string. Received ' + strArray[0]);\n    }\n\n    // If the first part is a plain protocol, we combine it with the next part.\n    if (strArray[0].match(/^[^/:]+:\\/*$/) && strArray.length > 1) {\n      var first = strArray.shift();\n      strArray[0] = first + strArray[0];\n    }\n\n    // There must be two or three slashes in the file protocol, two slashes in anything else.\n    if (strArray[0].match(/^file:\\/\\/\\//)) {\n      strArray[0] = strArray[0].replace(/^([^/:]+):\\/*/, '$1:///');\n    } else {\n      strArray[0] = strArray[0].replace(/^([^/:]+):\\/*/, '$1://');\n    }\n\n    for (var i = 0; i < strArray.length; i++) {\n      var component = strArray[i];\n\n      if (typeof component !== 'string') {\n        throw new TypeError('Url must be a string. Received ' + component);\n      }\n\n      if (component === '') { continue; }\n\n      if (i > 0) {\n        // Removing the starting slashes for each component but the first.\n        component = component.replace(/^[\\/]+/, '');\n      }\n      if (i < strArray.length - 1) {\n        // Removing the ending slashes for each component but the last.\n        component = component.replace(/[\\/]+$/, '');\n      } else {\n        // For the last component we will combine multiple slashes to a single one.\n        component = component.replace(/[\\/]+$/, '/');\n      }\n\n      resultArray.push(component);\n\n    }\n\n    var str = resultArray.join('/');\n    // Each input component is now separated by a single slash except the possible first plain protocol part.\n\n    // remove trailing slash before parameters or hash\n    str = str.replace(/\\/(\\?|&|#[^!])/g, '$1');\n\n    // replace ? in parameters with &\n    var parts = str.split('?');\n    str = parts.shift() + (parts.length > 0 ? '?': '') + parts.join('&');\n\n    return str;\n  }\n\n  return function () {\n    var input;\n\n    if (typeof arguments[0] === 'object') {\n      input = arguments[0];\n    } else {\n      input = [].slice.call(arguments);\n    }\n\n    return normalize(input);\n  };\n\n});\n","import jsonld from 'jsonld';\n\nconst fetchResource = async (resourceUri, config) => {\n  const { httpClient, jsonContext } = config;\n\n  let { json: data } = await httpClient(resourceUri);\n\n  if (!data) throw new Error('Not a valid JSON: ' + resourceUri);\n\n  data.id = data.id || data['@id'];\n\n  // We compact only if the context is different between the frontend and the middleware\n  // TODO deep compare if the context is an object\n  if (data['@context'] !== jsonContext) {\n    data = await jsonld.compact(data, jsonContext);\n  }\n\n  return data;\n};\n\nexport default fetchResource;\n","import fetchResource from '../utils/fetchResource';\n\nconst getOneMethod = config => async (resourceId, params) => {\n  const { resources } = config;\n  const dataModel = resources[resourceId];\n\n  if (!dataModel) throw new Error(`Resource ${resourceId} is not mapped in resources file`);\n\n  const data = await fetchResource(params.id, config);\n\n  // Transform single value into array if forceArray is set\n  if (dataModel.list?.forceArray) {\n    for (const forceArrayItem of dataModel.list?.forceArray) {\n      if (data[forceArrayItem] && !Array.isArray(data[forceArrayItem])) {\n        data[forceArrayItem] = [data[forceArrayItem]];\n      }\n    }\n  }\n\n  // TODO activate defaultFetchPlan option\n  // if (dataModel.list?.defaultFetchPlan) {\n  //   for (const node of dataModel.list?.defaultFetchPlan) {\n  //     if (\n  //       data[node] &&\n  //       typeof data[node] === 'string' &&\n  //       data[node].startsWith('http')\n  //     ) {\n  //       try {\n  //         const dataToEmbed = await fetchResource(data[node], config);\n  //         delete dataToEmbed['@context'];\n  //         data[node] = dataToEmbed;\n  //       } catch (e) {\n  //         // Ignore errors (this may happen if user does not have rights to see the resource)\n  //       }\n  //     }\n  //   }\n  // }\n\n  return { data };\n};\n\nexport default getOneMethod;\n","import createSlug from 'speakingurl';\nimport urlJoin from 'url-join';\n\nexport const getSlugWithExtension = fileName => {\n  let fileExtension = '';\n  let splitFileName = fileName.split('.');\n  if (splitFileName.length > 1) {\n    fileExtension = splitFileName.pop();\n    fileName = splitFileName.join('.');\n  }\n  return createSlug(fileName, { lang: 'fr' }) + '.' + fileExtension;\n};\n\nexport const isFile = o => o && o.rawFile && o.rawFile instanceof File;\n\nconst getUploadsContainerUri = config => {\n  const serverKey = Object.keys(config.dataServers).find(key => config.dataServers[key].uploadsContainer);\n  if (serverKey) {\n    return urlJoin(config.dataServers[serverKey].baseUrl, config.dataServers[serverKey].uploadsContainer);\n  }\n};\n\nconst uploadFile = async (rawFile, config) => {\n  const uploadsContainerUri = getUploadsContainerUri(config);\n  if (!uploadsContainerUri) throw new Error(\"You must define an uploadsContainer in one of the server's configuration\");\n\n  const response = await config.httpClient(uploadsContainerUri, {\n    method: 'POST',\n    body: rawFile,\n    headers: new Headers({\n      // We must sluggify the file name, because we can't use non-ASCII characters in the header\n      // However we keep the extension apart (if it exists) so that it is not replaced with a -\n      // TODO let the middleware guess the extension based on the content type\n      Slug: getSlugWithExtension(rawFile.name),\n      'Content-Type': rawFile.type\n    })\n  });\n\n  if (response.status === 201) {\n    return response.headers.get('Location');\n  }\n};\n\n/*\n * Look for raw files in the record data.\n * If there are any, upload them and replace the file by its URL.\n */\nconst uploadAllFiles = async (record, config) => {\n  for (let property in record) {\n    if (record.hasOwnProperty(property)) {\n      if (Array.isArray(record[property])) {\n        for (let i = 0; i < record[property].length; i++) {\n          if (isFile(record[property][i])) {\n            record[property][i] = await uploadFile(record[property][i].rawFile, config);\n          }\n        }\n      } else {\n        if (isFile(record[property])) {\n          record[property] = await uploadFile(record[property].rawFile, config);\n        }\n      }\n    }\n  }\n  return record;\n};\n\nexport default uploadAllFiles;\n","const getServerKeyFromType = (type, dataServers) => {\n  return Object.keys(dataServers).find(key => {\n    return dataServers[key][type];\n  });\n};\n\nexport default getServerKeyFromType;\n","import getServerKeyFromType from './getServerKeyFromType';\n\nconst parseServerKey = (serverKey, dataServers) => {\n  switch (serverKey) {\n    case '@default':\n      return getServerKeyFromType('default', dataServers);\n    case '@pod':\n      return getServerKeyFromType('pod', dataServers);\n    case '@authServer':\n      return getServerKeyFromType('authServer', dataServers);\n    default:\n      return serverKey;\n  }\n};\n\n// Return the list of servers keys in an array\n// parsing keywords like @all, @default, @pod and @authServer\nconst parseServerKeys = (serverKeys, dataServers) => {\n  if (Array.isArray(serverKeys)) {\n    if (serverKeys.includes('@all')) {\n      return Object.keys(dataServers);\n    } else {\n      return serverKeys.map(serverKey => parseServerKey(serverKey, dataServers));\n    }\n  } else if (typeof serverKeys === 'string') {\n    if (serverKeys === '@all') {\n      return Object.keys(dataServers);\n    } else if (serverKeys === '@remote') {\n      const defaultServerKey = getServerKeyFromType('default', dataServers);\n      return Object.keys(dataServers).filter(serverKey => serverKey !== defaultServerKey);\n    } else {\n      return [parseServerKey(serverKeys, dataServers)];\n    }\n  } else {\n    // If server key is empty\n    return false;\n  }\n};\n\nexport default parseServerKeys;\n","import urlJoin from 'url-join';\nimport parseServerKeys from './parseServerKeys';\n\nconst findContainersWithTypes = (types, serverKeys, dataServers) => {\n  let containers = {};\n  let existingContainers = [];\n\n  serverKeys = parseServerKeys(serverKeys, dataServers);\n\n  Object.keys(dataServers).forEach(key1 => {\n    Object.keys(dataServers[key1].containers).forEach(key2 => {\n      if (!serverKeys || serverKeys.includes(key2)) {\n        Object.keys(dataServers[key1].containers[key2]).forEach(type => {\n          if (types.includes(type)) {\n            dataServers[key1].containers[key2][type].map(path => {\n              const containerUri = urlJoin(dataServers[key2].baseUrl, path);\n\n              // Avoid returning the same container several times\n              if (!existingContainers.includes(containerUri)) {\n                existingContainers.push(containerUri);\n\n                if (!containers[key1]) containers[key1] = [];\n                containers[key1].push(containerUri);\n              }\n            });\n          }\n        });\n      }\n    });\n  });\n  return containers;\n};\n\nexport default findContainersWithTypes;\n","import urlJoin from 'url-join';\nimport getOne from './getOne';\nimport uploadAllFiles from '../utils/uploadAllFiles';\nimport findContainersWithTypes from '../utils/findContainersWithTypes';\n\nconst createMethod = config => async (resourceId, params) => {\n  const { dataServers, resources, httpClient, jsonContext } = config;\n  const dataModel = resources[resourceId];\n\n  if (!dataModel) Error(`Resource ${resourceId} is not mapped in resources file`);\n\n  const headers = new Headers();\n\n  let containerUri, serverKey;\n  if (dataModel.create?.container) {\n    serverKey = Object.keys(dataModel.create.container)[0];\n    containerUri = urlJoin(dataServers[serverKey].baseUrl, Object.values(dataModel.create.container)[0]);\n  } else {\n    serverKey = dataModel.create?.server || Object.keys(dataServers).find(key => dataServers[key].default === true);\n    if (!serverKey) throw new Error('You must define a server for the creation, or a container, or a default server');\n\n    const containers = findContainersWithTypes(dataModel.types, [serverKey], dataServers);\n    // Extract the containerUri from the results (and ensure there is only one)\n    const serverKeys = Object.keys(containers);\n\n    if (!serverKeys || serverKeys.length === 0)\n      throw new Error(`No container with types ${JSON.stringify(dataModel.types)} found on server ${serverKey}`);\n    if (serverKeys.length > 1 || containers[serverKeys[0]].length > 1)\n      throw new Error(\n        `More than one container detected with types ${JSON.stringify(dataModel.types)} on server ${serverKey}`\n      );\n    containerUri = containers[serverKeys[0]][0];\n  }\n\n  if (params.data) {\n    if (dataModel.fieldsMapping?.title) {\n      if (Array.isArray(dataModel.fieldsMapping.title)) {\n        headers.set('Slug', dataModel.fieldsMapping.title.map(f => params.data[f]).join(' '));\n      } else {\n        headers.set('Slug', params.data[dataModel.fieldsMapping.title]);\n      }\n    }\n\n    // Upload files, if there are any\n    params.data = await uploadAllFiles(params.data, config);\n\n    const { headers: responseHeaders } = await httpClient(containerUri, {\n      method: 'POST',\n      headers,\n      body: JSON.stringify({\n        '@context': jsonContext,\n        '@type': dataModel.types,\n        ...params.data\n      })\n    });\n\n    // Retrieve newly-created resource\n    const resourceUri = responseHeaders.get('Location');\n    return await getOne(config)(resourceId, { id: resourceUri });\n  } else if (params.id) {\n    headers.set('Content-Type', 'application/sparql-update');\n\n    await httpClient(containerUri, {\n      method: 'PATCH',\n      headers,\n      body: `\n        PREFIX ldp: <http://www.w3.org/ns/ldp#>\n        INSERT DATA { <${containerUri}> ldp:contains <${params.id}>. };\n      `\n    });\n\n    // Create must return the new data, so get them from the remote URI\n    return await getOne(config)(resourceId, { id: params.id });\n  }\n};\n\nexport default createMethod;\n","const deleteMethod = config => async (resourceId, params) => {\n  const { httpClient } = config;\n\n  await httpClient(params.id, {\n    method: 'DELETE'\n  });\n\n  return { data: { id: params.id } };\n};\n\nexport default deleteMethod;\n","const deleteManyMethod = config => async (resourceId, params) => {\n  const { httpClient } = config;\n  let ids = [];\n\n  for (let id of params.ids) {\n    try {\n      await httpClient(id, {\n        method: 'DELETE'\n      });\n      ids.push(id);\n    } catch (e) {\n      // Do nothing if we fail to delete a resource\n    }\n  }\n\n  return { data: ids };\n};\n\nexport default deleteManyMethod;\n","const getDataServers = config => () => {\n  return config.dataServers;\n};\n\nexport default getDataServers;\n","const getDataModels = config => () => {\n  return config.resources;\n};\n\nexport default getDataModels;\n","import jsonld from 'jsonld';\nimport isobject from 'isobject';\n\nexport const isType = (type, resource) => {\n  const resourceType = resource.type || resource['@type'];\n  return Array.isArray(resourceType) ? resourceType.includes(type) : resourceType === type;\n};\n\nconst fetchContainers = async (containers, resourceId, params, config) => {\n  const { httpClient, jsonContext } = config;\n\n  // Transform in an containerUri:serverKey object\n  const containersServers = Object.keys(containers).reduce(\n    (acc, serverKey) => ({\n      ...acc,\n      ...Object.fromEntries(containers[serverKey].map(containerUri => [containerUri, serverKey]))\n    }),\n    {}\n  );\n\n  const fetchPromises = Object.keys(containersServers).map(containerUri =>\n    httpClient(containerUri)\n      .then(({ json }) => {\n        // If container's context is different, compact it to have an uniform result\n        // TODO deep compare if the context is an object\n        if (json['@context'] !== jsonContext) {\n          return jsonld.compact(json, jsonContext);\n        } else {\n          return json;\n        }\n      })\n      .then(json => {\n        if (isType('ldp:Container', json)) {\n          return json['ldp:contains'];\n        } else {\n          throw new Error(containerUri + ' is not a LDP container');\n        }\n      })\n  );\n\n  // Fetch simultaneously all containers\n  let results = await Promise.all(fetchPromises);\n\n  if (results.length === 0) {\n    return { data: [], total: 0 };\n  } else {\n    // Merge all results in one array\n    results = [].concat.apply(...results);\n\n    let returnData = results.map(item => {\n      item.id = item.id || item['@id'];\n      return item;\n    });\n\n    // Apply filter to results\n    if (params.filter) {\n      // For SPARQL queries, we use \"a\" to filter types, but in containers it must be \"type\"\n      if (params.filter.a) {\n        params.filter.type = params.filter.a;\n        delete params.filter.a;\n      }\n\n      if (Object.keys(params.filter).length > 0) {\n        returnData = returnData.filter(resource => {\n          return Object.entries(params.filter).some(([k, v]) => {\n            if (k == 'q') {\n              // if fiter is q, all properties have to be checked\n              return Object.entries(resource).some(([kr, vr]) => {\n                if (!isobject(vr)) {\n                  return Array.isArray(vr) ? vr.some(va => va.includes(v)) : vr.includes(v);\n                } else {\n                  return false;\n                }\n              });\n            } else {\n              return Array.isArray(resource[k]) ? resource[k].includes(v) : resource[k].includes(v);\n            }\n          });\n        });\n      }\n    }\n\n    if (params.sort) {\n      returnData = returnData.sort((a, b) => {\n        if (a[params.sort.field] && b[params.sort.field]) {\n          if (params.sort.order === 'ASC') {\n            return a[params.sort.field].localeCompare(b[params.sort.field]);\n          } else {\n            return b[params.sort.field].localeCompare(a[params.sort.field]);\n          }\n        } else {\n          return true;\n        }\n      });\n    }\n    if (params.pagination) {\n      returnData = returnData.slice(\n        (params.pagination.page - 1) * params.pagination.perPage,\n        params.pagination.page * params.pagination.perPage\n      );\n    }\n\n    return { data: returnData, total: results.length };\n  }\n};\n\nexport default fetchContainers;\n","/*!\n * isobject <https://github.com/jonschlinkert/isobject>\n *\n * Copyright (c) 2014-2017, Jon Schlinkert.\n * Released under the MIT License.\n */\n\nexport default function isObject(val) {\n  return val != null && typeof val === 'object' && Array.isArray(val) === false;\n};\n","const getEmbedFrame = blankNodes => {\n  let embedFrame = {},\n    predicates;\n  if (blankNodes) {\n    for (let blankNode of blankNodes) {\n      if (blankNode.includes('/')) {\n        predicates = blankNode.split('/').reverse();\n      } else {\n        predicates = [blankNode];\n      }\n      embedFrame = {\n        ...embedFrame,\n        ...predicates.reduce(\n          (accumulator, predicate) => ({\n            [predicate]: {\n              '@embed': '@last',\n              ...accumulator\n            }\n          }),\n          {}\n        )\n      };\n    }\n    return embedFrame;\n  }\n};\n\nexport default getEmbedFrame;\n","const resolvePrefix = (item, ontologies) => {\n  if (item.startsWith('http://') || item.startsWith('https://')) {\n    // Already resolved, return the URI\n    return item;\n  } else if (item === 'a') {\n    // Special case\n    return 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type';\n  } else {\n    const [prefix, value] = item.split(':');\n    if (value) {\n      const ontology = ontologies.find(ontology => ontology.prefix === prefix);\n      if (ontology) {\n        return ontology.url + value;\n      } else {\n        throw new Error('No ontology found with prefix ' + prefix);\n      }\n    } else {\n      throw new Error(`The value \"${item}\" is not correct. It must include a prefix or be a full URI.`);\n    }\n  }\n};\n\nexport default resolvePrefix;\n","import { namedNode, triple, variable } from '@rdfjs/data-model';\nimport resolvePrefix from './resolvePrefix';\n\nconst defaultToArray = value => (!value ? [] : Array.isArray(value) ? value : [value]);\n\n// We need to always include the type or React-Admin will not work properly\nconst typeQuery = triple(\n  variable('s1'),\n  namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'),\n  variable('type')\n);\n\nconst buildBaseQuery = (predicates, ontologies) => {\n  let baseTriples;\n  if (predicates) {\n    baseTriples = defaultToArray(predicates).map((predicate, i) =>\n      triple(variable('s1'), namedNode(resolvePrefix(predicate, ontologies)), variable('o' + (i + 1)))\n    );\n    return {\n      construct: [typeQuery, ...baseTriples],\n      where: [typeQuery, ...baseTriples.map(triple => ({ type: 'optional', patterns: [triple] }))]\n    };\n  } else {\n    baseTriples = [triple(variable('s1'), variable('p1'), variable('o1'))];\n    return {\n      construct: baseTriples,\n      where: baseTriples\n    };\n  }\n};\n\nexport default buildBaseQuery;\n",";(function (root, factory) {\n\tif (typeof exports === \"object\") {\n\t\t// CommonJS\n\t\tmodule.exports = exports = factory();\n\t}\n\telse if (typeof define === \"function\" && define.amd) {\n\t\t// AMD\n\t\tdefine([], factory);\n\t}\n\telse {\n\t\t// Global (browser)\n\t\troot.CryptoJS = factory();\n\t}\n}(this, function () {\n\n\t/*globals window, global, require*/\n\n\t/**\n\t * CryptoJS core components.\n\t */\n\tvar CryptoJS = CryptoJS || (function (Math, undefined) {\n\n\t    var crypto;\n\n\t    // Native crypto from window (Browser)\n\t    if (typeof window !== 'undefined' && window.crypto) {\n\t        crypto = window.crypto;\n\t    }\n\n\t    // Native crypto in web worker (Browser)\n\t    if (typeof self !== 'undefined' && self.crypto) {\n\t        crypto = self.crypto;\n\t    }\n\n\t    // Native crypto from worker\n\t    if (typeof globalThis !== 'undefined' && globalThis.crypto) {\n\t        crypto = globalThis.crypto;\n\t    }\n\n\t    // Native (experimental IE 11) crypto from window (Browser)\n\t    if (!crypto && typeof window !== 'undefined' && window.msCrypto) {\n\t        crypto = window.msCrypto;\n\t    }\n\n\t    // Native crypto from global (NodeJS)\n\t    if (!crypto && typeof global !== 'undefined' && global.crypto) {\n\t        crypto = global.crypto;\n\t    }\n\n\t    // Native crypto import via require (NodeJS)\n\t    if (!crypto && typeof require === 'function') {\n\t        try {\n\t            crypto = require('crypto');\n\t        } catch (err) {}\n\t    }\n\n\t    /*\n\t     * Cryptographically secure pseudorandom number generator\n\t     *\n\t     * As Math.random() is cryptographically not safe to use\n\t     */\n\t    var cryptoSecureRandomInt = function () {\n\t        if (crypto) {\n\t            // Use getRandomValues method (Browser)\n\t            if (typeof crypto.getRandomValues === 'function') {\n\t                try {\n\t                    return crypto.getRandomValues(new Uint32Array(1))[0];\n\t                } catch (err) {}\n\t            }\n\n\t            // Use randomBytes method (NodeJS)\n\t            if (typeof crypto.randomBytes === 'function') {\n\t                try {\n\t                    return crypto.randomBytes(4).readInt32LE();\n\t                } catch (err) {}\n\t            }\n\t        }\n\n\t        throw new Error('Native crypto module could not be used to get secure random number.');\n\t    };\n\n\t    /*\n\t     * Local polyfill of Object.create\n\n\t     */\n\t    var create = Object.create || (function () {\n\t        function F() {}\n\n\t        return function (obj) {\n\t            var subtype;\n\n\t            F.prototype = obj;\n\n\t            subtype = new F();\n\n\t            F.prototype = null;\n\n\t            return subtype;\n\t        };\n\t    }());\n\n\t    /**\n\t     * CryptoJS namespace.\n\t     */\n\t    var C = {};\n\n\t    /**\n\t     * Library namespace.\n\t     */\n\t    var C_lib = C.lib = {};\n\n\t    /**\n\t     * Base object for prototypal inheritance.\n\t     */\n\t    var Base = C_lib.Base = (function () {\n\n\n\t        return {\n\t            /**\n\t             * Creates a new object that inherits from this object.\n\t             *\n\t             * @param {Object} overrides Properties to copy into the new object.\n\t             *\n\t             * @return {Object} The new object.\n\t             *\n\t             * @static\n\t             *\n\t             * @example\n\t             *\n\t             *     var MyType = CryptoJS.lib.Base.extend({\n\t             *         field: 'value',\n\t             *\n\t             *         method: function () {\n\t             *         }\n\t             *     });\n\t             */\n\t            extend: function (overrides) {\n\t                // Spawn\n\t                var subtype = create(this);\n\n\t                // Augment\n\t                if (overrides) {\n\t                    subtype.mixIn(overrides);\n\t                }\n\n\t                // Create default initializer\n\t                if (!subtype.hasOwnProperty('init') || this.init === subtype.init) {\n\t                    subtype.init = function () {\n\t                        subtype.$super.init.apply(this, arguments);\n\t                    };\n\t                }\n\n\t                // Initializer's prototype is the subtype object\n\t                subtype.init.prototype = subtype;\n\n\t                // Reference supertype\n\t                subtype.$super = this;\n\n\t                return subtype;\n\t            },\n\n\t            /**\n\t             * Extends this object and runs the init method.\n\t             * Arguments to create() will be passed to init().\n\t             *\n\t             * @return {Object} The new object.\n\t             *\n\t             * @static\n\t             *\n\t             * @example\n\t             *\n\t             *     var instance = MyType.create();\n\t             */\n\t            create: function () {\n\t                var instance = this.extend();\n\t                instance.init.apply(instance, arguments);\n\n\t                return instance;\n\t            },\n\n\t            /**\n\t             * Initializes a newly created object.\n\t             * Override this method to add some logic when your objects are created.\n\t             *\n\t             * @example\n\t             *\n\t             *     var MyType = CryptoJS.lib.Base.extend({\n\t             *         init: function () {\n\t             *             // ...\n\t             *         }\n\t             *     });\n\t             */\n\t            init: function () {\n\t            },\n\n\t            /**\n\t             * Copies properties into this object.\n\t             *\n\t             * @param {Object} properties The properties to mix in.\n\t             *\n\t             * @example\n\t             *\n\t             *     MyType.mixIn({\n\t             *         field: 'value'\n\t             *     });\n\t             */\n\t            mixIn: function (properties) {\n\t                for (var propertyName in properties) {\n\t                    if (properties.hasOwnProperty(propertyName)) {\n\t                        this[propertyName] = properties[propertyName];\n\t                    }\n\t                }\n\n\t                // IE won't copy toString using the loop above\n\t                if (properties.hasOwnProperty('toString')) {\n\t                    this.toString = properties.toString;\n\t                }\n\t            },\n\n\t            /**\n\t             * Creates a copy of this object.\n\t             *\n\t             * @return {Object} The clone.\n\t             *\n\t             * @example\n\t             *\n\t             *     var clone = instance.clone();\n\t             */\n\t            clone: function () {\n\t                return this.init.prototype.extend(this);\n\t            }\n\t        };\n\t    }());\n\n\t    /**\n\t     * An array of 32-bit words.\n\t     *\n\t     * @property {Array} words The array of 32-bit words.\n\t     * @property {number} sigBytes The number of significant bytes in this word array.\n\t     */\n\t    var WordArray = C_lib.WordArray = Base.extend({\n\t        /**\n\t         * Initializes a newly created word array.\n\t         *\n\t         * @param {Array} words (Optional) An array of 32-bit words.\n\t         * @param {number} sigBytes (Optional) The number of significant bytes in the words.\n\t         *\n\t         * @example\n\t         *\n\t         *     var wordArray = CryptoJS.lib.WordArray.create();\n\t         *     var wordArray = CryptoJS.lib.WordArray.create([0x00010203, 0x04050607]);\n\t         *     var wordArray = CryptoJS.lib.WordArray.create([0x00010203, 0x04050607], 6);\n\t         */\n\t        init: function (words, sigBytes) {\n\t            words = this.words = words || [];\n\n\t            if (sigBytes != undefined) {\n\t                this.sigBytes = sigBytes;\n\t            } else {\n\t                this.sigBytes = words.length * 4;\n\t            }\n\t        },\n\n\t        /**\n\t         * Converts this word array to a string.\n\t         *\n\t         * @param {Encoder} encoder (Optional) The encoding strategy to use. Default: CryptoJS.enc.Hex\n\t         *\n\t         * @return {string} The stringified word array.\n\t         *\n\t         * @example\n\t         *\n\t         *     var string = wordArray + '';\n\t         *     var string = wordArray.toString();\n\t         *     var string = wordArray.toString(CryptoJS.enc.Utf8);\n\t         */\n\t        toString: function (encoder) {\n\t            return (encoder || Hex).stringify(this);\n\t        },\n\n\t        /**\n\t         * Concatenates a word array to this word array.\n\t         *\n\t         * @param {WordArray} wordArray The word array to append.\n\t         *\n\t         * @return {WordArray} This word array.\n\t         *\n\t         * @example\n\t         *\n\t         *     wordArray1.concat(wordArray2);\n\t         */\n\t        concat: function (wordArray) {\n\t            // Shortcuts\n\t            var thisWords = this.words;\n\t            var thatWords = wordArray.words;\n\t            var thisSigBytes = this.sigBytes;\n\t            var thatSigBytes = wordArray.sigBytes;\n\n\t            // Clamp excess bits\n\t            this.clamp();\n\n\t            // Concat\n\t            if (thisSigBytes % 4) {\n\t                // Copy one byte at a time\n\t                for (var i = 0; i < thatSigBytes; i++) {\n\t                    var thatByte = (thatWords[i >>> 2] >>> (24 - (i % 4) * 8)) & 0xff;\n\t                    thisWords[(thisSigBytes + i) >>> 2] |= thatByte << (24 - ((thisSigBytes + i) % 4) * 8);\n\t                }\n\t            } else {\n\t                // Copy one word at a time\n\t                for (var j = 0; j < thatSigBytes; j += 4) {\n\t                    thisWords[(thisSigBytes + j) >>> 2] = thatWords[j >>> 2];\n\t                }\n\t            }\n\t            this.sigBytes += thatSigBytes;\n\n\t            // Chainable\n\t            return this;\n\t        },\n\n\t        /**\n\t         * Removes insignificant bits.\n\t         *\n\t         * @example\n\t         *\n\t         *     wordArray.clamp();\n\t         */\n\t        clamp: function () {\n\t            // Shortcuts\n\t            var words = this.words;\n\t            var sigBytes = this.sigBytes;\n\n\t            // Clamp\n\t            words[sigBytes >>> 2] &= 0xffffffff << (32 - (sigBytes % 4) * 8);\n\t            words.length = Math.ceil(sigBytes / 4);\n\t        },\n\n\t        /**\n\t         * Creates a copy of this word array.\n\t         *\n\t         * @return {WordArray} The clone.\n\t         *\n\t         * @example\n\t         *\n\t         *     var clone = wordArray.clone();\n\t         */\n\t        clone: function () {\n\t            var clone = Base.clone.call(this);\n\t            clone.words = this.words.slice(0);\n\n\t            return clone;\n\t        },\n\n\t        /**\n\t         * Creates a word array filled with random bytes.\n\t         *\n\t         * @param {number} nBytes The number of random bytes to generate.\n\t         *\n\t         * @return {WordArray} The random word array.\n\t         *\n\t         * @static\n\t         *\n\t         * @example\n\t         *\n\t         *     var wordArray = CryptoJS.lib.WordArray.random(16);\n\t         */\n\t        random: function (nBytes) {\n\t            var words = [];\n\n\t            for (var i = 0; i < nBytes; i += 4) {\n\t                words.push(cryptoSecureRandomInt());\n\t            }\n\n\t            return new WordArray.init(words, nBytes);\n\t        }\n\t    });\n\n\t    /**\n\t     * Encoder namespace.\n\t     */\n\t    var C_enc = C.enc = {};\n\n\t    /**\n\t     * Hex encoding strategy.\n\t     */\n\t    var Hex = C_enc.Hex = {\n\t        /**\n\t         * Converts a word array to a hex string.\n\t         *\n\t         * @param {WordArray} wordArray The word array.\n\t         *\n\t         * @return {string} The hex string.\n\t         *\n\t         * @static\n\t         *\n\t         * @example\n\t         *\n\t         *     var hexString = CryptoJS.enc.Hex.stringify(wordArray);\n\t         */\n\t        stringify: function (wordArray) {\n\t            // Shortcuts\n\t            var words = wordArray.words;\n\t            var sigBytes = wordArray.sigBytes;\n\n\t            // Convert\n\t            var hexChars = [];\n\t            for (var i = 0; i < sigBytes; i++) {\n\t                var bite = (words[i >>> 2] >>> (24 - (i % 4) * 8)) & 0xff;\n\t                hexChars.push((bite >>> 4).toString(16));\n\t                hexChars.push((bite & 0x0f).toString(16));\n\t            }\n\n\t            return hexChars.join('');\n\t        },\n\n\t        /**\n\t         * Converts a hex string to a word array.\n\t         *\n\t         * @param {string} hexStr The hex string.\n\t         *\n\t         * @return {WordArray} The word array.\n\t         *\n\t         * @static\n\t         *\n\t         * @example\n\t         *\n\t         *     var wordArray = CryptoJS.enc.Hex.parse(hexString);\n\t         */\n\t        parse: function (hexStr) {\n\t            // Shortcut\n\t            var hexStrLength = hexStr.length;\n\n\t            // Convert\n\t            var words = [];\n\t            for (var i = 0; i < hexStrLength; i += 2) {\n\t                words[i >>> 3] |= parseInt(hexStr.substr(i, 2), 16) << (24 - (i % 8) * 4);\n\t            }\n\n\t            return new WordArray.init(words, hexStrLength / 2);\n\t        }\n\t    };\n\n\t    /**\n\t     * Latin1 encoding strategy.\n\t     */\n\t    var Latin1 = C_enc.Latin1 = {\n\t        /**\n\t         * Converts a word array to a Latin1 string.\n\t         *\n\t         * @param {WordArray} wordArray The word array.\n\t         *\n\t         * @return {string} The Latin1 string.\n\t         *\n\t         * @static\n\t         *\n\t         * @example\n\t         *\n\t         *     var latin1String = CryptoJS.enc.Latin1.stringify(wordArray);\n\t         */\n\t        stringify: function (wordArray) {\n\t            // Shortcuts\n\t            var words = wordArray.words;\n\t            var sigBytes = wordArray.sigBytes;\n\n\t            // Convert\n\t            var latin1Chars = [];\n\t            for (var i = 0; i < sigBytes; i++) {\n\t                var bite = (words[i >>> 2] >>> (24 - (i % 4) * 8)) & 0xff;\n\t                latin1Chars.push(String.fromCharCode(bite));\n\t            }\n\n\t            return latin1Chars.join('');\n\t        },\n\n\t        /**\n\t         * Converts a Latin1 string to a word array.\n\t         *\n\t         * @param {string} latin1Str The Latin1 string.\n\t         *\n\t         * @return {WordArray} The word array.\n\t         *\n\t         * @static\n\t         *\n\t         * @example\n\t         *\n\t         *     var wordArray = CryptoJS.enc.Latin1.parse(latin1String);\n\t         */\n\t        parse: function (latin1Str) {\n\t            // Shortcut\n\t            var latin1StrLength = latin1Str.length;\n\n\t            // Convert\n\t            var words = [];\n\t            for (var i = 0; i < latin1StrLength; i++) {\n\t                words[i >>> 2] |= (latin1Str.charCodeAt(i) & 0xff) << (24 - (i % 4) * 8);\n\t            }\n\n\t            return new WordArray.init(words, latin1StrLength);\n\t        }\n\t    };\n\n\t    /**\n\t     * UTF-8 encoding strategy.\n\t     */\n\t    var Utf8 = C_enc.Utf8 = {\n\t        /**\n\t         * Converts a word array to a UTF-8 string.\n\t         *\n\t         * @param {WordArray} wordArray The word array.\n\t         *\n\t         * @return {string} The UTF-8 string.\n\t         *\n\t         * @static\n\t         *\n\t         * @example\n\t         *\n\t         *     var utf8String = CryptoJS.enc.Utf8.stringify(wordArray);\n\t         */\n\t        stringify: function (wordArray) {\n\t            try {\n\t                return decodeURIComponent(escape(Latin1.stringify(wordArray)));\n\t            } catch (e) {\n\t                throw new Error('Malformed UTF-8 data');\n\t            }\n\t        },\n\n\t        /**\n\t         * Converts a UTF-8 string to a word array.\n\t         *\n\t         * @param {string} utf8Str The UTF-8 string.\n\t         *\n\t         * @return {WordArray} The word array.\n\t         *\n\t         * @static\n\t         *\n\t         * @example\n\t         *\n\t         *     var wordArray = CryptoJS.enc.Utf8.parse(utf8String);\n\t         */\n\t        parse: function (utf8Str) {\n\t            return Latin1.parse(unescape(encodeURIComponent(utf8Str)));\n\t        }\n\t    };\n\n\t    /**\n\t     * Abstract buffered block algorithm template.\n\t     *\n\t     * The property blockSize must be implemented in a concrete subtype.\n\t     *\n\t     * @property {number} _minBufferSize The number of blocks that should be kept unprocessed in the buffer. Default: 0\n\t     */\n\t    var BufferedBlockAlgorithm = C_lib.BufferedBlockAlgorithm = Base.extend({\n\t        /**\n\t         * Resets this block algorithm's data buffer to its initial state.\n\t         *\n\t         * @example\n\t         *\n\t         *     bufferedBlockAlgorithm.reset();\n\t         */\n\t        reset: function () {\n\t            // Initial values\n\t            this._data = new WordArray.init();\n\t            this._nDataBytes = 0;\n\t        },\n\n\t        /**\n\t         * Adds new data to this block algorithm's buffer.\n\t         *\n\t         * @param {WordArray|string} data The data to append. Strings are converted to a WordArray using UTF-8.\n\t         *\n\t         * @example\n\t         *\n\t         *     bufferedBlockAlgorithm._append('data');\n\t         *     bufferedBlockAlgorithm._append(wordArray);\n\t         */\n\t        _append: function (data) {\n\t            // Convert string to WordArray, else assume WordArray already\n\t            if (typeof data == 'string') {\n\t                data = Utf8.parse(data);\n\t            }\n\n\t            // Append\n\t            this._data.concat(data);\n\t            this._nDataBytes += data.sigBytes;\n\t        },\n\n\t        /**\n\t         * Processes available data blocks.\n\t         *\n\t         * This method invokes _doProcessBlock(offset), which must be implemented by a concrete subtype.\n\t         *\n\t         * @param {boolean} doFlush Whether all blocks and partial blocks should be processed.\n\t         *\n\t         * @return {WordArray} The processed data.\n\t         *\n\t         * @example\n\t         *\n\t         *     var processedData = bufferedBlockAlgorithm._process();\n\t         *     var processedData = bufferedBlockAlgorithm._process(!!'flush');\n\t         */\n\t        _process: function (doFlush) {\n\t            var processedWords;\n\n\t            // Shortcuts\n\t            var data = this._data;\n\t            var dataWords = data.words;\n\t            var dataSigBytes = data.sigBytes;\n\t            var blockSize = this.blockSize;\n\t            var blockSizeBytes = blockSize * 4;\n\n\t            // Count blocks ready\n\t            var nBlocksReady = dataSigBytes / blockSizeBytes;\n\t            if (doFlush) {\n\t                // Round up to include partial blocks\n\t                nBlocksReady = Math.ceil(nBlocksReady);\n\t            } else {\n\t                // Round down to include only full blocks,\n\t                // less the number of blocks that must remain in the buffer\n\t                nBlocksReady = Math.max((nBlocksReady | 0) - this._minBufferSize, 0);\n\t            }\n\n\t            // Count words ready\n\t            var nWordsReady = nBlocksReady * blockSize;\n\n\t            // Count bytes ready\n\t            var nBytesReady = Math.min(nWordsReady * 4, dataSigBytes);\n\n\t            // Process blocks\n\t            if (nWordsReady) {\n\t                for (var offset = 0; offset < nWordsReady; offset += blockSize) {\n\t                    // Perform concrete-algorithm logic\n\t                    this._doProcessBlock(dataWords, offset);\n\t                }\n\n\t                // Remove processed words\n\t                processedWords = dataWords.splice(0, nWordsReady);\n\t                data.sigBytes -= nBytesReady;\n\t            }\n\n\t            // Return processed words\n\t            return new WordArray.init(processedWords, nBytesReady);\n\t        },\n\n\t        /**\n\t         * Creates a copy of this object.\n\t         *\n\t         * @return {Object} The clone.\n\t         *\n\t         * @example\n\t         *\n\t         *     var clone = bufferedBlockAlgorithm.clone();\n\t         */\n\t        clone: function () {\n\t            var clone = Base.clone.call(this);\n\t            clone._data = this._data.clone();\n\n\t            return clone;\n\t        },\n\n\t        _minBufferSize: 0\n\t    });\n\n\t    /**\n\t     * Abstract hasher template.\n\t     *\n\t     * @property {number} blockSize The number of 32-bit words this hasher operates on. Default: 16 (512 bits)\n\t     */\n\t    var Hasher = C_lib.Hasher = BufferedBlockAlgorithm.extend({\n\t        /**\n\t         * Configuration options.\n\t         */\n\t        cfg: Base.extend(),\n\n\t        /**\n\t         * Initializes a newly created hasher.\n\t         *\n\t         * @param {Object} cfg (Optional) The configuration options to use for this hash computation.\n\t         *\n\t         * @example\n\t         *\n\t         *     var hasher = CryptoJS.algo.SHA256.create();\n\t         */\n\t        init: function (cfg) {\n\t            // Apply config defaults\n\t            this.cfg = this.cfg.extend(cfg);\n\n\t            // Set initial values\n\t            this.reset();\n\t        },\n\n\t        /**\n\t         * Resets this hasher to its initial state.\n\t         *\n\t         * @example\n\t         *\n\t         *     hasher.reset();\n\t         */\n\t        reset: function () {\n\t            // Reset data buffer\n\t            BufferedBlockAlgorithm.reset.call(this);\n\n\t            // Perform concrete-hasher logic\n\t            this._doReset();\n\t        },\n\n\t        /**\n\t         * Updates this hasher with a message.\n\t         *\n\t         * @param {WordArray|string} messageUpdate The message to append.\n\t         *\n\t         * @return {Hasher} This hasher.\n\t         *\n\t         * @example\n\t         *\n\t         *     hasher.update('message');\n\t         *     hasher.update(wordArray);\n\t         */\n\t        update: function (messageUpdate) {\n\t            // Append\n\t            this._append(messageUpdate);\n\n\t            // Update the hash\n\t            this._process();\n\n\t            // Chainable\n\t            return this;\n\t        },\n\n\t        /**\n\t         * Finalizes the hash computation.\n\t         * Note that the finalize operation is effectively a destructive, read-once operation.\n\t         *\n\t         * @param {WordArray|string} messageUpdate (Optional) A final message update.\n\t         *\n\t         * @return {WordArray} The hash.\n\t         *\n\t         * @example\n\t         *\n\t         *     var hash = hasher.finalize();\n\t         *     var hash = hasher.finalize('message');\n\t         *     var hash = hasher.finalize(wordArray);\n\t         */\n\t        finalize: function (messageUpdate) {\n\t            // Final message update\n\t            if (messageUpdate) {\n\t                this._append(messageUpdate);\n\t            }\n\n\t            // Perform concrete-hasher logic\n\t            var hash = this._doFinalize();\n\n\t            return hash;\n\t        },\n\n\t        blockSize: 512/32,\n\n\t        /**\n\t         * Creates a shortcut function to a hasher's object interface.\n\t         *\n\t         * @param {Hasher} hasher The hasher to create a helper for.\n\t         *\n\t         * @return {Function} The shortcut function.\n\t         *\n\t         * @static\n\t         *\n\t         * @example\n\t         *\n\t         *     var SHA256 = CryptoJS.lib.Hasher._createHelper(CryptoJS.algo.SHA256);\n\t         */\n\t        _createHelper: function (hasher) {\n\t            return function (message, cfg) {\n\t                return new hasher.init(cfg).finalize(message);\n\t            };\n\t        },\n\n\t        /**\n\t         * Creates a shortcut function to the HMAC's object interface.\n\t         *\n\t         * @param {Hasher} hasher The hasher to use in this HMAC helper.\n\t         *\n\t         * @return {Function} The shortcut function.\n\t         *\n\t         * @static\n\t         *\n\t         * @example\n\t         *\n\t         *     var HmacSHA256 = CryptoJS.lib.Hasher._createHmacHelper(CryptoJS.algo.SHA256);\n\t         */\n\t        _createHmacHelper: function (hasher) {\n\t            return function (message, key) {\n\t                return new C_algo.HMAC.init(hasher, key).finalize(message);\n\t            };\n\t        }\n\t    });\n\n\t    /**\n\t     * Algorithm namespace.\n\t     */\n\t    var C_algo = C.algo = {};\n\n\t    return C;\n\t}(Math));\n\n\n\treturn CryptoJS;\n\n}));",";(function (root, factory) {\n\tif (typeof exports === \"object\") {\n\t\t// CommonJS\n\t\tmodule.exports = exports = factory(require(\"./core\"));\n\t}\n\telse if (typeof define === \"function\" && define.amd) {\n\t\t// AMD\n\t\tdefine([\"./core\"], factory);\n\t}\n\telse {\n\t\t// Global (browser)\n\t\tfactory(root.CryptoJS);\n\t}\n}(this, function (CryptoJS) {\n\n\t(function (Math) {\n\t    // Shortcuts\n\t    var C = CryptoJS;\n\t    var C_lib = C.lib;\n\t    var WordArray = C_lib.WordArray;\n\t    var Hasher = C_lib.Hasher;\n\t    var C_algo = C.algo;\n\n\t    // Constants table\n\t    var T = [];\n\n\t    // Compute constants\n\t    (function () {\n\t        for (var i = 0; i < 64; i++) {\n\t            T[i] = (Math.abs(Math.sin(i + 1)) * 0x100000000) | 0;\n\t        }\n\t    }());\n\n\t    /**\n\t     * MD5 hash algorithm.\n\t     */\n\t    var MD5 = C_algo.MD5 = Hasher.extend({\n\t        _doReset: function () {\n\t            this._hash = new WordArray.init([\n\t                0x67452301, 0xefcdab89,\n\t                0x98badcfe, 0x10325476\n\t            ]);\n\t        },\n\n\t        _doProcessBlock: function (M, offset) {\n\t            // Swap endian\n\t            for (var i = 0; i < 16; i++) {\n\t                // Shortcuts\n\t                var offset_i = offset + i;\n\t                var M_offset_i = M[offset_i];\n\n\t                M[offset_i] = (\n\t                    (((M_offset_i << 8)  | (M_offset_i >>> 24)) & 0x00ff00ff) |\n\t                    (((M_offset_i << 24) | (M_offset_i >>> 8))  & 0xff00ff00)\n\t                );\n\t            }\n\n\t            // Shortcuts\n\t            var H = this._hash.words;\n\n\t            var M_offset_0  = M[offset + 0];\n\t            var M_offset_1  = M[offset + 1];\n\t            var M_offset_2  = M[offset + 2];\n\t            var M_offset_3  = M[offset + 3];\n\t            var M_offset_4  = M[offset + 4];\n\t            var M_offset_5  = M[offset + 5];\n\t            var M_offset_6  = M[offset + 6];\n\t            var M_offset_7  = M[offset + 7];\n\t            var M_offset_8  = M[offset + 8];\n\t            var M_offset_9  = M[offset + 9];\n\t            var M_offset_10 = M[offset + 10];\n\t            var M_offset_11 = M[offset + 11];\n\t            var M_offset_12 = M[offset + 12];\n\t            var M_offset_13 = M[offset + 13];\n\t            var M_offset_14 = M[offset + 14];\n\t            var M_offset_15 = M[offset + 15];\n\n\t            // Working varialbes\n\t            var a = H[0];\n\t            var b = H[1];\n\t            var c = H[2];\n\t            var d = H[3];\n\n\t            // Computation\n\t            a = FF(a, b, c, d, M_offset_0,  7,  T[0]);\n\t            d = FF(d, a, b, c, M_offset_1,  12, T[1]);\n\t            c = FF(c, d, a, b, M_offset_2,  17, T[2]);\n\t            b = FF(b, c, d, a, M_offset_3,  22, T[3]);\n\t            a = FF(a, b, c, d, M_offset_4,  7,  T[4]);\n\t            d = FF(d, a, b, c, M_offset_5,  12, T[5]);\n\t            c = FF(c, d, a, b, M_offset_6,  17, T[6]);\n\t            b = FF(b, c, d, a, M_offset_7,  22, T[7]);\n\t            a = FF(a, b, c, d, M_offset_8,  7,  T[8]);\n\t            d = FF(d, a, b, c, M_offset_9,  12, T[9]);\n\t            c = FF(c, d, a, b, M_offset_10, 17, T[10]);\n\t            b = FF(b, c, d, a, M_offset_11, 22, T[11]);\n\t            a = FF(a, b, c, d, M_offset_12, 7,  T[12]);\n\t            d = FF(d, a, b, c, M_offset_13, 12, T[13]);\n\t            c = FF(c, d, a, b, M_offset_14, 17, T[14]);\n\t            b = FF(b, c, d, a, M_offset_15, 22, T[15]);\n\n\t            a = GG(a, b, c, d, M_offset_1,  5,  T[16]);\n\t            d = GG(d, a, b, c, M_offset_6,  9,  T[17]);\n\t            c = GG(c, d, a, b, M_offset_11, 14, T[18]);\n\t            b = GG(b, c, d, a, M_offset_0,  20, T[19]);\n\t            a = GG(a, b, c, d, M_offset_5,  5,  T[20]);\n\t            d = GG(d, a, b, c, M_offset_10, 9,  T[21]);\n\t            c = GG(c, d, a, b, M_offset_15, 14, T[22]);\n\t            b = GG(b, c, d, a, M_offset_4,  20, T[23]);\n\t            a = GG(a, b, c, d, M_offset_9,  5,  T[24]);\n\t            d = GG(d, a, b, c, M_offset_14, 9,  T[25]);\n\t            c = GG(c, d, a, b, M_offset_3,  14, T[26]);\n\t            b = GG(b, c, d, a, M_offset_8,  20, T[27]);\n\t            a = GG(a, b, c, d, M_offset_13, 5,  T[28]);\n\t            d = GG(d, a, b, c, M_offset_2,  9,  T[29]);\n\t            c = GG(c, d, a, b, M_offset_7,  14, T[30]);\n\t            b = GG(b, c, d, a, M_offset_12, 20, T[31]);\n\n\t            a = HH(a, b, c, d, M_offset_5,  4,  T[32]);\n\t            d = HH(d, a, b, c, M_offset_8,  11, T[33]);\n\t            c = HH(c, d, a, b, M_offset_11, 16, T[34]);\n\t            b = HH(b, c, d, a, M_offset_14, 23, T[35]);\n\t            a = HH(a, b, c, d, M_offset_1,  4,  T[36]);\n\t            d = HH(d, a, b, c, M_offset_4,  11, T[37]);\n\t            c = HH(c, d, a, b, M_offset_7,  16, T[38]);\n\t            b = HH(b, c, d, a, M_offset_10, 23, T[39]);\n\t            a = HH(a, b, c, d, M_offset_13, 4,  T[40]);\n\t            d = HH(d, a, b, c, M_offset_0,  11, T[41]);\n\t            c = HH(c, d, a, b, M_offset_3,  16, T[42]);\n\t            b = HH(b, c, d, a, M_offset_6,  23, T[43]);\n\t            a = HH(a, b, c, d, M_offset_9,  4,  T[44]);\n\t            d = HH(d, a, b, c, M_offset_12, 11, T[45]);\n\t            c = HH(c, d, a, b, M_offset_15, 16, T[46]);\n\t            b = HH(b, c, d, a, M_offset_2,  23, T[47]);\n\n\t            a = II(a, b, c, d, M_offset_0,  6,  T[48]);\n\t            d = II(d, a, b, c, M_offset_7,  10, T[49]);\n\t            c = II(c, d, a, b, M_offset_14, 15, T[50]);\n\t            b = II(b, c, d, a, M_offset_5,  21, T[51]);\n\t            a = II(a, b, c, d, M_offset_12, 6,  T[52]);\n\t            d = II(d, a, b, c, M_offset_3,  10, T[53]);\n\t            c = II(c, d, a, b, M_offset_10, 15, T[54]);\n\t            b = II(b, c, d, a, M_offset_1,  21, T[55]);\n\t            a = II(a, b, c, d, M_offset_8,  6,  T[56]);\n\t            d = II(d, a, b, c, M_offset_15, 10, T[57]);\n\t            c = II(c, d, a, b, M_offset_6,  15, T[58]);\n\t            b = II(b, c, d, a, M_offset_13, 21, T[59]);\n\t            a = II(a, b, c, d, M_offset_4,  6,  T[60]);\n\t            d = II(d, a, b, c, M_offset_11, 10, T[61]);\n\t            c = II(c, d, a, b, M_offset_2,  15, T[62]);\n\t            b = II(b, c, d, a, M_offset_9,  21, T[63]);\n\n\t            // Intermediate hash value\n\t            H[0] = (H[0] + a) | 0;\n\t            H[1] = (H[1] + b) | 0;\n\t            H[2] = (H[2] + c) | 0;\n\t            H[3] = (H[3] + d) | 0;\n\t        },\n\n\t        _doFinalize: function () {\n\t            // Shortcuts\n\t            var data = this._data;\n\t            var dataWords = data.words;\n\n\t            var nBitsTotal = this._nDataBytes * 8;\n\t            var nBitsLeft = data.sigBytes * 8;\n\n\t            // Add padding\n\t            dataWords[nBitsLeft >>> 5] |= 0x80 << (24 - nBitsLeft % 32);\n\n\t            var nBitsTotalH = Math.floor(nBitsTotal / 0x100000000);\n\t            var nBitsTotalL = nBitsTotal;\n\t            dataWords[(((nBitsLeft + 64) >>> 9) << 4) + 15] = (\n\t                (((nBitsTotalH << 8)  | (nBitsTotalH >>> 24)) & 0x00ff00ff) |\n\t                (((nBitsTotalH << 24) | (nBitsTotalH >>> 8))  & 0xff00ff00)\n\t            );\n\t            dataWords[(((nBitsLeft + 64) >>> 9) << 4) + 14] = (\n\t                (((nBitsTotalL << 8)  | (nBitsTotalL >>> 24)) & 0x00ff00ff) |\n\t                (((nBitsTotalL << 24) | (nBitsTotalL >>> 8))  & 0xff00ff00)\n\t            );\n\n\t            data.sigBytes = (dataWords.length + 1) * 4;\n\n\t            // Hash final blocks\n\t            this._process();\n\n\t            // Shortcuts\n\t            var hash = this._hash;\n\t            var H = hash.words;\n\n\t            // Swap endian\n\t            for (var i = 0; i < 4; i++) {\n\t                // Shortcut\n\t                var H_i = H[i];\n\n\t                H[i] = (((H_i << 8)  | (H_i >>> 24)) & 0x00ff00ff) |\n\t                       (((H_i << 24) | (H_i >>> 8))  & 0xff00ff00);\n\t            }\n\n\t            // Return final computed hash\n\t            return hash;\n\t        },\n\n\t        clone: function () {\n\t            var clone = Hasher.clone.call(this);\n\t            clone._hash = this._hash.clone();\n\n\t            return clone;\n\t        }\n\t    });\n\n\t    function FF(a, b, c, d, x, s, t) {\n\t        var n = a + ((b & c) | (~b & d)) + x + t;\n\t        return ((n << s) | (n >>> (32 - s))) + b;\n\t    }\n\n\t    function GG(a, b, c, d, x, s, t) {\n\t        var n = a + ((b & d) | (c & ~d)) + x + t;\n\t        return ((n << s) | (n >>> (32 - s))) + b;\n\t    }\n\n\t    function HH(a, b, c, d, x, s, t) {\n\t        var n = a + (b ^ c ^ d) + x + t;\n\t        return ((n << s) | (n >>> (32 - s))) + b;\n\t    }\n\n\t    function II(a, b, c, d, x, s, t) {\n\t        var n = a + (c ^ (b | ~d)) + x + t;\n\t        return ((n << s) | (n >>> (32 - s))) + b;\n\t    }\n\n\t    /**\n\t     * Shortcut function to the hasher's object interface.\n\t     *\n\t     * @param {WordArray|string} message The message to hash.\n\t     *\n\t     * @return {WordArray} The hash.\n\t     *\n\t     * @static\n\t     *\n\t     * @example\n\t     *\n\t     *     var hash = CryptoJS.MD5('message');\n\t     *     var hash = CryptoJS.MD5(wordArray);\n\t     */\n\t    C.MD5 = Hasher._createHelper(MD5);\n\n\t    /**\n\t     * Shortcut function to the HMAC's object interface.\n\t     *\n\t     * @param {WordArray|string} message The message to hash.\n\t     * @param {WordArray|string} key The secret key.\n\t     *\n\t     * @return {WordArray} The HMAC.\n\t     *\n\t     * @static\n\t     *\n\t     * @example\n\t     *\n\t     *     var hmac = CryptoJS.HmacMD5(message, key);\n\t     */\n\t    C.HmacMD5 = Hasher._createHmacHelper(MD5);\n\t}(Math));\n\n\n\treturn CryptoJS.MD5;\n\n}));","import md5 from 'crypto-js/md5';\nimport { namedNode, triple, variable } from '@rdfjs/data-model';\nimport resolvePrefix from './resolvePrefix';\n\n// Transform ['ont:predicate1/ont:predicate2'] to ['ont:predicate1', 'ont:predicate1/ont:predicate2']\nconst extractNodes = blankNodes => {\n  let nodes = [];\n  if (blankNodes) {\n    for (let predicate of blankNodes) {\n      if (predicate.includes('/')) {\n        const nodeNames = predicate.split('/');\n        for (let i = 1; i <= nodeNames.length; i++) {\n          nodes.push(nodeNames.slice(0, i).join('/'));\n        }\n      } else {\n        nodes.push(predicate);\n      }\n    }\n  }\n  return nodes;\n};\n\nconst generateSparqlVarName = node => md5(node);\n\nconst getParentNode = node => node.includes('/') && node.split('/')[0];\n\nconst getPredicate = node => (node.includes('/') ? node.split('/')[1] : node);\n\nconst buildUnionQuery = queries =>\n  queries.map(q => {\n    let triples = q.query;\n    const firstTriple = queries.find(q2 => q.parentNode === q2.node);\n    if (firstTriple !== undefined) {\n      triples = triples.concat(firstTriple.query[0]);\n    }\n    return {\n      type: 'bgp',\n      triples\n    };\n  });\n\nconst buildBlankNodesQuery = (blankNodes, baseQuery, ontologies) => {\n  let queries = [];\n  const nodes = extractNodes(blankNodes);\n\n  if (nodes && ontologies && ontologies.length > 0) {\n    for (let node of nodes) {\n      const parentNode = getParentNode(node);\n      const predicate = getPredicate(node);\n      const varName = generateSparqlVarName(node);\n      const parentVarName = parentNode ? generateSparqlVarName(parentNode) : '1';\n\n      const query = [\n        triple(variable('s' + parentVarName), namedNode(resolvePrefix(predicate, ontologies)), variable('s' + varName)),\n        triple(variable('s' + varName), variable('p' + varName), variable('o' + varName))\n      ];\n\n      queries.push({\n        node,\n        parentNode,\n        query,\n        filter: '' // `FILTER(isBLANK(?s${varName})) .`\n      });\n    }\n\n    return {\n      construct: queries.length > 0 ? queries.map(q => q.query).reduce((pre, cur) => pre.concat(cur)) : null,\n      where: {\n        type: 'union',\n        patterns: [baseQuery.where, ...buildUnionQuery(queries)]\n      }\n    };\n  } else {\n    return {\n      construct: '',\n      where: ''\n    };\n  }\n};\n\nexport default buildBlankNodesQuery;\n","import DataFactory from '@rdfjs/data-model';\nimport buildBaseQuery from './buildBaseQuery';\nimport buildBlankNodesQuery from './buildBlankNodesQuery';\nimport resolvePrefix from './resolvePrefix';\nconst { literal, namedNode, triple, variable } = DataFactory;\n\nconst SparqlGenerator = require('sparqljs').Generator;\nconst generator = new SparqlGenerator({\n  /* prefixes, baseIRI, factory, sparqlStar */\n});\n\nconst reservedFilterKeys = ['q', 'sparqlWhere', 'blankNodes', '_servers', '_predicates'];\n\nconst buildSparqlQuery = ({ containers, params: { filter }, blankNodes, predicates, ontologies }) => {\n  const baseQuery = buildBaseQuery(predicates, ontologies);\n\n  let sparqlJsParams = {\n    queryType: 'CONSTRUCT',\n    template: baseQuery.construct,\n    where: [],\n    type: 'query',\n    prefixes: Object.fromEntries(ontologies.map(ontology => [ontology.prefix, ontology.url]))\n  };\n\n  let containerWhere = [\n    {\n      type: 'values',\n      values: containers.map(containerUri => ({ '?containerUri': namedNode(containerUri) }))\n    },\n    triple(variable('containerUri'), namedNode('http://www.w3.org/ns/ldp#contains'), variable('s1')),\n    {\n      type: 'filter',\n      expression: {\n        type: 'operation',\n        operator: 'isiri',\n        args: [variable('s1')]\n      }\n    }\n  ];\n\n  let resourceWhere = [];\n\n  if (filter && Object.keys(filter).length > 0) {\n    const hasSPARQLFilter = filter.sparqlWhere && Object.keys(filter.sparqlWhere).length > 0;\n    const hasFullTextSearch = filter.q && filter.q.length > 0;\n\n    if (hasSPARQLFilter) {\n      /* \n        Example of usage :\n        {\n          \"sparqlWhere\": {\n            \"type\": \"bgp\",\n            \"triples\": [{\n              \"subject\": {\"termType\": \"Variable\", \"value\": \"s1\"},\n              \"predicate\": {\"termType\": \"NameNode\", \"value\": \"http://virtual-assembly.org/ontologies/pair#label\"},\n              \"object\": {\"termType\": \"Literal\", \"value\": \"My Organization\"}\n            }]\n          }\n        }\n      */\n      // initialize array in case of single value :\n      [].concat(filter.sparqlWhere).forEach(sw => {\n        resourceWhere.push(sw);\n      });\n    }\n\n    if (hasFullTextSearch) {\n      resourceWhere.push({\n        type: 'group',\n        patterns: [\n          {\n            queryType: 'SELECT',\n            variables: [variable('s1')],\n            where: [\n              triple(variable('s1'), variable('p1'), variable('o1')),\n              {\n                type: 'filter',\n                expression: {\n                  type: 'operation',\n                  operator: 'isliteral',\n                  args: [variable('o1')]\n                }\n              },\n              {\n                type: 'filter',\n                expression: {\n                  type: 'operation',\n                  operator: 'regex',\n                  args: [\n                    {\n                      type: 'operation',\n                      operator: 'lcase',\n                      args: [\n                        {\n                          type: 'operation',\n                          operator: 'str',\n                          args: [variable('o1')]\n                        }\n                      ]\n                    },\n                    literal(filter.q.toLowerCase(), '', namedNode('http://www.w3.org/2001/XMLSchema#string'))\n                  ]\n                }\n              }\n            ],\n            type: 'query'\n          }\n        ]\n      });\n    }\n\n    // Other filters\n    // SPARQL keyword a = filter based on the class of a resource (example => 'a': 'pair:OrganizationType')\n    // Other filters are based on a value (example => 'petr:hasAudience': 'http://localhost:3000/audiences/tout-public')\n    Object.entries(filter).forEach(([predicate, object]) => {\n      if (!reservedFilterKeys.includes(predicate)) {\n        resourceWhere.unshift(\n          triple(\n            variable('s1'),\n            namedNode(resolvePrefix(predicate, ontologies)),\n            namedNode(resolvePrefix(object, ontologies))\n          )\n        );\n      }\n    });\n  }\n\n  // Blank nodes\n  const blankNodesQuery = buildBlankNodesQuery(blankNodes, baseQuery, ontologies);\n  if (blankNodesQuery && blankNodesQuery.construct) {\n    resourceWhere = resourceWhere.concat(blankNodesQuery.where);\n    sparqlJsParams.template = sparqlJsParams.template.concat(blankNodesQuery.construct);\n  } else {\n    resourceWhere.push(baseQuery.where);\n  }\n\n  sparqlJsParams.where.push(\n    {\n      type: 'union',\n      patterns: [\n        containerWhere,\n        {\n          type: 'graph',\n          name: namedNode('http://semapps.org/mirror'),\n          patterns: containerWhere\n        }\n      ]\n    },\n    {\n      type: 'union',\n      patterns: [\n        resourceWhere,\n        {\n          type: 'graph',\n          name: namedNode('http://semapps.org/mirror'),\n          patterns: resourceWhere\n        }\n      ]\n    }\n  );\n\n  return generator.stringify(sparqlJsParams);\n};\n\nexport default buildSparqlQuery;\n","// Based on the dataServers config, returns the blank nodes for the given containers\nconst getBlankNodesFromDataServers = (containers, dataServers) => {\n  const blankNodes = [];\n  for (let serverKey of Object.keys(dataServers)) {\n    if (dataServers[serverKey].blankNodes) {\n      for (let containerUri of Object.keys(dataServers[serverKey].blankNodes)) {\n        if (containers.includes(containerUri)) {\n          blankNodes.push(...dataServers[serverKey].blankNodes[containerUri]);\n        }\n      }\n    }\n  }\n  // Remove duplicates\n  return [...new Set(blankNodes)];\n};\n\nexport default getBlankNodesFromDataServers;\n","import getEmbedFrame from './getEmbedFrame';\nimport buildSparqlQuery from './buildSparqlQuery';\nimport getBlankNodesFromDataServers from './getBlankNodesFromDataServers';\nimport jsonld from 'jsonld';\n\nconst compare = (a, b) => {\n  switch (typeof a) {\n    case 'string':\n      return a.localeCompare(b);\n    case 'number':\n    case 'bigint':\n      return a - b;\n    default:\n      return 0;\n  }\n};\n\nconst fetchSparqlEndpoints = async (containers, resourceId, params, config) => {\n  const { dataServers, resources, httpClient, jsonContext, ontologies } = config;\n  const dataModel = resources[resourceId];\n\n  const sparqlQueryPromises = Object.keys(containers).map(\n    serverKey =>\n      new Promise((resolve, reject) => {\n        const blankNodes =\n          params.filter?.blankNodes ||\n          dataModel.list?.blankNodes ||\n          getBlankNodesFromDataServers(containers[serverKey], dataServers);\n\n        const predicates = params.filter?._predicates || dataModel.list?.predicates;\n\n        // When the SPARQL request comes from the browser's URL, it comes as JSON string which must must be parsed\n        if (\n          params.filter?.sparqlWhere &&\n          (typeof params.filter.sparqlWhere === 'string' || params.filter.sparqlWhere instanceof String)\n        ) {\n          params.filter.sparqlWhere = JSON.parse(decodeURIComponent(params.filter.sparqlWhere));\n        }\n        const sparqlQuery = buildSparqlQuery({\n          containers: containers[serverKey],\n          params: { ...params, filter: { ...dataModel.list?.filter, ...params.filter } },\n          blankNodes,\n          predicates,\n          ontologies\n        });\n\n        httpClient(dataServers[serverKey].sparqlEndpoint, {\n          method: 'POST',\n          body: sparqlQuery\n        })\n          .then(({ json }) => {\n            // By default, embed only the blank nodes we explicitly asked to dereference\n            // Otherwise we may have same-type resources embedded in other resources\n            // To increase performances, you can set explicitEmbedOnFraming to false (make sure the result is still OK)\n            const frame =\n              dataModel.list?.explicitEmbedOnFraming !== false\n                ? {\n                    '@context': jsonContext,\n                    '@type': dataModel.types,\n                    '@embed': '@never',\n                    ...getEmbedFrame(blankNodes)\n                  }\n                : {\n                    '@context': jsonContext,\n                    '@type': dataModel.types\n                  };\n\n            // omitGraph option force results to be in a @graph, even if we have a single result\n            return jsonld.frame(json, frame, { omitGraph: false });\n          })\n          .then(compactJson => {\n            if (compactJson['@id']) {\n              const { '@context': context, ...rest } = compactJson;\n              compactJson = {\n                '@context': context,\n                '@graph': [rest]\n              };\n            }\n            resolve(compactJson['@graph'] || []);\n          })\n          .catch(e => reject(e));\n      })\n  );\n\n  // Run simultaneous SPARQL queries\n  let results = await Promise.all(sparqlQueryPromises);\n\n  if (results.length === 0) {\n    return { data: [], total: 0 };\n  } else {\n    // Merge all results in one array\n    results = [].concat(...results);\n\n    // Add id in addition to @id, as this is what React-Admin expects\n    let returnData = results.map(item => {\n      item.id = item.id || item['@id'];\n      return item;\n    });\n\n    // TODO sort and paginate the results in the SPARQL query to improve performances\n    if (params.sort) {\n      returnData = returnData.sort((a, b) => {\n        if (a[params.sort.field] !== undefined && b[params.sort.field] !== undefined) {\n          if (params.sort.order === 'ASC') {\n            return compare(a[params.sort.field], b[params.sort.field]);\n          } else {\n            return compare(b[params.sort.field], a[params.sort.field]);\n          }\n        } else {\n          return 0;\n        }\n      });\n    }\n    if (params.pagination) {\n      returnData = returnData.slice(\n        (params.pagination.page - 1) * params.pagination.perPage,\n        params.pagination.page * params.pagination.perPage\n      );\n    }\n\n    return { data: returnData, total: results.length };\n  }\n};\n\nexport default fetchSparqlEndpoints;\n","import urlJoin from 'url-join';\n\nconst findContainersWithPaths = (paths, dataServers) => {\n  let containers = {};\n  Object.keys(paths).forEach(serverKey => {\n    if (dataServers[serverKey]) {\n      containers[serverKey] = [];\n      paths[serverKey].forEach(path => {\n        containers[serverKey].push(urlJoin(dataServers[serverKey].baseUrl, path));\n      });\n    } else {\n      throw new Error('No server found with key ' + serverKey);\n    }\n  });\n  return containers;\n};\n\nexport default findContainersWithPaths;\n","import findContainersWithTypes from '../utils/findContainersWithTypes';\nimport fetchContainers from '../utils/fetchContainers';\nimport fetchSparqlEndpoints from '../utils/fetchSparqlEndpoints';\nimport findContainersWithPaths from '../utils/findContainersWithPath';\n\nconst getListMethod = config => async (resourceId, params = {}) => {\n  let { dataServers, resources } = config;\n  const dataModel = resources[resourceId];\n\n  if (!dataModel) throw new Error(`Resource ${resourceId} is not mapped in resources file`);\n\n  let containers;\n  if (!params.filter?._servers && dataModel.list?.containers) {\n    if (Array.isArray(dataModel.list?.containers))\n      throw new Error(\n        `The list.containers property of ${resourceId} dataModel must be of type object ({ serverKey: [containerUri] })`\n      );\n    // If containers are set explicitly, use them\n    containers = findContainersWithPaths(dataModel.list.containers, dataServers);\n  } else {\n    // Otherwise find the container URIs on the given servers (either in the filter or the data model)\n    containers = findContainersWithTypes(\n      dataModel.types,\n      params.filter?._servers || dataModel.list?.servers,\n      dataServers\n    );\n  }\n\n  if (dataModel.list?.fetchContainer) {\n    return fetchContainers(containers, resourceId, params, config);\n  } else {\n    return fetchSparqlEndpoints(containers, resourceId, params, config);\n  }\n};\n\nexport default getListMethod;\n","import getOne from './getOne';\n\nconst getManyMethod = config => async (resourceId, params) => {\n  const { returnFailedResources } = config;\n\n  let returnData = await Promise.all(\n    params.ids.map(id =>\n      getOne(config)(resourceId, { id: typeof id === 'object' ? id['@id'] : id })\n        .then(({ data }) => data)\n        .catch(() => {\n          // Catch if one resource fails to load\n          // Otherwise no references will be show if only one is missing\n          // See https://github.com/marmelab/react-admin/issues/5190\n          if (returnFailedResources) {\n            return { id, _error: true };\n          } else {\n            // Returning nothing\n          }\n        })\n    )\n  );\n\n  // We don't want undefined results to appear in the results as it will break with react-admin\n  returnData = returnData.filter(e => e);\n\n  return { data: returnData };\n};\n\nexport default getManyMethod;\n","import getList from './getList';\n\nconst getManyReferenceMethod = config => async (resourceId, params) => {\n  params.filter = { ...params.filter, [params.target]: params.id };\n  delete params.target;\n  return await getList(config)(resourceId, params);\n};\n\nexport default getManyReferenceMethod;\n","import uploadAllFiles from '../utils/uploadAllFiles';\n\nconst updateMethod = config => async (resourceId, params) => {\n  const { httpClient, jsonContext } = config;\n\n  // Upload files, if there are any\n  params.data = await uploadAllFiles(params.data, config);\n\n  await httpClient(params.id, {\n    method: 'PUT',\n    body: JSON.stringify({\n      '@context': jsonContext,\n      ...params.data\n    })\n  });\n\n  return { data: params.data };\n};\n\nexport default updateMethod;\n","function e(e){this.message=e}e.prototype=new Error,e.prototype.name=\"InvalidCharacterError\";var r=\"undefined\"!=typeof window&&window.atob&&window.atob.bind(window)||function(r){var t=String(r).replace(/=+$/,\"\");if(t.length%4==1)throw new e(\"'atob' failed: The string to be decoded is not correctly encoded.\");for(var n,o,a=0,i=0,c=\"\";o=t.charAt(i++);~o&&(n=a%4?64*n+o:o,a++%4)?c+=String.fromCharCode(255&n>>(-2*a&6)):0)o=\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=\".indexOf(o);return c};function t(e){var t=e.replace(/-/g,\"+\").replace(/_/g,\"/\");switch(t.length%4){case 0:break;case 2:t+=\"==\";break;case 3:t+=\"=\";break;default:throw\"Illegal base64url string!\"}try{return function(e){return decodeURIComponent(r(e).replace(/(.)/g,(function(e,r){var t=r.charCodeAt(0).toString(16).toUpperCase();return t.length<2&&(t=\"0\"+t),\"%\"+t})))}(t)}catch(e){return r(t)}}function n(e){this.message=e}function o(e,r){if(\"string\"!=typeof e)throw new n(\"Invalid token specified\");var o=!0===(r=r||{}).header?0:1;try{return JSON.parse(t(e.split(\".\")[o]))}catch(e){throw new n(\"Invalid token specified: \"+e.message)}}n.prototype=new Error,n.prototype.name=\"InvalidTokenError\";export default o;export{n as InvalidTokenError};\n//# sourceMappingURL=jwt-decode.esm.js.map\n","import jwtDecode from 'jwt-decode';\nimport getServerKeyFromType from './getServerKeyFromType';\nimport urlJoin from 'url-join';\n\nconst fetchUserConfig = async config => {\n  const { dataServers, httpClient } = config;\n  const token = localStorage.getItem('token');\n  const podKey = getServerKeyFromType('pod', dataServers);\n  const authServerKey = getServerKeyFromType('authServer', dataServers);\n\n  // If the user is logged in\n  if (token) {\n    const { webId } = jwtDecode(token);\n    let userData;\n\n    try {\n      const { json } = await httpClient(webId);\n      userData = json;\n    } catch (e) {\n      console.error(e);\n      // If the webId cannot be fetched, assume an invalid token and disconnect the user\n      localStorage.clear();\n      window.location.reload();\n      return;\n    }\n\n    // If we have a POD server\n    if (podKey) {\n      // Fill the config provided to the data provider\n      // We must modify the config object directly\n      config.dataServers[podKey].name = 'My Pod';\n      config.dataServers[podKey].baseUrl = urlJoin(webId, 'data'); // TODO find POD URI from user profile\n      config.dataServers[podKey].sparqlEndpoint =\n        userData.endpoints?.['void:sparqlEndpoint'] || urlJoin(webId, 'sparql');\n    }\n\n    if (authServerKey) {\n      // Fill the config provided to the data provider\n      // We must modify the config object directly\n      config.dataServers[authServerKey].proxyUrl = userData.endpoints?.proxyUrl;\n    }\n  } else {\n    // if (podKey) {\n    //   // If the user is not logged in, ignore the POD server\n    //   delete config.dataServers[podKey];\n    // }\n  }\n};\n\nexport default fetchUserConfig;\n","const defaultToArray = value => (!value ? undefined : Array.isArray(value) ? value : [value]);\n\nconst fetchVoidEndpoints = async config => {\n  const fetchPromises = Object.entries(config.dataServers)\n    .filter(([key, server]) => server.pod !== true)\n    .map(([key, server]) =>\n      config\n        .httpClient(new URL('/.well-known/void', server.baseUrl).toString())\n        .then(result => ({ key, datasets: result.json['@graph'] }))\n        .catch(e => {\n          if (e.status === 404 || e.status === 401) {\n            return { key, error: e };\n          } else {\n            throw e;\n          }\n        })\n    );\n\n  let results = [];\n\n  try {\n    results = await Promise.all(fetchPromises);\n  } catch (e) {\n    // Do not throw error if no endpoint found\n  }\n\n  for (let result of results) {\n    config.dataServers[result.key].containers = config.dataServers[result.key].containers || {};\n    config.dataServers[result.key].blankNodes = config.dataServers[result.key].blankNodes || {};\n\n    // Ignore unfetchable endpoints\n    if (result.datasets) {\n      for (let dataset of result.datasets) {\n        const datasetServerKey = Object.keys(config.dataServers).find(\n          key => dataset['void:uriSpace'] === config.dataServers[key].baseUrl\n        );\n\n        // If the dataset is not part of a server mapped in the dataServers, ignore it\n        if (datasetServerKey) {\n          // If this is the local dataset, add the base information\n          if (datasetServerKey === result.key) {\n            config.dataServers[result.key].name = config.dataServers[result.key].name || dataset['dc:title'];\n            config.dataServers[result.key].description =\n              config.dataServers[result.key].description || dataset['dc:description'];\n            config.dataServers[result.key].sparqlEndpoint =\n              config.dataServers[result.key].sparqlEndpoint || dataset['void:sparqlEndpoint'];\n          }\n\n          config.dataServers[result.key].containers[datasetServerKey] =\n            config.dataServers[result.key].containers[datasetServerKey] || {};\n\n          for (let partition of defaultToArray(dataset['void:classPartition'])) {\n            for (let type of defaultToArray(partition['void:class'])) {\n              // Set containers by type\n              const path = partition['void:uriSpace'].replace(dataset['void:uriSpace'], '/');\n              if (config.dataServers[result.key].containers[datasetServerKey][type]) {\n                config.dataServers[result.key].containers[datasetServerKey][type].push(path);\n              } else {\n                config.dataServers[result.key].containers[datasetServerKey][type] = [path];\n              }\n\n              // Set blank nodes by containers\n              const blankNodes = defaultToArray(partition['semapps:blankNodes']);\n              if (blankNodes) {\n                config.dataServers[result.key].blankNodes[partition['void:uriSpace']] = defaultToArray(\n                  partition['semapps:blankNodes']\n                );\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n};\n\nexport default fetchVoidEndpoints;\n","// Return the first server matching with the baseUrl\nconst getServerKeyFromUri = (uri, dataServers) => {\n  return Object.keys(dataServers).find(key => {\n    if (dataServers[key].pod) {\n      // The baseUrl ends with /data so remove this part to match with the webId and webId-related URLs (/inbox, /outbox...)\n      return dataServers[key].baseUrl && uri.startsWith(dataServers[key].baseUrl.replace('/data', ''));\n    } else {\n      return uri.startsWith(dataServers[key].baseUrl);\n    }\n  });\n};\n\nexport default getServerKeyFromUri;\n","import { useCallback, useMemo, useContext } from 'react';\nimport { DataProviderContext } from 'react-admin';\n\nconst compute = (externalLinks, record) =>\n  typeof externalLinks === 'function' ? externalLinks(record) : externalLinks;\nconst isURL = url => typeof url === 'string' && url.startsWith('http');\n\nconst useGetExternalLink = componentExternalLinks => {\n  // Since the externalLinks config is defined only locally, we don't need to wait for VOID endpoints fetching\n  const dataProvider = useContext(DataProviderContext);\n  const dataServers = dataProvider.getLocalDataServers();\n\n  const serversExternalLinks = useMemo(() => {\n    if (dataServers) {\n      return Object.fromEntries(\n        Object.values(dataServers).map(server => {\n          // If externalLinks is not defined in the data server, use external links for non-default servers\n          const externalLinks = server.externalLinks !== undefined ? server.externalLinks : !server.default;\n          return [server.baseUrl, externalLinks];\n        })\n      );\n    }\n  }, [dataServers]);\n\n  return useCallback(\n    record => {\n      const computedComponentExternalLinks = compute(componentExternalLinks, record);\n      // If the component explicitly asks not to display as external links, use an internal link\n      if (computedComponentExternalLinks === false) return false;\n\n      if (!record?.id) return false;\n\n      const serverBaseUrl = Object.keys(serversExternalLinks).find(baseUrl => record?.id.startsWith(baseUrl));\n      // If no matching data servers could be found, assume we have an internal link\n      if (!serverBaseUrl) return false;\n\n      const computedServerExternalLinks = compute(serversExternalLinks[serverBaseUrl], record);\n      // If the data server explicitly asks not to display as external links, use an internal link\n      if (computedServerExternalLinks === false) return false;\n\n      if (isURL(computedComponentExternalLinks)) {\n        return computedComponentExternalLinks;\n      } else if (isURL(computedServerExternalLinks)) {\n        return computedServerExternalLinks;\n      } else {\n        return record.id;\n      }\n    },\n    [serversExternalLinks, componentExternalLinks]\n  );\n};\n\nexport default useGetExternalLink;\n","import { useContext, useState, useEffect } from 'react';\nimport { DataProviderContext } from 'react-admin';\n\nconst useDataModel = resourceId => {\n  // Get the raw data provider, since useDataProvider returns a wrapper\n  const dataProvider = useContext(DataProviderContext);\n  const [dataModel, setDataModel] = useState();\n\n  useEffect(() => {\n    dataProvider.getDataModels().then(results => setDataModel(results[resourceId]));\n  }, [dataProvider, resourceId, setDataModel]);\n\n  return dataModel;\n};\n\nexport default useDataModel;\n","import { useContext, useState, useEffect } from 'react';\nimport { DataProviderContext } from 'react-admin';\n\nconst useDataServers = () => {\n  // Get the raw data provider, since useDataProvider returns a wrapper\n  const dataProvider = useContext(DataProviderContext);\n  const [dataServers, setDataServers] = useState();\n\n  useEffect(() => {\n    dataProvider.getDataServers().then(results => setDataServers(results));\n  }, [dataProvider, setDataServers]);\n\n  return dataServers;\n};\n\nexport default useDataServers;\n","import urlJoin from 'url-join';\n\nconst findCreateContainerWithTypes = (types, createServerKey, dataServers) => {\n  let containers = [];\n\n  if (Object.keys(dataServers[createServerKey].containers[createServerKey]).length > 0) {\n    Object.keys(dataServers[createServerKey].containers[createServerKey]).forEach(type => {\n      if (types.includes(type)) {\n        dataServers[createServerKey].containers[createServerKey][type].map(path => {\n          const containerUri = urlJoin(dataServers[createServerKey].baseUrl, path);\n          if (!containers.includes(containerUri)) {\n            containers.push(containerUri);\n          }\n        });\n      }\n    });\n  }\n\n  if (containers.length === 0) {\n    throw new Error(\n      `No container found matching with types ${JSON.stringify(\n        types\n      )}. You can set explicitely the create.container property of the resource.`\n    );\n  } else if (containers.length > 1) {\n    throw new Error(\n      `More than one container found matching with types ${JSON.stringify(\n        types\n      )}. You must set the create.server or create.container property for the resource.`\n    );\n  }\n\n  return containers[0];\n};\n\nexport default findCreateContainerWithTypes;\n","import React, { useState, useEffect } from 'react';\n\n/**\n * @example\n * <Show>\n *   <FilterHandler\n *     source=\"property\" // ex pair:organizationOfMembership\n *     filter={{\n *       'propertyToFilter':'value'\n *     }} // ex {{'pair:membershipRole':'http://localhost:3000/membership-roles/role-1'}}\n *     >\n *     <SingleFieldList>\n *    </SingleFieldList>\n *   </FilterHandler>\n * </Show>\n */\n\nconst FilterHandler = ({ children, record, filter, source, ...otherProps }) => {\n  const [filtered, setFiltered] = useState();\n  useEffect(() => {\n    if (record && source && Array.isArray(record?.[source])) {\n      const filteredData = record?.[source].filter(r => {\n        let eq = true;\n        for (const key in filter) {\n          const value = r[key];\n          if (Array.isArray(value)) {\n            if (!value.includes(filter[key])) {\n              eq = false;\n            }\n          } else {\n            if (value !== filter[key]) {\n              eq = false;\n            }\n          }\n        }\n        return eq;\n      });\n      let newRecord = {\n        ...record\n      };\n      //undefined setted if no data to obtain no render in RightLabel or equivalent\n      newRecord[source] = filteredData.length > 0 ? filteredData : undefined;\n      setFiltered(newRecord);\n    }\n  }, [record, source, filter]);\n\n  return (\n    <>\n      {React.Children.map(children, (child, i) => {\n        return React.cloneElement(child, {\n          ...otherProps,\n          record: filtered,\n          addLabel: true,\n          source\n        });\n      })}\n    </>\n  );\n};\nexport default FilterHandler;\n","import React, { useEffect, useState } from 'react';\nimport { ArrayInput, SimpleFormIterator, TextInput } from 'react-admin';\nimport { makeStyles } from '@material-ui/core/styles';\n\nconst useReferenceInputStyles = makeStyles({\n  form: {\n    display: 'flex'\n  },\n  input: {\n    paddingRight: '20px'\n  }\n});\n\nconst useHideInputStyles = makeStyles({\n  root: {\n    display: 'none'\n  }\n});\n\nconst ReificationArrayInput = props => {\n  const { reificationClass, children, ...otherProps } = props;\n  const flexFormClasses = useReferenceInputStyles();\n  const hideInputStyles = useHideInputStyles();\n\n  return (\n    <ArrayInput {...otherProps}>\n      <SimpleFormIterator classes={{ form: flexFormClasses.form }}>\n        {React.Children.map(props.children, (child, i) => {\n          return React.cloneElement(child, {\n            className: flexFormClasses.input\n          });\n        })}\n        <TextInput className={hideInputStyles.root} source=\"type\" initialValue={reificationClass} />\n      </SimpleFormIterator>\n    </ArrayInput>\n  );\n};\n\nexport default ReificationArrayInput;\n","import React from 'react';\nimport { useQueryWithStore } from 'react-admin';\nimport { default as FilterHandler } from './FilterHandler';\n\n/*\n * @example Label used in examples\n *  const Label = ({label, ...otherProps})=>{\n *     return <h2>{label}</h2>\n *  }\n *\n * @example show header for each group with group property thanks to groupHeader\n * <GroupedReferenceHandler\n *   source=\"property\" // predicat of main record to show / ex pair:organizationOfMembership\n *   groupReference=\"RAresource\" // React-Admin resource reference. this is the \"group by\" ressource. / ex MembershipRole\n *   groupHeader={({group,...otherProps}) => <Label {...otherProps} label={group['pair:label']}></Label> }\n *   filterProperty=\"property of source filtered by groupReference\"\n *   addLabel={false}\n * >\n *   <ArrayField source=\"property\"> // same props as GroupedArrayField source\n *    <GridList>\n *    </GridList>\n *   </ArrayField>\n * </GroupedReferenceHandler>\n *\n * @example call chhildren with label thanks to groupLabel\n * <GroupedReferenceHandler\n *   source=\"property\" // predicat of main record to show / ex pair:organizationOfMembership\n *   groupReference=\"RAresource\" // React-Admin resource reference. this is the \"group by\" ressource. / ex MembershipRole\n *   groupLabel=\"property of RAresource display\" // property of React-Admin resource to display. children call whith props \"label\" filled by groupLabel property of groupReference\n *   filterProperty=\"property of source filtered by groupReference\"\n *   addLabel={false}\n * >\n *   <Label>\n *   <ArrayField source=\"property\"> // same props as GroupedArrayField source\n *    <GridList>\n *    </GridList>\n *   </ArrayField>\n * </GroupedReferenceHandler>\n *\n * @example conditional show of group if no data in source. Conditionale groupHeader is not possible because GroupedArrayField define group before filter ; need use chhildren.\n * const ConditionalSourceDefinedHandler = ({record,source,children,...otherProps})=>{\n *   if (record?.[source] && (!Array.isArray(record[source])||record[source].length>0)){\n *     return  React.Children.map(children, (child, i) => {\n *         return React.cloneElement(child, {...otherProps,record,source});\n *       })\n *   }else{\n *     return <></>\n *   }\n * }\n *\n * <GroupedReferenceHandler\n *   source=\"property\" // predicat of main record to show / ex pair:organizationOfMembership\n *   groupReference=\"RAresource\" // React-Admin resource reference. this is the \"group by\" ressource. / ex MembershipRole\n *   groupLabel=\"property of RAresource display\" // property of React-Admin resource to display. children call whith props \"label\" filled by groupLabel property of groupReference\n *   filterProperty=\"property of source filtered by groupReference\"\n *   addLabel={false}\n * >\n *  <ConditionalSourceDefinedHandler>\n *   <Label>\n *   <ArrayField source=\"property\"> // same props as GroupedArrayField source\n *    <GridList>\n *    </GridList>\n *   </ArrayField>\n *  </ConditionalSourceDefinedHandler>\n * </GroupedReferenceHandler>\n *\n *\n */\nconst GroupedReferenceHandler = ({\n  children,\n  groupReference,\n  groupLabel,\n  groupHeader,\n  filterProperty,\n  ...otherProps\n}) => {\n  const { data } = useQueryWithStore({\n    type: 'getList',\n    resource: groupReference,\n    payload: {}\n  });\n\n  return (\n    <>\n      {data?.map((data, index) => {\n        let filter = {};\n        filter[filterProperty] = data.id;\n        return (\n          <>\n            {groupHeader && groupHeader({ ...otherProps, group: data })}\n            <FilterHandler {...otherProps} filter={filter} label={data[groupLabel]}>\n              {children}\n            </FilterHandler>\n          </>\n        );\n      })}\n    </>\n  );\n};\n\nexport default GroupedReferenceHandler;\n","import createMethod from './methods/create';\nimport deleteMethod from './methods/delete';\nimport deleteManyMethod from './methods/deleteMany';\nimport getDataServersMethod from './methods/getDataServers';\nimport getDataModelsMethod from './methods/getDataModels';\nimport getListMethod from './methods/getList';\nimport getManyMethod from './methods/getMany';\nimport getManyReferenceMethod from './methods/getManyReference';\nimport getOneMethod from './methods/getOne';\nimport updateMethod from './methods/update';\nimport fetchUserConfig from './utils/fetchUserConfig';\nimport fetchVoidEndpoints from './utils/fetchVoidEndpoints';\nimport getServerKeyFromType from './utils/getServerKeyFromType';\nimport httpClient from './httpClient';\n\nconst dataProvider = config => {\n  // TODO verify all data provider config + data models\n  if (!getServerKeyFromType('default', config.dataServers))\n    throw new Error('You must define a default server in your dataServers config');\n\n  if (!config.jsonContext) config.jsonContext = Object.fromEntries(config.ontologies.map(o => [o.prefix, o.url]));\n  if (!config.returnFailedResources) config.returnFailedResources = false;\n\n  // Configure httpClient with data servers (this is needed for proxy calls)\n  config.httpClient = httpClient(config.dataServers);\n\n  const fetchUserConfigPromise = fetchUserConfig(config);\n  const fetchVoidEndpointsPromise = fetchVoidEndpoints(config);\n\n  const waitForVoidEndpoints = method => async (...arg) => {\n    await fetchUserConfigPromise;\n    await fetchVoidEndpointsPromise; // Return immediately if promise is fulfilled\n    return await method(...arg);\n  };\n\n  return {\n    getList: waitForVoidEndpoints(getListMethod(config)),\n    getMany: waitForVoidEndpoints(getManyMethod(config)),\n    getManyReference: waitForVoidEndpoints(getManyReferenceMethod(config)),\n    getOne: waitForVoidEndpoints(getOneMethod(config)),\n    create: waitForVoidEndpoints(createMethod(config)),\n    update: waitForVoidEndpoints(updateMethod(config)),\n    updateMany: () => {\n      throw new Error('updateMany is not implemented yet');\n    },\n    delete: waitForVoidEndpoints(deleteMethod(config)),\n    deleteMany: waitForVoidEndpoints(deleteManyMethod(config)),\n    // Custom methods\n    getDataModels: waitForVoidEndpoints(getDataModelsMethod(config)),\n    getDataServers: waitForVoidEndpoints(getDataServersMethod(config)),\n    getLocalDataServers: getDataServersMethod(config),\n    fetch: waitForVoidEndpoints(config.httpClient)\n  };\n};\n\nexport default dataProvider;\n","import { fetchUtils } from 'react-admin';\nimport getServerKeyFromUri from './utils/getServerKeyFromUri';\nimport getServerKeyFromType from './utils/getServerKeyFromType';\n\n/*\n * HTTP client used by all calls in data provider and auth provider\n * Do proxy calls if a proxy endpoint is available and the server is different from the auth server\n */\nconst httpClient = dataServers => (url, options = {}) => {\n  const authServerKey = getServerKeyFromType('authServer', dataServers);\n  const serverKey = getServerKeyFromUri(url, dataServers);\n  const useProxy =\n    serverKey !== authServerKey && dataServers[authServerKey]?.proxyUrl && dataServers[serverKey]?.noProxy !== true;\n\n  if (!options.headers) options.headers = new Headers();\n\n  switch (options.method) {\n    case 'POST':\n    case 'PATCH':\n    case 'PUT':\n      if (!options.headers.has('Accept')) options.headers.set('Accept', 'application/ld+json');\n      if (!options.headers.has('Content-Type')) options.headers.set('Content-Type', 'application/ld+json');\n      break;\n\n    case 'DELETE':\n      break;\n\n    case 'GET':\n    default:\n      if (!options.headers.has('Accept')) options.headers.set('Accept', 'application/ld+json');\n      break;\n  }\n\n  if (useProxy) {\n    const formData = new FormData();\n\n    formData.append('id', url);\n    formData.append('method', options.method || 'GET');\n    formData.append('headers', JSON.stringify(Object.fromEntries(options.headers.entries())));\n\n    if (options.body) {\n      if (options.body instanceof File) {\n        formData.append('body', options.body, options.body.name);\n      } else {\n        formData.append('body', options.body);\n      }\n    }\n\n    // Post to proxy endpoint with multipart/form-data format\n    return fetchUtils.fetchJson(dataServers[authServerKey].proxyUrl, {\n      method: 'POST',\n      headers: new Headers({\n        Authorization: `Bearer ${localStorage.getItem('token')}`\n      }),\n      body: formData\n    });\n  } else {\n    // Add token if the server is the same as the auth server\n    if (serverKey === authServerKey) {\n      const token = localStorage.getItem('token');\n      if (token) options.headers.set('Authorization', `Bearer ${token}`);\n    }\n    return fetchUtils.fetchJson(url, options);\n  }\n};\n\nexport default httpClient;\n","import { useState, useEffect } from 'react';\nimport useDataModel from './useDataModel';\nimport useDataServers from './useDataServers';\nimport findContainersWithTypes from '../dataProvider/utils/findContainersWithTypes';\n\nconst useContainers = (resourceId, serverKeys = '@all') => {\n  const dataModel = useDataModel(resourceId);\n  const dataServers = useDataServers();\n  const [containers, setContainers] = useState();\n\n  useEffect(() => {\n    if (dataModel && dataServers) {\n      setContainers(findContainersWithTypes(dataModel.types, serverKeys, dataServers));\n    }\n  }, [dataModel, dataServers, serverKeys]);\n\n  return containers;\n};\n\nexport default useContainers;\n","import { useState, useEffect } from 'react';\nimport urlJoin from 'url-join';\nimport useDataModel from './useDataModel';\nimport useDataServers from './useDataServers';\nimport findCreateContainerWithTypes from '../dataProvider/utils/findCreateContainerWithTypes';\nimport getServerKeyFromType from '../dataProvider/utils/getServerKeyFromType';\n\nconst useCreateContainer = resourceId => {\n  const dataModel = useDataModel(resourceId);\n  const dataServers = useDataServers();\n  const [createContainer, setCreateContainer] = useState();\n\n  useEffect(() => {\n    if (dataModel && dataServers) {\n      if (dataModel.create?.container) {\n        const [serverKey, path] = Object.entries(dataModel.create.container)[0];\n        if (!serverKey || !dataServers[serverKey]) {\n          throw new Error('Wrong key for the dataModel.create.container config of resource ' + resourceId);\n        }\n        setCreateContainer(urlJoin(dataServers[serverKey].baseUrl, path));\n      } else if (dataModel.create?.server) {\n        setCreateContainer(findCreateContainerWithTypes(dataModel.types, dataModel.create?.server, dataServers));\n      } else {\n        const defaultServerKey = getServerKeyFromType('default', dataServers);\n        setCreateContainer(findCreateContainerWithTypes(dataModel.types, defaultServerKey, dataServers));\n      }\n    }\n  }, [dataModel, dataServers, setCreateContainer]);\n\n  return createContainer;\n};\n\nexport default useCreateContainer;\n","import { useContext, useState, useEffect } from 'react';\nimport { DataProviderContext } from 'react-admin';\n\nconst useDataModels = () => {\n  // Get the raw data provider, since useDataProvider returns a wrapper\n  const dataProvider = useContext(DataProviderContext);\n  const [dataModels, setDataModels] = useState();\n\n  useEffect(() => {\n    dataProvider.getDataModels().then(results => setDataModels(results));\n  }, [dataProvider, setDataModels]);\n\n  return dataModels;\n};\n\nexport default useDataModels;\n"],"names":["context","definition","this","normalize","strArray","resultArray","length","TypeError","match","first","shift","replace","i","component","push","str","join","parts","split","arguments","slice","call","module","exports","fetchResource","resourceUri","config","httpClient","jsonContext","data","json","Error","id","jsonld","compact","getOneMethod","resourceId","params","resources","dataModel","list","_dataModel$list","forceArray","_dataModel$list2","forceArrayItem","Array","isArray","isFile","o","rawFile","File","getUploadsContainerUri","serverKey","Object","keys","dataServers","find","key","uploadsContainer","urlJoin","baseUrl","uploadFile","uploadsContainerUri","method","body","headers","Headers","Slug","fileName","name","fileExtension","splitFileName","pop","createSlug","lang","type","response","status","get","uploadAllFiles","record","property","hasOwnProperty","getServerKeyFromType","parseServerKey","findContainersWithTypes","types","serverKeys","containers","existingContainers","includes","map","defaultServerKey","filter","parseServerKeys","forEach","key1","key2","path","containerUri","createMethod","create","_dataModel$create","container","values","server","JSON","stringify","fieldsMapping","_dataModel$fieldsMapp","title","set","f","responseHeaders","getOne","deleteMethod","deleteManyMethod","ids","getDataServers","getDataModels","fetchContainers","containersServers","reduce","acc","fromEntries","fetchPromises","then","resourceType","resource","Promise","all","results","total","concat","apply","returnData","item","a","entries","some","k","v","val","vr","va","sort","b","field","order","localeCompare","pagination","page","perPage","getEmbedFrame","blankNodes","predicates","embedFrame","blankNode","reverse","accumulator","predicate","resolvePrefix","ontologies","startsWith","prefix","value","ontology","url","typeQuery","triple","variable","namedNode","buildBaseQuery","baseTriples","construct","where","patterns","CryptoJS","Math","undefined","crypto","window","self","globalThis","msCrypto","global","require","err","cryptoSecureRandomInt","getRandomValues","Uint32Array","randomBytes","readInt32LE","F","obj","subtype","prototype","C","C_lib","lib","Base","extend","overrides","mixIn","init","$super","instance","properties","propertyName","toString","clone","WordArray","words","sigBytes","encoder","Hex","wordArray","thisWords","thatWords","thisSigBytes","thatSigBytes","clamp","thatByte","j","ceil","random","nBytes","C_enc","enc","hexChars","bite","parse","hexStr","hexStrLength","parseInt","substr","Latin1","latin1Chars","String","fromCharCode","latin1Str","latin1StrLength","charCodeAt","Utf8","decodeURIComponent","escape","e","utf8Str","unescape","encodeURIComponent","BufferedBlockAlgorithm","reset","_data","_nDataBytes","_append","_process","doFlush","processedWords","dataWords","dataSigBytes","blockSize","nBlocksReady","nWordsReady","max","_minBufferSize","nBytesReady","min","offset","_doProcessBlock","splice","Hasher","cfg","_doReset","update","messageUpdate","finalize","_doFinalize","_createHelper","hasher","message","_createHmacHelper","C_algo","HMAC","algo","T","abs","sin","MD5","_hash","M","offset_i","M_offset_i","H","M_offset_0","M_offset_1","M_offset_2","M_offset_3","M_offset_4","M_offset_5","M_offset_6","M_offset_7","M_offset_8","M_offset_9","M_offset_10","M_offset_11","M_offset_12","M_offset_13","M_offset_14","M_offset_15","c","d","FF","GG","HH","II","nBitsTotal","nBitsLeft","nBitsTotalH","floor","nBitsTotalL","hash","H_i","x","s","t","n","HmacMD5","generateSparqlVarName","node","md5","getParentNode","getPredicate","buildUnionQuery","queries","q","triples","query","firstTriple","q2","parentNode","buildBlankNodesQuery","baseQuery","nodes","nodeNames","extractNodes","varName","parentVarName","pre","cur","literal","DataFactory","generator","SparqlGenerator","Generator","reservedFilterKeys","buildSparqlQuery","sparqlJsParams","queryType","template","prefixes","containerWhere","expression","operator","args","resourceWhere","hasSPARQLFilter","sparqlWhere","hasFullTextSearch","sw","variables","toLowerCase","object","unshift","blankNodesQuery","getBlankNodesFromDataServers","Set","compare","fetchSparqlEndpoints","sparqlQueryPromises","resolve","reject","_predicates","sparqlQuery","_dataModel$list3","sparqlEndpoint","frame","explicitEmbedOnFraming","omitGraph","compactJson","findContainersWithPaths","paths","getListMethod","_params$filter","_servers","servers","_dataModel$list4","fetchContainer","getManyMethod","returnFailedResources","_typeof","_error","getManyReferenceMethod","target","getList","updateMethod","InvalidCharacterError","r","atob","bind","input","bs","buffer","bc","idx","output","charAt","indexOf","fetchUserConfig","token","localStorage","getItem","podKey","authServerKey","jwtDecode","webId","userData","console","error","clear","location","reload","endpoints","proxyUrl","_userData$endpoints2","defaultToArray","fetchVoidEndpoints","pod","URL","result","datasets","dataset","datasetServerKey","description","partition","getServerKeyFromUri","uri","compute","externalLinks","isURL","useDataModel","dataProvider","useContext","DataProviderContext","useState","setDataModel","useEffect","useDataServers","setDataServers","findCreateContainerWithTypes","createServerKey","FilterHandler","children","source","otherProps","filtered","setFiltered","filteredData","eq","newRecord","React","Children","child","cloneElement","addLabel","useReferenceInputStyles","makeStyles","form","display","paddingRight","useHideInputStyles","root","groupReference","groupLabel","groupHeader","filterProperty","useQueryWithStore","payload","index","group","label","props","reificationClass","flexFormClasses","hideInputStyles","ArrayInput","SimpleFormIterator","classes","className","TextInput","initialValue","options","useProxy","_dataServers$authServ","noProxy","has","formData","FormData","append","fetchUtils","fetchJson","Authorization","fetchUserConfigPromise","fetchVoidEndpointsPromise","waitForVoidEndpoints","getMany","getManyReference","updateMany","deleteMany","getDataModelsMethod","getDataServersMethod","getLocalDataServers","fetch","setContainers","createContainer","setCreateContainer","_dataModel$create2","_dataModel$create3","dataModels","setDataModels","componentExternalLinks","serversExternalLinks","useMemo","useCallback","computedComponentExternalLinks","serverBaseUrl","computedServerExternalLinks"],"mappings":"8xIAAA,IAAiBA,EAASC,EAATD,EAIHE,EAJYD,EAIN,oBAETE,EAAWC,OACdC,EAAc,MACM,IAApBD,EAASE,aAAuB,MAET,iBAAhBF,EAAS,SACZ,IAAIG,UAAU,kCAAoCH,EAAS,OAI/DA,EAAS,GAAGI,MAAM,iBAAmBJ,EAASE,OAAS,EAAG,KACxDG,EAAQL,EAASM,QACrBN,EAAS,GAAKK,EAAQL,EAAS,GAI7BA,EAAS,GAAGI,MAAM,gBACpBJ,EAAS,GAAKA,EAAS,GAAGO,QAAQ,gBAAiB,UAEnDP,EAAS,GAAKA,EAAS,GAAGO,QAAQ,gBAAiB,aAGhD,IAAIC,EAAI,EAAGA,EAAIR,EAASE,OAAQM,IAAK,KACpCC,EAAYT,EAASQ,MAEA,iBAAdC,QACH,IAAIN,UAAU,kCAAoCM,GAGxC,KAAdA,IAEAD,EAAI,IAENC,EAAYA,EAAUF,QAAQ,SAAU,KAIxCE,EAFED,EAAIR,EAASE,OAAS,EAEZO,EAAUF,QAAQ,SAAU,IAG5BE,EAAUF,QAAQ,SAAU,KAG1CN,EAAYS,KAAKD,QAIfE,EAAMV,EAAYW,KAAK,KAOvBC,GAHJF,EAAMA,EAAIJ,QAAQ,kBAAmB,OAGrBO,MAAM,YACtBH,EAAME,EAAMP,SAAWO,EAAMX,OAAS,EAAI,IAAK,IAAMW,EAAMD,KAAK,YAK3D,kBASEb,EANqB,iBAAjBgB,UAAU,GACXA,UAAU,GAEV,GAAGC,MAAMC,KAAKF,cAtEWG,EAAOC,QAASD,UAAiBrB,IAEjED,EAAO,QAASC,OCDjBuB,8CAAgB,WAAOC,EAAaC,sGAChCC,EAA4BD,EAA5BC,WAAYC,EAAgBF,EAAhBE,qBAEOD,EAAWF,sBAA1BI,IAANC,2BAEW,IAAIC,MAAM,qBAAuBN,aAElDI,EAAKG,GAAKH,EAAKG,IAAMH,EAAK,OAItBA,EAAK,cAAgBD,oCACVK,UAAOC,QAAQL,EAAMD,WAAlCC,0CAGKA,uGCfHM,EAAe,SAAAT,sDAAU,WAAOU,EAAYC,0GACxCC,EAAcZ,EAAdY,UACFC,EAAYD,EAAUF,yBAEN,IAAIL,yBAAkBK,8DAEzBZ,EAAca,EAAOL,GAAIN,aAAtCG,mBAGFU,EAAUC,mBAAVC,EAAgBC,WAAY,eACDH,EAAUC,yBAAVG,EAAgBD,2CAAlCE,UACLf,EAAKe,KAAoBC,MAAMC,QAAQjB,EAAKe,MAC9Cf,EAAKe,GAAkB,CAACf,EAAKe,6DAwB5B,CAAEf,KAAAA,wGCzBEkB,EAAS,SAAAC,UAAKA,GAAKA,EAAEC,SAAWD,EAAEC,mBAAmBC,MAE5DC,EAAyB,SAAAzB,OACvB0B,EAAYC,OAAOC,KAAK5B,EAAO6B,aAAaC,MAAK,SAAAC,UAAO/B,EAAO6B,YAAYE,GAAKC,uBAClFN,SACKO,EAAQjC,EAAO6B,YAAYH,GAAWQ,QAASlC,EAAO6B,YAAYH,GAAWM,mBAIlFG,8CAAa,WAAOZ,EAASvB,8FAC3BoC,EAAsBX,EAAuBzB,yBACnB,IAAIK,MAAM,mGAEnBL,EAAOC,WAAWmC,EAAqB,CAC5DC,OAAQ,OACRC,KAAMf,EACNgB,QAAS,IAAIC,QAAQ,CAInBC,MA9B8BC,EA8BHnB,EAAQoB,KA7BnCC,OAAAA,EACAC,OAAAA,EADAD,EAAgB,GAChBC,EAAgBH,EAASlD,MAAM,KAC/BqD,EAAcjE,OAAS,IACzBgE,EAAgBC,EAAcC,MAC9BJ,EAAWG,EAAcvD,KAAK,MAEzByD,UAAWL,EAAU,CAAEM,KAAM,OAAU,IAAMJ,kBAwBhCrB,EAAQ0B,mBAIJ,OAZlBC,UAYOC,gDACJD,EAASX,QAAQa,IAAI,8CApCI,IAAAV,EAC9BE,EACAC,mEA0CAQ,8CAAiB,WAAOC,EAAQtD,wHACfsD,oDAAZC,cACHD,EAAOE,eAAeD,wBACpBpC,MAAMC,QAAQkC,EAAOC,qBACdrE,EAAI,cAAGA,EAAIoE,EAAOC,GAAU3E,6BAC/ByC,EAAOiC,EAAOC,GAAUrE,sCACEiD,EAAWmB,EAAOC,GAAUrE,GAAGqC,QAASvB,WAApEsD,EAAOC,GAAUrE,kBAFwBA,uDAMzCmC,EAAOiC,EAAOC,sCACSpB,EAAWmB,EAAOC,GAAUhC,QAASvB,WAA9DsD,EAAOC,kEAKRD,uGC/DHG,EAAuB,SAACR,EAAMpB,UAC3BF,OAAOC,KAAKC,GAAaC,MAAK,SAAAC,UAC5BF,EAAYE,GAAKkB,OCAtBS,EAAiB,SAAChC,EAAWG,UACzBH,OACD,kBACI+B,EAAqB,UAAW5B,OACpC,cACI4B,EAAqB,MAAO5B,OAChC,qBACI4B,EAAqB,aAAc5B,kBAEnCH,ICRPiC,EAA0B,SAACC,EAAOC,EAAYhC,OAC9CiC,EAAa,GACbC,EAAqB,UAEzBF,EDUsB,SAACA,EAAYhC,MAC/BV,MAAMC,QAAQyC,UACZA,EAAWG,SAAS,QACfrC,OAAOC,KAAKC,GAEZgC,EAAWI,KAAI,SAAAvC,UAAagC,EAAehC,EAAWG,MAE1D,GAA0B,iBAAfgC,EAAyB,IACtB,SAAfA,SACKlC,OAAOC,KAAKC,GACd,GAAmB,YAAfgC,EAA0B,KAC7BK,EAAmBT,EAAqB,UAAW5B,UAClDF,OAAOC,KAAKC,GAAasC,QAAO,SAAAzC,UAAaA,IAAcwC,WAE3D,CAACR,EAAeG,EAAYhC,WAI9B,EC5BIuC,CAAgBP,EAAYhC,GAEzCF,OAAOC,KAAKC,GAAawC,SAAQ,SAAAC,GAC/B3C,OAAOC,KAAKC,EAAYyC,GAAMR,YAAYO,SAAQ,SAAAE,GAC3CV,IAAcA,EAAWG,SAASO,IACrC5C,OAAOC,KAAKC,EAAYyC,GAAMR,WAAWS,IAAOF,SAAQ,SAAApB,GAClDW,EAAMI,SAASf,IACjBpB,EAAYyC,GAAMR,WAAWS,GAAMtB,GAAMgB,KAAI,SAAAO,OACrCC,EAAexC,EAAQJ,EAAY0C,GAAMrC,QAASsC,GAGnDT,EAAmBC,SAASS,KAC/BV,EAAmB3E,KAAKqF,GAEnBX,EAAWQ,KAAOR,EAAWQ,GAAQ,IAC1CR,EAAWQ,GAAMlF,KAAKqF,gBAQ7BX,GCzBHY,EAAe,SAAA1E,sDAAU,WAAOU,EAAYC,0HACxCkB,EAAoD7B,EAApD6B,YAAajB,EAAuCZ,EAAvCY,UAAWX,EAA4BD,EAA5BC,WAAYC,EAAgBF,EAAhBE,YACtCW,EAAYD,EAAUF,GAItB6B,EAAU,IAAIC,kBAGhB3B,EAAU8D,sBAAVC,EAAkBC,0BACpBnD,EAAYC,OAAOC,KAAKf,EAAU8D,OAAOE,WAAW,GACpDJ,EAAexC,EAAQJ,EAAYH,GAAWQ,QAASP,OAAOmD,OAAOjE,EAAU8D,OAAOE,WAAW,8BAEjGnD,aAAYb,EAAU8D,6BAAQI,SAAUpD,OAAOC,KAAKC,GAAaC,MAAK,SAAAC,UAAoC,IAA7BF,EAAYE,qCACnE,IAAI1B,MAAM,6FAE1ByD,EAAaH,EAAwB9C,EAAU+C,MAAO,CAAClC,GAAYG,IAEnEgC,EAAalC,OAAOC,KAAKkC,KAEU,IAAtBD,EAAWjF,8BACtB,IAAIyB,wCAAiC2E,KAAKC,UAAUpE,EAAU+C,mCAA0BlC,iBAC5FmC,EAAWjF,OAAS,GAAKkF,EAAWD,EAAW,IAAIjF,OAAS,0BACxD,IAAIyB,4DACuC2E,KAAKC,UAAUpE,EAAU+C,6BAAoBlC,YAEhG+C,EAAeX,EAAWD,EAAW,IAAI,eAGvClD,EAAOR,uCACLU,EAAUqE,4BAAVC,EAAyBC,QACvBjE,MAAMC,QAAQP,EAAUqE,cAAcE,OACxC7C,EAAQ8C,IAAI,OAAQxE,EAAUqE,cAAcE,MAAMnB,KAAI,SAAAqB,UAAK3E,EAAOR,KAAKmF,MAAIhG,KAAK,MAEhFiD,EAAQ8C,IAAI,OAAQ1E,EAAOR,KAAKU,EAAUqE,cAAcE,mBAKxC/B,EAAe1C,EAAOR,KAAMH,kBAAhDW,EAAOR,sBAEoCF,EAAWwE,EAAc,CAClEpC,OAAQ,OACRE,QAAAA,EACAD,KAAM0C,KAAKC,wBACG/E,UACHW,EAAU+C,OAChBjD,EAAOR,iCANGoF,IAAThD,QAWFxC,EAAcwF,EAAgBnC,IAAI,sBAC3BoC,EAAOxF,EAAPwF,CAAe9E,EAAY,CAAEJ,GAAIP,yDACrCY,EAAOL,2BAChBiC,EAAQ8C,IAAI,eAAgB,uCAEtBpF,EAAWwE,EAAc,CAC7BpC,OAAQ,QACRE,QAAAA,EACAD,yFAEmBmC,6BAA+B9D,EAAOL,+CAK9CkF,EAAOxF,EAAPwF,CAAe9E,EAAY,CAAEJ,GAAIK,EAAOL,mJCxEnDmF,EAAe,SAAAzF,sDAAU,WAAOU,EAAYC,gGACxCV,EAAeD,EAAfC,oBAEFA,EAAWU,EAAOL,GAAI,CAC1B+B,OAAQ,2CAGH,CAAElC,KAAM,CAAEG,GAAIK,EAAOL,0GCPxBoF,EAAmB,SAAA1F,sDAAU,WAAOU,EAAYC,iGAC5CV,EAAeD,EAAfC,WACJ0F,EAAM,OAEKhF,EAAOgF,qEAAbrF,6BAECL,EAAWK,EAAI,CACnB+B,OAAQ,mBAEVsD,EAAIvG,KAAKkB,6NAMN,CAAEH,KAAMwF,oICfXC,EAAiB,SAAA5F,UAAU,kBACxBA,EAAO6B,cCDVgE,EAAgB,SAAA7F,UAAU,kBACvBA,EAAOY,YCET,IAKDkF,8CAAkB,WAAOhC,EAAYpD,EAAYC,EAAQX,4GACrDC,EAA4BD,EAA5BC,WAAYC,EAAgBF,EAAhBE,YAGd6F,EAAoBpE,OAAOC,KAAKkC,GAAYkC,QAChD,SAACC,EAAKvE,iBACDuE,GACAtE,OAAOuE,YAAYpC,EAAWpC,GAAWuC,KAAI,SAAAQ,SAAgB,CAACA,EAAc/C,UAEjF,IAGIyE,EAAgBxE,OAAOC,KAAKmE,GAAmB9B,KAAI,SAAAQ,UACvDxE,EAAWwE,GACR2B,MAAK,gBAAGhG,IAAAA,YAGHA,EAAK,cAAgBF,EAChBK,UAAOC,QAAQJ,EAAMF,GAErBE,KAGVgG,MAAK,SAAAhG,MA5BW6C,EA6BJ,gBA5BXoD,GADqBC,EA6BOlG,GA5BJ6C,MAAQqD,EAAS,SACxCnF,MAAMC,QAAQiF,GAAgBA,EAAarC,SAASf,GAAQoD,IAAiBpD,SA4BrE7C,EAAK,sBAEN,IAAIC,MAAMoE,EAAe,2BAhCnB,IAACxB,EAAMqD,EACrBD,iBAqCcE,QAAQC,IAAIL,aAET,KAFnBM,UAEQ7H,iDACH,CAAEuB,KAAM,GAAIuG,MAAO,mBAG1BD,QAAaE,QAAOC,gBAASH,IAEzBI,EAAaJ,EAAQxC,KAAI,SAAA6C,UAC3BA,EAAKxG,GAAKwG,EAAKxG,IAAMwG,EAAK,OACnBA,KAILnG,EAAOwD,SAELxD,EAAOwD,OAAO4C,IAChBpG,EAAOwD,OAAOlB,KAAOtC,EAAOwD,OAAO4C,SAC5BpG,EAAOwD,OAAO4C,GAGnBpF,OAAOC,KAAKjB,EAAOwD,QAAQvF,OAAS,IACtCiI,EAAaA,EAAW1C,QAAO,SAAAmC,UACtB3E,OAAOqF,QAAQrG,EAAOwD,QAAQ8C,MAAK,yBAAEC,OAAGC,aACpC,KAALD,EAEKvF,OAAOqF,QAAQV,GAAUW,MAAK,kCC5DlBG,ED4DwBC,cC3DzC,OADiBD,ED6DHC,IC5DS,iBAARD,IAA2C,IAAvBjG,MAAMC,QAAQgG,MD6DxCjG,MAAMC,QAAQiG,GAAMA,EAAGJ,MAAK,SAAAK,UAAMA,EAAGtD,SAASmD,MAAME,EAAGrD,SAASmD,QAMpEhG,MAAMC,QAAQkF,EAASY,IAAMZ,EAASY,GAAGlD,SAASmD,YAO/DxG,EAAO4G,OACTV,EAAaA,EAAWU,MAAK,SAACR,EAAGS,UAC3BT,EAAEpG,EAAO4G,KAAKE,SAAUD,EAAE7G,EAAO4G,KAAKE,SACd,QAAtB9G,EAAO4G,KAAKG,MACPX,EAAEpG,EAAO4G,KAAKE,OAAOE,cAAcH,EAAE7G,EAAO4G,KAAKE,QAEjDD,EAAE7G,EAAO4G,KAAKE,OAAOE,cAAcZ,EAAEpG,EAAO4G,KAAKE,aAO5D9G,EAAOiH,aACTf,EAAaA,EAAWnH,OACrBiB,EAAOiH,WAAWC,KAAO,GAAKlH,EAAOiH,WAAWE,QACjDnH,EAAOiH,WAAWC,KAAOlH,EAAOiH,WAAWE,4BAIxC,CAAE3H,KAAM0G,EAAYH,MAAOD,EAAQ7H,iHEtGxCmJ,EAAgB,SAAAC,OAElBC,EADEC,EAAa,MAEbF,EAAY,WACQA,kCAAY,KAAzBG,UAELF,EADEE,EAAUnE,SAAS,KACRmE,EAAU3I,MAAM,KAAK4I,UAErB,CAACD,GAEhBD,SACKA,GACAD,EAAWjC,QACZ,SAACqC,EAAaC,eACXA,cACW,SACPD,MAGP,2CAICH,ICvBLK,EAAgB,SAACzB,EAAM0B,MACvB1B,EAAK2B,WAAW,YAAc3B,EAAK2B,WAAW,mBAEzC3B,EACF,GAAa,MAATA,QAEF,0DAEiBA,EAAKtH,MAAM,QAA5BkJ,OAAQC,UACXA,EAAO,KACHC,EAAWJ,EAAW1G,MAAK,SAAA8G,UAAYA,EAASF,SAAWA,QAC7DE,SACKA,EAASC,IAAMF,QAEhB,IAAItI,MAAM,iCAAmCqI,SAG/C,IAAIrI,2BAAoByG,oECX9BgC,EAAYC,SAChBC,WAAS,MACTC,YAAU,mDACVD,WAAS,SAGLE,EAAiB,SAACjB,EAAYO,OAC9BW,EAViBR,SAWjBV,GACFkB,GAZmBR,EAYUV,EAZCU,EAAaxH,MAAMC,QAAQuH,GAASA,EAAQ,CAACA,GAArC,IAYG1E,KAAI,SAACqE,EAAWpJ,UACvD6J,SAAOC,WAAS,MAAOC,YAAUV,EAAcD,EAAWE,IAAcQ,WAAS,KAAO9J,EAAI,QAEvF,CACLkK,WAAYN,YAAcK,IAC1BE,OAAQP,YAAcK,EAAYlF,KAAI,SAAA8E,SAAW,CAAE9F,KAAM,WAAYqG,SAAU,CAACP,WAI3E,CACLK,UAFFD,EAAc,CAACJ,SAAOC,WAAS,MAAOA,WAAS,MAAOA,WAAS,QAG7DK,MAAOF,uBC1BX,IAoBGI,EAjBH3J,UAiBG2J,EAAWA,GAAa,SAAUC,EAAMC,OAEpCC,KAGkB,oBAAXC,QAA0BA,OAAOD,SACxCA,EAASC,OAAOD,QAIA,oBAATE,MAAwBA,KAAKF,SACpCA,EAASE,KAAKF,QAIQ,oBAAfG,YAA8BA,WAAWH,SAChDA,EAASG,WAAWH,SAInBA,GAA4B,oBAAXC,QAA0BA,OAAOG,WACnDJ,EAASC,OAAOG,WAIfJ,QAA4B,IAAXK,GAA0BA,EAAOL,SACnDA,EAASK,EAAOL,SAIfA,MAEGA,EAASM,UACX,MAAOC,QAQTC,EAAwB,cACpBR,EAAQ,IAE8B,mBAA3BA,EAAOS,2BAEHT,EAAOS,gBAAgB,IAAIC,YAAY,IAAI,GACpD,MAAOH,OAIqB,mBAAvBP,EAAOW,uBAEHX,EAAOW,YAAY,GAAGC,cAC/B,MAAOL,WAIX,IAAI5J,MAAM,wEAOhBsE,EAAShD,OAAOgD,QAAW,oBAClB4F,YAEF,SAAUC,OACTC,SAEJF,EAAEG,UAAYF,EAEdC,EAAU,IAAIF,EAEdA,EAAEG,UAAY,KAEPD,GAZgB,GAmB3BE,EAAI,GAKJC,EAAQD,EAAEE,IAAM,GAKhBC,EAAOF,EAAME,KAGN,CAmBHC,OAAQ,SAAUC,OAEVP,EAAU9F,EAAOnG,aAGjBwM,GACAP,EAAQQ,MAAMD,GAIbP,EAAQjH,eAAe,SAAWhF,KAAK0M,OAAST,EAAQS,OACzDT,EAAQS,KAAO,WACXT,EAAQU,OAAOD,KAAKtE,MAAMpI,KAAMiB,aAKxCgL,EAAQS,KAAKR,UAAYD,EAGzBA,EAAQU,OAAS3M,KAEViM,GAeX9F,OAAQ,eACAyG,EAAW5M,KAAKuM,gBACpBK,EAASF,KAAKtE,MAAMwE,EAAU3L,WAEvB2L,GAeXF,KAAM,aAcND,MAAO,SAAUI,OACR,IAAIC,KAAgBD,EACjBA,EAAW7H,eAAe8H,UACrBA,GAAgBD,EAAWC,IAKpCD,EAAW7H,eAAe,mBACrB+H,SAAWF,EAAWE,WAanCC,MAAO,kBACIhN,KAAK0M,KAAKR,UAAUK,OAAOvM,QAW1CiN,EAAYb,EAAMa,UAAYX,EAAKC,OAAO,CAa1CG,KAAM,SAAUQ,EAAOC,GACnBD,EAAQlN,KAAKkN,MAAQA,GAAS,QAGrBC,SA7OO,MA4OZA,EACgBA,EAEe,EAAfD,EAAM9M,QAiB9B2M,SAAU,SAAUK,UACRA,GAAWC,GAAK5G,UAAUzG,OActCmI,OAAQ,SAAUmF,OAEVC,EAAYvN,KAAKkN,MACjBM,EAAYF,EAAUJ,MACtBO,EAAezN,KAAKmN,SACpBO,EAAeJ,EAAUH,iBAGxBQ,QAGDF,EAAe,MAEV,IAAI/M,EAAI,EAAGA,EAAIgN,EAAchN,IAAK,KAC/BkN,EAAYJ,EAAU9M,IAAM,KAAQ,GAAMA,EAAI,EAAK,EAAM,IAC7D6M,EAAWE,EAAe/M,IAAO,IAAMkN,GAAa,IAAOH,EAAe/M,GAAK,EAAK,WAInF,IAAImN,EAAI,EAAGA,EAAIH,EAAcG,GAAK,EACnCN,EAAWE,EAAeI,IAAO,GAAKL,EAAUK,IAAM,eAGzDV,UAAYO,EAGV1N,MAUX2N,MAAO,eAECT,EAAQlN,KAAKkN,MACbC,EAAWnN,KAAKmN,SAGpBD,EAAMC,IAAa,IAAM,YAAe,GAAMA,EAAW,EAAK,EAC9DD,EAAM9M,OAAS4K,EAAK8C,KAAKX,EAAW,IAYxCH,MAAO,eACCA,EAAQV,EAAKU,MAAM7L,KAAKnB,aAC5BgN,EAAME,MAAQlN,KAAKkN,MAAMhM,MAAM,GAExB8L,GAgBXe,OAAQ,SAAUC,WACVd,EAAQ,GAEHxM,EAAI,EAAGA,EAAIsN,EAAQtN,GAAK,EAC7BwM,EAAMtM,KAAK8K,YAGR,IAAIuB,EAAUP,KAAKQ,EAAOc,MAOrCC,EAAQ9B,EAAE+B,IAAM,GAKhBb,EAAMY,EAAMZ,IAAM,CAclB5G,UAAW,SAAU6G,WAEbJ,EAAQI,EAAUJ,MAClBC,EAAWG,EAAUH,SAGrBgB,EAAW,GACNzN,EAAI,EAAGA,EAAIyM,EAAUzM,IAAK,KAC3B0N,EAAQlB,EAAMxM,IAAM,KAAQ,GAAMA,EAAI,EAAK,EAAM,IACrDyN,EAASvN,MAAMwN,IAAS,GAAGrB,SAAS,KACpCoB,EAASvN,MAAa,GAAPwN,GAAarB,SAAS,YAGlCoB,EAASrN,KAAK,KAgBzBuN,MAAO,SAAUC,WAETC,EAAeD,EAAOlO,OAGtB8M,EAAQ,GACHxM,EAAI,EAAGA,EAAI6N,EAAc7N,GAAK,EACnCwM,EAAMxM,IAAM,IAAM8N,SAASF,EAAOG,OAAO/N,EAAG,GAAI,KAAQ,GAAMA,EAAI,EAAK,SAGpE,IAAIuM,EAAUP,KAAKQ,EAAOqB,EAAe,KAOpDG,EAAST,EAAMS,OAAS,CAcxBjI,UAAW,SAAU6G,WAEbJ,EAAQI,EAAUJ,MAClBC,EAAWG,EAAUH,SAGrBwB,EAAc,GACTjO,EAAI,EAAGA,EAAIyM,EAAUzM,IAAK,KAC3B0N,EAAQlB,EAAMxM,IAAM,KAAQ,GAAMA,EAAI,EAAK,EAAM,IACrDiO,EAAY/N,KAAKgO,OAAOC,aAAaT,WAGlCO,EAAY7N,KAAK,KAgB5BuN,MAAO,SAAUS,WAETC,EAAkBD,EAAU1O,OAG5B8M,EAAQ,GACHxM,EAAI,EAAGA,EAAIqO,EAAiBrO,IACjCwM,EAAMxM,IAAM,KAAiC,IAA1BoO,EAAUE,WAAWtO,KAAe,GAAMA,EAAI,EAAK,SAGnE,IAAIuM,EAAUP,KAAKQ,EAAO6B,KAOrCE,EAAOhB,EAAMgB,KAAO,CAcpBxI,UAAW,SAAU6G,cAEN4B,mBAAmBC,OAAOT,EAAOjI,UAAU6G,KACpD,MAAO8B,SACC,IAAIvN,MAAM,0BAiBxBwM,MAAO,SAAUgB,UACNX,EAAOL,MAAMiB,SAASC,mBAAmBF,OAWpDG,EAAyBpD,EAAMoD,uBAAyBlD,EAAKC,OAAO,CAQpEkD,MAAO,gBAEEC,MAAQ,IAAIzC,EAAUP,UACtBiD,YAAc,GAavBC,QAAS,SAAUjO,GAEI,iBAARA,IACPA,EAAOsN,EAAKZ,MAAM1M,SAIjB+N,MAAMvH,OAAOxG,QACbgO,aAAehO,EAAKwL,UAiB7B0C,SAAU,SAAUC,OACZC,EAGApO,EAAO3B,KAAK0P,MACZM,EAAYrO,EAAKuL,MACjB+C,EAAetO,EAAKwL,SACpB+C,EAAYlQ,KAAKkQ,UAIjBC,EAAeF,GAHc,EAAZC,GAcjBE,GARAD,EAFAL,EAEe9E,EAAK8C,KAAKqC,GAIVnF,EAAKqF,KAAoB,EAAfF,GAAoBnQ,KAAKsQ,eAAgB,IAIrCJ,EAG7BK,EAAcvF,EAAKwF,IAAkB,EAAdJ,EAAiBH,MAGxCG,EAAa,KACR,IAAIK,EAAS,EAAGA,EAASL,EAAaK,GAAUP,OAE5CQ,gBAAgBV,EAAWS,GAIpCV,EAAiBC,EAAUW,OAAO,EAAGP,GACrCzO,EAAKwL,UAAYoD,SAId,IAAItD,EAAUP,KAAKqD,EAAgBQ,IAY9CvD,MAAO,eACCA,EAAQV,EAAKU,MAAM7L,KAAKnB,aAC5BgN,EAAM0C,MAAQ1P,KAAK0P,MAAM1C,QAElBA,GAGXsD,eAAgB,IAQPlE,EAAMwE,OAASpB,EAAuBjD,OAAO,CAItDsE,IAAKvE,EAAKC,SAWVG,KAAM,SAAUmE,QAEPA,IAAM7Q,KAAK6Q,IAAItE,OAAOsE,QAGtBpB,SAUTA,MAAO,WAEHD,EAAuBC,MAAMtO,KAAKnB,WAG7B8Q,YAeTC,OAAQ,SAAUC,eAETpB,QAAQoB,QAGRnB,WAGE7P,MAiBXiR,SAAU,SAAUD,UAEZA,QACKpB,QAAQoB,GAINhR,KAAKkR,eAKpBhB,UAAW,GAeXiB,cAAe,SAAUC,UACd,SAAUC,EAASR,UACf,IAAIO,EAAO1E,KAAKmE,GAAKI,SAASI,KAiB7CC,kBAAmB,SAAUF,UAClB,SAAUC,EAAS9N,UACf,IAAIgO,EAAOC,KAAK9E,KAAK0E,EAAQ7N,GAAK0N,SAASI,WAQ1DE,EAASpF,EAAEsF,KAAO,UAEftF,EA5wBiB,CA6wB1BnB,4BCjyBD,IAagBD,EAVhB3J,WAUgB2J,EAVmBS,WAYzBR,OAEHmB,EAAIpB,EACJqB,EAAQD,EAAEE,IACVY,EAAYb,EAAMa,UAClB2D,EAASxE,EAAMwE,OACfW,EAASpF,EAAEsF,KAGXC,EAAI,mBAIC,IAAIhR,EAAI,EAAGA,EAAI,GAAIA,IACpBgR,EAAEhR,GAAkC,WAA5BsK,EAAK2G,IAAI3G,EAAK4G,IAAIlR,EAAI,IAAqB,SAOvDmR,EAAMN,EAAOM,IAAMjB,EAAOrE,OAAO,CACjCuE,SAAU,gBACDgB,MAAQ,IAAI7E,EAAUP,KAAK,CAC5B,WAAY,WACZ,WAAY,aAIpBgE,gBAAiB,SAAUqB,EAAGtB,OAErB,IAAI/P,EAAI,EAAGA,EAAI,GAAIA,IAAK,KAErBsR,EAAWvB,EAAS/P,EACpBuR,EAAaF,EAAEC,GAEnBD,EAAEC,GACgD,UAA3CC,GAAc,EAAOA,IAAe,IACO,YAA3CA,GAAc,GAAOA,IAAe,OAK3CC,EAAIlS,KAAK8R,MAAM5E,MAEfiF,EAAcJ,EAAEtB,EAAS,GACzB2B,EAAcL,EAAEtB,EAAS,GACzB4B,EAAcN,EAAEtB,EAAS,GACzB6B,EAAcP,EAAEtB,EAAS,GACzB8B,EAAcR,EAAEtB,EAAS,GACzB+B,EAAcT,EAAEtB,EAAS,GACzBgC,EAAcV,EAAEtB,EAAS,GACzBiC,EAAcX,EAAEtB,EAAS,GACzBkC,EAAcZ,EAAEtB,EAAS,GACzBmC,EAAcb,EAAEtB,EAAS,GACzBoC,EAAcd,EAAEtB,EAAS,IACzBqC,EAAcf,EAAEtB,EAAS,IACzBsC,EAAchB,EAAEtB,EAAS,IACzBuC,EAAcjB,EAAEtB,EAAS,IACzBwC,EAAclB,EAAEtB,EAAS,IACzByC,EAAcnB,EAAEtB,EAAS,IAGzBlI,EAAI2J,EAAE,GACNlJ,EAAIkJ,EAAE,GACNiB,EAAIjB,EAAE,GACNkB,EAAIlB,EAAE,GAGV3J,EAAI8K,EAAG9K,EAAGS,EAAGmK,EAAGC,EAAGjB,EAAa,EAAIT,EAAE,IACtC0B,EAAIC,EAAGD,EAAG7K,EAAGS,EAAGmK,EAAGf,EAAa,GAAIV,EAAE,IACtCyB,EAAIE,EAAGF,EAAGC,EAAG7K,EAAGS,EAAGqJ,EAAa,GAAIX,EAAE,IACtC1I,EAAIqK,EAAGrK,EAAGmK,EAAGC,EAAG7K,EAAG+J,EAAa,GAAIZ,EAAE,IACtCnJ,EAAI8K,EAAG9K,EAAGS,EAAGmK,EAAGC,EAAGb,EAAa,EAAIb,EAAE,IACtC0B,EAAIC,EAAGD,EAAG7K,EAAGS,EAAGmK,EAAGX,EAAa,GAAId,EAAE,IACtCyB,EAAIE,EAAGF,EAAGC,EAAG7K,EAAGS,EAAGyJ,EAAa,GAAIf,EAAE,IACtC1I,EAAIqK,EAAGrK,EAAGmK,EAAGC,EAAG7K,EAAGmK,EAAa,GAAIhB,EAAE,IACtCnJ,EAAI8K,EAAG9K,EAAGS,EAAGmK,EAAGC,EAAGT,EAAa,EAAIjB,EAAE,IACtC0B,EAAIC,EAAGD,EAAG7K,EAAGS,EAAGmK,EAAGP,EAAa,GAAIlB,EAAE,IACtCyB,EAAIE,EAAGF,EAAGC,EAAG7K,EAAGS,EAAG6J,EAAa,GAAInB,EAAE,KACtC1I,EAAIqK,EAAGrK,EAAGmK,EAAGC,EAAG7K,EAAGuK,EAAa,GAAIpB,EAAE,KACtCnJ,EAAI8K,EAAG9K,EAAGS,EAAGmK,EAAGC,EAAGL,EAAa,EAAIrB,EAAE,KACtC0B,EAAIC,EAAGD,EAAG7K,EAAGS,EAAGmK,EAAGH,EAAa,GAAItB,EAAE,KACtCyB,EAAIE,EAAGF,EAAGC,EAAG7K,EAAGS,EAAGiK,EAAa,GAAIvB,EAAE,KAGtCnJ,EAAI+K,EAAG/K,EAFPS,EAAIqK,EAAGrK,EAAGmK,EAAGC,EAAG7K,EAAG2K,EAAa,GAAIxB,EAAE,KAEzByB,EAAGC,EAAGhB,EAAa,EAAIV,EAAE,KACtC0B,EAAIE,EAAGF,EAAG7K,EAAGS,EAAGmK,EAAGV,EAAa,EAAIf,EAAE,KACtCyB,EAAIG,EAAGH,EAAGC,EAAG7K,EAAGS,EAAG8J,EAAa,GAAIpB,EAAE,KACtC1I,EAAIsK,EAAGtK,EAAGmK,EAAGC,EAAG7K,EAAG4J,EAAa,GAAIT,EAAE,KACtCnJ,EAAI+K,EAAG/K,EAAGS,EAAGmK,EAAGC,EAAGZ,EAAa,EAAId,EAAE,KACtC0B,EAAIE,EAAGF,EAAG7K,EAAGS,EAAGmK,EAAGN,EAAa,EAAInB,EAAE,KACtCyB,EAAIG,EAAGH,EAAGC,EAAG7K,EAAGS,EAAGkK,EAAa,GAAIxB,EAAE,KACtC1I,EAAIsK,EAAGtK,EAAGmK,EAAGC,EAAG7K,EAAGgK,EAAa,GAAIb,EAAE,KACtCnJ,EAAI+K,EAAG/K,EAAGS,EAAGmK,EAAGC,EAAGR,EAAa,EAAIlB,EAAE,KACtC0B,EAAIE,EAAGF,EAAG7K,EAAGS,EAAGmK,EAAGF,EAAa,EAAIvB,EAAE,KACtCyB,EAAIG,EAAGH,EAAGC,EAAG7K,EAAGS,EAAGsJ,EAAa,GAAIZ,EAAE,KACtC1I,EAAIsK,EAAGtK,EAAGmK,EAAGC,EAAG7K,EAAGoK,EAAa,GAAIjB,EAAE,KACtCnJ,EAAI+K,EAAG/K,EAAGS,EAAGmK,EAAGC,EAAGJ,EAAa,EAAItB,EAAE,KACtC0B,EAAIE,EAAGF,EAAG7K,EAAGS,EAAGmK,EAAGd,EAAa,EAAIX,EAAE,KACtCyB,EAAIG,EAAGH,EAAGC,EAAG7K,EAAGS,EAAG0J,EAAa,GAAIhB,EAAE,KAGtCnJ,EAAIgL,EAAGhL,EAFPS,EAAIsK,EAAGtK,EAAGmK,EAAGC,EAAG7K,EAAGwK,EAAa,GAAIrB,EAAE,KAEzByB,EAAGC,EAAGZ,EAAa,EAAId,EAAE,KACtC0B,EAAIG,EAAGH,EAAG7K,EAAGS,EAAGmK,EAAGR,EAAa,GAAIjB,EAAE,KACtCyB,EAAII,EAAGJ,EAAGC,EAAG7K,EAAGS,EAAG8J,EAAa,GAAIpB,EAAE,KACtC1I,EAAIuK,EAAGvK,EAAGmK,EAAGC,EAAG7K,EAAG0K,EAAa,GAAIvB,EAAE,KACtCnJ,EAAIgL,EAAGhL,EAAGS,EAAGmK,EAAGC,EAAGhB,EAAa,EAAIV,EAAE,KACtC0B,EAAIG,EAAGH,EAAG7K,EAAGS,EAAGmK,EAAGZ,EAAa,GAAIb,EAAE,KACtCyB,EAAII,EAAGJ,EAAGC,EAAG7K,EAAGS,EAAG0J,EAAa,GAAIhB,EAAE,KACtC1I,EAAIuK,EAAGvK,EAAGmK,EAAGC,EAAG7K,EAAGsK,EAAa,GAAInB,EAAE,KACtCnJ,EAAIgL,EAAGhL,EAAGS,EAAGmK,EAAGC,EAAGJ,EAAa,EAAItB,EAAE,KACtC0B,EAAIG,EAAGH,EAAG7K,EAAGS,EAAGmK,EAAGhB,EAAa,GAAIT,EAAE,KACtCyB,EAAII,EAAGJ,EAAGC,EAAG7K,EAAGS,EAAGsJ,EAAa,GAAIZ,EAAE,KACtC1I,EAAIuK,EAAGvK,EAAGmK,EAAGC,EAAG7K,EAAGkK,EAAa,GAAIf,EAAE,KACtCnJ,EAAIgL,EAAGhL,EAAGS,EAAGmK,EAAGC,EAAGR,EAAa,EAAIlB,EAAE,KACtC0B,EAAIG,EAAGH,EAAG7K,EAAGS,EAAGmK,EAAGJ,EAAa,GAAIrB,EAAE,KACtCyB,EAAII,EAAGJ,EAAGC,EAAG7K,EAAGS,EAAGkK,EAAa,GAAIxB,EAAE,KAGtCnJ,EAAIiL,EAAGjL,EAFPS,EAAIuK,EAAGvK,EAAGmK,EAAGC,EAAG7K,EAAG8J,EAAa,GAAIX,EAAE,KAEzByB,EAAGC,EAAGjB,EAAa,EAAIT,EAAE,KACtC0B,EAAII,EAAGJ,EAAG7K,EAAGS,EAAGmK,EAAGT,EAAa,GAAIhB,EAAE,KACtCyB,EAAIK,EAAGL,EAAGC,EAAG7K,EAAGS,EAAGiK,EAAa,GAAIvB,EAAE,KACtC1I,EAAIwK,EAAGxK,EAAGmK,EAAGC,EAAG7K,EAAGiK,EAAa,GAAId,EAAE,KACtCnJ,EAAIiL,EAAGjL,EAAGS,EAAGmK,EAAGC,EAAGL,EAAa,EAAIrB,EAAE,KACtC0B,EAAII,EAAGJ,EAAG7K,EAAGS,EAAGmK,EAAGb,EAAa,GAAIZ,EAAE,KACtCyB,EAAIK,EAAGL,EAAGC,EAAG7K,EAAGS,EAAG6J,EAAa,GAAInB,EAAE,KACtC1I,EAAIwK,EAAGxK,EAAGmK,EAAGC,EAAG7K,EAAG6J,EAAa,GAAIV,EAAE,KACtCnJ,EAAIiL,EAAGjL,EAAGS,EAAGmK,EAAGC,EAAGT,EAAa,EAAIjB,EAAE,KACtC0B,EAAII,EAAGJ,EAAG7K,EAAGS,EAAGmK,EAAGD,EAAa,GAAIxB,EAAE,KACtCyB,EAAIK,EAAGL,EAAGC,EAAG7K,EAAGS,EAAGyJ,EAAa,GAAIf,EAAE,KACtC1I,EAAIwK,EAAGxK,EAAGmK,EAAGC,EAAG7K,EAAGyK,EAAa,GAAItB,EAAE,KACtCnJ,EAAIiL,EAAGjL,EAAGS,EAAGmK,EAAGC,EAAGb,EAAa,EAAIb,EAAE,KACtC0B,EAAII,EAAGJ,EAAG7K,EAAGS,EAAGmK,EAAGL,EAAa,GAAIpB,EAAE,KACtCyB,EAAIK,EAAGL,EAAGC,EAAG7K,EAAGS,EAAGqJ,EAAa,GAAIX,EAAE,KACtC1I,EAAIwK,EAAGxK,EAAGmK,EAAGC,EAAG7K,EAAGqK,EAAa,GAAIlB,EAAE,KAGtCQ,EAAE,GAAMA,EAAE,GAAK3J,EAAK,EACpB2J,EAAE,GAAMA,EAAE,GAAKlJ,EAAK,EACpBkJ,EAAE,GAAMA,EAAE,GAAKiB,EAAK,EACpBjB,EAAE,GAAMA,EAAE,GAAKkB,EAAK,GAGxBlC,YAAa,eAELvP,EAAO3B,KAAK0P,MACZM,EAAYrO,EAAKuL,MAEjBuG,EAAgC,EAAnBzT,KAAK2P,YAClB+D,EAA4B,EAAhB/R,EAAKwL,SAGrB6C,EAAU0D,IAAc,IAAM,KAAS,GAAKA,EAAY,OAEpDC,EAAc3I,EAAK4I,MAAMH,EAAa,YACtCI,EAAcJ,EAClBzD,EAA4C,IAA/B0D,EAAY,KAAQ,GAAM,IACa,UAA7CC,GAAe,EAAOA,IAAgB,IACO,YAA7CA,GAAe,GAAOA,IAAgB,GAE7C3D,EAA4C,IAA/B0D,EAAY,KAAQ,GAAM,IACa,UAA7CG,GAAe,EAAOA,IAAgB,IACO,YAA7CA,GAAe,GAAOA,IAAgB,GAG7ClS,EAAKwL,SAAoC,GAAxB6C,EAAU5P,OAAS,QAG/ByP,mBAGDiE,EAAO9T,KAAK8R,MACZI,EAAI4B,EAAK5G,MAGJxM,EAAI,EAAGA,EAAI,EAAGA,IAAK,KAEpBqT,EAAM7B,EAAExR,GAEZwR,EAAExR,GAAqC,UAA7BqT,GAAO,EAAOA,IAAQ,IACO,YAA7BA,GAAO,GAAOA,IAAQ,UAI7BD,GAGX9G,MAAO,eACCA,EAAQ4D,EAAO5D,MAAM7L,KAAKnB,aAC9BgN,EAAM8E,MAAQ9R,KAAK8R,MAAM9E,QAElBA,cAINqG,EAAG9K,EAAGS,EAAGmK,EAAGC,EAAGY,EAAGC,EAAGC,OACtBC,EAAI5L,GAAMS,EAAImK,GAAOnK,EAAIoK,GAAMY,EAAIE,SAC9BC,GAAKF,EAAME,IAAO,GAAKF,GAAOjL,WAGlCsK,EAAG/K,EAAGS,EAAGmK,EAAGC,EAAGY,EAAGC,EAAGC,OACtBC,EAAI5L,GAAMS,EAAIoK,EAAMD,GAAKC,GAAMY,EAAIE,SAC9BC,GAAKF,EAAME,IAAO,GAAKF,GAAOjL,WAGlCuK,EAAGhL,EAAGS,EAAGmK,EAAGC,EAAGY,EAAGC,EAAGC,OACtBC,EAAI5L,GAAKS,EAAImK,EAAIC,GAAKY,EAAIE,SACrBC,GAAKF,EAAME,IAAO,GAAKF,GAAOjL,WAGlCwK,EAAGjL,EAAGS,EAAGmK,EAAGC,EAAGY,EAAGC,EAAGC,OACtBC,EAAI5L,GAAK4K,GAAKnK,GAAKoK,IAAMY,EAAIE,SACxBC,GAAKF,EAAME,IAAO,GAAKF,GAAOjL,EAiB3CmD,EAAE0F,IAAMjB,EAAOO,cAAcU,GAgB7B1F,EAAEiI,QAAUxD,EAAOU,kBAAkBO,IACvC7G,MAGKD,EAAS8G,QCnPXwC,EAAwB,SAAAC,UAAQC,EAAID,IAEpCE,EAAgB,SAAAF,UAAQA,EAAK9O,SAAS,MAAQ8O,EAAKtT,MAAM,KAAK,IAE9DyT,EAAe,SAAAH,UAASA,EAAK9O,SAAS,KAAO8O,EAAKtT,MAAM,KAAK,GAAKsT,GAElEI,EAAkB,SAAAC,UACtBA,EAAQlP,KAAI,SAAAmP,OACNC,EAAUD,EAAEE,MACVC,EAAcJ,EAAQrR,MAAK,SAAA0R,UAAMJ,EAAEK,aAAeD,EAAGV,oBACvCrJ,IAAhB8J,IACFF,EAAUA,EAAQ1M,OAAO4M,EAAYD,MAAM,KAEtC,CACLrQ,KAAM,MACNoQ,QAAAA,OAIAK,GAAuB,SAAC1L,EAAY2L,EAAWnL,OAC/C2K,EAAU,GACRS,EAtCa,SAAA5L,OACf4L,EAAQ,MACR5L,EAAY,WACQA,kCAAY,KAAzBM,aACHA,EAAUtE,SAAS,aACf6P,EAAYvL,EAAU9I,MAAM,KACzBN,EAAI,EAAGA,GAAK2U,EAAUjV,OAAQM,IACrC0U,EAAMxU,KAAKyU,EAAUnU,MAAM,EAAGR,GAAGI,KAAK,WAGxCsU,EAAMxU,KAAKkJ,0CAIVsL,EAwBOE,CAAa9L,MAEvB4L,GAASpL,GAAcA,EAAW5J,OAAS,EAAG,WAC/BgV,kCAAO,KAAfd,UACDW,EAAaT,EAAcF,GAC3BxK,EAAY2K,EAAaH,GACzBiB,EAAUlB,EAAsBC,GAChCkB,EAAgBP,EAAaZ,EAAsBY,GAAc,IAEjEH,EAAQ,CACZvK,SAAOC,WAAS,IAAMgL,GAAgB/K,YAAUV,EAAcD,EAAWE,IAAcQ,WAAS,IAAM+K,IACtGhL,SAAOC,WAAS,IAAM+K,GAAU/K,WAAS,IAAM+K,GAAU/K,WAAS,IAAM+K,KAG1EZ,EAAQ/T,KAAK,CACX0T,KAAAA,EACAW,WAAAA,EACAH,MAAAA,EACAnP,OAAQ,0CAIL,CACLiF,UAAW+J,EAAQvU,OAAS,EAAIuU,EAAQlP,KAAI,SAAAmP,UAAKA,EAAEE,SAAOtN,QAAO,SAACiO,EAAKC,UAAQD,EAAItN,OAAOuN,MAAQ,KAClG7K,MAAO,CACLpG,KAAM,QACNqG,UAAWqK,EAAUtK,gBAAU6J,EAAgBC,aAI5C,CACL/J,UAAW,GACXC,MAAO,KCvEL8K,GAAyCC,UAAzCD,QAASlL,GAAgCmL,UAAhCnL,UAAWF,GAAqBqL,UAArBrL,OAAQC,GAAaoL,UAAbpL,SAG9BqL,GAAY,IAAIC,EADEtK,QAAQ,YAAYuK,WACN,IAIhCC,GAAqB,CAAC,IAAK,cAAe,aAAc,WAAY,eAEpEC,GAAmB,gBAAG3Q,IAAAA,WAAsBK,IAAVxD,OAAUwD,OAAU6D,IAAAA,WAAYC,IAAAA,WAAYO,IAAAA,WAC5EmL,EAAYzK,EAAejB,EAAYO,GAEzCkM,EAAiB,CACnBC,UAAW,YACXC,SAAUjB,EAAUvK,UACpBC,MAAO,GACPpG,KAAM,QACN4R,SAAUlT,OAAOuE,YAAYsC,EAAWvE,KAAI,SAAA2E,SAAY,CAACA,EAASF,OAAQE,EAASC,UAGjFiM,EAAiB,CACnB,CACE7R,KAAM,SACN6B,OAAQhB,EAAWG,KAAI,SAAAQ,SAAiB,iBAAmBwE,GAAUxE,QAEvEsE,GAAOC,GAAS,gBAAiBC,GAAU,qCAAsCD,GAAS,OAC1F,CACE/F,KAAM,SACN8R,WAAY,CACV9R,KAAM,YACN+R,SAAU,QACVC,KAAM,CAACjM,GAAS,UAKlBkM,EAAgB,MAEhB/Q,GAAUxC,OAAOC,KAAKuC,GAAQvF,OAAS,EAAG,KACtCuW,EAAkBhR,EAAOiR,aAAezT,OAAOC,KAAKuC,EAAOiR,aAAaxW,OAAS,EACjFyW,EAAoBlR,EAAOiP,GAAKjP,EAAOiP,EAAExU,OAAS,EAEpDuW,MAeCxO,OAAOxC,EAAOiR,aAAa/Q,SAAQ,SAAAiR,GACpCJ,EAAc9V,KAAKkW,MAInBD,GACFH,EAAc9V,KAAK,CACjB6D,KAAM,QACNqG,SAAU,CACR,CACEqL,UAAW,SACXY,UAAW,CAACvM,GAAS,OACrBK,MAAO,CACLN,GAAOC,GAAS,MAAOA,GAAS,MAAOA,GAAS,OAChD,CACE/F,KAAM,SACN8R,WAAY,CACV9R,KAAM,YACN+R,SAAU,YACVC,KAAM,CAACjM,GAAS,SAGpB,CACE/F,KAAM,SACN8R,WAAY,CACV9R,KAAM,YACN+R,SAAU,QACVC,KAAM,CACJ,CACEhS,KAAM,YACN+R,SAAU,QACVC,KAAM,CACJ,CACEhS,KAAM,YACN+R,SAAU,MACVC,KAAM,CAACjM,GAAS,UAItBmL,GAAQhQ,EAAOiP,EAAEoC,cAAe,GAAIvM,GAAU,gDAKtDhG,KAAM,YASdtB,OAAOqF,QAAQ7C,GAAQE,SAAQ,yBAAEiE,OAAWmN,OACrCjB,GAAmBxQ,SAASsE,IAC/B4M,EAAcQ,QACZ3M,GACEC,GAAS,MACTC,GAAUV,EAAcD,EAAWE,IACnCS,GAAUV,EAAckN,EAAQjN,aAQpCmN,EAAkBjC,GAAqB1L,EAAY2L,EAAWnL,UAChEmN,GAAmBA,EAAgBvM,WACrC8L,EAAgBA,EAAcvO,OAAOgP,EAAgBtM,OACrDqL,EAAeE,SAAWF,EAAeE,SAASjO,OAAOgP,EAAgBvM,YAEzE8L,EAAc9V,KAAKuU,EAAUtK,OAG/BqL,EAAerL,MAAMjK,KACnB,CACE6D,KAAM,QACNqG,SAAU,CACRwL,EACA,CACE7R,KAAM,QACNN,KAAMsG,GAAU,6BAChBK,SAAUwL,KAIhB,CACE7R,KAAM,QACNqG,SAAU,CACR4L,EACA,CACEjS,KAAM,QACNN,KAAMsG,GAAU,6BAChBK,SAAU4L,MAMXb,GAAUpP,UAAUyP,IChKvBkB,GAA+B,SAAC9R,EAAYjC,WAC1CmG,EAAa,SACGrG,OAAOC,KAAKC,kBAAc,KAAvCH,UACHG,EAAYH,GAAWsG,yBACArG,OAAOC,KAAKC,EAAYH,GAAWsG,2BAAa,KAAhEvD,OACHX,EAAWE,SAASS,IACtBuD,EAAW5I,WAAX4I,IAAmBnG,EAAYH,GAAWsG,WAAWvD,eAMlD,IAAIoR,IAAI7N,qBCRf8N,GAAU,SAAC/O,EAAGS,YACHT,QACR,gBACIA,EAAEY,cAAcH,OACpB,aACA,gBACIT,EAAIS,iBAEJ,IAIPuO,+CAAuB,WAAOjS,EAAYpD,EAAYC,EAAQX,kHAC1D6B,EAAgE7B,EAAhE6B,YAAajB,EAAmDZ,EAAnDY,UAAWX,EAAwCD,EAAxCC,WAAYC,EAA4BF,EAA5BE,YAAasI,EAAexI,EAAfwI,WACnD3H,EAAYD,EAAUF,GAEtBsV,EAAsBrU,OAAOC,KAAKkC,GAAYG,KAClD,SAAAvC,UACE,IAAI6E,SAAQ,SAAC0P,EAASC,mBACdlO,aACJrH,EAAOwD,6BAAQ6D,wBACfnH,EAAUC,yBAAVC,EAAgBiH,aAChB4N,GAA6B9R,EAAWpC,GAAYG,GAEhDoG,aAAatH,EAAOwD,6BAAQgS,yBAAetV,EAAUC,yBAAVG,EAAgBgH,sBAI/DtH,EAAOwD,uBAAQiR,cACuB,iBAA9BzU,EAAOwD,OAAOiR,aAA4BzU,EAAOwD,OAAOiR,uBAAuBhI,UAEvFzM,EAAOwD,OAAOiR,YAAcpQ,KAAK6H,MAAMa,mBAAmB/M,EAAOwD,OAAOiR,mBAEpEgB,EAAc3B,GAAiB,CACnC3Q,WAAYA,EAAWpC,GACvBf,cAAaA,OAAQwD,wBAAatD,EAAUC,yBAAVuV,EAAgBlS,QAAWxD,EAAOwD,UACpE6D,WAAAA,EACAC,WAAAA,EACAO,WAAAA,IAGFvI,EAAW4B,EAAYH,GAAW4U,eAAgB,CAChDjU,OAAQ,OACRC,KAAM8T,IAELhQ,MAAK,kBAAGhG,IAAAA,KAIDmW,GACuC,eAA3C1V,EAAUC,2BAAM0V,sCAEEtW,UACHW,EAAU+C,eACT,UACPmE,EAAcC,IAEnB,YACc9H,UACHW,EAAU+C,cAIpBrD,UAAOgW,MAAMnW,EAAMmW,EAAO,CAAEE,WAAW,OAE/CrQ,MAAK,SAAAsQ,MACAA,EAAY,OAAQ,OACmBA,EACzCA,EAAc,cADN,qBAGI,WAGdT,EAAQS,EAAY,WAAa,cAE5B,SAAA9I,UAAKsI,EAAOtI,qBAKPrH,QAAQC,IAAIwP,aAET,KAFnBvP,UAEQ7H,iDACH,CAAEuB,KAAM,GAAIuG,MAAO,mBAG1BD,SAAaE,iBAAUF,IAGnBI,EAAaJ,EAAQxC,KAAI,SAAA6C,UAC3BA,EAAKxG,GAAKwG,EAAKxG,IAAMwG,EAAK,OACnBA,KAILnG,EAAO4G,OACTV,EAAaA,EAAWU,MAAK,SAACR,EAAGS,eACFiC,IAAzB1C,EAAEpG,EAAO4G,KAAKE,aAAiDgC,IAAzBjC,EAAE7G,EAAO4G,KAAKE,OAC5B,QAAtB9G,EAAO4G,KAAKG,MACPoO,GAAQ/O,EAAEpG,EAAO4G,KAAKE,OAAQD,EAAE7G,EAAO4G,KAAKE,QAE5CqO,GAAQtO,EAAE7G,EAAO4G,KAAKE,OAAQV,EAAEpG,EAAO4G,KAAKE,QAG9C,MAIT9G,EAAOiH,aACTf,EAAaA,EAAWnH,OACrBiB,EAAOiH,WAAWC,KAAO,GAAKlH,EAAOiH,WAAWE,QACjDnH,EAAOiH,WAAWC,KAAOlH,EAAOiH,WAAWE,4BAIxC,CAAE3H,KAAM0G,EAAYH,MAAOD,EAAQ7H,iHCtHxC+X,GAA0B,SAACC,EAAO/U,OAClCiC,EAAa,UACjBnC,OAAOC,KAAKgV,GAAOvS,SAAQ,SAAA3C,OACrBG,EAAYH,SAMR,IAAIrB,MAAM,4BAA8BqB,GAL9CoC,EAAWpC,GAAa,GACxBkV,EAAMlV,GAAW2C,SAAQ,SAAAG,GACvBV,EAAWpC,GAAWtC,KAAK6C,EAAQJ,EAAYH,GAAWQ,QAASsC,UAMlEV,GCTH+S,GAAgB,SAAA7W,sDAAU,WAAOU,4HAAYC,iCAAS,GACpDkB,EAA2B7B,EAA3B6B,YAAajB,EAAcZ,EAAdY,UACbC,EAAYD,EAAUF,yBAEN,IAAIL,yBAAkBK,2DAGvCC,EAAOwD,qBAAP2S,EAAeC,oBAAYlW,EAAUC,oBAAVC,EAAgB+C,gCAC1C3C,MAAMC,kBAAQP,EAAUC,yBAAVG,EAAgB6C,kCAC1B,IAAIzD,gDAC2BK,+EAGvCoD,EAAa6S,GAAwB9V,EAAUC,KAAKgD,WAAYjC,2BAGhEiC,EAAaH,EACX9C,EAAU+C,iBACVjD,EAAOwD,6BAAQ4S,sBAAYlW,EAAUC,yBAAVuV,EAAgBW,SAC3CnV,wBAIAhB,EAAUC,oBAAVmW,EAAgBC,yDACXpR,EAAgBhC,EAAYpD,EAAYC,EAAQX,qCAEhD+V,GAAqBjS,EAAYpD,EAAYC,EAAQX,uGC7B1DmX,GAAgB,SAAAnX,sDAAU,WAAOU,EAAYC,kGACzCyW,EAA0BpX,EAA1BoX,+BAEe7Q,QAAQC,IAC7B7F,EAAOgF,IAAI1B,KAAI,SAAA3D,UACbkF,EAAOxF,EAAPwF,CAAe9E,EAAY,CAAEJ,GAAkB,WAAd+W,EAAO/W,GAAkBA,EAAG,OAASA,IACnE8F,MAAK,qBAAGjG,eACF,cAIDiX,QACK,CAAE9W,GAAAA,EAAIgX,QAAQ,wBAS/BzQ,GAlBIA,UAkBoB1C,QAAO,SAAAyJ,UAAKA,uBAE7B,CAAEzN,KAAM0G,wGCvBX0Q,GAAyB,SAAAvX,sDAAU,WAAOU,EAAYC,0FAC1DA,EAAOwD,cAAcxD,EAAOwD,gBAASxD,EAAO6W,OAAS7W,EAAOL,YACrDK,EAAO6W,gBACDC,GAAQzX,EAARyX,CAAgB/W,EAAYC,+ICHrC+W,GAAe,SAAA1X,sDAAU,WAAOU,EAAYC,kGACxCV,EAA4BD,EAA5BC,WAAYC,EAAgBF,EAAhBE,qBAGAmD,EAAe1C,EAAOR,KAAMH,iBAAhDW,EAAOR,qBAEDF,EAAWU,EAAOL,GAAI,CAC1B+B,OAAQ,MACRC,KAAM0C,KAAKC,wBACG/E,GACTS,EAAOR,yCAIP,CAAEA,KAAMQ,EAAOR,2GCTxB,SAASwX,GAAsB9H,QACtBA,QAAUA,EAGnB8H,GAAsBjN,UAAY,IAAIrK,MACtCsX,GAAsBjN,UAAU/H,KAAO,wBA6BvC,IAAAiV,GAAkC,oBAAXjO,QACnBA,OAAOkO,MACPlO,OAAOkO,KAAKC,KAAKnO,SA7BrB,SAAkBoO,OACV1Y,EAAM+N,OAAO2K,GAAO9Y,QAAQ,MAAO,OACnCI,EAAIT,OAAS,GAAK,EAClB,MAAM,IAAI+Y,GACN,yEAKJ,IAAYK,EAAIC,EAAZC,EAAK,EAAeC,EAAM,EAAGC,EAAS,GAEzCH,EAAS5Y,EAAIgZ,OAAOF,MAEpBF,IACCD,EAAKE,EAAK,EAAS,GAALF,EAAUC,EAASA,EAG/BC,IAAO,GACVE,GAAUhL,OAAOC,aAAa,IAAO2K,KAAS,EAAIE,EAAM,IACzD,EAGAD,EA/BI,oEA+BWK,QAAQL,UAEpBG,2qBClCX,IAAMG,+CAAkB,WAAMvY,kHACpB6B,EAA4B7B,EAA5B6B,YAAa5B,EAAeD,EAAfC,WACfuY,EAAQC,aAAaC,QAAQ,SAC7BC,EAASlV,EAAqB,MAAO5B,GACrC+W,EAAgBnV,EAAqB,aAAc5B,IAGrD2W,4BACgBK,GAAUL,GAApBM,IAAAA,wBAIiB7Y,EAAW6Y,mBAA1B1Y,IAAAA,KACR2Y,EAAW3Y,2DAEX4Y,QAAQC,YAERR,aAAaS,QACbvP,OAAOwP,SAASC,oCAKdT,IAGF3Y,EAAO6B,YAAY8W,GAAQhW,KAAO,SAClC3C,EAAO6B,YAAY8W,GAAQzW,QAAUD,EAAQ6W,EAAO,QACpD9Y,EAAO6B,YAAY8W,GAAQrC,0BACzByC,EAASM,gCAAY,yBAA0BpX,EAAQ6W,EAAO,WAG9DF,IAGF5Y,EAAO6B,YAAY+W,GAAeU,mBAAWP,EAASM,8BAATE,EAAoBD,0ICvCjEE,GAAiB,SAAA7Q,UAAWA,EAAoBxH,MAAMC,QAAQuH,GAASA,EAAQ,CAACA,QAA5Cc,GAEpCgQ,+CAAqB,WAAMzZ,8GACzBmG,EAAgBxE,OAAOqF,QAAQhH,EAAO6B,aACzCsC,QAAO,sCAAkC,SAARuV,OACjCzV,KAAI,yBAAElC,OAAKgD,cACV/E,EACGC,WAAW,IAAI0Z,IAAI,oBAAqB5U,EAAO7C,SAASqJ,YACxDnF,MAAK,SAAAwT,SAAW,CAAE7X,IAAAA,EAAK8X,SAAUD,EAAOxZ,KAAK,qBACvC,SAAAwN,MACY,MAAbA,EAAEzK,QAA+B,MAAbyK,EAAEzK,aACjB,CAAEpB,IAAAA,EAAKkX,MAAOrL,SAEfA,QAKZnH,EAAU,qBAGIF,QAAQC,IAAIL,UAA5BM,qEAKiBA,qCAAVmT,UACP5Z,EAAO6B,YAAY+X,EAAO7X,KAAK+B,WAAa9D,EAAO6B,YAAY+X,EAAO7X,KAAK+B,YAAc,GACzF9D,EAAO6B,YAAY+X,EAAO7X,KAAKiG,WAAahI,EAAO6B,YAAY+X,EAAO7X,KAAKiG,YAAc,GAGrF4R,EAAOC,SAAU,KACCD,EAAOC,mCAAlBC,UACDC,EAAmBpY,OAAOC,KAAK5B,EAAO6B,aAAaC,MACvD,SAAAC,UAAO+X,EAAQ,mBAAqB9Z,EAAO6B,YAAYE,GAAKG,cAI1D6X,EAAkB,CAEhBA,IAAqBH,EAAO7X,MAC9B/B,EAAO6B,YAAY+X,EAAO7X,KAAKY,KAAO3C,EAAO6B,YAAY+X,EAAO7X,KAAKY,MAAQmX,EAAQ,YACrF9Z,EAAO6B,YAAY+X,EAAO7X,KAAKiY,YAC7Bha,EAAO6B,YAAY+X,EAAO7X,KAAKiY,aAAeF,EAAQ,kBACxD9Z,EAAO6B,YAAY+X,EAAO7X,KAAKuU,eAC7BtW,EAAO6B,YAAY+X,EAAO7X,KAAKuU,gBAAkBwD,EAAQ,wBAG7D9Z,EAAO6B,YAAY+X,EAAO7X,KAAK+B,WAAWiW,GACxC/Z,EAAO6B,YAAY+X,EAAO7X,KAAK+B,WAAWiW,IAAqB,aAE3CP,GAAeM,EAAQ,wDAAyB,OAA7DG,cACUT,GAAeS,EAAU,+CAAgB,KAAjDhX,UAEDuB,EAAOyV,EAAU,iBAAiBhb,QAAQ6a,EAAQ,iBAAkB,KACtE9Z,EAAO6B,YAAY+X,EAAO7X,KAAK+B,WAAWiW,GAAkB9W,GAC9DjD,EAAO6B,YAAY+X,EAAO7X,KAAK+B,WAAWiW,GAAkB9W,GAAM7D,KAAKoF,GAEvExE,EAAO6B,YAAY+X,EAAO7X,KAAK+B,WAAWiW,GAAkB9W,GAAQ,CAACuB,GAIpDgV,GAAeS,EAAU,yBAE1Cja,EAAO6B,YAAY+X,EAAO7X,KAAKiG,WAAWiS,EAAU,kBAAoBT,GACtES,EAAU,kSChEtBC,GAAsB,SAACC,EAAKtY,UACzBF,OAAOC,KAAKC,GAAaC,MAAK,SAAAC,UAC/BF,EAAYE,GAAK2X,IAEZ7X,EAAYE,GAAKG,SAAWiY,EAAI1R,WAAW5G,EAAYE,GAAKG,QAAQjD,QAAQ,QAAS,KAErFkb,EAAI1R,WAAW5G,EAAYE,GAAKG,aCJvCkY,GAAU,SAACC,EAAe/W,SACL,mBAAlB+W,EAA+BA,EAAc/W,GAAU+W,GAC1DC,GAAQ,SAAAzR,SAAsB,iBAARA,GAAoBA,EAAIJ,WAAW,SCFzD8R,GAAe,SAAA7Z,OAEb8Z,EAAeC,aAAWC,2BACEC,gBAA3B9Z,OAAW+Z,cAElBC,aAAU,WACRL,EAAa3U,gBAAgBO,MAAK,SAAAK,UAAWmU,EAAanU,EAAQ/F,SACjE,CAAC8Z,EAAc9Z,EAAYka,IAEvB/Z,GCTHia,GAAiB,eAEfN,EAAeC,aAAWC,2BACMC,gBAA/B9Y,OAAakZ,cAEpBF,aAAU,WACRL,EAAa5U,iBAAiBQ,MAAK,SAAAK,UAAWsU,EAAetU,QAC5D,CAAC+T,EAAcO,IAEXlZ,GCVHmZ,GAA+B,SAACpX,EAAOqX,EAAiBpZ,OACxDiC,EAAa,MAEbnC,OAAOC,KAAKC,EAAYoZ,GAAiBnX,WAAWmX,IAAkBrc,OAAS,GACjF+C,OAAOC,KAAKC,EAAYoZ,GAAiBnX,WAAWmX,IAAkB5W,SAAQ,SAAApB,GACxEW,EAAMI,SAASf,IACjBpB,EAAYoZ,GAAiBnX,WAAWmX,GAAiBhY,GAAMgB,KAAI,SAAAO,OAC3DC,EAAexC,EAAQJ,EAAYoZ,GAAiB/Y,QAASsC,GAC9DV,EAAWE,SAASS,IACvBX,EAAW1E,KAAKqF,SAOA,IAAtBX,EAAWlF,aACP,IAAIyB,uDACkC2E,KAAKC,UAC7CrB,gFAGC,GAAIE,EAAWlF,OAAS,QACvB,IAAIyB,kEAC6C2E,KAAKC,UACxDrB,8FAKCE,EAAW,+CCfdoX,GAAgB,gBAAGC,IAAAA,SAAU7X,IAAAA,OAAQa,IAAAA,OAAQiX,IAAAA,OAAWC,cAC5BV,gBAAzBW,OAAUC,cACjBV,aAAU,cACJvX,GAAU8X,GAAUja,MAAMC,QAAQkC,MAAAA,SAAAA,EAAS8X,IAAU,KACjDI,EAAelY,MAAAA,SAAAA,EAAS8X,GAAQjX,QAAO,SAAAyT,OACvC6D,GAAK,MACJ,IAAM1Z,KAAOoC,EAAQ,KAClBwE,EAAQiP,EAAE7V,GACZZ,MAAMC,QAAQuH,GACXA,EAAM3E,SAASG,EAAOpC,MACzB0Z,GAAK,GAGH9S,IAAUxE,EAAOpC,KACnB0Z,GAAK,UAIJA,KAELC,OACCpY,GAGLoY,EAAUN,GAAUI,EAAa5c,OAAS,EAAI4c,OAAe/R,EAC7D8R,EAAYG,MAEb,CAACpY,EAAQ8X,EAAQjX,IAGlBwX,gDACGA,UAAMC,SAAS3X,IAAIkX,GAAU,SAACU,EAAO3c,UAC7Byc,UAAMG,aAAaD,SACrBR,OACH/X,OAAQgY,EACRS,UAAU,EACVX,OAAAA,0HCjDJY,GAA0BC,aAAW,CACzCC,KAAM,CACJC,QAAS,QAEXpE,MAAO,CACLqE,aAAc,UAIZC,GAAqBJ,aAAW,CACpCK,KAAM,CACJH,QAAS,mECqDmB,gBAC9BhB,IAAAA,SACAoB,IAAAA,eACAC,IAAAA,WACAC,IAAAA,YACAC,IAAAA,eACGrB,UAEKlb,EAASwc,oBAAkB,CACjC1Z,KAAM,UACNqD,SAAUiW,EACVK,QAAS,KAHHzc,YAONwb,gDACGxb,MAAAA,SAAAA,EAAM8D,KAAI,SAAC9D,EAAM0c,OACZ1Y,EAAS,UACbA,EAAOuY,GAAkBvc,EAAKG,GAE5Bqb,gDACGc,GAAeA,SAAiBpB,OAAYyB,MAAO3c,KACpDwb,wBAACT,QAAkBG,GAAYlX,OAAQA,EAAQ4Y,MAAO5c,EAAKqc,KACxDrB,uCDxEe,SAAA6B,OACpBC,EAA8CD,EAA9CC,iBAA8CD,EAA5B7B,aAAaE,IAAe2B,MAChDE,EAAkBlB,KAClBmB,EAAkBd,YAGtBV,wBAACyB,aAAe/B,EACdM,wBAAC0B,sBAAmBC,QAAS,CAAEpB,KAAMgB,EAAgBhB,OAClDP,UAAMC,SAAS3X,IAAI+Y,EAAM7B,UAAU,SAACU,EAAO3c,UACnCyc,UAAMG,aAAaD,EAAO,CAC/B0B,UAAWL,EAAgBnF,WAG/B4D,wBAAC6B,aAAUD,UAAWJ,EAAgBb,KAAMlB,OAAO,OAAOqC,aAAcR,wFEjB3D,SAAAjd,OAEdyD,EAAqB,UAAWzD,EAAO6B,aAC1C,MAAM,IAAIxB,MAAM,+DCVD,IAAAwB,EDYZ7B,EAAOE,cAAaF,EAAOE,YAAcyB,OAAOuE,YAAYlG,EAAOwI,WAAWvE,KAAI,SAAA3C,SAAK,CAACA,EAAEoH,OAAQpH,EAAEuH,UACpG7I,EAAOoX,wBAAuBpX,EAAOoX,uBAAwB,GAGlEpX,EAAOC,YChBU4B,EDgBc7B,EAAO6B,YChBN,SAACgH,WAAK6U,yDAAU,GAC1C9E,EAAgBnV,EAAqB,aAAc5B,GACnDH,EAAYwY,GAAoBrR,EAAKhH,GACrC8b,EACJjc,IAAckX,cAAiB/W,EAAY+W,uBAAZgF,EAA4BtE,YAAgD,eAApCzX,EAAYH,yBAAYmc,gBAE5FH,EAAQnb,UAASmb,EAAQnb,QAAU,IAAIC,SAEpCkb,EAAQrb,YACT,WACA,YACA,MACEqb,EAAQnb,QAAQub,IAAI,WAAWJ,EAAQnb,QAAQ8C,IAAI,SAAU,uBAC7DqY,EAAQnb,QAAQub,IAAI,iBAAiBJ,EAAQnb,QAAQ8C,IAAI,eAAgB,iCAG3E,mBAGA,cAEEqY,EAAQnb,QAAQub,IAAI,WAAWJ,EAAQnb,QAAQ8C,IAAI,SAAU,0BAIlEsY,EAAU,KACNI,EAAW,IAAIC,gBAErBD,EAASE,OAAO,KAAMpV,GACtBkV,EAASE,OAAO,SAAUP,EAAQrb,QAAU,OAC5C0b,EAASE,OAAO,UAAWjZ,KAAKC,UAAUtD,OAAOuE,YAAYwX,EAAQnb,QAAQyE,aAEzE0W,EAAQpb,OACNob,EAAQpb,gBAAgBd,KAC1Buc,EAASE,OAAO,OAAQP,EAAQpb,KAAMob,EAAQpb,KAAKK,MAEnDob,EAASE,OAAO,OAAQP,EAAQpb,OAK7B4b,aAAWC,UAAUtc,EAAY+W,GAAeU,SAAU,CAC/DjX,OAAQ,OACRE,QAAS,IAAIC,QAAQ,CACnB4b,+BAAyB3F,aAAaC,QAAQ,YAEhDpW,KAAMyb,OAIJrc,IAAckX,EAAe,KACzBJ,EAAQC,aAAaC,QAAQ,SAC/BF,GAAOkF,EAAQnb,QAAQ8C,IAAI,iCAA2BmT,WAErD0F,aAAWC,UAAUtV,EAAK6U,SDpC7BW,EAAyB9F,GAAgBvY,GACzCse,EAA4B7E,GAAmBzZ,GAE/Cue,EAAuB,SAAAlc,qCAAU,6HAC/Bgc,yBACAC,yBACOjc,4GAGR,CACLoV,QAAS8G,EAAqB1H,GAAc7W,IAC5Cwe,QAASD,EAAqBpH,GAAcnX,IAC5Cye,iBAAkBF,EAAqBhH,GAAuBvX,IAC9DwF,OAAQ+Y,EAAqB9d,EAAaT,IAC1C2E,OAAQ4Z,EAAqB7Z,EAAa1E,IAC1CuP,OAAQgP,EAAqB7G,GAAa1X,IAC1C0e,WAAY,iBACJ,IAAIre,MAAM,6CAEVke,EAAqB9Y,EAAazF,IAC1C2e,WAAYJ,EAAqB7Y,EAAiB1F,IAElD6F,cAAe0Y,EAAqBK,EAAoB5e,IACxD4F,eAAgB2Y,EAAqBM,EAAqB7e,IAC1D8e,oBAAqBD,EAAqB7e,GAC1C+e,MAAOR,EAAqBve,EAAOC,oCE9CjB,SAACS,OAAYmD,yDAAa,OACxChD,EAAY0Z,GAAa7Z,GACzBmB,EAAciZ,OACgBH,sBAA7B7W,OAAYkb,cAEnBnE,aAAU,WACJha,GAAagB,GACfmd,EAAcrb,EAAwB9C,EAAU+C,MAAOC,EAAYhC,MAEpE,CAAChB,EAAWgB,EAAagC,IAErBC,8BCTkB,SAAApD,OACnBG,EAAY0Z,GAAa7Z,GACzBmB,EAAciZ,SAC0BH,gBAAvCsE,OAAiBC,cAExBrE,aAAU,sBACJha,GAAagB,eACXhB,EAAU8D,qBAAVC,EAAkBC,UAAW,SACLlD,OAAOqF,QAAQnG,EAAU8D,OAAOE,WAAW,MAA9DnD,OAAW8C,WACb9C,IAAcG,EAAYH,SACvB,IAAIrB,MAAM,mEAAqEK,GAEvFwe,EAAmBjd,EAAQJ,EAAYH,GAAWQ,QAASsC,SACtD,aAAI3D,EAAU8D,qBAAVwa,EAAkBpa,OAAQ,OACnCma,EAAmBlE,GAA6Bna,EAAU+C,gBAAO/C,EAAU8D,2BAAVya,EAAkBra,OAAQlD,QACtF,KACCqC,EAAmBT,EAAqB,UAAW5B,GACzDqd,EAAmBlE,GAA6Bna,EAAU+C,MAAOM,EAAkBrC,OAGtF,CAAChB,EAAWgB,EAAaqd,IAErBD,iDC1Ba,eAEdzE,EAAeC,aAAWC,2BACIC,gBAA7B0E,OAAYC,cAEnBzE,aAAU,WACRL,EAAa3U,gBAAgBO,MAAK,SAAAK,UAAW6Y,EAAc7Y,QAC1D,CAAC+T,EAAc8E,IAEXD,wDXLkB,SAAAE,OAGnB1d,EADe4Y,aAAWC,uBACCoE,sBAE3BU,EAAuBC,WAAQ,cAC/B5d,SACKF,OAAOuE,YACZvE,OAAOmD,OAAOjD,GAAaoC,KAAI,SAAAc,OAEvBsV,OAAyC5Q,IAAzB1E,EAAOsV,cAA8BtV,EAAOsV,eAAiBtV,gBAC5E,CAACA,EAAO7C,QAASmY,SAI7B,CAACxY,WAEG6d,eACL,SAAApc,OACQqc,EAAiCvF,GAAQmF,EAAwBjc,OAEhC,IAAnCqc,EAA0C,OAAO,KAEhDrc,MAAAA,IAAAA,EAAQhD,GAAI,OAAO,MAElBsf,EAAgBje,OAAOC,KAAK4d,GAAsB1d,MAAK,SAAAI,UAAWoB,MAAAA,SAAAA,EAAQhD,GAAGmI,WAAWvG,UAEzF0d,EAAe,OAAO,MAErBC,EAA8BzF,GAAQoF,EAAqBI,GAAgBtc,UAE7C,IAAhCuc,IAEAvF,GAAMqF,GACDA,EACErF,GAAMuF,GACRA,EAEAvc,EAAOhD,MAGlB,CAACkf,EAAsBD"}