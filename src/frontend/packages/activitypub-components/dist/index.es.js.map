{"version":3,"file":"index.es.js","sources":["../../../node_modules/rdf-canonize/lib/IdentifierIssuer.js","../../../node_modules/rdf-canonize/lib/MessageDigest.js","../../../node_modules/rdf-canonize/lib/Permuter.js","../../../node_modules/rdf-canonize/lib/NQuads.js","../../../node_modules/rdf-canonize/lib/URDNA2015.js","../../../node_modules/rdf-canonize/lib/URGNA2012.js","../../../node_modules/rdf-canonize/lib/URDNA2015Sync.js","../../../node_modules/rdf-canonize/lib/URGNA2012Sync.js","../../../node_modules/rdf-canonize/lib/index.js","../../../node_modules/rdf-canonize/index.js","../../../node_modules/jsonld/lib/types.js","../../../node_modules/jsonld/lib/graphTypes.js","../../../node_modules/jsonld/lib/JsonLdError.js","../../../node_modules/jsonld/lib/util.js","../../../node_modules/jsonld/lib/constants.js","../../../node_modules/jsonld/lib/RequestQueue.js","../../../node_modules/jsonld/lib/url.js","../../../node_modules/data-uri-to-buffer/dist/src/index.js","../../../node_modules/fetch-blob/index.js","../../../node_modules/ky-universal/node_modules/node-fetch/src/errors/base.js","../../../node_modules/ky-universal/node_modules/node-fetch/src/errors/fetch-error.js","../../../node_modules/ky-universal/node_modules/node-fetch/src/utils/is.js","../../../node_modules/ky-universal/node_modules/node-fetch/src/utils/form-data.js","../../../node_modules/ky-universal/node_modules/node-fetch/src/body.js","../../../node_modules/ky-universal/node_modules/node-fetch/src/headers.js","../../../node_modules/ky-universal/node_modules/node-fetch/src/utils/is-redirect.js","../../../node_modules/ky-universal/node_modules/node-fetch/src/response.js","../../../node_modules/ky-universal/node_modules/node-fetch/src/utils/get-search.js","../../../node_modules/ky-universal/node_modules/node-fetch/src/request.js","../../../node_modules/ky-universal/node_modules/node-fetch/src/errors/abort-error.js","../../../node_modules/ky-universal/node_modules/node-fetch/src/index.js","../../../node_modules/event-target-shim/dist/event-target-shim.mjs","../../../node_modules/abort-controller/dist/abort-controller.mjs","../../../node_modules/ky/umd.js","../../../node_modules/ky-universal/index.js","../../../node_modules/@digitalbazaar/http-client/main.js","../../../node_modules/jsonld/lib/documentLoaders/node.js","../../../node_modules/jsonld/lib/platform.js","../../../node_modules/jsonld/node_modules/yallist/iterator.js","../../../node_modules/jsonld/node_modules/yallist/yallist.js","../../../node_modules/jsonld/node_modules/lru-cache/index.js","../../../node_modules/jsonld/lib/ResolvedContext.js","../../../node_modules/jsonld/lib/ContextResolver.js","../../../node_modules/jsonld/lib/NQuads.js","../../../node_modules/jsonld/lib/context.js","../../../node_modules/jsonld/lib/expand.js","../../../node_modules/jsonld/lib/nodeMap.js","../../../node_modules/jsonld/lib/flatten.js","../../../node_modules/jsonld/lib/fromRdf.js","../../../node_modules/jsonld/lib/toRdf.js","../../../node_modules/canonicalize/lib/canonicalize.js","../../../node_modules/jsonld/lib/frame.js","../../../node_modules/jsonld/lib/compact.js","../../../node_modules/jsonld/lib/jsonld.js","../../../node_modules/jsonld/lib/JsonLdProcessor.js","../../../node_modules/speakingurl/lib/speakingurl.js","../../../node_modules/speakingurl/index.js","../src/components/CollectionList.js","../src/components/ReferenceCollectionField.js","../src/hooks/useCollection.js","../src/hooks/useInbox.js","../src/hooks/useOutbox.js","../src/hooks/useWebfinger.js"],"sourcesContent":["/*\n * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nmodule.exports = class IdentifierIssuer {\n  /**\n   * Creates a new IdentifierIssuer. A IdentifierIssuer issues unique\n   * identifiers, keeping track of any previously issued identifiers.\n   *\n   * @param prefix the prefix to use ('<prefix><counter>').\n   * @param existing an existing Map to use.\n   * @param counter the counter to use.\n   */\n  constructor(prefix, existing = new Map(), counter = 0) {\n    this.prefix = prefix;\n    this._existing = existing;\n    this.counter = counter;\n  }\n\n  /**\n   * Copies this IdentifierIssuer.\n   *\n   * @return a copy of this IdentifierIssuer.\n   */\n  clone() {\n    const {prefix, _existing, counter} = this;\n    return new IdentifierIssuer(prefix, new Map(_existing), counter);\n  }\n\n  /**\n   * Gets the new identifier for the given old identifier, where if no old\n   * identifier is given a new identifier will be generated.\n   *\n   * @param [old] the old identifier to get the new identifier for.\n   *\n   * @return the new identifier.\n   */\n  getId(old) {\n    // return existing old identifier\n    const existing = old && this._existing.get(old);\n    if(existing) {\n      return existing;\n    }\n\n    // get next identifier\n    const identifier = this.prefix + this.counter;\n    this.counter++;\n\n    // save mapping\n    if(old) {\n      this._existing.set(old, identifier);\n    }\n\n    return identifier;\n  }\n\n  /**\n   * Returns true if the given old identifer has already been assigned a new\n   * identifier.\n   *\n   * @param old the old identifier to check.\n   *\n   * @return true if the old identifier has been assigned a new identifier,\n   *   false if not.\n   */\n  hasId(old) {\n    return this._existing.has(old);\n  }\n\n  /**\n   * Returns all of the IDs that have been issued new IDs in the order in\n   * which they were issued new IDs.\n   *\n   * @return the list of old IDs that has been issued new IDs in order.\n   */\n  getOldIds() {\n    return [...this._existing.keys()];\n  }\n};\n","/*\n * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst crypto = require('crypto');\n\nmodule.exports = class MessageDigest {\n  /**\n   * Creates a new MessageDigest.\n   *\n   * @param algorithm the algorithm to use.\n   */\n  constructor(algorithm) {\n    this.md = crypto.createHash(algorithm);\n  }\n\n  update(msg) {\n    this.md.update(msg, 'utf8');\n  }\n\n  digest() {\n    return this.md.digest('hex');\n  }\n};\n","/*\n * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\n// TODO: convert to ES6 iterable?\n\nmodule.exports = class Permuter {\n  /**\n   * A Permuter iterates over all possible permutations of the given array\n   * of elements.\n   *\n   * @param list the array of elements to iterate over.\n   */\n  constructor(list) {\n    // original array\n    this.current = list.sort();\n    // indicates whether there are more permutations\n    this.done = false;\n    // directional info for permutation algorithm\n    this.dir = new Map();\n    for(let i = 0; i < list.length; ++i) {\n      this.dir.set(list[i], true);\n    }\n  }\n\n  /**\n   * Returns true if there is another permutation.\n   *\n   * @return true if there is another permutation, false if not.\n   */\n  hasNext() {\n    return !this.done;\n  }\n\n  /**\n   * Gets the next permutation. Call hasNext() to ensure there is another one\n   * first.\n   *\n   * @return the next permutation.\n   */\n  next() {\n    // copy current permutation to return it\n    const {current, dir} = this;\n    const rval = current.slice();\n\n    /* Calculate the next permutation using the Steinhaus-Johnson-Trotter\n     permutation algorithm. */\n\n    // get largest mobile element k\n    // (mobile: element is greater than the one it is looking at)\n    let k = null;\n    let pos = 0;\n    const length = current.length;\n    for(let i = 0; i < length; ++i) {\n      const element = current[i];\n      const left = dir.get(element);\n      if((k === null || element > k) &&\n        ((left && i > 0 && element > current[i - 1]) ||\n        (!left && i < (length - 1) && element > current[i + 1]))) {\n        k = element;\n        pos = i;\n      }\n    }\n\n    // no more permutations\n    if(k === null) {\n      this.done = true;\n    } else {\n      // swap k and the element it is looking at\n      const swap = dir.get(k) ? pos - 1 : pos + 1;\n      current[pos] = current[swap];\n      current[swap] = k;\n\n      // reverse the direction of all elements larger than k\n      for(const element of current) {\n        if(element > k) {\n          dir.set(element, !dir.get(element));\n        }\n      }\n    }\n\n    return rval;\n  }\n};\n","/*\n * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\n// eslint-disable-next-line no-unused-vars\nconst TERMS = ['subject', 'predicate', 'object', 'graph'];\nconst RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\nconst RDF_LANGSTRING = RDF + 'langString';\nconst XSD_STRING = 'http://www.w3.org/2001/XMLSchema#string';\n\nconst TYPE_NAMED_NODE = 'NamedNode';\nconst TYPE_BLANK_NODE = 'BlankNode';\nconst TYPE_LITERAL = 'Literal';\nconst TYPE_DEFAULT_GRAPH = 'DefaultGraph';\n\n// build regexes\nconst REGEX = {};\n(() => {\n  const iri = '(?:<([^:]+:[^>]*)>)';\n  // https://www.w3.org/TR/turtle/#grammar-production-BLANK_NODE_LABEL\n  const PN_CHARS_BASE =\n    'A-Z' + 'a-z' +\n    '\\u00C0-\\u00D6' +\n    '\\u00D8-\\u00F6' +\n    '\\u00F8-\\u02FF' +\n    '\\u0370-\\u037D' +\n    '\\u037F-\\u1FFF' +\n    '\\u200C-\\u200D' +\n    '\\u2070-\\u218F' +\n    '\\u2C00-\\u2FEF' +\n    '\\u3001-\\uD7FF' +\n    '\\uF900-\\uFDCF' +\n    '\\uFDF0-\\uFFFD';\n    // TODO:\n    //'\\u10000-\\uEFFFF';\n  const PN_CHARS_U =\n    PN_CHARS_BASE +\n    '_';\n  const PN_CHARS =\n    PN_CHARS_U +\n    '0-9' +\n    '-' +\n    '\\u00B7' +\n    '\\u0300-\\u036F' +\n    '\\u203F-\\u2040';\n  const BLANK_NODE_LABEL =\n    '(_:' +\n      '(?:[' + PN_CHARS_U + '0-9])' +\n      '(?:(?:[' + PN_CHARS + '.])*(?:[' + PN_CHARS + ']))?' +\n    ')';\n  const bnode = BLANK_NODE_LABEL;\n  const plain = '\"([^\"\\\\\\\\]*(?:\\\\\\\\.[^\"\\\\\\\\]*)*)\"';\n  const datatype = '(?:\\\\^\\\\^' + iri + ')';\n  const language = '(?:@([a-zA-Z]+(?:-[a-zA-Z0-9]+)*))';\n  const literal = '(?:' + plain + '(?:' + datatype + '|' + language + ')?)';\n  const ws = '[ \\\\t]+';\n  const wso = '[ \\\\t]*';\n\n  // define quad part regexes\n  const subject = '(?:' + iri + '|' + bnode + ')' + ws;\n  const property = iri + ws;\n  const object = '(?:' + iri + '|' + bnode + '|' + literal + ')' + wso;\n  const graphName = '(?:\\\\.|(?:(?:' + iri + '|' + bnode + ')' + wso + '\\\\.))';\n\n  // end of line and empty regexes\n  REGEX.eoln = /(?:\\r\\n)|(?:\\n)|(?:\\r)/g;\n  REGEX.empty = new RegExp('^' + wso + '$');\n\n  // full quad regex\n  REGEX.quad = new RegExp(\n    '^' + wso + subject + property + object + graphName + wso + '$');\n})();\n\nmodule.exports = class NQuads {\n  /**\n   * Parses RDF in the form of N-Quads.\n   *\n   * @param input the N-Quads input to parse.\n   *\n   * @return an RDF dataset (an array of quads per http://rdf.js.org/).\n   */\n  static parse(input) {\n    // build RDF dataset\n    const dataset = [];\n\n    const graphs = {};\n\n    // split N-Quad input into lines\n    const lines = input.split(REGEX.eoln);\n    let lineNumber = 0;\n    for(const line of lines) {\n      lineNumber++;\n\n      // skip empty lines\n      if(REGEX.empty.test(line)) {\n        continue;\n      }\n\n      // parse quad\n      const match = line.match(REGEX.quad);\n      if(match === null) {\n        throw new Error('N-Quads parse error on line ' + lineNumber + '.');\n      }\n\n      // create RDF quad\n      const quad = {subject: null, predicate: null, object: null, graph: null};\n\n      // get subject\n      if(match[1] !== undefined) {\n        quad.subject = {termType: TYPE_NAMED_NODE, value: match[1]};\n      } else {\n        quad.subject = {termType: TYPE_BLANK_NODE, value: match[2]};\n      }\n\n      // get predicate\n      quad.predicate = {termType: TYPE_NAMED_NODE, value: match[3]};\n\n      // get object\n      if(match[4] !== undefined) {\n        quad.object = {termType: TYPE_NAMED_NODE, value: match[4]};\n      } else if(match[5] !== undefined) {\n        quad.object = {termType: TYPE_BLANK_NODE, value: match[5]};\n      } else {\n        quad.object = {\n          termType: TYPE_LITERAL,\n          value: undefined,\n          datatype: {\n            termType: TYPE_NAMED_NODE\n          }\n        };\n        if(match[7] !== undefined) {\n          quad.object.datatype.value = match[7];\n        } else if(match[8] !== undefined) {\n          quad.object.datatype.value = RDF_LANGSTRING;\n          quad.object.language = match[8];\n        } else {\n          quad.object.datatype.value = XSD_STRING;\n        }\n        quad.object.value = _unescape(match[6]);\n      }\n\n      // get graph\n      if(match[9] !== undefined) {\n        quad.graph = {\n          termType: TYPE_NAMED_NODE,\n          value: match[9]\n        };\n      } else if(match[10] !== undefined) {\n        quad.graph = {\n          termType: TYPE_BLANK_NODE,\n          value: match[10]\n        };\n      } else {\n        quad.graph = {\n          termType: TYPE_DEFAULT_GRAPH,\n          value: ''\n        };\n      }\n\n      // only add quad if it is unique in its graph\n      if(!(quad.graph.value in graphs)) {\n        graphs[quad.graph.value] = [quad];\n        dataset.push(quad);\n      } else {\n        let unique = true;\n        const quads = graphs[quad.graph.value];\n        for(const q of quads) {\n          if(_compareTriples(q, quad)) {\n            unique = false;\n            break;\n          }\n        }\n        if(unique) {\n          quads.push(quad);\n          dataset.push(quad);\n        }\n      }\n    }\n\n    return dataset;\n  }\n\n  /**\n   * Converts an RDF dataset to N-Quads.\n   *\n   * @param dataset (array of quads) the RDF dataset to convert.\n   *\n   * @return the N-Quads string.\n   */\n  static serialize(dataset) {\n    if(!Array.isArray(dataset)) {\n      dataset = NQuads.legacyDatasetToQuads(dataset);\n    }\n    const quads = [];\n    for(const quad of dataset) {\n      quads.push(NQuads.serializeQuad(quad));\n    }\n    return quads.sort().join('');\n  }\n\n  /**\n   * Converts an RDF quad to an N-Quad string (a single quad).\n   *\n   * @param quad the RDF quad convert.\n   *\n   * @return the N-Quad string.\n   */\n  static serializeQuad(quad) {\n    const s = quad.subject;\n    const p = quad.predicate;\n    const o = quad.object;\n    const g = quad.graph;\n\n    let nquad = '';\n\n    // subject can only be NamedNode or BlankNode\n    if(s.termType === TYPE_NAMED_NODE) {\n      nquad += `<${s.value}>`;\n    } else {\n      nquad += `${s.value}`;\n    }\n\n    // predicate can only be NamedNode\n    nquad += ` <${p.value}> `;\n\n    // object is NamedNode, BlankNode, or Literal\n    if(o.termType === TYPE_NAMED_NODE) {\n      nquad += `<${o.value}>`;\n    } else if(o.termType === TYPE_BLANK_NODE) {\n      nquad += o.value;\n    } else {\n      nquad += `\"${_escape(o.value)}\"`;\n      if(o.datatype.value === RDF_LANGSTRING) {\n        if(o.language) {\n          nquad += `@${o.language}`;\n        }\n      } else if(o.datatype.value !== XSD_STRING) {\n        nquad += `^^<${o.datatype.value}>`;\n      }\n    }\n\n    // graph can only be NamedNode or BlankNode (or DefaultGraph, but that\n    // does not add to `nquad`)\n    if(g.termType === TYPE_NAMED_NODE) {\n      nquad += ` <${g.value}>`;\n    } else if(g.termType === TYPE_BLANK_NODE) {\n      nquad += ` ${g.value}`;\n    }\n\n    nquad += ' .\\n';\n    return nquad;\n  }\n\n  /**\n   * Converts a legacy-formatted dataset to an array of quads dataset per\n   * http://rdf.js.org/.\n   *\n   * @param dataset the legacy dataset to convert.\n   *\n   * @return the array of quads dataset.\n   */\n  static legacyDatasetToQuads(dataset) {\n    const quads = [];\n\n    const termTypeMap = {\n      'blank node': TYPE_BLANK_NODE,\n      IRI: TYPE_NAMED_NODE,\n      literal: TYPE_LITERAL\n    };\n\n    for(const graphName in dataset) {\n      const triples = dataset[graphName];\n      triples.forEach(triple => {\n        const quad = {};\n        for(const componentName in triple) {\n          const oldComponent = triple[componentName];\n          const newComponent = {\n            termType: termTypeMap[oldComponent.type],\n            value: oldComponent.value\n          };\n          if(newComponent.termType === TYPE_LITERAL) {\n            newComponent.datatype = {\n              termType: TYPE_NAMED_NODE\n            };\n            if('datatype' in oldComponent) {\n              newComponent.datatype.value = oldComponent.datatype;\n            }\n            if('language' in oldComponent) {\n              if(!('datatype' in oldComponent)) {\n                newComponent.datatype.value = RDF_LANGSTRING;\n              }\n              newComponent.language = oldComponent.language;\n            } else if(!('datatype' in oldComponent)) {\n              newComponent.datatype.value = XSD_STRING;\n            }\n          }\n          quad[componentName] = newComponent;\n        }\n        if(graphName === '@default') {\n          quad.graph = {\n            termType: TYPE_DEFAULT_GRAPH,\n            value: ''\n          };\n        } else {\n          quad.graph = {\n            termType: graphName.startsWith('_:') ?\n              TYPE_BLANK_NODE : TYPE_NAMED_NODE,\n            value: graphName\n          };\n        }\n        quads.push(quad);\n      });\n    }\n\n    return quads;\n  }\n};\n\n/**\n * Compares two RDF triples for equality.\n *\n * @param t1 the first triple.\n * @param t2 the second triple.\n *\n * @return true if the triples are the same, false if not.\n */\nfunction _compareTriples(t1, t2) {\n  // compare subject and object types first as it is the quickest check\n  if(!(t1.subject.termType === t2.subject.termType &&\n    t1.object.termType === t2.object.termType)) {\n    return false;\n  }\n  // compare values\n  if(!(t1.subject.value === t2.subject.value &&\n    t1.predicate.value === t2.predicate.value &&\n    t1.object.value === t2.object.value)) {\n    return false;\n  }\n  if(t1.object.termType !== TYPE_LITERAL) {\n    // no `datatype` or `language` to check\n    return true;\n  }\n  return (\n    (t1.object.datatype.termType === t2.object.datatype.termType) &&\n    (t1.object.language === t2.object.language) &&\n    (t1.object.datatype.value === t2.object.datatype.value)\n  );\n}\n\nconst _escapeRegex = /[\"\\\\\\n\\r]/g;\n/**\n * Escape string to N-Quads literal\n */\nfunction _escape(s) {\n  return s.replace(_escapeRegex, function(match) {\n    switch(match) {\n      case '\"': return '\\\\\"';\n      case '\\\\': return '\\\\\\\\';\n      case '\\n': return '\\\\n';\n      case '\\r': return '\\\\r';\n    }\n  });\n}\n\nconst _unescapeRegex =\n  /(?:\\\\([tbnrf\"'\\\\]))|(?:\\\\u([0-9A-Fa-f]{4}))|(?:\\\\U([0-9A-Fa-f]{8}))/g;\n/**\n * Unescape N-Quads literal to string\n */\nfunction _unescape(s) {\n  return s.replace(_unescapeRegex, function(match, code, u, U) {\n    if(code) {\n      switch(code) {\n        case 't': return '\\t';\n        case 'b': return '\\b';\n        case 'n': return '\\n';\n        case 'r': return '\\r';\n        case 'f': return '\\f';\n        case '\"': return '\"';\n        case '\\'': return '\\'';\n        case '\\\\': return '\\\\';\n      }\n    }\n    if(u) {\n      return String.fromCharCode(parseInt(u, 16));\n    }\n    if(U) {\n      // FIXME: support larger values\n      throw new Error('Unsupported U escape');\n    }\n  });\n}\n","/*\n * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst IdentifierIssuer = require('./IdentifierIssuer');\nconst MessageDigest = require('./MessageDigest');\nconst Permuter = require('./Permuter');\nconst NQuads = require('./NQuads');\n\nmodule.exports = class URDNA2015 {\n  constructor() {\n    this.name = 'URDNA2015';\n    this.blankNodeInfo = new Map();\n    this.canonicalIssuer = new IdentifierIssuer('_:c14n');\n    this.hashAlgorithm = 'sha256';\n    this.quads = null;\n  }\n\n  // 4.4) Normalization Algorithm\n  async main(dataset) {\n    this.quads = dataset;\n\n    // 1) Create the normalization state.\n    // 2) For every quad in input dataset:\n    for(const quad of dataset) {\n      // 2.1) For each blank node that occurs in the quad, add a reference\n      // to the quad using the blank node identifier in the blank node to\n      // quads map, creating a new entry if necessary.\n      this._addBlankNodeQuadInfo({quad, component: quad.subject});\n      this._addBlankNodeQuadInfo({quad, component: quad.object});\n      this._addBlankNodeQuadInfo({quad, component: quad.graph});\n    }\n\n    // 3) Create a list of non-normalized blank node identifiers\n    // non-normalized identifiers and populate it using the keys from the\n    // blank node to quads map.\n    // Note: We use a map here and it was generated during step 2.\n\n    // 4) `simple` flag is skipped -- loop is optimized away. This optimization\n    // is permitted because there was a typo in the hash first degree quads\n    // algorithm in the URDNA2015 spec that was implemented widely making it\n    // such that it could not be fixed; the result was that the loop only\n    // needs to be run once and the first degree quad hashes will never change.\n    // 5.1-5.2 are skipped; first degree quad hashes are generated just once\n    // for all non-normalized blank nodes.\n\n    // 5.3) For each blank node identifier identifier in non-normalized\n    // identifiers:\n    const hashToBlankNodes = new Map();\n    const nonNormalized = [...this.blankNodeInfo.keys()];\n    let i = 0;\n    for(const id of nonNormalized) {\n      // Note: batch hashing first degree quads 100 at a time\n      if(++i % 100 === 0) {\n        await this._yield();\n      }\n      // steps 5.3.1 and 5.3.2:\n      await this._hashAndTrackBlankNode({id, hashToBlankNodes});\n    }\n\n    // 5.4) For each hash to identifier list mapping in hash to blank\n    // nodes map, lexicographically-sorted by hash:\n    const hashes = [...hashToBlankNodes.keys()].sort();\n    // optimize away second sort, gather non-unique hashes in order as we go\n    const nonUnique = [];\n    for(const hash of hashes) {\n      // 5.4.1) If the length of identifier list is greater than 1,\n      // continue to the next mapping.\n      const idList = hashToBlankNodes.get(hash);\n      if(idList.length > 1) {\n        nonUnique.push(idList);\n        continue;\n      }\n\n      // 5.4.2) Use the Issue Identifier algorithm, passing canonical\n      // issuer and the single blank node identifier in identifier\n      // list, identifier, to issue a canonical replacement identifier\n      // for identifier.\n      const id = idList[0];\n      this.canonicalIssuer.getId(id);\n\n      // Note: These steps are skipped, optimized away since the loop\n      // only needs to be run once.\n      // 5.4.3) Remove identifier from non-normalized identifiers.\n      // 5.4.4) Remove hash from the hash to blank nodes map.\n      // 5.4.5) Set simple to true.\n    }\n\n    // 6) For each hash to identifier list mapping in hash to blank nodes map,\n    // lexicographically-sorted by hash:\n    // Note: sort optimized away, use `nonUnique`.\n    for(const idList of nonUnique) {\n      // 6.1) Create hash path list where each item will be a result of\n      // running the Hash N-Degree Quads algorithm.\n      const hashPathList = [];\n\n      // 6.2) For each blank node identifier identifier in identifier list:\n      for(const id of idList) {\n        // 6.2.1) If a canonical identifier has already been issued for\n        // identifier, continue to the next identifier.\n        if(this.canonicalIssuer.hasId(id)) {\n          continue;\n        }\n\n        // 6.2.2) Create temporary issuer, an identifier issuer\n        // initialized with the prefix _:b.\n        const issuer = new IdentifierIssuer('_:b');\n\n        // 6.2.3) Use the Issue Identifier algorithm, passing temporary\n        // issuer and identifier, to issue a new temporary blank node\n        // identifier for identifier.\n        issuer.getId(id);\n\n        // 6.2.4) Run the Hash N-Degree Quads algorithm, passing\n        // temporary issuer, and append the result to the hash path list.\n        const result = await this.hashNDegreeQuads(id, issuer);\n        hashPathList.push(result);\n      }\n\n      // 6.3) For each result in the hash path list,\n      // lexicographically-sorted by the hash in result:\n      hashPathList.sort(_stringHashCompare);\n      for(const result of hashPathList) {\n        // 6.3.1) For each blank node identifier, existing identifier,\n        // that was issued a temporary identifier by identifier issuer\n        // in result, issue a canonical identifier, in the same order,\n        // using the Issue Identifier algorithm, passing canonical\n        // issuer and existing identifier.\n        const oldIds = result.issuer.getOldIds();\n        for(const id of oldIds) {\n          this.canonicalIssuer.getId(id);\n        }\n      }\n    }\n\n    /* Note: At this point all blank nodes in the set of RDF quads have been\n    assigned canonical identifiers, which have been stored in the canonical\n    issuer. Here each quad is updated by assigning each of its blank nodes\n    its new identifier. */\n\n    // 7) For each quad, quad, in input dataset:\n    const normalized = [];\n    for(const quad of this.quads) {\n      // 7.1) Create a copy, quad copy, of quad and replace any existing\n      // blank node identifiers using the canonical identifiers\n      // previously issued by canonical issuer.\n      // Note: We optimize with shallow copies here.\n      const q = {...quad};\n      q.subject = this._useCanonicalId({component: q.subject});\n      q.object = this._useCanonicalId({component: q.object});\n      q.graph = this._useCanonicalId({component: q.graph});\n      // 7.2) Add quad copy to the normalized dataset.\n      normalized.push(NQuads.serializeQuad(q));\n    }\n\n    // sort normalized output\n    normalized.sort();\n\n    // 8) Return the normalized dataset.\n    return normalized.join('');\n  }\n\n  // 4.6) Hash First Degree Quads\n  async hashFirstDegreeQuads(id) {\n    // 1) Initialize nquads to an empty list. It will be used to store quads in\n    // N-Quads format.\n    const nquads = [];\n\n    // 2) Get the list of quads `quads` associated with the reference blank node\n    // identifier in the blank node to quads map.\n    const info = this.blankNodeInfo.get(id);\n    const quads = info.quads;\n\n    // 3) For each quad `quad` in `quads`:\n    for(const quad of quads) {\n      // 3.1) Serialize the quad in N-Quads format with the following special\n      // rule:\n\n      // 3.1.1) If any component in quad is an blank node, then serialize it\n      // using a special identifier as follows:\n      const copy = {\n        subject: null, predicate: quad.predicate, object: null, graph: null\n      };\n      // 3.1.2) If the blank node's existing blank node identifier matches\n      // the reference blank node identifier then use the blank node\n      // identifier _:a, otherwise, use the blank node identifier _:z.\n      copy.subject = this.modifyFirstDegreeComponent(\n        id, quad.subject, 'subject');\n      copy.object = this.modifyFirstDegreeComponent(\n        id, quad.object, 'object');\n      copy.graph = this.modifyFirstDegreeComponent(\n        id, quad.graph, 'graph');\n      nquads.push(NQuads.serializeQuad(copy));\n    }\n\n    // 4) Sort nquads in lexicographical order.\n    nquads.sort();\n\n    // 5) Return the hash that results from passing the sorted, joined nquads\n    // through the hash algorithm.\n    const md = new MessageDigest(this.hashAlgorithm);\n    for(const nquad of nquads) {\n      md.update(nquad);\n    }\n    info.hash = await md.digest();\n    return info.hash;\n  }\n\n  // 4.7) Hash Related Blank Node\n  async hashRelatedBlankNode(related, quad, issuer, position) {\n    // 1) Set the identifier to use for related, preferring first the canonical\n    // identifier for related if issued, second the identifier issued by issuer\n    // if issued, and last, if necessary, the result of the Hash First Degree\n    // Quads algorithm, passing related.\n    let id;\n    if(this.canonicalIssuer.hasId(related)) {\n      id = this.canonicalIssuer.getId(related);\n    } else if(issuer.hasId(related)) {\n      id = issuer.getId(related);\n    } else {\n      id = this.blankNodeInfo.get(related).hash;\n    }\n\n    // 2) Initialize a string input to the value of position.\n    // Note: We use a hash object instead.\n    const md = new MessageDigest(this.hashAlgorithm);\n    md.update(position);\n\n    // 3) If position is not g, append <, the value of the predicate in quad,\n    // and > to input.\n    if(position !== 'g') {\n      md.update(this.getRelatedPredicate(quad));\n    }\n\n    // 4) Append identifier to input.\n    md.update(id);\n\n    // 5) Return the hash that results from passing input through the hash\n    // algorithm.\n    return md.digest();\n  }\n\n  // 4.8) Hash N-Degree Quads\n  async hashNDegreeQuads(id, issuer) {\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    // Note: 2) and 3) handled within `createHashToRelated`\n    const md = new MessageDigest(this.hashAlgorithm);\n    const hashToRelated = await this.createHashToRelated(id, issuer);\n\n    // 4) Create an empty string, data to hash.\n    // Note: We created a hash object `md` above instead.\n\n    // 5) For each related hash to blank node list mapping in hash to related\n    // blank nodes map, sorted lexicographically by related hash:\n    const hashes = [...hashToRelated.keys()].sort();\n    for(const hash of hashes) {\n      // 5.1) Append the related hash to the data to hash.\n      md.update(hash);\n\n      // 5.2) Create a string chosen path.\n      let chosenPath = '';\n\n      // 5.3) Create an unset chosen issuer variable.\n      let chosenIssuer;\n\n      // 5.4) For each permutation of blank node list:\n      const permuter = new Permuter(hashToRelated.get(hash));\n      let i = 0;\n      while(permuter.hasNext()) {\n        const permutation = permuter.next();\n        // Note: batch permutations 3 at a time\n        if(++i % 3 === 0) {\n          await this._yield();\n        }\n\n        // 5.4.1) Create a copy of issuer, issuer copy.\n        let issuerCopy = issuer.clone();\n\n        // 5.4.2) Create a string path.\n        let path = '';\n\n        // 5.4.3) Create a recursion list, to store blank node identifiers\n        // that must be recursively processed by this algorithm.\n        const recursionList = [];\n\n        // 5.4.4) For each related in permutation:\n        let nextPermutation = false;\n        for(const related of permutation) {\n          // 5.4.4.1) If a canonical identifier has been issued for\n          // related, append it to path.\n          if(this.canonicalIssuer.hasId(related)) {\n            path += this.canonicalIssuer.getId(related);\n          } else {\n            // 5.4.4.2) Otherwise:\n            // 5.4.4.2.1) If issuer copy has not issued an identifier for\n            // related, append related to recursion list.\n            if(!issuerCopy.hasId(related)) {\n              recursionList.push(related);\n            }\n            // 5.4.4.2.2) Use the Issue Identifier algorithm, passing\n            // issuer copy and related and append the result to path.\n            path += issuerCopy.getId(related);\n          }\n\n          // 5.4.4.3) If chosen path is not empty and the length of path\n          // is greater than or equal to the length of chosen path and\n          // path is lexicographically greater than chosen path, then\n          // skip to the next permutation.\n          // Note: Comparing path length to chosen path length can be optimized\n          // away; only compare lexicographically.\n          if(chosenPath.length !== 0 && path > chosenPath) {\n            nextPermutation = true;\n            break;\n          }\n        }\n\n        if(nextPermutation) {\n          continue;\n        }\n\n        // 5.4.5) For each related in recursion list:\n        for(const related of recursionList) {\n          // 5.4.5.1) Set result to the result of recursively executing\n          // the Hash N-Degree Quads algorithm, passing related for\n          // identifier and issuer copy for path identifier issuer.\n          const result = await this.hashNDegreeQuads(related, issuerCopy);\n\n          // 5.4.5.2) Use the Issue Identifier algorithm, passing issuer\n          // copy and related and append the result to path.\n          path += issuerCopy.getId(related);\n\n          // 5.4.5.3) Append <, the hash in result, and > to path.\n          path += `<${result.hash}>`;\n\n          // 5.4.5.4) Set issuer copy to the identifier issuer in\n          // result.\n          issuerCopy = result.issuer;\n\n          // 5.4.5.5) If chosen path is not empty and the length of path\n          // is greater than or equal to the length of chosen path and\n          // path is lexicographically greater than chosen path, then\n          // skip to the next permutation.\n          // Note: Comparing path length to chosen path length can be optimized\n          // away; only compare lexicographically.\n          if(chosenPath.length !== 0 && path > chosenPath) {\n            nextPermutation = true;\n            break;\n          }\n        }\n\n        if(nextPermutation) {\n          continue;\n        }\n\n        // 5.4.6) If chosen path is empty or path is lexicographically\n        // less than chosen path, set chosen path to path and chosen\n        // issuer to issuer copy.\n        if(chosenPath.length === 0 || path < chosenPath) {\n          chosenPath = path;\n          chosenIssuer = issuerCopy;\n        }\n      }\n\n      // 5.5) Append chosen path to data to hash.\n      md.update(chosenPath);\n\n      // 5.6) Replace issuer, by reference, with chosen issuer.\n      issuer = chosenIssuer;\n    }\n\n    // 6) Return issuer and the hash that results from passing data to hash\n    // through the hash algorithm.\n    return {hash: await md.digest(), issuer};\n  }\n\n  // helper for modifying component during Hash First Degree Quads\n  modifyFirstDegreeComponent(id, component) {\n    if(component.termType !== 'BlankNode') {\n      return component;\n    }\n    /* Note: A mistake in the URDNA2015 spec that made its way into\n    implementations (and therefore must stay to avoid interop breakage)\n    resulted in an assigned canonical ID, if available for\n    `component.value`, not being used in place of `_:a`/`_:z`, so\n    we don't use it here. */\n    return {\n      termType: 'BlankNode',\n      value: component.value === id ? '_:a' : '_:z'\n    };\n  }\n\n  // helper for getting a related predicate\n  getRelatedPredicate(quad) {\n    return `<${quad.predicate.value}>`;\n  }\n\n  // helper for creating hash to related blank nodes map\n  async createHashToRelated(id, issuer) {\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    const hashToRelated = new Map();\n\n    // 2) Get a reference, quads, to the list of quads in the blank node to\n    // quads map for the key identifier.\n    const quads = this.blankNodeInfo.get(id).quads;\n\n    // 3) For each quad in quads:\n    let i = 0;\n    for(const quad of quads) {\n      // Note: batch hashing related blank node quads 100 at a time\n      if(++i % 100 === 0) {\n        await this._yield();\n      }\n      // 3.1) For each component in quad, if component is the subject, object,\n      // and graph name and it is a blank node that is not identified by\n      // identifier:\n      // steps 3.1.1 and 3.1.2 occur in helpers:\n      await Promise.all([\n        this._addRelatedBlankNodeHash({\n          quad, component: quad.subject, position: 's',\n          id, issuer, hashToRelated\n        }),\n        this._addRelatedBlankNodeHash({\n          quad, component: quad.object, position: 'o',\n          id, issuer, hashToRelated\n        }),\n        this._addRelatedBlankNodeHash({\n          quad, component: quad.graph, position: 'g',\n          id, issuer, hashToRelated\n        })\n      ]);\n    }\n\n    return hashToRelated;\n  }\n\n  async _hashAndTrackBlankNode({id, hashToBlankNodes}) {\n    // 5.3.1) Create a hash, hash, according to the Hash First Degree\n    // Quads algorithm.\n    const hash = await this.hashFirstDegreeQuads(id);\n\n    // 5.3.2) Add hash and identifier to hash to blank nodes map,\n    // creating a new entry if necessary.\n    const idList = hashToBlankNodes.get(hash);\n    if(!idList) {\n      hashToBlankNodes.set(hash, [id]);\n    } else {\n      idList.push(id);\n    }\n  }\n\n  _addBlankNodeQuadInfo({quad, component}) {\n    if(component.termType !== 'BlankNode') {\n      return;\n    }\n    const id = component.value;\n    const info = this.blankNodeInfo.get(id);\n    if(info) {\n      info.quads.add(quad);\n    } else {\n      this.blankNodeInfo.set(id, {quads: new Set([quad]), hash: null});\n    }\n  }\n\n  async _addRelatedBlankNodeHash(\n    {quad, component, position, id, issuer, hashToRelated}) {\n    if(!(component.termType === 'BlankNode' && component.value !== id)) {\n      return;\n    }\n    // 3.1.1) Set hash to the result of the Hash Related Blank Node\n    // algorithm, passing the blank node identifier for component as\n    // related, quad, path identifier issuer as issuer, and position as\n    // either s, o, or g based on whether component is a subject, object,\n    // graph name, respectively.\n    const related = component.value;\n    const hash = await this.hashRelatedBlankNode(\n      related, quad, issuer, position);\n\n    // 3.1.2) Add a mapping of hash to the blank node identifier for\n    // component to hash to related blank nodes map, adding an entry as\n    // necessary.\n    const entries = hashToRelated.get(hash);\n    if(entries) {\n      entries.push(related);\n    } else {\n      hashToRelated.set(hash, [related]);\n    }\n  }\n\n  _useCanonicalId({component}) {\n    if(component.termType === 'BlankNode' &&\n      !component.value.startsWith(this.canonicalIssuer.prefix)) {\n      return {\n        termType: 'BlankNode',\n        value: this.canonicalIssuer.getId(component.value)\n      };\n    }\n    return component;\n  }\n\n  async _yield() {\n    return new Promise(resolve => setImmediate(resolve));\n  }\n};\n\nfunction _stringHashCompare(a, b) {\n  return a.hash < b.hash ? -1 : a.hash > b.hash ? 1 : 0;\n}\n","/*\n * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst URDNA2015 = require('./URDNA2015');\n\nmodule.exports = class URDNA2012 extends URDNA2015 {\n  constructor() {\n    super();\n    this.name = 'URGNA2012';\n    this.hashAlgorithm = 'sha1';\n  }\n\n  // helper for modifying component during Hash First Degree Quads\n  modifyFirstDegreeComponent(id, component, key) {\n    if(component.termType !== 'BlankNode') {\n      return component;\n    }\n    if(key === 'graph') {\n      return {\n        termType: 'BlankNode',\n        value: '_:g'\n      };\n    }\n    return {\n      termType: 'BlankNode',\n      value: (component.value === id ? '_:a' : '_:z')\n    };\n  }\n\n  // helper for getting a related predicate\n  getRelatedPredicate(quad) {\n    return quad.predicate.value;\n  }\n\n  // helper for creating hash to related blank nodes map\n  async createHashToRelated(id, issuer) {\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    const hashToRelated = new Map();\n\n    // 2) Get a reference, quads, to the list of quads in the blank node to\n    // quads map for the key identifier.\n    const quads = this.blankNodeInfo.get(id).quads;\n\n    // 3) For each quad in quads:\n    let i = 0;\n    for(const quad of quads) {\n      // 3.1) If the quad's subject is a blank node that does not match\n      // identifier, set hash to the result of the Hash Related Blank Node\n      // algorithm, passing the blank node identifier for subject as related,\n      // quad, path identifier issuer as issuer, and p as position.\n      let position;\n      let related;\n      if(quad.subject.termType === 'BlankNode' && quad.subject.value !== id) {\n        related = quad.subject.value;\n        position = 'p';\n      } else if(\n        quad.object.termType === 'BlankNode' && quad.object.value !== id) {\n        // 3.2) Otherwise, if quad's object is a blank node that does not match\n        // identifier, to the result of the Hash Related Blank Node algorithm,\n        // passing the blank node identifier for object as related, quad, path\n        // identifier issuer as issuer, and r as position.\n        related = quad.object.value;\n        position = 'r';\n      } else {\n        // 3.3) Otherwise, continue to the next quad.\n        continue;\n      }\n      // Note: batch hashing related blank nodes 100 at a time\n      if(++i % 100 === 0) {\n        await this._yield();\n      }\n      // 3.4) Add a mapping of hash to the blank node identifier for the\n      // component that matched (subject or object) to hash to related blank\n      // nodes map, adding an entry as necessary.\n      const hash = await this.hashRelatedBlankNode(\n        related, quad, issuer, position);\n      const entries = hashToRelated.get(hash);\n      if(entries) {\n        entries.push(related);\n      } else {\n        hashToRelated.set(hash, [related]);\n      }\n    }\n\n    return hashToRelated;\n  }\n};\n","/*\n * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst IdentifierIssuer = require('./IdentifierIssuer');\nconst MessageDigest = require('./MessageDigest');\nconst Permuter = require('./Permuter');\nconst NQuads = require('./NQuads');\n\nmodule.exports = class URDNA2015Sync {\n  constructor() {\n    this.name = 'URDNA2015';\n    this.blankNodeInfo = new Map();\n    this.canonicalIssuer = new IdentifierIssuer('_:c14n');\n    this.hashAlgorithm = 'sha256';\n    this.quads = null;\n  }\n\n  // 4.4) Normalization Algorithm\n  main(dataset) {\n    this.quads = dataset;\n\n    // 1) Create the normalization state.\n    // 2) For every quad in input dataset:\n    for(const quad of dataset) {\n      // 2.1) For each blank node that occurs in the quad, add a reference\n      // to the quad using the blank node identifier in the blank node to\n      // quads map, creating a new entry if necessary.\n      this._addBlankNodeQuadInfo({quad, component: quad.subject});\n      this._addBlankNodeQuadInfo({quad, component: quad.object});\n      this._addBlankNodeQuadInfo({quad, component: quad.graph});\n    }\n\n    // 3) Create a list of non-normalized blank node identifiers\n    // non-normalized identifiers and populate it using the keys from the\n    // blank node to quads map.\n    // Note: We use a map here and it was generated during step 2.\n\n    // 4) `simple` flag is skipped -- loop is optimized away. This optimization\n    // is permitted because there was a typo in the hash first degree quads\n    // algorithm in the URDNA2015 spec that was implemented widely making it\n    // such that it could not be fixed; the result was that the loop only\n    // needs to be run once and the first degree quad hashes will never change.\n    // 5.1-5.2 are skipped; first degree quad hashes are generated just once\n    // for all non-normalized blank nodes.\n\n    // 5.3) For each blank node identifier identifier in non-normalized\n    // identifiers:\n    const hashToBlankNodes = new Map();\n    const nonNormalized = [...this.blankNodeInfo.keys()];\n    for(const id of nonNormalized) {\n      // steps 5.3.1 and 5.3.2:\n      this._hashAndTrackBlankNode({id, hashToBlankNodes});\n    }\n\n    // 5.4) For each hash to identifier list mapping in hash to blank\n    // nodes map, lexicographically-sorted by hash:\n    const hashes = [...hashToBlankNodes.keys()].sort();\n    // optimize away second sort, gather non-unique hashes in order as we go\n    const nonUnique = [];\n    for(const hash of hashes) {\n      // 5.4.1) If the length of identifier list is greater than 1,\n      // continue to the next mapping.\n      const idList = hashToBlankNodes.get(hash);\n      if(idList.length > 1) {\n        nonUnique.push(idList);\n        continue;\n      }\n\n      // 5.4.2) Use the Issue Identifier algorithm, passing canonical\n      // issuer and the single blank node identifier in identifier\n      // list, identifier, to issue a canonical replacement identifier\n      // for identifier.\n      const id = idList[0];\n      this.canonicalIssuer.getId(id);\n\n      // Note: These steps are skipped, optimized away since the loop\n      // only needs to be run once.\n      // 5.4.3) Remove identifier from non-normalized identifiers.\n      // 5.4.4) Remove hash from the hash to blank nodes map.\n      // 5.4.5) Set simple to true.\n    }\n\n    // 6) For each hash to identifier list mapping in hash to blank nodes map,\n    // lexicographically-sorted by hash:\n    // Note: sort optimized away, use `nonUnique`.\n    for(const idList of nonUnique) {\n      // 6.1) Create hash path list where each item will be a result of\n      // running the Hash N-Degree Quads algorithm.\n      const hashPathList = [];\n\n      // 6.2) For each blank node identifier identifier in identifier list:\n      for(const id of idList) {\n        // 6.2.1) If a canonical identifier has already been issued for\n        // identifier, continue to the next identifier.\n        if(this.canonicalIssuer.hasId(id)) {\n          continue;\n        }\n\n        // 6.2.2) Create temporary issuer, an identifier issuer\n        // initialized with the prefix _:b.\n        const issuer = new IdentifierIssuer('_:b');\n\n        // 6.2.3) Use the Issue Identifier algorithm, passing temporary\n        // issuer and identifier, to issue a new temporary blank node\n        // identifier for identifier.\n        issuer.getId(id);\n\n        // 6.2.4) Run the Hash N-Degree Quads algorithm, passing\n        // temporary issuer, and append the result to the hash path list.\n        const result = this.hashNDegreeQuads(id, issuer);\n        hashPathList.push(result);\n      }\n\n      // 6.3) For each result in the hash path list,\n      // lexicographically-sorted by the hash in result:\n      hashPathList.sort(_stringHashCompare);\n      for(const result of hashPathList) {\n        // 6.3.1) For each blank node identifier, existing identifier,\n        // that was issued a temporary identifier by identifier issuer\n        // in result, issue a canonical identifier, in the same order,\n        // using the Issue Identifier algorithm, passing canonical\n        // issuer and existing identifier.\n        const oldIds = result.issuer.getOldIds();\n        for(const id of oldIds) {\n          this.canonicalIssuer.getId(id);\n        }\n      }\n    }\n\n    /* Note: At this point all blank nodes in the set of RDF quads have been\n    assigned canonical identifiers, which have been stored in the canonical\n    issuer. Here each quad is updated by assigning each of its blank nodes\n    its new identifier. */\n\n    // 7) For each quad, quad, in input dataset:\n    const normalized = [];\n    for(const quad of this.quads) {\n      // 7.1) Create a copy, quad copy, of quad and replace any existing\n      // blank node identifiers using the canonical identifiers\n      // previously issued by canonical issuer.\n      // Note: We optimize with shallow copies here.\n      const q = {...quad};\n      q.subject = this._useCanonicalId({component: q.subject});\n      q.object = this._useCanonicalId({component: q.object});\n      q.graph = this._useCanonicalId({component: q.graph});\n      // 7.2) Add quad copy to the normalized dataset.\n      normalized.push(NQuads.serializeQuad(q));\n    }\n\n    // sort normalized output\n    normalized.sort();\n\n    // 8) Return the normalized dataset.\n    return normalized.join('');\n  }\n\n  // 4.6) Hash First Degree Quads\n  hashFirstDegreeQuads(id) {\n    // 1) Initialize nquads to an empty list. It will be used to store quads in\n    // N-Quads format.\n    const nquads = [];\n\n    // 2) Get the list of quads `quads` associated with the reference blank node\n    // identifier in the blank node to quads map.\n    const info = this.blankNodeInfo.get(id);\n    const quads = info.quads;\n\n    // 3) For each quad `quad` in `quads`:\n    for(const quad of quads) {\n      // 3.1) Serialize the quad in N-Quads format with the following special\n      // rule:\n\n      // 3.1.1) If any component in quad is an blank node, then serialize it\n      // using a special identifier as follows:\n      const copy = {\n        subject: null, predicate: quad.predicate, object: null, graph: null\n      };\n      // 3.1.2) If the blank node's existing blank node identifier matches\n      // the reference blank node identifier then use the blank node\n      // identifier _:a, otherwise, use the blank node identifier _:z.\n      copy.subject = this.modifyFirstDegreeComponent(\n        id, quad.subject, 'subject');\n      copy.object = this.modifyFirstDegreeComponent(\n        id, quad.object, 'object');\n      copy.graph = this.modifyFirstDegreeComponent(\n        id, quad.graph, 'graph');\n      nquads.push(NQuads.serializeQuad(copy));\n    }\n\n    // 4) Sort nquads in lexicographical order.\n    nquads.sort();\n\n    // 5) Return the hash that results from passing the sorted, joined nquads\n    // through the hash algorithm.\n    const md = new MessageDigest(this.hashAlgorithm);\n    for(const nquad of nquads) {\n      md.update(nquad);\n    }\n    info.hash = md.digest();\n    return info.hash;\n  }\n\n  // 4.7) Hash Related Blank Node\n  hashRelatedBlankNode(related, quad, issuer, position) {\n    // 1) Set the identifier to use for related, preferring first the canonical\n    // identifier for related if issued, second the identifier issued by issuer\n    // if issued, and last, if necessary, the result of the Hash First Degree\n    // Quads algorithm, passing related.\n    let id;\n    if(this.canonicalIssuer.hasId(related)) {\n      id = this.canonicalIssuer.getId(related);\n    } else if(issuer.hasId(related)) {\n      id = issuer.getId(related);\n    } else {\n      id = this.blankNodeInfo.get(related).hash;\n    }\n\n    // 2) Initialize a string input to the value of position.\n    // Note: We use a hash object instead.\n    const md = new MessageDigest(this.hashAlgorithm);\n    md.update(position);\n\n    // 3) If position is not g, append <, the value of the predicate in quad,\n    // and > to input.\n    if(position !== 'g') {\n      md.update(this.getRelatedPredicate(quad));\n    }\n\n    // 4) Append identifier to input.\n    md.update(id);\n\n    // 5) Return the hash that results from passing input through the hash\n    // algorithm.\n    return md.digest();\n  }\n\n  // 4.8) Hash N-Degree Quads\n  hashNDegreeQuads(id, issuer) {\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    // Note: 2) and 3) handled within `createHashToRelated`\n    const md = new MessageDigest(this.hashAlgorithm);\n    const hashToRelated = this.createHashToRelated(id, issuer);\n\n    // 4) Create an empty string, data to hash.\n    // Note: We created a hash object `md` above instead.\n\n    // 5) For each related hash to blank node list mapping in hash to related\n    // blank nodes map, sorted lexicographically by related hash:\n    const hashes = [...hashToRelated.keys()].sort();\n    for(const hash of hashes) {\n      // 5.1) Append the related hash to the data to hash.\n      md.update(hash);\n\n      // 5.2) Create a string chosen path.\n      let chosenPath = '';\n\n      // 5.3) Create an unset chosen issuer variable.\n      let chosenIssuer;\n\n      // 5.4) For each permutation of blank node list:\n      const permuter = new Permuter(hashToRelated.get(hash));\n      while(permuter.hasNext()) {\n        const permutation = permuter.next();\n\n        // 5.4.1) Create a copy of issuer, issuer copy.\n        let issuerCopy = issuer.clone();\n\n        // 5.4.2) Create a string path.\n        let path = '';\n\n        // 5.4.3) Create a recursion list, to store blank node identifiers\n        // that must be recursively processed by this algorithm.\n        const recursionList = [];\n\n        // 5.4.4) For each related in permutation:\n        let nextPermutation = false;\n        for(const related of permutation) {\n          // 5.4.4.1) If a canonical identifier has been issued for\n          // related, append it to path.\n          if(this.canonicalIssuer.hasId(related)) {\n            path += this.canonicalIssuer.getId(related);\n          } else {\n            // 5.4.4.2) Otherwise:\n            // 5.4.4.2.1) If issuer copy has not issued an identifier for\n            // related, append related to recursion list.\n            if(!issuerCopy.hasId(related)) {\n              recursionList.push(related);\n            }\n            // 5.4.4.2.2) Use the Issue Identifier algorithm, passing\n            // issuer copy and related and append the result to path.\n            path += issuerCopy.getId(related);\n          }\n\n          // 5.4.4.3) If chosen path is not empty and the length of path\n          // is greater than or equal to the length of chosen path and\n          // path is lexicographically greater than chosen path, then\n          // skip to the next permutation.\n          // Note: Comparing path length to chosen path length can be optimized\n          // away; only compare lexicographically.\n          if(chosenPath.length !== 0 && path > chosenPath) {\n            nextPermutation = true;\n            break;\n          }\n        }\n\n        if(nextPermutation) {\n          continue;\n        }\n\n        // 5.4.5) For each related in recursion list:\n        for(const related of recursionList) {\n          // 5.4.5.1) Set result to the result of recursively executing\n          // the Hash N-Degree Quads algorithm, passing related for\n          // identifier and issuer copy for path identifier issuer.\n          const result = this.hashNDegreeQuads(related, issuerCopy);\n\n          // 5.4.5.2) Use the Issue Identifier algorithm, passing issuer\n          // copy and related and append the result to path.\n          path += issuerCopy.getId(related);\n\n          // 5.4.5.3) Append <, the hash in result, and > to path.\n          path += `<${result.hash}>`;\n\n          // 5.4.5.4) Set issuer copy to the identifier issuer in\n          // result.\n          issuerCopy = result.issuer;\n\n          // 5.4.5.5) If chosen path is not empty and the length of path\n          // is greater than or equal to the length of chosen path and\n          // path is lexicographically greater than chosen path, then\n          // skip to the next permutation.\n          // Note: Comparing path length to chosen path length can be optimized\n          // away; only compare lexicographically.\n          if(chosenPath.length !== 0 && path > chosenPath) {\n            nextPermutation = true;\n            break;\n          }\n        }\n\n        if(nextPermutation) {\n          continue;\n        }\n\n        // 5.4.6) If chosen path is empty or path is lexicographically\n        // less than chosen path, set chosen path to path and chosen\n        // issuer to issuer copy.\n        if(chosenPath.length === 0 || path < chosenPath) {\n          chosenPath = path;\n          chosenIssuer = issuerCopy;\n        }\n      }\n\n      // 5.5) Append chosen path to data to hash.\n      md.update(chosenPath);\n\n      // 5.6) Replace issuer, by reference, with chosen issuer.\n      issuer = chosenIssuer;\n    }\n\n    // 6) Return issuer and the hash that results from passing data to hash\n    // through the hash algorithm.\n    return {hash: md.digest(), issuer};\n  }\n\n  // helper for modifying component during Hash First Degree Quads\n  modifyFirstDegreeComponent(id, component) {\n    if(component.termType !== 'BlankNode') {\n      return component;\n    }\n    /* Note: A mistake in the URDNA2015 spec that made its way into\n    implementations (and therefore must stay to avoid interop breakage)\n    resulted in an assigned canonical ID, if available for\n    `component.value`, not being used in place of `_:a`/`_:z`, so\n    we don't use it here. */\n    return {\n      termType: 'BlankNode',\n      value: component.value === id ? '_:a' : '_:z'\n    };\n  }\n\n  // helper for getting a related predicate\n  getRelatedPredicate(quad) {\n    return `<${quad.predicate.value}>`;\n  }\n\n  // helper for creating hash to related blank nodes map\n  createHashToRelated(id, issuer) {\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    const hashToRelated = new Map();\n\n    // 2) Get a reference, quads, to the list of quads in the blank node to\n    // quads map for the key identifier.\n    const quads = this.blankNodeInfo.get(id).quads;\n\n    // 3) For each quad in quads:\n    for(const quad of quads) {\n      // 3.1) For each component in quad, if component is the subject, object,\n      // or graph name and it is a blank node that is not identified by\n      // identifier:\n      // steps 3.1.1 and 3.1.2 occur in helpers:\n      this._addRelatedBlankNodeHash({\n        quad, component: quad.subject, position: 's',\n        id, issuer, hashToRelated\n      });\n      this._addRelatedBlankNodeHash({\n        quad, component: quad.object, position: 'o',\n        id, issuer, hashToRelated\n      });\n      this._addRelatedBlankNodeHash({\n        quad, component: quad.graph, position: 'g',\n        id, issuer, hashToRelated\n      });\n    }\n\n    return hashToRelated;\n  }\n\n  _hashAndTrackBlankNode({id, hashToBlankNodes}) {\n    // 5.3.1) Create a hash, hash, according to the Hash First Degree\n    // Quads algorithm.\n    const hash = this.hashFirstDegreeQuads(id);\n\n    // 5.3.2) Add hash and identifier to hash to blank nodes map,\n    // creating a new entry if necessary.\n    const idList = hashToBlankNodes.get(hash);\n    if(!idList) {\n      hashToBlankNodes.set(hash, [id]);\n    } else {\n      idList.push(id);\n    }\n  }\n\n  _addBlankNodeQuadInfo({quad, component}) {\n    if(component.termType !== 'BlankNode') {\n      return;\n    }\n    const id = component.value;\n    const info = this.blankNodeInfo.get(id);\n    if(info) {\n      info.quads.add(quad);\n    } else {\n      this.blankNodeInfo.set(id, {quads: new Set([quad]), hash: null});\n    }\n  }\n\n  _addRelatedBlankNodeHash(\n    {quad, component, position, id, issuer, hashToRelated}) {\n    if(!(component.termType === 'BlankNode' && component.value !== id)) {\n      return;\n    }\n    // 3.1.1) Set hash to the result of the Hash Related Blank Node\n    // algorithm, passing the blank node identifier for component as\n    // related, quad, path identifier issuer as issuer, and position as\n    // either s, o, or g based on whether component is a subject, object,\n    // graph name, respectively.\n    const related = component.value;\n    const hash = this.hashRelatedBlankNode(related, quad, issuer, position);\n\n    // 3.1.2) Add a mapping of hash to the blank node identifier for\n    // component to hash to related blank nodes map, adding an entry as\n    // necessary.\n    const entries = hashToRelated.get(hash);\n    if(entries) {\n      entries.push(related);\n    } else {\n      hashToRelated.set(hash, [related]);\n    }\n  }\n\n  _useCanonicalId({component}) {\n    if(component.termType === 'BlankNode' &&\n      !component.value.startsWith(this.canonicalIssuer.prefix)) {\n      return {\n        termType: 'BlankNode',\n        value: this.canonicalIssuer.getId(component.value)\n      };\n    }\n    return component;\n  }\n};\n\nfunction _stringHashCompare(a, b) {\n  return a.hash < b.hash ? -1 : a.hash > b.hash ? 1 : 0;\n}\n","/*\n * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst URDNA2015Sync = require('./URDNA2015Sync');\n\nmodule.exports = class URDNA2012Sync extends URDNA2015Sync {\n  constructor() {\n    super();\n    this.name = 'URGNA2012';\n    this.hashAlgorithm = 'sha1';\n  }\n\n  // helper for modifying component during Hash First Degree Quads\n  modifyFirstDegreeComponent(id, component, key) {\n    if(component.termType !== 'BlankNode') {\n      return component;\n    }\n    if(key === 'graph') {\n      return {\n        termType: 'BlankNode',\n        value: '_:g'\n      };\n    }\n    return {\n      termType: 'BlankNode',\n      value: (component.value === id ? '_:a' : '_:z')\n    };\n  }\n\n  // helper for getting a related predicate\n  getRelatedPredicate(quad) {\n    return quad.predicate.value;\n  }\n\n  // helper for creating hash to related blank nodes map\n  createHashToRelated(id, issuer) {\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    const hashToRelated = new Map();\n\n    // 2) Get a reference, quads, to the list of quads in the blank node to\n    // quads map for the key identifier.\n    const quads = this.blankNodeInfo.get(id).quads;\n\n    // 3) For each quad in quads:\n    for(const quad of quads) {\n      // 3.1) If the quad's subject is a blank node that does not match\n      // identifier, set hash to the result of the Hash Related Blank Node\n      // algorithm, passing the blank node identifier for subject as related,\n      // quad, path identifier issuer as issuer, and p as position.\n      let position;\n      let related;\n      if(quad.subject.termType === 'BlankNode' && quad.subject.value !== id) {\n        related = quad.subject.value;\n        position = 'p';\n      } else if(\n        quad.object.termType === 'BlankNode' && quad.object.value !== id) {\n        // 3.2) Otherwise, if quad's object is a blank node that does not match\n        // identifier, to the result of the Hash Related Blank Node algorithm,\n        // passing the blank node identifier for object as related, quad, path\n        // identifier issuer as issuer, and r as position.\n        related = quad.object.value;\n        position = 'r';\n      } else {\n        // 3.3) Otherwise, continue to the next quad.\n        continue;\n      }\n      // 3.4) Add a mapping of hash to the blank node identifier for the\n      // component that matched (subject or object) to hash to related blank\n      // nodes map, adding an entry as necessary.\n      const hash = this.hashRelatedBlankNode(related, quad, issuer, position);\n      const entries = hashToRelated.get(hash);\n      if(entries) {\n        entries.push(related);\n      } else {\n        hashToRelated.set(hash, [related]);\n      }\n    }\n\n    return hashToRelated;\n  }\n};\n","/**\n * An implementation of the RDF Dataset Normalization specification.\n * This library works in the browser and node.js.\n *\n * BSD 3-Clause License\n * Copyright (c) 2016-2021 Digital Bazaar, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * Redistributions of source code must retain the above copyright notice,\n * this list of conditions and the following disclaimer.\n *\n * Redistributions in binary form must reproduce the above copyright\n * notice, this list of conditions and the following disclaimer in the\n * documentation and/or other materials provided with the distribution.\n *\n * Neither the name of the Digital Bazaar, Inc. nor the names of its\n * contributors may be used to endorse or promote products derived from\n * this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\n * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n'use strict';\n\nconst URDNA2015 = require('./URDNA2015');\nconst URGNA2012 = require('./URGNA2012');\nconst URDNA2015Sync = require('./URDNA2015Sync');\nconst URGNA2012Sync = require('./URGNA2012Sync');\n\n// optional native support\nlet rdfCanonizeNative;\ntry {\n  rdfCanonizeNative = require('rdf-canonize-native');\n} catch(e) {}\n\nconst api = {};\nmodule.exports = api;\n\n// expose helpers\napi.NQuads = require('./NQuads');\napi.IdentifierIssuer = require('./IdentifierIssuer');\n\n/**\n * Get or set native API.\n *\n * @param api the native API.\n *\n * @return the currently set native API.\n */\napi._rdfCanonizeNative = function(api) {\n  if(api) {\n    rdfCanonizeNative = api;\n  }\n  return rdfCanonizeNative;\n};\n\n/**\n * Asynchronously canonizes an RDF dataset.\n *\n * @param dataset the dataset to canonize.\n * @param options the options to use:\n *          algorithm the canonicalization algorithm to use, `URDNA2015` or\n *            `URGNA2012`.\n *          [useNative] use native implementation (default: false).\n *\n * @return a Promise that resolves to the canonicalized RDF Dataset.\n */\napi.canonize = async function(dataset, options) {\n  // back-compat with legacy dataset\n  if(!Array.isArray(dataset)) {\n    dataset = api.NQuads.legacyDatasetToQuads(dataset);\n  }\n\n  if(options.useNative) {\n    if(!rdfCanonizeNative) {\n      throw new Error('rdf-canonize-native not available');\n    }\n    // TODO: convert native algorithm to Promise-based async\n    return new Promise((resolve, reject) =>\n      rdfCanonizeNative.canonize(dataset, options, (err, canonical) =>\n        err ? reject(err) : resolve(canonical)));\n  }\n\n  if(options.algorithm === 'URDNA2015') {\n    return new URDNA2015(options).main(dataset);\n  }\n  if(options.algorithm === 'URGNA2012') {\n    return new URGNA2012(options).main(dataset);\n  }\n  if(!('algorithm' in options)) {\n    throw new Error('No RDF Dataset Canonicalization algorithm specified.');\n  }\n  throw new Error(\n    'Invalid RDF Dataset Canonicalization algorithm: ' + options.algorithm);\n};\n\n/**\n * This method is no longer available in the public API, it is for testing\n * only. It synchronously canonizes an RDF dataset and does not work in the\n * browser.\n *\n * @param dataset the dataset to canonize.\n * @param options the options to use:\n *          algorithm the canonicalization algorithm to use, `URDNA2015` or\n *            `URGNA2012`.\n *          [useNative] use native implementation (default: false).\n *\n * @return the RDF dataset in canonical form.\n */\napi._canonizeSync = function(dataset, options) {\n  // back-compat with legacy dataset\n  if(!Array.isArray(dataset)) {\n    dataset = api.NQuads.legacyDatasetToQuads(dataset);\n  }\n\n  if(options.useNative) {\n    if(rdfCanonizeNative) {\n      return rdfCanonizeNative.canonizeSync(dataset, options);\n    }\n    throw new Error('rdf-canonize-native not available');\n  }\n  if(options.algorithm === 'URDNA2015') {\n    return new URDNA2015Sync(options).main(dataset);\n  }\n  if(options.algorithm === 'URGNA2012') {\n    return new URGNA2012Sync(options).main(dataset);\n  }\n  if(!('algorithm' in options)) {\n    throw new Error('No RDF Dataset Canonicalization algorithm specified.');\n  }\n  throw new Error(\n    'Invalid RDF Dataset Canonicalization algorithm: ' + options.algorithm);\n};\n","/**\n * An implementation of the RDF Dataset Normalization specification.\n *\n * @author Dave Longley\n *\n * Copyright 2010-2021 Digital Bazaar, Inc.\n */\nmodule.exports = require('./lib');\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Returns true if the given value is an Array.\n *\n * @param v the value to check.\n *\n * @return true if the value is an Array, false if not.\n */\napi.isArray = Array.isArray;\n\n/**\n * Returns true if the given value is a Boolean.\n *\n * @param v the value to check.\n *\n * @return true if the value is a Boolean, false if not.\n */\napi.isBoolean = v => (typeof v === 'boolean' ||\n  Object.prototype.toString.call(v) === '[object Boolean]');\n\n/**\n * Returns true if the given value is a double.\n *\n * @param v the value to check.\n *\n * @return true if the value is a double, false if not.\n */\napi.isDouble = v => api.isNumber(v) &&\n  (String(v).indexOf('.') !== -1 || Math.abs(v) >= 1e21);\n\n/**\n * Returns true if the given value is an empty Object.\n *\n * @param v the value to check.\n *\n * @return true if the value is an empty Object, false if not.\n */\napi.isEmptyObject = v => api.isObject(v) && Object.keys(v).length === 0;\n\n/**\n * Returns true if the given value is a Number.\n *\n * @param v the value to check.\n *\n * @return true if the value is a Number, false if not.\n */\napi.isNumber = v => (typeof v === 'number' ||\n  Object.prototype.toString.call(v) === '[object Number]');\n\n/**\n * Returns true if the given value is numeric.\n *\n * @param v the value to check.\n *\n * @return true if the value is numeric, false if not.\n */\napi.isNumeric = v => !isNaN(parseFloat(v)) && isFinite(v);\n\n/**\n * Returns true if the given value is an Object.\n *\n * @param v the value to check.\n *\n * @return true if the value is an Object, false if not.\n */\napi.isObject = v => Object.prototype.toString.call(v) === '[object Object]';\n\n/**\n * Returns true if the given value is a String.\n *\n * @param v the value to check.\n *\n * @return true if the value is a String, false if not.\n */\napi.isString = v => (typeof v === 'string' ||\n  Object.prototype.toString.call(v) === '[object String]');\n\n/**\n * Returns true if the given value is undefined.\n *\n * @param v the value to check.\n *\n * @return true if the value is undefined, false if not.\n */\napi.isUndefined = v => typeof v === 'undefined';\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst types = require('./types');\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Returns true if the given value is a subject with properties.\n *\n * @param v the value to check.\n *\n * @return true if the value is a subject with properties, false if not.\n */\napi.isSubject = v => {\n  // Note: A value is a subject if all of these hold true:\n  // 1. It is an Object.\n  // 2. It is not a @value, @set, or @list.\n  // 3. It has more than 1 key OR any existing key is not @id.\n  if(types.isObject(v) &&\n    !(('@value' in v) || ('@set' in v) || ('@list' in v))) {\n    const keyCount = Object.keys(v).length;\n    return (keyCount > 1 || !('@id' in v));\n  }\n  return false;\n};\n\n/**\n * Returns true if the given value is a subject reference.\n *\n * @param v the value to check.\n *\n * @return true if the value is a subject reference, false if not.\n */\napi.isSubjectReference = v =>\n  // Note: A value is a subject reference if all of these hold true:\n  // 1. It is an Object.\n  // 2. It has a single key: @id.\n  (types.isObject(v) && Object.keys(v).length === 1 && ('@id' in v));\n\n/**\n * Returns true if the given value is a @value.\n *\n * @param v the value to check.\n *\n * @return true if the value is a @value, false if not.\n */\napi.isValue = v =>\n  // Note: A value is a @value if all of these hold true:\n  // 1. It is an Object.\n  // 2. It has the @value property.\n  types.isObject(v) && ('@value' in v);\n\n/**\n * Returns true if the given value is a @list.\n *\n * @param v the value to check.\n *\n * @return true if the value is a @list, false if not.\n */\napi.isList = v =>\n  // Note: A value is a @list if all of these hold true:\n  // 1. It is an Object.\n  // 2. It has the @list property.\n  types.isObject(v) && ('@list' in v);\n\n/**\n * Returns true if the given value is a @graph.\n *\n * @return true if the value is a @graph, false if not.\n */\napi.isGraph = v => {\n  // Note: A value is a graph if all of these hold true:\n  // 1. It is an object.\n  // 2. It has an `@graph` key.\n  // 3. It may have '@id' or '@index'\n  return types.isObject(v) &&\n    '@graph' in v &&\n    Object.keys(v)\n      .filter(key => key !== '@id' && key !== '@index').length === 1;\n};\n\n/**\n * Returns true if the given value is a simple @graph.\n *\n * @return true if the value is a simple @graph, false if not.\n */\napi.isSimpleGraph = v => {\n  // Note: A value is a simple graph if all of these hold true:\n  // 1. It is an object.\n  // 2. It has an `@graph` key.\n  // 3. It has only 1 key or 2 keys where one of them is `@index`.\n  return api.isGraph(v) && !('@id' in v);\n};\n\n/**\n * Returns true if the given value is a blank node.\n *\n * @param v the value to check.\n *\n * @return true if the value is a blank node, false if not.\n */\napi.isBlankNode = v => {\n  // Note: A value is a blank node if all of these hold true:\n  // 1. It is an Object.\n  // 2. If it has an @id key its value begins with '_:'.\n  // 3. It has no keys OR is not a @value, @set, or @list.\n  if(types.isObject(v)) {\n    if('@id' in v) {\n      return (v['@id'].indexOf('_:') === 0);\n    }\n    return (Object.keys(v).length === 0 ||\n      !(('@value' in v) || ('@set' in v) || ('@list' in v)));\n  }\n  return false;\n};\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nmodule.exports = class JsonLdError extends Error {\n  /**\n   * Creates a JSON-LD Error.\n   *\n   * @param msg the error message.\n   * @param type the error type.\n   * @param details the error details.\n   */\n  constructor(\n    message = 'An unspecified JSON-LD error occurred.',\n    name = 'jsonld.Error',\n    details = {}) {\n    super(message);\n    this.name = name;\n    this.message = message;\n    this.details = details;\n  }\n};\n","/*\n * Copyright (c) 2017-2019 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst graphTypes = require('./graphTypes');\nconst types = require('./types');\n// TODO: move `IdentifierIssuer` to its own package\nconst IdentifierIssuer = require('rdf-canonize').IdentifierIssuer;\nconst JsonLdError = require('./JsonLdError');\n\n// constants\nconst REGEX_LINK_HEADERS = /(?:<[^>]*?>|\"[^\"]*?\"|[^,])+/g;\nconst REGEX_LINK_HEADER = /\\s*<([^>]*?)>\\s*(?:;\\s*(.*))?/;\nconst REGEX_LINK_HEADER_PARAMS =\n  /(.*?)=(?:(?:\"([^\"]*?)\")|([^\"]*?))\\s*(?:(?:;\\s*)|$)/g;\n\nconst DEFAULTS = {\n  headers: {\n    accept: 'application/ld+json, application/json'\n  }\n};\n\nconst api = {};\nmodule.exports = api;\napi.IdentifierIssuer = IdentifierIssuer;\n\n/**\n * Clones an object, array, Map, Set, or string/number. If a typed JavaScript\n * object is given, such as a Date, it will be converted to a string.\n *\n * @param value the value to clone.\n *\n * @return the cloned value.\n */\napi.clone = function(value) {\n  if(value && typeof value === 'object') {\n    let rval;\n    if(types.isArray(value)) {\n      rval = [];\n      for(let i = 0; i < value.length; ++i) {\n        rval[i] = api.clone(value[i]);\n      }\n    } else if(value instanceof Map) {\n      rval = new Map();\n      for(const [k, v] of value) {\n        rval.set(k, api.clone(v));\n      }\n    } else if(value instanceof Set) {\n      rval = new Set();\n      for(const v of value) {\n        rval.add(api.clone(v));\n      }\n    } else if(types.isObject(value)) {\n      rval = {};\n      for(const key in value) {\n        rval[key] = api.clone(value[key]);\n      }\n    } else {\n      rval = value.toString();\n    }\n    return rval;\n  }\n  return value;\n};\n\n/**\n * Ensure a value is an array. If the value is an array, it is returned.\n * Otherwise, it is wrapped in an array.\n *\n * @param value the value to return as an array.\n *\n * @return the value as an array.\n */\napi.asArray = function(value) {\n  return Array.isArray(value) ? value : [value];\n};\n\n/**\n * Builds an HTTP headers object for making a JSON-LD request from custom\n * headers and asserts the `accept` header isn't overridden.\n *\n * @param headers an object of headers with keys as header names and values\n *          as header values.\n *\n * @return an object of headers with a valid `accept` header.\n */\napi.buildHeaders = (headers = {}) => {\n  const hasAccept = Object.keys(headers).some(\n    h => h.toLowerCase() === 'accept');\n\n  if(hasAccept) {\n    throw new RangeError(\n      'Accept header may not be specified; only \"' +\n      DEFAULTS.headers.accept + '\" is supported.');\n  }\n\n  return Object.assign({Accept: DEFAULTS.headers.accept}, headers);\n};\n\n/**\n * Parses a link header. The results will be key'd by the value of \"rel\".\n *\n * Link: <http://json-ld.org/contexts/person.jsonld>;\n * rel=\"http://www.w3.org/ns/json-ld#context\"; type=\"application/ld+json\"\n *\n * Parses as: {\n *   'http://www.w3.org/ns/json-ld#context': {\n *     target: http://json-ld.org/contexts/person.jsonld,\n *     type: 'application/ld+json'\n *   }\n * }\n *\n * If there is more than one \"rel\" with the same IRI, then entries in the\n * resulting map for that \"rel\" will be arrays.\n *\n * @param header the link header to parse.\n */\napi.parseLinkHeader = header => {\n  const rval = {};\n  // split on unbracketed/unquoted commas\n  const entries = header.match(REGEX_LINK_HEADERS);\n  for(let i = 0; i < entries.length; ++i) {\n    let match = entries[i].match(REGEX_LINK_HEADER);\n    if(!match) {\n      continue;\n    }\n    const result = {target: match[1]};\n    const params = match[2];\n    while((match = REGEX_LINK_HEADER_PARAMS.exec(params))) {\n      result[match[1]] = (match[2] === undefined) ? match[3] : match[2];\n    }\n    const rel = result['rel'] || '';\n    if(Array.isArray(rval[rel])) {\n      rval[rel].push(result);\n    } else if(rval.hasOwnProperty(rel)) {\n      rval[rel] = [rval[rel], result];\n    } else {\n      rval[rel] = result;\n    }\n  }\n  return rval;\n};\n\n/**\n * Throws an exception if the given value is not a valid @type value.\n *\n * @param v the value to check.\n */\napi.validateTypeValue = (v, isFrame) => {\n  if(types.isString(v)) {\n    return;\n  }\n\n  if(types.isArray(v) && v.every(vv => types.isString(vv))) {\n    return;\n  }\n  if(isFrame && types.isObject(v)) {\n    switch(Object.keys(v).length) {\n      case 0:\n        // empty object is wildcard\n        return;\n      case 1:\n        // default entry is all strings\n        if('@default' in v &&\n          api.asArray(v['@default']).every(vv => types.isString(vv))) {\n          return;\n        }\n    }\n  }\n\n  throw new JsonLdError(\n    'Invalid JSON-LD syntax; \"@type\" value must a string, an array of ' +\n    'strings, an empty object, ' +\n    'or a default object.', 'jsonld.SyntaxError',\n    {code: 'invalid type value', value: v});\n};\n\n/**\n * Returns true if the given subject has the given property.\n *\n * @param subject the subject to check.\n * @param property the property to look for.\n *\n * @return true if the subject has the given property, false if not.\n */\napi.hasProperty = (subject, property) => {\n  if(subject.hasOwnProperty(property)) {\n    const value = subject[property];\n    return (!types.isArray(value) || value.length > 0);\n  }\n  return false;\n};\n\n/**\n * Determines if the given value is a property of the given subject.\n *\n * @param subject the subject to check.\n * @param property the property to check.\n * @param value the value to check.\n *\n * @return true if the value exists, false if not.\n */\napi.hasValue = (subject, property, value) => {\n  if(api.hasProperty(subject, property)) {\n    let val = subject[property];\n    const isList = graphTypes.isList(val);\n    if(types.isArray(val) || isList) {\n      if(isList) {\n        val = val['@list'];\n      }\n      for(let i = 0; i < val.length; ++i) {\n        if(api.compareValues(value, val[i])) {\n          return true;\n        }\n      }\n    } else if(!types.isArray(value)) {\n      // avoid matching the set of values with an array value parameter\n      return api.compareValues(value, val);\n    }\n  }\n  return false;\n};\n\n/**\n * Adds a value to a subject. If the value is an array, all values in the\n * array will be added.\n *\n * @param subject the subject to add the value to.\n * @param property the property that relates the value to the subject.\n * @param value the value to add.\n * @param [options] the options to use:\n *        [propertyIsArray] true if the property is always an array, false\n *          if not (default: false).\n *        [valueIsArray] true if the value to be added should be preserved as\n *          an array (lists) (default: false).\n *        [allowDuplicate] true to allow duplicates, false not to (uses a\n *          simple shallow comparison of subject ID or value) (default: true).\n *        [prependValue] false to prepend value to any existing values.\n *          (default: false)\n */\napi.addValue = (subject, property, value, options) => {\n  options = options || {};\n  if(!('propertyIsArray' in options)) {\n    options.propertyIsArray = false;\n  }\n  if(!('valueIsArray' in options)) {\n    options.valueIsArray = false;\n  }\n  if(!('allowDuplicate' in options)) {\n    options.allowDuplicate = true;\n  }\n  if(!('prependValue' in options)) {\n    options.prependValue = false;\n  }\n\n  if(options.valueIsArray) {\n    subject[property] = value;\n  } else if(types.isArray(value)) {\n    if(value.length === 0 && options.propertyIsArray &&\n      !subject.hasOwnProperty(property)) {\n      subject[property] = [];\n    }\n    if(options.prependValue) {\n      value = value.concat(subject[property]);\n      subject[property] = [];\n    }\n    for(let i = 0; i < value.length; ++i) {\n      api.addValue(subject, property, value[i], options);\n    }\n  } else if(subject.hasOwnProperty(property)) {\n    // check if subject already has value if duplicates not allowed\n    const hasValue = (!options.allowDuplicate &&\n      api.hasValue(subject, property, value));\n\n    // make property an array if value not present or always an array\n    if(!types.isArray(subject[property]) &&\n      (!hasValue || options.propertyIsArray)) {\n      subject[property] = [subject[property]];\n    }\n\n    // add new value\n    if(!hasValue) {\n      if(options.prependValue) {\n        subject[property].unshift(value);\n      } else {\n        subject[property].push(value);\n      }\n    }\n  } else {\n    // add new value as set or single value\n    subject[property] = options.propertyIsArray ? [value] : value;\n  }\n};\n\n/**\n * Gets all of the values for a subject's property as an array.\n *\n * @param subject the subject.\n * @param property the property.\n *\n * @return all of the values for a subject's property as an array.\n */\napi.getValues = (subject, property) => [].concat(subject[property] || []);\n\n/**\n * Removes a property from a subject.\n *\n * @param subject the subject.\n * @param property the property.\n */\napi.removeProperty = (subject, property) => {\n  delete subject[property];\n};\n\n/**\n * Removes a value from a subject.\n *\n * @param subject the subject.\n * @param property the property that relates the value to the subject.\n * @param value the value to remove.\n * @param [options] the options to use:\n *          [propertyIsArray] true if the property is always an array, false\n *            if not (default: false).\n */\napi.removeValue = (subject, property, value, options) => {\n  options = options || {};\n  if(!('propertyIsArray' in options)) {\n    options.propertyIsArray = false;\n  }\n\n  // filter out value\n  const values = api.getValues(subject, property).filter(\n    e => !api.compareValues(e, value));\n\n  if(values.length === 0) {\n    api.removeProperty(subject, property);\n  } else if(values.length === 1 && !options.propertyIsArray) {\n    subject[property] = values[0];\n  } else {\n    subject[property] = values;\n  }\n};\n\n/**\n * Relabels all blank nodes in the given JSON-LD input.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [issuer] an IdentifierIssuer to use to label blank nodes.\n */\napi.relabelBlankNodes = (input, options) => {\n  options = options || {};\n  const issuer = options.issuer || new IdentifierIssuer('_:b');\n  return _labelBlankNodes(issuer, input);\n};\n\n/**\n * Compares two JSON-LD values for equality. Two JSON-LD values will be\n * considered equal if:\n *\n * 1. They are both primitives of the same type and value.\n * 2. They are both @values with the same @value, @type, @language,\n *   and @index, OR\n * 3. They both have @ids they are the same.\n *\n * @param v1 the first value.\n * @param v2 the second value.\n *\n * @return true if v1 and v2 are considered equal, false if not.\n */\napi.compareValues = (v1, v2) => {\n  // 1. equal primitives\n  if(v1 === v2) {\n    return true;\n  }\n\n  // 2. equal @values\n  if(graphTypes.isValue(v1) && graphTypes.isValue(v2) &&\n    v1['@value'] === v2['@value'] &&\n    v1['@type'] === v2['@type'] &&\n    v1['@language'] === v2['@language'] &&\n    v1['@index'] === v2['@index']) {\n    return true;\n  }\n\n  // 3. equal @ids\n  if(types.isObject(v1) &&\n    ('@id' in v1) &&\n    types.isObject(v2) &&\n    ('@id' in v2)) {\n    return v1['@id'] === v2['@id'];\n  }\n\n  return false;\n};\n\n/**\n * Compares two strings first based on length and then lexicographically.\n *\n * @param a the first string.\n * @param b the second string.\n *\n * @return -1 if a < b, 1 if a > b, 0 if a === b.\n */\napi.compareShortestLeast = (a, b) => {\n  if(a.length < b.length) {\n    return -1;\n  }\n  if(b.length < a.length) {\n    return 1;\n  }\n  if(a === b) {\n    return 0;\n  }\n  return (a < b) ? -1 : 1;\n};\n\n/**\n * Labels the blank nodes in the given value using the given IdentifierIssuer.\n *\n * @param issuer the IdentifierIssuer to use.\n * @param element the element with blank nodes to rename.\n *\n * @return the element.\n */\nfunction _labelBlankNodes(issuer, element) {\n  if(types.isArray(element)) {\n    for(let i = 0; i < element.length; ++i) {\n      element[i] = _labelBlankNodes(issuer, element[i]);\n    }\n  } else if(graphTypes.isList(element)) {\n    element['@list'] = _labelBlankNodes(issuer, element['@list']);\n  } else if(types.isObject(element)) {\n    // relabel blank node\n    if(graphTypes.isBlankNode(element)) {\n      element['@id'] = issuer.getId(element['@id']);\n    }\n\n    // recursively apply to all keys\n    const keys = Object.keys(element).sort();\n    for(let ki = 0; ki < keys.length; ++ki) {\n      const key = keys[ki];\n      if(key !== '@id') {\n        element[key] = _labelBlankNodes(issuer, element[key]);\n      }\n    }\n  }\n\n  return element;\n}\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\nconst XSD = 'http://www.w3.org/2001/XMLSchema#';\n\nmodule.exports = {\n  // TODO: Deprecated and will be removed later. Use LINK_HEADER_CONTEXT.\n  LINK_HEADER_REL: 'http://www.w3.org/ns/json-ld#context',\n\n  LINK_HEADER_CONTEXT: 'http://www.w3.org/ns/json-ld#context',\n\n  RDF,\n  RDF_LIST: RDF + 'List',\n  RDF_FIRST: RDF + 'first',\n  RDF_REST: RDF + 'rest',\n  RDF_NIL: RDF + 'nil',\n  RDF_TYPE: RDF + 'type',\n  RDF_PLAIN_LITERAL: RDF + 'PlainLiteral',\n  RDF_XML_LITERAL: RDF + 'XMLLiteral',\n  RDF_JSON_LITERAL: RDF + 'JSON',\n  RDF_OBJECT: RDF + 'object',\n  RDF_LANGSTRING: RDF + 'langString',\n\n  XSD,\n  XSD_BOOLEAN: XSD + 'boolean',\n  XSD_DOUBLE: XSD + 'double',\n  XSD_INTEGER: XSD + 'integer',\n  XSD_STRING: XSD + 'string',\n};\n","/*\n * Copyright (c) 2017-2019 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nmodule.exports = class RequestQueue {\n  /**\n   * Creates a simple queue for requesting documents.\n   */\n  constructor() {\n    this._requests = {};\n  }\n\n  wrapLoader(loader) {\n    const self = this;\n    self._loader = loader;\n    return function(/* url */) {\n      return self.add.apply(self, arguments);\n    };\n  }\n\n  async add(url) {\n    let promise = this._requests[url];\n    if(promise) {\n      // URL already queued, wait for it to load\n      return Promise.resolve(promise);\n    }\n\n    // queue URL and load it\n    promise = this._requests[url] = this._loader(url);\n\n    try {\n      return await promise;\n    } finally {\n      delete this._requests[url];\n    }\n  }\n};\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst types = require('./types');\n\nconst api = {};\nmodule.exports = api;\n\n// define URL parser\n// parseUri 1.2.2\n// (c) Steven Levithan <stevenlevithan.com>\n// MIT License\n// with local jsonld.js modifications\napi.parsers = {\n  simple: {\n    // RFC 3986 basic parts\n    keys: [\n      'href', 'scheme', 'authority', 'path', 'query', 'fragment'\n    ],\n    /* eslint-disable-next-line max-len */\n    regex: /^(?:([^:\\/?#]+):)?(?:\\/\\/([^\\/?#]*))?([^?#]*)(?:\\?([^#]*))?(?:#(.*))?/\n  },\n  full: {\n    keys: [\n      'href', 'protocol', 'scheme', 'authority', 'auth', 'user', 'password',\n      'hostname', 'port', 'path', 'directory', 'file', 'query', 'fragment'\n    ],\n    /* eslint-disable-next-line max-len */\n    regex: /^(([^:\\/?#]+):)?(?:\\/\\/((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d*))?))?(?:(((?:[^?#\\/]*\\/)*)([^?#]*))(?:\\?([^#]*))?(?:#(.*))?)/\n  }\n};\napi.parse = (str, parser) => {\n  const parsed = {};\n  const o = api.parsers[parser || 'full'];\n  const m = o.regex.exec(str);\n  let i = o.keys.length;\n  while(i--) {\n    parsed[o.keys[i]] = (m[i] === undefined) ? null : m[i];\n  }\n\n  // remove default ports in found in URLs\n  if((parsed.scheme === 'https' && parsed.port === '443') ||\n    (parsed.scheme === 'http' && parsed.port === '80')) {\n    parsed.href = parsed.href.replace(':' + parsed.port, '');\n    parsed.authority = parsed.authority.replace(':' + parsed.port, '');\n    parsed.port = null;\n  }\n\n  parsed.normalizedPath = api.removeDotSegments(parsed.path);\n  return parsed;\n};\n\n/**\n * Prepends a base IRI to the given relative IRI.\n *\n * @param base the base IRI.\n * @param iri the relative IRI.\n *\n * @return the absolute IRI.\n */\napi.prependBase = (base, iri) => {\n  // skip IRI processing\n  if(base === null) {\n    return iri;\n  }\n  // already an absolute IRI\n  if(api.isAbsolute(iri)) {\n    return iri;\n  }\n\n  // parse base if it is a string\n  if(!base || types.isString(base)) {\n    base = api.parse(base || '');\n  }\n\n  // parse given IRI\n  const rel = api.parse(iri);\n\n  // per RFC3986 5.2.2\n  const transform = {\n    protocol: base.protocol || ''\n  };\n\n  if(rel.authority !== null) {\n    transform.authority = rel.authority;\n    transform.path = rel.path;\n    transform.query = rel.query;\n  } else {\n    transform.authority = base.authority;\n\n    if(rel.path === '') {\n      transform.path = base.path;\n      if(rel.query !== null) {\n        transform.query = rel.query;\n      } else {\n        transform.query = base.query;\n      }\n    } else {\n      if(rel.path.indexOf('/') === 0) {\n        // IRI represents an absolute path\n        transform.path = rel.path;\n      } else {\n        // merge paths\n        let path = base.path;\n\n        // append relative path to the end of the last directory from base\n        path = path.substr(0, path.lastIndexOf('/') + 1);\n        if((path.length > 0 || base.authority) && path.substr(-1) !== '/') {\n          path += '/';\n        }\n        path += rel.path;\n\n        transform.path = path;\n      }\n      transform.query = rel.query;\n    }\n  }\n\n  if(rel.path !== '') {\n    // remove slashes and dots in path\n    transform.path = api.removeDotSegments(transform.path);\n  }\n\n  // construct URL\n  let rval = transform.protocol;\n  if(transform.authority !== null) {\n    rval += '//' + transform.authority;\n  }\n  rval += transform.path;\n  if(transform.query !== null) {\n    rval += '?' + transform.query;\n  }\n  if(rel.fragment !== null) {\n    rval += '#' + rel.fragment;\n  }\n\n  // handle empty base\n  if(rval === '') {\n    rval = './';\n  }\n\n  return rval;\n};\n\n/**\n * Removes a base IRI from the given absolute IRI.\n *\n * @param base the base IRI.\n * @param iri the absolute IRI.\n *\n * @return the relative IRI if relative to base, otherwise the absolute IRI.\n */\napi.removeBase = (base, iri) => {\n  // skip IRI processing\n  if(base === null) {\n    return iri;\n  }\n\n  if(!base || types.isString(base)) {\n    base = api.parse(base || '');\n  }\n\n  // establish base root\n  let root = '';\n  if(base.href !== '') {\n    root += (base.protocol || '') + '//' + (base.authority || '');\n  } else if(iri.indexOf('//')) {\n    // support network-path reference with empty base\n    root += '//';\n  }\n\n  // IRI not relative to base\n  if(iri.indexOf(root) !== 0) {\n    return iri;\n  }\n\n  // remove root from IRI and parse remainder\n  const rel = api.parse(iri.substr(root.length));\n\n  // remove path segments that match (do not remove last segment unless there\n  // is a hash or query)\n  const baseSegments = base.normalizedPath.split('/');\n  const iriSegments = rel.normalizedPath.split('/');\n  const last = (rel.fragment || rel.query) ? 0 : 1;\n  while(baseSegments.length > 0 && iriSegments.length > last) {\n    if(baseSegments[0] !== iriSegments[0]) {\n      break;\n    }\n    baseSegments.shift();\n    iriSegments.shift();\n  }\n\n  // use '../' for each non-matching base segment\n  let rval = '';\n  if(baseSegments.length > 0) {\n    // don't count the last segment (if it ends with '/' last path doesn't\n    // count and if it doesn't end with '/' it isn't a path)\n    baseSegments.pop();\n    for(let i = 0; i < baseSegments.length; ++i) {\n      rval += '../';\n    }\n  }\n\n  // prepend remaining segments\n  rval += iriSegments.join('/');\n\n  // add query and hash\n  if(rel.query !== null) {\n    rval += '?' + rel.query;\n  }\n  if(rel.fragment !== null) {\n    rval += '#' + rel.fragment;\n  }\n\n  // handle empty base\n  if(rval === '') {\n    rval = './';\n  }\n\n  return rval;\n};\n\n/**\n * Removes dot segments from a URL path.\n *\n * @param path the path to remove dot segments from.\n */\napi.removeDotSegments = path => {\n  // RFC 3986 5.2.4 (reworked)\n\n  // empty path shortcut\n  if(path.length === 0) {\n    return '';\n  }\n\n  const input = path.split('/');\n  const output = [];\n\n  while(input.length > 0) {\n    const next = input.shift();\n    const done = input.length === 0;\n\n    if(next === '.') {\n      if(done) {\n        // ensure output has trailing /\n        output.push('');\n      }\n      continue;\n    }\n\n    if(next === '..') {\n      output.pop();\n      if(done) {\n        // ensure output has trailing /\n        output.push('');\n      }\n      continue;\n    }\n\n    output.push(next);\n  }\n\n  // if path was absolute, ensure output has leading /\n  if(path[0] === '/' && output.length > 0 && output[0] !== '') {\n    output.unshift('');\n  }\n  if(output.length === 1 && output[0] === '') {\n    return '/';\n  }\n\n  return output.join('/');\n};\n\n// TODO: time better isAbsolute/isRelative checks using full regexes:\n// http://jmrware.com/articles/2009/uri_regexp/URI_regex.html\n\n// regex to check for absolute IRI (starting scheme and ':') or blank node IRI\nconst isAbsoluteRegex = /^([A-Za-z][A-Za-z0-9+-.]*|_):[^\\s]*$/;\n\n/**\n * Returns true if the given value is an absolute IRI or blank node IRI, false\n * if not.\n * Note: This weak check only checks for a correct starting scheme.\n *\n * @param v the value to check.\n *\n * @return true if the value is an absolute IRI, false if not.\n */\napi.isAbsolute = v => types.isString(v) && isAbsoluteRegex.test(v);\n\n/**\n * Returns true if the given value is a relative IRI, false if not.\n * Note: this is a weak check.\n *\n * @param v the value to check.\n *\n * @return true if the value is a relative IRI, false if not.\n */\napi.isRelative = v => types.isString(v);\n","\"use strict\";\n/**\n * Returns a `Buffer` instance from the given data URI `uri`.\n *\n * @param {String} uri Data URI to turn into a Buffer instance\n * @return {Buffer} Buffer instance from Data URI\n * @api public\n */\nfunction dataUriToBuffer(uri) {\n    if (!/^data:/i.test(uri)) {\n        throw new TypeError('`uri` does not appear to be a Data URI (must begin with \"data:\")');\n    }\n    // strip newlines\n    uri = uri.replace(/\\r?\\n/g, '');\n    // split the URI up into the \"metadata\" and the \"data\" portions\n    const firstComma = uri.indexOf(',');\n    if (firstComma === -1 || firstComma <= 4) {\n        throw new TypeError('malformed data: URI');\n    }\n    // remove the \"data:\" scheme and parse the metadata\n    const meta = uri.substring(5, firstComma).split(';');\n    let charset = '';\n    let base64 = false;\n    const type = meta[0] || 'text/plain';\n    let typeFull = type;\n    for (let i = 1; i < meta.length; i++) {\n        if (meta[i] === 'base64') {\n            base64 = true;\n        }\n        else {\n            typeFull += `;${meta[i]}`;\n            if (meta[i].indexOf('charset=') === 0) {\n                charset = meta[i].substring(8);\n            }\n        }\n    }\n    // defaults to US-ASCII only if type is not provided\n    if (!meta[0] && !charset.length) {\n        typeFull += ';charset=US-ASCII';\n        charset = 'US-ASCII';\n    }\n    // get the encoded data portion and decode URI-encoded chars\n    const encoding = base64 ? 'base64' : 'ascii';\n    const data = unescape(uri.substring(firstComma + 1));\n    const buffer = Buffer.from(data, encoding);\n    // set `.type` and `.typeFull` properties to MIME type\n    buffer.type = type;\n    buffer.typeFull = typeFull;\n    // set the `.charset` property\n    buffer.charset = charset;\n    return buffer;\n}\nmodule.exports = dataUriToBuffer;\n//# sourceMappingURL=index.js.map","const {Readable} = require('stream');\n\n/**\n * @type {WeakMap<Blob, {type: string, size: number, parts: (Blob | Buffer)[] }>}\n */\nconst wm = new WeakMap();\n\nasync function * read(parts) {\n\tfor (const part of parts) {\n\t\tif ('stream' in part) {\n\t\t\tyield * part.stream();\n\t\t} else {\n\t\t\tyield part;\n\t\t}\n\t}\n}\n\nclass Blob {\n\t/**\n\t * The Blob() constructor returns a new Blob object. The content\n\t * of the blob consists of the concatenation of the values given\n\t * in the parameter array.\n\t *\n\t * @param {(ArrayBufferLike | ArrayBufferView | Blob | Buffer | string)[]} blobParts\n\t * @param {{ type?: string }} [options]\n\t */\n\tconstructor(blobParts = [], options = {}) {\n\t\tlet size = 0;\n\n\t\tconst parts = blobParts.map(element => {\n\t\t\tlet buffer;\n\t\t\tif (element instanceof Buffer) {\n\t\t\t\tbuffer = element;\n\t\t\t} else if (ArrayBuffer.isView(element)) {\n\t\t\t\tbuffer = Buffer.from(element.buffer, element.byteOffset, element.byteLength);\n\t\t\t} else if (element instanceof ArrayBuffer) {\n\t\t\t\tbuffer = Buffer.from(element);\n\t\t\t} else if (element instanceof Blob) {\n\t\t\t\tbuffer = element;\n\t\t\t} else {\n\t\t\t\tbuffer = Buffer.from(typeof element === 'string' ? element : String(element));\n\t\t\t}\n\n\t\t\t// eslint-disable-next-line unicorn/explicit-length-check\n\t\t\tsize += buffer.length || buffer.size || 0;\n\t\t\treturn buffer;\n\t\t});\n\n\t\tconst type = options.type === undefined ? '' : String(options.type).toLowerCase();\n\n\t\twm.set(this, {\n\t\t\ttype: /[^\\u0020-\\u007E]/.test(type) ? '' : type,\n\t\t\tsize,\n\t\t\tparts\n\t\t});\n\t}\n\n\t/**\n\t * The Blob interface's size property returns the\n\t * size of the Blob in bytes.\n\t */\n\tget size() {\n\t\treturn wm.get(this).size;\n\t}\n\n\t/**\n\t * The type property of a Blob object returns the MIME type of the file.\n\t */\n\tget type() {\n\t\treturn wm.get(this).type;\n\t}\n\n\t/**\n\t * The text() method in the Blob interface returns a Promise\n\t * that resolves with a string containing the contents of\n\t * the blob, interpreted as UTF-8.\n\t *\n\t * @return {Promise<string>}\n\t */\n\tasync text() {\n\t\treturn Buffer.from(await this.arrayBuffer()).toString();\n\t}\n\n\t/**\n\t * The arrayBuffer() method in the Blob interface returns a\n\t * Promise that resolves with the contents of the blob as\n\t * binary data contained in an ArrayBuffer.\n\t *\n\t * @return {Promise<ArrayBuffer>}\n\t */\n\tasync arrayBuffer() {\n\t\tconst data = new Uint8Array(this.size);\n\t\tlet offset = 0;\n\t\tfor await (const chunk of this.stream()) {\n\t\t\tdata.set(chunk, offset);\n\t\t\toffset += chunk.length;\n\t\t}\n\n\t\treturn data.buffer;\n\t}\n\n\t/**\n\t * The Blob interface's stream() method is difference from native\n\t * and uses node streams instead of whatwg streams.\n\t *\n\t * @returns {Readable} Node readable stream\n\t */\n\tstream() {\n\t\treturn Readable.from(read(wm.get(this).parts));\n\t}\n\n\t/**\n\t * The Blob interface's slice() method creates and returns a\n\t * new Blob object which contains data from a subset of the\n\t * blob on which it's called.\n\t *\n\t * @param {number} [start]\n\t * @param {number} [end]\n\t * @param {string} [type]\n\t */\n\tslice(start = 0, end = this.size, type = '') {\n\t\tconst {size} = this;\n\n\t\tlet relativeStart = start < 0 ? Math.max(size + start, 0) : Math.min(start, size);\n\t\tlet relativeEnd = end < 0 ? Math.max(size + end, 0) : Math.min(end, size);\n\n\t\tconst span = Math.max(relativeEnd - relativeStart, 0);\n\t\tconst parts = wm.get(this).parts.values();\n\t\tconst blobParts = [];\n\t\tlet added = 0;\n\n\t\tfor (const part of parts) {\n\t\t\tconst size = ArrayBuffer.isView(part) ? part.byteLength : part.size;\n\t\t\tif (relativeStart && size <= relativeStart) {\n\t\t\t\t// Skip the beginning and change the relative\n\t\t\t\t// start & end position as we skip the unwanted parts\n\t\t\t\trelativeStart -= size;\n\t\t\t\trelativeEnd -= size;\n\t\t\t} else {\n\t\t\t\tconst chunk = part.slice(relativeStart, Math.min(size, relativeEnd));\n\t\t\t\tblobParts.push(chunk);\n\t\t\t\tadded += ArrayBuffer.isView(chunk) ? chunk.byteLength : chunk.size;\n\t\t\t\trelativeStart = 0; // All next sequental parts should start at 0\n\n\t\t\t\t// don't add the overflow to new blobParts\n\t\t\t\tif (added >= span) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tconst blob = new Blob([], {type: String(type).toLowerCase()});\n\t\tObject.assign(wm.get(blob), {size: span, parts: blobParts});\n\n\t\treturn blob;\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Blob';\n\t}\n\n\tstatic [Symbol.hasInstance](object) {\n\t\treturn (\n\t\t\tobject &&\n\t\t\ttypeof object === 'object' &&\n\t\t\ttypeof object.stream === 'function' &&\n\t\t\tobject.stream.length === 0 &&\n\t\t\ttypeof object.constructor === 'function' &&\n\t\t\t/^(Blob|File)$/.test(object[Symbol.toStringTag])\n\t\t);\n\t}\n}\n\nObject.defineProperties(Blob.prototype, {\n\tsize: {enumerable: true},\n\ttype: {enumerable: true},\n\tslice: {enumerable: true}\n});\n\nmodule.exports = Blob;\n","'use strict';\n\nexport class FetchBaseError extends Error {\n\tconstructor(message, type) {\n\t\tsuper(message);\n\t\t// Hide custom error implementation details from end-users\n\t\tError.captureStackTrace(this, this.constructor);\n\n\t\tthis.type = type;\n\t}\n\n\tget name() {\n\t\treturn this.constructor.name;\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.name;\n\t}\n}\n\n","\nimport {FetchBaseError} from './base.js';\n\n/**\n * @typedef {{ address?: string, code: string, dest?: string, errno: number, info?: object, message: string, path?: string, port?: number, syscall: string}} SystemError\n*/\n\n/**\n * FetchError interface for operational errors\n */\nexport class FetchError extends FetchBaseError {\n\t/**\n\t * @param  {string} message -      Error message for human\n\t * @param  {string} [type] -        Error type for machine\n\t * @param  {SystemError} [systemError] - For Node.js system error\n\t */\n\tconstructor(message, type, systemError) {\n\t\tsuper(message, type);\n\t\t// When err.type is `system`, err.erroredSysCall contains system error and err.code contains system error code\n\t\tif (systemError) {\n\t\t\t// eslint-disable-next-line no-multi-assign\n\t\t\tthis.code = this.errno = systemError.code;\n\t\t\tthis.erroredSysCall = systemError.syscall;\n\t\t}\n\t}\n}\n","/**\n * Is.js\n *\n * Object type checks.\n */\n\nconst NAME = Symbol.toStringTag;\n\n/**\n * Check if `obj` is a URLSearchParams object\n * ref: https://github.com/node-fetch/node-fetch/issues/296#issuecomment-307598143\n *\n * @param  {*} obj\n * @return {boolean}\n */\nexport const isURLSearchParameters = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.append === 'function' &&\n\t\ttypeof object.delete === 'function' &&\n\t\ttypeof object.get === 'function' &&\n\t\ttypeof object.getAll === 'function' &&\n\t\ttypeof object.has === 'function' &&\n\t\ttypeof object.set === 'function' &&\n\t\ttypeof object.sort === 'function' &&\n\t\tobject[NAME] === 'URLSearchParams'\n\t);\n};\n\n/**\n * Check if `object` is a W3C `Blob` object (which `File` inherits from)\n *\n * @param  {*} obj\n * @return {boolean}\n */\nexport const isBlob = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.arrayBuffer === 'function' &&\n\t\ttypeof object.type === 'string' &&\n\t\ttypeof object.stream === 'function' &&\n\t\ttypeof object.constructor === 'function' &&\n\t\t/^(Blob|File)$/.test(object[NAME])\n\t);\n};\n\n/**\n * Check if `obj` is a spec-compliant `FormData` object\n *\n * @param {*} object\n * @return {boolean}\n */\nexport function isFormData(object) {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.append === 'function' &&\n\t\ttypeof object.set === 'function' &&\n\t\ttypeof object.get === 'function' &&\n\t\ttypeof object.getAll === 'function' &&\n\t\ttypeof object.delete === 'function' &&\n\t\ttypeof object.keys === 'function' &&\n\t\ttypeof object.values === 'function' &&\n\t\ttypeof object.entries === 'function' &&\n\t\ttypeof object.constructor === 'function' &&\n\t\tobject[NAME] === 'FormData'\n\t);\n}\n\n/**\n * Check if `obj` is an instance of AbortSignal.\n *\n * @param  {*} obj\n * @return {boolean}\n */\nexport const isAbortSignal = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\tobject[NAME] === 'AbortSignal'\n\t);\n};\n\n","import {randomBytes} from 'crypto';\n\nimport {isBlob} from './is.js';\n\nconst carriage = '\\r\\n';\nconst dashes = '-'.repeat(2);\nconst carriageLength = Buffer.byteLength(carriage);\n\n/**\n * @param {string} boundary\n */\nconst getFooter = boundary => `${dashes}${boundary}${dashes}${carriage.repeat(2)}`;\n\n/**\n * @param {string} boundary\n * @param {string} name\n * @param {*} field\n *\n * @return {string}\n */\nfunction getHeader(boundary, name, field) {\n\tlet header = '';\n\n\theader += `${dashes}${boundary}${carriage}`;\n\theader += `Content-Disposition: form-data; name=\"${name}\"`;\n\n\tif (isBlob(field)) {\n\t\theader += `; filename=\"${field.name}\"${carriage}`;\n\t\theader += `Content-Type: ${field.type || 'application/octet-stream'}`;\n\t}\n\n\treturn `${header}${carriage.repeat(2)}`;\n}\n\n/**\n * @return {string}\n */\nexport const getBoundary = () => randomBytes(8).toString('hex');\n\n/**\n * @param {FormData} form\n * @param {string} boundary\n */\nexport async function * formDataIterator(form, boundary) {\n\tfor (const [name, value] of form) {\n\t\tyield getHeader(boundary, name, value);\n\n\t\tif (isBlob(value)) {\n\t\t\tyield * value.stream();\n\t\t} else {\n\t\t\tyield value;\n\t\t}\n\n\t\tyield carriage;\n\t}\n\n\tyield getFooter(boundary);\n}\n\n/**\n * @param {FormData} form\n * @param {string} boundary\n */\nexport function getFormDataLength(form, boundary) {\n\tlet length = 0;\n\n\tfor (const [name, value] of form) {\n\t\tlength += Buffer.byteLength(getHeader(boundary, name, value));\n\n\t\tif (isBlob(value)) {\n\t\t\tlength += value.size;\n\t\t} else {\n\t\t\tlength += Buffer.byteLength(String(value));\n\t\t}\n\n\t\tlength += carriageLength;\n\t}\n\n\tlength += Buffer.byteLength(getFooter(boundary));\n\n\treturn length;\n}\n","\n/**\n * Body.js\n *\n * Body interface provides common methods for Request and Response\n */\n\nimport Stream, {PassThrough} from 'stream';\nimport {types} from 'util';\n\nimport Blob from 'fetch-blob';\n\nimport {FetchError} from './errors/fetch-error.js';\nimport {FetchBaseError} from './errors/base.js';\nimport {formDataIterator, getBoundary, getFormDataLength} from './utils/form-data.js';\nimport {isBlob, isURLSearchParameters, isFormData} from './utils/is.js';\n\nconst INTERNALS = Symbol('Body internals');\n\n/**\n * Body mixin\n *\n * Ref: https://fetch.spec.whatwg.org/#body\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nexport default class Body {\n\tconstructor(body, {\n\t\tsize = 0\n\t} = {}) {\n\t\tlet boundary = null;\n\n\t\tif (body === null) {\n\t\t\t// Body is undefined or null\n\t\t\tbody = null;\n\t\t} else if (isURLSearchParameters(body)) {\n\t\t// Body is a URLSearchParams\n\t\t\tbody = Buffer.from(body.toString());\n\t\t} else if (isBlob(body)) {\n\t\t\t// Body is blob\n\t\t} else if (Buffer.isBuffer(body)) {\n\t\t\t// Body is Buffer\n\t\t} else if (types.isAnyArrayBuffer(body)) {\n\t\t\t// Body is ArrayBuffer\n\t\t\tbody = Buffer.from(body);\n\t\t} else if (ArrayBuffer.isView(body)) {\n\t\t\t// Body is ArrayBufferView\n\t\t\tbody = Buffer.from(body.buffer, body.byteOffset, body.byteLength);\n\t\t} else if (body instanceof Stream) {\n\t\t\t// Body is stream\n\t\t} else if (isFormData(body)) {\n\t\t\t// Body is an instance of formdata-node\n\t\t\tboundary = `NodeFetchFormDataBoundary${getBoundary()}`;\n\t\t\tbody = Stream.Readable.from(formDataIterator(body, boundary));\n\t\t} else {\n\t\t\t// None of the above\n\t\t\t// coerce to string then buffer\n\t\t\tbody = Buffer.from(String(body));\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\tbody,\n\t\t\tboundary,\n\t\t\tdisturbed: false,\n\t\t\terror: null\n\t\t};\n\t\tthis.size = size;\n\n\t\tif (body instanceof Stream) {\n\t\t\tbody.on('error', err => {\n\t\t\t\tconst error = err instanceof FetchBaseError ?\n\t\t\t\t\terr :\n\t\t\t\t\tnew FetchError(`Invalid response body while trying to fetch ${this.url}: ${err.message}`, 'system', err);\n\t\t\t\tthis[INTERNALS].error = error;\n\t\t\t});\n\t\t}\n\t}\n\n\tget body() {\n\t\treturn this[INTERNALS].body;\n\t}\n\n\tget bodyUsed() {\n\t\treturn this[INTERNALS].disturbed;\n\t}\n\n\t/**\n\t * Decode response as ArrayBuffer\n\t *\n\t * @return  Promise\n\t */\n\tasync arrayBuffer() {\n\t\tconst {buffer, byteOffset, byteLength} = await consumeBody(this);\n\t\treturn buffer.slice(byteOffset, byteOffset + byteLength);\n\t}\n\n\t/**\n\t * Return raw response as Blob\n\t *\n\t * @return Promise\n\t */\n\tasync blob() {\n\t\tconst ct = (this.headers && this.headers.get('content-type')) || (this[INTERNALS].body && this[INTERNALS].body.type) || '';\n\t\tconst buf = await this.buffer();\n\n\t\treturn new Blob([buf], {\n\t\t\ttype: ct\n\t\t});\n\t}\n\n\t/**\n\t * Decode response as json\n\t *\n\t * @return  Promise\n\t */\n\tasync json() {\n\t\tconst buffer = await consumeBody(this);\n\t\treturn JSON.parse(buffer.toString());\n\t}\n\n\t/**\n\t * Decode response as text\n\t *\n\t * @return  Promise\n\t */\n\tasync text() {\n\t\tconst buffer = await consumeBody(this);\n\t\treturn buffer.toString();\n\t}\n\n\t/**\n\t * Decode response as buffer (non-spec api)\n\t *\n\t * @return  Promise\n\t */\n\tbuffer() {\n\t\treturn consumeBody(this);\n\t}\n}\n\n// In browsers, all properties are enumerable.\nObject.defineProperties(Body.prototype, {\n\tbody: {enumerable: true},\n\tbodyUsed: {enumerable: true},\n\tarrayBuffer: {enumerable: true},\n\tblob: {enumerable: true},\n\tjson: {enumerable: true},\n\ttext: {enumerable: true}\n});\n\n/**\n * Consume and convert an entire Body to a Buffer.\n *\n * Ref: https://fetch.spec.whatwg.org/#concept-body-consume-body\n *\n * @return Promise\n */\nasync function consumeBody(data) {\n\tif (data[INTERNALS].disturbed) {\n\t\tthrow new TypeError(`body used already for: ${data.url}`);\n\t}\n\n\tdata[INTERNALS].disturbed = true;\n\n\tif (data[INTERNALS].error) {\n\t\tthrow data[INTERNALS].error;\n\t}\n\n\tlet {body} = data;\n\n\t// Body is null\n\tif (body === null) {\n\t\treturn Buffer.alloc(0);\n\t}\n\n\t// Body is blob\n\tif (isBlob(body)) {\n\t\tbody = body.stream();\n\t}\n\n\t// Body is buffer\n\tif (Buffer.isBuffer(body)) {\n\t\treturn body;\n\t}\n\n\t/* c8 ignore next 3 */\n\tif (!(body instanceof Stream)) {\n\t\treturn Buffer.alloc(0);\n\t}\n\n\t// Body is stream\n\t// get ready to actually consume the body\n\tconst accum = [];\n\tlet accumBytes = 0;\n\n\ttry {\n\t\tfor await (const chunk of body) {\n\t\t\tif (data.size > 0 && accumBytes + chunk.length > data.size) {\n\t\t\t\tconst err = new FetchError(`content size at ${data.url} over limit: ${data.size}`, 'max-size');\n\t\t\t\tbody.destroy(err);\n\t\t\t\tthrow err;\n\t\t\t}\n\n\t\t\taccumBytes += chunk.length;\n\t\t\taccum.push(chunk);\n\t\t}\n\t} catch (error) {\n\t\tif (error instanceof FetchBaseError) {\n\t\t\tthrow error;\n\t\t} else {\n\t\t\t// Other errors, such as incorrect content-encoding\n\t\t\tthrow new FetchError(`Invalid response body while trying to fetch ${data.url}: ${error.message}`, 'system', error);\n\t\t}\n\t}\n\n\tif (body.readableEnded === true || body._readableState.ended === true) {\n\t\ttry {\n\t\t\tif (accum.every(c => typeof c === 'string')) {\n\t\t\t\treturn Buffer.from(accum.join(''));\n\t\t\t}\n\n\t\t\treturn Buffer.concat(accum, accumBytes);\n\t\t} catch (error) {\n\t\t\tthrow new FetchError(`Could not create Buffer from response body for ${data.url}: ${error.message}`, 'system', error);\n\t\t}\n\t} else {\n\t\tthrow new FetchError(`Premature close of server response while trying to fetch ${data.url}`);\n\t}\n}\n\n/**\n * Clone body given Res/Req instance\n *\n * @param   Mixed   instance       Response or Request instance\n * @param   String  highWaterMark  highWaterMark for both PassThrough body streams\n * @return  Mixed\n */\nexport const clone = (instance, highWaterMark) => {\n\tlet p1;\n\tlet p2;\n\tlet {body} = instance;\n\n\t// Don't allow cloning a used body\n\tif (instance.bodyUsed) {\n\t\tthrow new Error('cannot clone body after it is used');\n\t}\n\n\t// Check that body is a stream and not form-data object\n\t// note: we can't clone the form-data object without having it as a dependency\n\tif ((body instanceof Stream) && (typeof body.getBoundary !== 'function')) {\n\t\t// Tee instance body\n\t\tp1 = new PassThrough({highWaterMark});\n\t\tp2 = new PassThrough({highWaterMark});\n\t\tbody.pipe(p1);\n\t\tbody.pipe(p2);\n\t\t// Set instance body to teed body and return the other teed body\n\t\tinstance[INTERNALS].body = p1;\n\t\tbody = p2;\n\t}\n\n\treturn body;\n};\n\n/**\n * Performs the operation \"extract a `Content-Type` value from |object|\" as\n * specified in the specification:\n * https://fetch.spec.whatwg.org/#concept-bodyinit-extract\n *\n * This function assumes that instance.body is present.\n *\n * @param {any} body Any options.body input\n * @returns {string | null}\n */\nexport const extractContentType = (body, request) => {\n\t// Body is null or undefined\n\tif (body === null) {\n\t\treturn null;\n\t}\n\n\t// Body is string\n\tif (typeof body === 'string') {\n\t\treturn 'text/plain;charset=UTF-8';\n\t}\n\n\t// Body is a URLSearchParams\n\tif (isURLSearchParameters(body)) {\n\t\treturn 'application/x-www-form-urlencoded;charset=UTF-8';\n\t}\n\n\t// Body is blob\n\tif (isBlob(body)) {\n\t\treturn body.type || null;\n\t}\n\n\t// Body is a Buffer (Buffer, ArrayBuffer or ArrayBufferView)\n\tif (Buffer.isBuffer(body) || types.isAnyArrayBuffer(body) || ArrayBuffer.isView(body)) {\n\t\treturn null;\n\t}\n\n\t// Detect form data input from form-data module\n\tif (body && typeof body.getBoundary === 'function') {\n\t\treturn `multipart/form-data;boundary=${body.getBoundary()}`;\n\t}\n\n\tif (isFormData(body)) {\n\t\treturn `multipart/form-data; boundary=${request[INTERNALS].boundary}`;\n\t}\n\n\t// Body is stream - can't really do much about this\n\tif (body instanceof Stream) {\n\t\treturn null;\n\t}\n\n\t// Body constructor defaults other things to string\n\treturn 'text/plain;charset=UTF-8';\n};\n\n/**\n * The Fetch Standard treats this as if \"total bytes\" is a property on the body.\n * For us, we have to explicitly get it with a function.\n *\n * ref: https://fetch.spec.whatwg.org/#concept-body-total-bytes\n *\n * @param {any} obj.body Body object from the Body instance.\n * @returns {number | null}\n */\nexport const getTotalBytes = request => {\n\tconst {body} = request;\n\n\t// Body is null or undefined\n\tif (body === null) {\n\t\treturn 0;\n\t}\n\n\t// Body is Blob\n\tif (isBlob(body)) {\n\t\treturn body.size;\n\t}\n\n\t// Body is Buffer\n\tif (Buffer.isBuffer(body)) {\n\t\treturn body.length;\n\t}\n\n\t// Detect form data input from form-data module\n\tif (body && typeof body.getLengthSync === 'function') {\n\t\treturn body.hasKnownLength && body.hasKnownLength() ? body.getLengthSync() : null;\n\t}\n\n\t// Body is a spec-compliant form-data\n\tif (isFormData(body)) {\n\t\treturn getFormDataLength(request[INTERNALS].boundary);\n\t}\n\n\t// Body is stream\n\treturn null;\n};\n\n/**\n * Write a Body to a Node.js WritableStream (e.g. http.Request) object.\n *\n * @param {Stream.Writable} dest The stream to write to.\n * @param obj.body Body object from the Body instance.\n * @returns {void}\n */\nexport const writeToStream = (dest, {body}) => {\n\tif (body === null) {\n\t\t// Body is null\n\t\tdest.end();\n\t} else if (isBlob(body)) {\n\t\t// Body is Blob\n\t\tbody.stream().pipe(dest);\n\t} else if (Buffer.isBuffer(body)) {\n\t\t// Body is buffer\n\t\tdest.write(body);\n\t\tdest.end();\n\t} else {\n\t\t// Body is stream\n\t\tbody.pipe(dest);\n\t}\n};\n\n","/**\n * Headers.js\n *\n * Headers class offers convenient helpers\n */\n\nimport {types} from 'util';\nimport http from 'http';\n\nconst validateHeaderName = typeof http.validateHeaderName === 'function' ?\n\thttp.validateHeaderName :\n\tname => {\n\t\tif (!/^[\\^`\\-\\w!#$%&'*+.|~]+$/.test(name)) {\n\t\t\tconst err = new TypeError(`Header name must be a valid HTTP token [${name}]`);\n\t\t\tObject.defineProperty(err, 'code', {value: 'ERR_INVALID_HTTP_TOKEN'});\n\t\t\tthrow err;\n\t\t}\n\t};\n\nconst validateHeaderValue = typeof http.validateHeaderValue === 'function' ?\n\thttp.validateHeaderValue :\n\t(name, value) => {\n\t\tif (/[^\\t\\u0020-\\u007E\\u0080-\\u00FF]/.test(value)) {\n\t\t\tconst err = new TypeError(`Invalid character in header content [\"${name}\"]`);\n\t\t\tObject.defineProperty(err, 'code', {value: 'ERR_INVALID_CHAR'});\n\t\t\tthrow err;\n\t\t}\n\t};\n\n/**\n * @typedef {Headers | Record<string, string> | Iterable<readonly [string, string]> | Iterable<Iterable<string>>} HeadersInit\n */\n\n/**\n * This Fetch API interface allows you to perform various actions on HTTP request and response headers.\n * These actions include retrieving, setting, adding to, and removing.\n * A Headers object has an associated header list, which is initially empty and consists of zero or more name and value pairs.\n * You can add to this using methods like append() (see Examples.)\n * In all methods of this interface, header names are matched by case-insensitive byte sequence.\n *\n */\nexport default class Headers extends URLSearchParams {\n\t/**\n\t * Headers class\n\t *\n\t * @constructor\n\t * @param {HeadersInit} [init] - Response headers\n\t */\n\tconstructor(init) {\n\t\t// Validate and normalize init object in [name, value(s)][]\n\t\t/** @type {string[][]} */\n\t\tlet result = [];\n\t\tif (init instanceof Headers) {\n\t\t\tconst raw = init.raw();\n\t\t\tfor (const [name, values] of Object.entries(raw)) {\n\t\t\t\tresult.push(...values.map(value => [name, value]));\n\t\t\t}\n\t\t} else if (init == null) { // eslint-disable-line no-eq-null, eqeqeq\n\t\t\t// No op\n\t\t} else if (typeof init === 'object' && !types.isBoxedPrimitive(init)) {\n\t\t\tconst method = init[Symbol.iterator];\n\t\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\t\tif (method == null) {\n\t\t\t\t// Record<ByteString, ByteString>\n\t\t\t\tresult.push(...Object.entries(init));\n\t\t\t} else {\n\t\t\t\tif (typeof method !== 'function') {\n\t\t\t\t\tthrow new TypeError('Header pairs must be iterable');\n\t\t\t\t}\n\n\t\t\t\t// Sequence<sequence<ByteString>>\n\t\t\t\t// Note: per spec we have to first exhaust the lists then process them\n\t\t\t\tresult = [...init]\n\t\t\t\t\t.map(pair => {\n\t\t\t\t\t\tif (\n\t\t\t\t\t\t\ttypeof pair !== 'object' || types.isBoxedPrimitive(pair)\n\t\t\t\t\t\t) {\n\t\t\t\t\t\t\tthrow new TypeError('Each header pair must be an iterable object');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn [...pair];\n\t\t\t\t\t}).map(pair => {\n\t\t\t\t\t\tif (pair.length !== 2) {\n\t\t\t\t\t\t\tthrow new TypeError('Each header pair must be a name/value tuple');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn [...pair];\n\t\t\t\t\t});\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new TypeError('Failed to construct \\'Headers\\': The provided value is not of type \\'(sequence<sequence<ByteString>> or record<ByteString, ByteString>)');\n\t\t}\n\n\t\t// Validate and lowercase\n\t\tresult =\n\t\t\tresult.length > 0 ?\n\t\t\t\tresult.map(([name, value]) => {\n\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\treturn [String(name).toLowerCase(), String(value)];\n\t\t\t\t}) :\n\t\t\t\tundefined;\n\n\t\tsuper(result);\n\n\t\t// Returning a Proxy that will lowercase key names, validate parameters and sort keys\n\t\t// eslint-disable-next-line no-constructor-return\n\t\treturn new Proxy(this, {\n\t\t\tget(target, p, receiver) {\n\t\t\t\tswitch (p) {\n\t\t\t\t\tcase 'append':\n\t\t\t\t\tcase 'set':\n\t\t\t\t\t\treturn (name, value) => {\n\t\t\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\t\t\treturn URLSearchParams.prototype[p].call(\n\t\t\t\t\t\t\t\treceiver,\n\t\t\t\t\t\t\t\tString(name).toLowerCase(),\n\t\t\t\t\t\t\t\tString(value)\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\n\t\t\t\t\tcase 'delete':\n\t\t\t\t\tcase 'has':\n\t\t\t\t\tcase 'getAll':\n\t\t\t\t\t\treturn name => {\n\t\t\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\t\t\treturn URLSearchParams.prototype[p].call(\n\t\t\t\t\t\t\t\treceiver,\n\t\t\t\t\t\t\t\tString(name).toLowerCase()\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\n\t\t\t\t\tcase 'keys':\n\t\t\t\t\t\treturn () => {\n\t\t\t\t\t\t\ttarget.sort();\n\t\t\t\t\t\t\treturn new Set(URLSearchParams.prototype.keys.call(target)).keys();\n\t\t\t\t\t\t};\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn Reflect.get(target, p, receiver);\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* c8 ignore next */\n\t\t});\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.name;\n\t}\n\n\ttoString() {\n\t\treturn Object.prototype.toString.call(this);\n\t}\n\n\tget(name) {\n\t\tconst values = this.getAll(name);\n\t\tif (values.length === 0) {\n\t\t\treturn null;\n\t\t}\n\n\t\tlet value = values.join(', ');\n\t\tif (/^content-encoding$/i.test(name)) {\n\t\t\tvalue = value.toLowerCase();\n\t\t}\n\n\t\treturn value;\n\t}\n\n\tforEach(callback) {\n\t\tfor (const name of this.keys()) {\n\t\t\tcallback(this.get(name), name);\n\t\t}\n\t}\n\n\t* values() {\n\t\tfor (const name of this.keys()) {\n\t\t\tyield this.get(name);\n\t\t}\n\t}\n\n\t/**\n\t * @type {() => IterableIterator<[string, string]>}\n\t */\n\t* entries() {\n\t\tfor (const name of this.keys()) {\n\t\t\tyield [name, this.get(name)];\n\t\t}\n\t}\n\n\t[Symbol.iterator]() {\n\t\treturn this.entries();\n\t}\n\n\t/**\n\t * Node-fetch non-spec method\n\t * returning all headers and their values as array\n\t * @returns {Record<string, string[]>}\n\t */\n\traw() {\n\t\treturn [...this.keys()].reduce((result, key) => {\n\t\t\tresult[key] = this.getAll(key);\n\t\t\treturn result;\n\t\t}, {});\n\t}\n\n\t/**\n\t * For better console.log(headers) and also to convert Headers into Node.js Request compatible format\n\t */\n\t[Symbol.for('nodejs.util.inspect.custom')]() {\n\t\treturn [...this.keys()].reduce((result, key) => {\n\t\t\tconst values = this.getAll(key);\n\t\t\t// Http.request() only supports string as Host header.\n\t\t\t// This hack makes specifying custom Host header possible.\n\t\t\tif (key === 'host') {\n\t\t\t\tresult[key] = values[0];\n\t\t\t} else {\n\t\t\t\tresult[key] = values.length > 1 ? values : values[0];\n\t\t\t}\n\n\t\t\treturn result;\n\t\t}, {});\n\t}\n}\n\n/**\n * Re-shaping object for Web IDL tests\n * Only need to do it for overridden methods\n */\nObject.defineProperties(\n\tHeaders.prototype,\n\t['get', 'entries', 'forEach', 'values'].reduce((result, property) => {\n\t\tresult[property] = {enumerable: true};\n\t\treturn result;\n\t}, {})\n);\n\n/**\n * Create a Headers object from an http.IncomingMessage.rawHeaders, ignoring those that do\n * not conform to HTTP grammar productions.\n * @param {import('http').IncomingMessage['rawHeaders']} headers\n */\nexport function fromRawHeaders(headers = []) {\n\treturn new Headers(\n\t\theaders\n\t\t\t// Split into pairs\n\t\t\t.reduce((result, value, index, array) => {\n\t\t\t\tif (index % 2 === 0) {\n\t\t\t\t\tresult.push(array.slice(index, index + 2));\n\t\t\t\t}\n\n\t\t\t\treturn result;\n\t\t\t}, [])\n\t\t\t.filter(([name, value]) => {\n\t\t\t\ttry {\n\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\treturn true;\n\t\t\t\t} catch {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t})\n\n\t);\n}\n","const redirectStatus = new Set([301, 302, 303, 307, 308]);\n\n/**\n * Redirect code matching\n *\n * @param {number} code - Status code\n * @return {boolean}\n */\nexport const isRedirect = code => {\n\treturn redirectStatus.has(code);\n};\n","/**\n * Response.js\n *\n * Response class provides content decoding\n */\n\nimport Headers from './headers.js';\nimport Body, {clone, extractContentType} from './body.js';\nimport {isRedirect} from './utils/is-redirect.js';\n\nconst INTERNALS = Symbol('Response internals');\n\n/**\n * Response class\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nexport default class Response extends Body {\n\tconstructor(body = null, options = {}) {\n\t\tsuper(body, options);\n\n\t\tconst status = options.status || 200;\n\t\tconst headers = new Headers(options.headers);\n\n\t\tif (body !== null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(body);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\turl: options.url,\n\t\t\tstatus,\n\t\t\tstatusText: options.statusText || '',\n\t\t\theaders,\n\t\t\tcounter: options.counter,\n\t\t\thighWaterMark: options.highWaterMark\n\t\t};\n\t}\n\n\tget url() {\n\t\treturn this[INTERNALS].url || '';\n\t}\n\n\tget status() {\n\t\treturn this[INTERNALS].status;\n\t}\n\n\t/**\n\t * Convenience property representing if the request ended normally\n\t */\n\tget ok() {\n\t\treturn this[INTERNALS].status >= 200 && this[INTERNALS].status < 300;\n\t}\n\n\tget redirected() {\n\t\treturn this[INTERNALS].counter > 0;\n\t}\n\n\tget statusText() {\n\t\treturn this[INTERNALS].statusText;\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS].headers;\n\t}\n\n\tget highWaterMark() {\n\t\treturn this[INTERNALS].highWaterMark;\n\t}\n\n\t/**\n\t * Clone this response\n\t *\n\t * @return  Response\n\t */\n\tclone() {\n\t\treturn new Response(clone(this, this.highWaterMark), {\n\t\t\turl: this.url,\n\t\t\tstatus: this.status,\n\t\t\tstatusText: this.statusText,\n\t\t\theaders: this.headers,\n\t\t\tok: this.ok,\n\t\t\tredirected: this.redirected,\n\t\t\tsize: this.size\n\t\t});\n\t}\n\n\t/**\n\t * @param {string} url    The URL that the new response is to originate from.\n\t * @param {number} status An optional status code for the response (e.g., 302.)\n\t * @returns {Response}    A Response object.\n\t */\n\tstatic redirect(url, status = 302) {\n\t\tif (!isRedirect(status)) {\n\t\t\tthrow new RangeError('Failed to execute \"redirect\" on \"response\": Invalid status code');\n\t\t}\n\n\t\treturn new Response(null, {\n\t\t\theaders: {\n\t\t\t\tlocation: new URL(url).toString()\n\t\t\t},\n\t\t\tstatus\n\t\t});\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Response';\n\t}\n}\n\nObject.defineProperties(Response.prototype, {\n\turl: {enumerable: true},\n\tstatus: {enumerable: true},\n\tok: {enumerable: true},\n\tredirected: {enumerable: true},\n\tstatusText: {enumerable: true},\n\theaders: {enumerable: true},\n\tclone: {enumerable: true}\n});\n\n","export const getSearch = parsedURL => {\n\tif (parsedURL.search) {\n\t\treturn parsedURL.search;\n\t}\n\n\tconst lastOffset = parsedURL.href.length - 1;\n\tconst hash = parsedURL.hash || (parsedURL.href[lastOffset] === '#' ? '#' : '');\n\treturn parsedURL.href[lastOffset - hash.length] === '?' ? '?' : '';\n};\n","\n/**\n * Request.js\n *\n * Request class contains server only options\n *\n * All spec algorithm step numbers are based on https://fetch.spec.whatwg.org/commit-snapshots/ae716822cb3a61843226cd090eefc6589446c1d2/.\n */\n\nimport {format as formatUrl} from 'url';\nimport Headers from './headers.js';\nimport Body, {clone, extractContentType, getTotalBytes} from './body.js';\nimport {isAbortSignal} from './utils/is.js';\nimport {getSearch} from './utils/get-search.js';\n\nconst INTERNALS = Symbol('Request internals');\n\n/**\n * Check if `obj` is an instance of Request.\n *\n * @param  {*} obj\n * @return {boolean}\n */\nconst isRequest = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object[INTERNALS] === 'object'\n\t);\n};\n\n/**\n * Request class\n *\n * @param   Mixed   input  Url or Request instance\n * @param   Object  init   Custom options\n * @return  Void\n */\nexport default class Request extends Body {\n\tconstructor(input, init = {}) {\n\t\tlet parsedURL;\n\n\t\t// Normalize input and force URL to be encoded as UTF-8 (https://github.com/node-fetch/node-fetch/issues/245)\n\t\tif (isRequest(input)) {\n\t\t\tparsedURL = new URL(input.url);\n\t\t} else {\n\t\t\tparsedURL = new URL(input);\n\t\t\tinput = {};\n\t\t}\n\n\t\tlet method = init.method || input.method || 'GET';\n\t\tmethod = method.toUpperCase();\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tif (((init.body != null || isRequest(input)) && input.body !== null) &&\n\t\t\t(method === 'GET' || method === 'HEAD')) {\n\t\t\tthrow new TypeError('Request with GET/HEAD method cannot have body');\n\t\t}\n\n\t\tconst inputBody = init.body ?\n\t\t\tinit.body :\n\t\t\t(isRequest(input) && input.body !== null ?\n\t\t\t\tclone(input) :\n\t\t\t\tnull);\n\n\t\tsuper(inputBody, {\n\t\t\tsize: init.size || input.size || 0\n\t\t});\n\n\t\tconst headers = new Headers(init.headers || input.headers || {});\n\n\t\tif (inputBody !== null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(inputBody, this);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tlet signal = isRequest(input) ?\n\t\t\tinput.signal :\n\t\t\tnull;\n\t\tif ('signal' in init) {\n\t\t\tsignal = init.signal;\n\t\t}\n\n\t\tif (signal !== null && !isAbortSignal(signal)) {\n\t\t\tthrow new TypeError('Expected signal to be an instanceof AbortSignal');\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\tmethod,\n\t\t\tredirect: init.redirect || input.redirect || 'follow',\n\t\t\theaders,\n\t\t\tparsedURL,\n\t\t\tsignal\n\t\t};\n\n\t\t// Node-fetch-only options\n\t\tthis.follow = init.follow === undefined ? (input.follow === undefined ? 20 : input.follow) : init.follow;\n\t\tthis.compress = init.compress === undefined ? (input.compress === undefined ? true : input.compress) : init.compress;\n\t\tthis.counter = init.counter || input.counter || 0;\n\t\tthis.agent = init.agent || input.agent;\n\t\tthis.highWaterMark = init.highWaterMark || input.highWaterMark || 16384;\n\t\tthis.insecureHTTPParser = init.insecureHTTPParser || input.insecureHTTPParser || false;\n\t}\n\n\tget method() {\n\t\treturn this[INTERNALS].method;\n\t}\n\n\tget url() {\n\t\treturn formatUrl(this[INTERNALS].parsedURL);\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS].headers;\n\t}\n\n\tget redirect() {\n\t\treturn this[INTERNALS].redirect;\n\t}\n\n\tget signal() {\n\t\treturn this[INTERNALS].signal;\n\t}\n\n\t/**\n\t * Clone this request\n\t *\n\t * @return  Request\n\t */\n\tclone() {\n\t\treturn new Request(this);\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Request';\n\t}\n}\n\nObject.defineProperties(Request.prototype, {\n\tmethod: {enumerable: true},\n\turl: {enumerable: true},\n\theaders: {enumerable: true},\n\tredirect: {enumerable: true},\n\tclone: {enumerable: true},\n\tsignal: {enumerable: true}\n});\n\n/**\n * Convert a Request to Node.js http request options.\n *\n * @param   Request  A Request instance\n * @return  Object   The options object to be passed to http.request\n */\nexport const getNodeRequestOptions = request => {\n\tconst {parsedURL} = request[INTERNALS];\n\tconst headers = new Headers(request[INTERNALS].headers);\n\n\t// Fetch step 1.3\n\tif (!headers.has('Accept')) {\n\t\theaders.set('Accept', '*/*');\n\t}\n\n\t// HTTP-network-or-cache fetch steps 2.4-2.7\n\tlet contentLengthValue = null;\n\tif (request.body === null && /^(post|put)$/i.test(request.method)) {\n\t\tcontentLengthValue = '0';\n\t}\n\n\tif (request.body !== null) {\n\t\tconst totalBytes = getTotalBytes(request);\n\t\t// Set Content-Length if totalBytes is a number (that is not NaN)\n\t\tif (typeof totalBytes === 'number' && !Number.isNaN(totalBytes)) {\n\t\t\tcontentLengthValue = String(totalBytes);\n\t\t}\n\t}\n\n\tif (contentLengthValue) {\n\t\theaders.set('Content-Length', contentLengthValue);\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.11\n\tif (!headers.has('User-Agent')) {\n\t\theaders.set('User-Agent', 'node-fetch');\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.15\n\tif (request.compress && !headers.has('Accept-Encoding')) {\n\t\theaders.set('Accept-Encoding', 'gzip,deflate,br');\n\t}\n\n\tlet {agent} = request;\n\tif (typeof agent === 'function') {\n\t\tagent = agent(parsedURL);\n\t}\n\n\tif (!headers.has('Connection') && !agent) {\n\t\theaders.set('Connection', 'close');\n\t}\n\n\t// HTTP-network fetch step 4.2\n\t// chunked encoding is handled by Node.js\n\n\tconst search = getSearch(parsedURL);\n\n\t// Manually spread the URL object instead of spread syntax\n\tconst requestOptions = {\n\t\tpath: parsedURL.pathname + search,\n\t\tpathname: parsedURL.pathname,\n\t\thostname: parsedURL.hostname,\n\t\tprotocol: parsedURL.protocol,\n\t\tport: parsedURL.port,\n\t\thash: parsedURL.hash,\n\t\tsearch: parsedURL.search,\n\t\tquery: parsedURL.query,\n\t\thref: parsedURL.href,\n\t\tmethod: request.method,\n\t\theaders: headers[Symbol.for('nodejs.util.inspect.custom')](),\n\t\tinsecureHTTPParser: request.insecureHTTPParser,\n\t\tagent\n\t};\n\n\treturn requestOptions;\n};\n","import {FetchBaseError} from './base.js';\n\n/**\n * AbortError interface for cancelled requests\n */\nexport class AbortError extends FetchBaseError {\n\tconstructor(message, type = 'aborted') {\n\t\tsuper(message, type);\n\t}\n}\n","/**\n * Index.js\n *\n * a request API compatible with window.fetch\n *\n * All spec algorithm step numbers are based on https://fetch.spec.whatwg.org/commit-snapshots/ae716822cb3a61843226cd090eefc6589446c1d2/.\n */\n\nimport http from 'http';\nimport https from 'https';\nimport zlib from 'zlib';\nimport Stream, {PassThrough, pipeline as pump} from 'stream';\nimport dataUriToBuffer from 'data-uri-to-buffer';\n\nimport {writeToStream} from './body.js';\nimport Response from './response.js';\nimport Headers, {fromRawHeaders} from './headers.js';\nimport Request, {getNodeRequestOptions} from './request.js';\nimport {FetchError} from './errors/fetch-error.js';\nimport {AbortError} from './errors/abort-error.js';\nimport {isRedirect} from './utils/is-redirect.js';\n\nexport {Headers, Request, Response, FetchError, AbortError, isRedirect};\n\nconst supportedSchemas = new Set(['data:', 'http:', 'https:']);\n\n/**\n * Fetch function\n *\n * @param   {string | URL | import('./request').default} url - Absolute url or Request instance\n * @param   {*} [options_] - Fetch options\n * @return  {Promise<import('./response').default>}\n */\nexport default async function fetch(url, options_) {\n\treturn new Promise((resolve, reject) => {\n\t\t// Build request object\n\t\tconst request = new Request(url, options_);\n\t\tconst options = getNodeRequestOptions(request);\n\t\tif (!supportedSchemas.has(options.protocol)) {\n\t\t\tthrow new TypeError(`node-fetch cannot load ${url}. URL scheme \"${options.protocol.replace(/:$/, '')}\" is not supported.`);\n\t\t}\n\n\t\tif (options.protocol === 'data:') {\n\t\t\tconst data = dataUriToBuffer(request.url);\n\t\t\tconst response = new Response(data, {headers: {'Content-Type': data.typeFull}});\n\t\t\tresolve(response);\n\t\t\treturn;\n\t\t}\n\n\t\t// Wrap http.request into fetch\n\t\tconst send = (options.protocol === 'https:' ? https : http).request;\n\t\tconst {signal} = request;\n\t\tlet response = null;\n\n\t\tconst abort = () => {\n\t\t\tconst error = new AbortError('The operation was aborted.');\n\t\t\treject(error);\n\t\t\tif (request.body && request.body instanceof Stream.Readable) {\n\t\t\t\trequest.body.destroy(error);\n\t\t\t}\n\n\t\t\tif (!response || !response.body) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tresponse.body.emit('error', error);\n\t\t};\n\n\t\tif (signal && signal.aborted) {\n\t\t\tabort();\n\t\t\treturn;\n\t\t}\n\n\t\tconst abortAndFinalize = () => {\n\t\t\tabort();\n\t\t\tfinalize();\n\t\t};\n\n\t\t// Send request\n\t\tconst request_ = send(options);\n\n\t\tif (signal) {\n\t\t\tsignal.addEventListener('abort', abortAndFinalize);\n\t\t}\n\n\t\tconst finalize = () => {\n\t\t\trequest_.abort();\n\t\t\tif (signal) {\n\t\t\t\tsignal.removeEventListener('abort', abortAndFinalize);\n\t\t\t}\n\t\t};\n\n\t\trequest_.on('error', err => {\n\t\t\treject(new FetchError(`request to ${request.url} failed, reason: ${err.message}`, 'system', err));\n\t\t\tfinalize();\n\t\t});\n\n\t\trequest_.on('response', response_ => {\n\t\t\trequest_.setTimeout(0);\n\t\t\tconst headers = fromRawHeaders(response_.rawHeaders);\n\n\t\t\t// HTTP fetch step 5\n\t\t\tif (isRedirect(response_.statusCode)) {\n\t\t\t\t// HTTP fetch step 5.2\n\t\t\t\tconst location = headers.get('Location');\n\n\t\t\t\t// HTTP fetch step 5.3\n\t\t\t\tconst locationURL = location === null ? null : new URL(location, request.url);\n\n\t\t\t\t// HTTP fetch step 5.5\n\t\t\t\tswitch (request.redirect) {\n\t\t\t\t\tcase 'error':\n\t\t\t\t\t\treject(new FetchError(`uri requested responds with a redirect, redirect mode is set to error: ${request.url}`, 'no-redirect'));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\tcase 'manual':\n\t\t\t\t\t\t// Node-fetch-specific step: make manual redirect a bit easier to use by setting the Location header value to the resolved URL.\n\t\t\t\t\t\tif (locationURL !== null) {\n\t\t\t\t\t\t\t// Handle corrupted header\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\theaders.set('Location', locationURL);\n\t\t\t\t\t\t\t\t/* c8 ignore next 3 */\n\t\t\t\t\t\t\t} catch (error) {\n\t\t\t\t\t\t\t\treject(error);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 'follow': {\n\t\t\t\t\t\t// HTTP-redirect fetch step 2\n\t\t\t\t\t\tif (locationURL === null) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 5\n\t\t\t\t\t\tif (request.counter >= request.follow) {\n\t\t\t\t\t\t\treject(new FetchError(`maximum redirect reached at: ${request.url}`, 'max-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 6 (counter increment)\n\t\t\t\t\t\t// Create a new Request object.\n\t\t\t\t\t\tconst requestOptions = {\n\t\t\t\t\t\t\theaders: new Headers(request.headers),\n\t\t\t\t\t\t\tfollow: request.follow,\n\t\t\t\t\t\t\tcounter: request.counter + 1,\n\t\t\t\t\t\t\tagent: request.agent,\n\t\t\t\t\t\t\tcompress: request.compress,\n\t\t\t\t\t\t\tmethod: request.method,\n\t\t\t\t\t\t\tbody: request.body,\n\t\t\t\t\t\t\tsignal: request.signal,\n\t\t\t\t\t\t\tsize: request.size\n\t\t\t\t\t\t};\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 9\n\t\t\t\t\t\tif (response_.statusCode !== 303 && request.body && options_.body instanceof Stream.Readable) {\n\t\t\t\t\t\t\treject(new FetchError('Cannot follow redirect with body being a readable stream', 'unsupported-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 11\n\t\t\t\t\t\tif (response_.statusCode === 303 || ((response_.statusCode === 301 || response_.statusCode === 302) && request.method === 'POST')) {\n\t\t\t\t\t\t\trequestOptions.method = 'GET';\n\t\t\t\t\t\t\trequestOptions.body = undefined;\n\t\t\t\t\t\t\trequestOptions.headers.delete('content-length');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 15\n\t\t\t\t\t\tresolve(fetch(new Request(locationURL, requestOptions)));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t// Do nothing\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Prepare response\n\t\t\tresponse_.once('end', () => {\n\t\t\t\tif (signal) {\n\t\t\t\t\tsignal.removeEventListener('abort', abortAndFinalize);\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tlet body = pump(response_, new PassThrough(), error => {\n\t\t\t\treject(error);\n\t\t\t});\n\t\t\t// see https://github.com/nodejs/node/pull/29376\n\t\t\tif (process.version < 'v12.10') {\n\t\t\t\tresponse_.on('aborted', abortAndFinalize);\n\t\t\t}\n\n\t\t\tconst responseOptions = {\n\t\t\t\turl: request.url,\n\t\t\t\tstatus: response_.statusCode,\n\t\t\t\tstatusText: response_.statusMessage,\n\t\t\t\theaders,\n\t\t\t\tsize: request.size,\n\t\t\t\tcounter: request.counter,\n\t\t\t\thighWaterMark: request.highWaterMark\n\t\t\t};\n\n\t\t\t// HTTP-network fetch step 12.1.1.3\n\t\t\tconst codings = headers.get('Content-Encoding');\n\n\t\t\t// HTTP-network fetch step 12.1.1.4: handle content codings\n\n\t\t\t// in following scenarios we ignore compression support\n\t\t\t// 1. compression support is disabled\n\t\t\t// 2. HEAD request\n\t\t\t// 3. no Content-Encoding header\n\t\t\t// 4. no content response (204)\n\t\t\t// 5. content not modified response (304)\n\t\t\tif (!request.compress || request.method === 'HEAD' || codings === null || response_.statusCode === 204 || response_.statusCode === 304) {\n\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For Node v6+\n\t\t\t// Be less strict when decoding compressed responses, since sometimes\n\t\t\t// servers send slightly invalid responses that are still accepted\n\t\t\t// by common browsers.\n\t\t\t// Always using Z_SYNC_FLUSH is what cURL does.\n\t\t\tconst zlibOptions = {\n\t\t\t\tflush: zlib.Z_SYNC_FLUSH,\n\t\t\t\tfinishFlush: zlib.Z_SYNC_FLUSH\n\t\t\t};\n\n\t\t\t// For gzip\n\t\t\tif (codings === 'gzip' || codings === 'x-gzip') {\n\t\t\t\tbody = pump(body, zlib.createGunzip(zlibOptions), error => {\n\t\t\t\t\treject(error);\n\t\t\t\t});\n\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For deflate\n\t\t\tif (codings === 'deflate' || codings === 'x-deflate') {\n\t\t\t\t// Handle the infamous raw deflate response from old servers\n\t\t\t\t// a hack for old IIS and Apache servers\n\t\t\t\tconst raw = pump(response_, new PassThrough(), error => {\n\t\t\t\t\treject(error);\n\t\t\t\t});\n\t\t\t\traw.once('data', chunk => {\n\t\t\t\t\t// See http://stackoverflow.com/questions/37519828\n\t\t\t\t\tif ((chunk[0] & 0x0F) === 0x08) {\n\t\t\t\t\t\tbody = pump(body, zlib.createInflate(), error => {\n\t\t\t\t\t\t\treject(error);\n\t\t\t\t\t\t});\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbody = pump(body, zlib.createInflateRaw(), error => {\n\t\t\t\t\t\t\treject(error);\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\n\t\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\t\tresolve(response);\n\t\t\t\t});\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For br\n\t\t\tif (codings === 'br') {\n\t\t\t\tbody = pump(body, zlib.createBrotliDecompress(), error => {\n\t\t\t\t\treject(error);\n\t\t\t\t});\n\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Otherwise, use response as-is\n\t\t\tresponse = new Response(body, responseOptions);\n\t\t\tresolve(response);\n\t\t});\n\n\t\twriteToStream(request_, request);\n\t});\n}\n","/**\n * @author Toru Nagashima <https://github.com/mysticatea>\n * @copyright 2015 Toru Nagashima. All rights reserved.\n * See LICENSE file in root directory for full license.\n */\n/**\n * @typedef {object} PrivateData\n * @property {EventTarget} eventTarget The event target.\n * @property {{type:string}} event The original event object.\n * @property {number} eventPhase The current event phase.\n * @property {EventTarget|null} currentTarget The current event target.\n * @property {boolean} canceled The flag to prevent default.\n * @property {boolean} stopped The flag to stop propagation.\n * @property {boolean} immediateStopped The flag to stop propagation immediately.\n * @property {Function|null} passiveListener The listener if the current listener is passive. Otherwise this is null.\n * @property {number} timeStamp The unix time.\n * @private\n */\n\n/**\n * Private data for event wrappers.\n * @type {WeakMap<Event, PrivateData>}\n * @private\n */\nconst privateData = new WeakMap();\n\n/**\n * Cache for wrapper classes.\n * @type {WeakMap<Object, Function>}\n * @private\n */\nconst wrappers = new WeakMap();\n\n/**\n * Get private data.\n * @param {Event} event The event object to get private data.\n * @returns {PrivateData} The private data of the event.\n * @private\n */\nfunction pd(event) {\n    const retv = privateData.get(event);\n    console.assert(\n        retv != null,\n        \"'this' is expected an Event object, but got\",\n        event\n    );\n    return retv\n}\n\n/**\n * https://dom.spec.whatwg.org/#set-the-canceled-flag\n * @param data {PrivateData} private data.\n */\nfunction setCancelFlag(data) {\n    if (data.passiveListener != null) {\n        if (\n            typeof console !== \"undefined\" &&\n            typeof console.error === \"function\"\n        ) {\n            console.error(\n                \"Unable to preventDefault inside passive event listener invocation.\",\n                data.passiveListener\n            );\n        }\n        return\n    }\n    if (!data.event.cancelable) {\n        return\n    }\n\n    data.canceled = true;\n    if (typeof data.event.preventDefault === \"function\") {\n        data.event.preventDefault();\n    }\n}\n\n/**\n * @see https://dom.spec.whatwg.org/#interface-event\n * @private\n */\n/**\n * The event wrapper.\n * @constructor\n * @param {EventTarget} eventTarget The event target of this dispatching.\n * @param {Event|{type:string}} event The original event to wrap.\n */\nfunction Event(eventTarget, event) {\n    privateData.set(this, {\n        eventTarget,\n        event,\n        eventPhase: 2,\n        currentTarget: eventTarget,\n        canceled: false,\n        stopped: false,\n        immediateStopped: false,\n        passiveListener: null,\n        timeStamp: event.timeStamp || Date.now(),\n    });\n\n    // https://heycam.github.io/webidl/#Unforgeable\n    Object.defineProperty(this, \"isTrusted\", { value: false, enumerable: true });\n\n    // Define accessors\n    const keys = Object.keys(event);\n    for (let i = 0; i < keys.length; ++i) {\n        const key = keys[i];\n        if (!(key in this)) {\n            Object.defineProperty(this, key, defineRedirectDescriptor(key));\n        }\n    }\n}\n\n// Should be enumerable, but class methods are not enumerable.\nEvent.prototype = {\n    /**\n     * The type of this event.\n     * @type {string}\n     */\n    get type() {\n        return pd(this).event.type\n    },\n\n    /**\n     * The target of this event.\n     * @type {EventTarget}\n     */\n    get target() {\n        return pd(this).eventTarget\n    },\n\n    /**\n     * The target of this event.\n     * @type {EventTarget}\n     */\n    get currentTarget() {\n        return pd(this).currentTarget\n    },\n\n    /**\n     * @returns {EventTarget[]} The composed path of this event.\n     */\n    composedPath() {\n        const currentTarget = pd(this).currentTarget;\n        if (currentTarget == null) {\n            return []\n        }\n        return [currentTarget]\n    },\n\n    /**\n     * Constant of NONE.\n     * @type {number}\n     */\n    get NONE() {\n        return 0\n    },\n\n    /**\n     * Constant of CAPTURING_PHASE.\n     * @type {number}\n     */\n    get CAPTURING_PHASE() {\n        return 1\n    },\n\n    /**\n     * Constant of AT_TARGET.\n     * @type {number}\n     */\n    get AT_TARGET() {\n        return 2\n    },\n\n    /**\n     * Constant of BUBBLING_PHASE.\n     * @type {number}\n     */\n    get BUBBLING_PHASE() {\n        return 3\n    },\n\n    /**\n     * The target of this event.\n     * @type {number}\n     */\n    get eventPhase() {\n        return pd(this).eventPhase\n    },\n\n    /**\n     * Stop event bubbling.\n     * @returns {void}\n     */\n    stopPropagation() {\n        const data = pd(this);\n\n        data.stopped = true;\n        if (typeof data.event.stopPropagation === \"function\") {\n            data.event.stopPropagation();\n        }\n    },\n\n    /**\n     * Stop event bubbling.\n     * @returns {void}\n     */\n    stopImmediatePropagation() {\n        const data = pd(this);\n\n        data.stopped = true;\n        data.immediateStopped = true;\n        if (typeof data.event.stopImmediatePropagation === \"function\") {\n            data.event.stopImmediatePropagation();\n        }\n    },\n\n    /**\n     * The flag to be bubbling.\n     * @type {boolean}\n     */\n    get bubbles() {\n        return Boolean(pd(this).event.bubbles)\n    },\n\n    /**\n     * The flag to be cancelable.\n     * @type {boolean}\n     */\n    get cancelable() {\n        return Boolean(pd(this).event.cancelable)\n    },\n\n    /**\n     * Cancel this event.\n     * @returns {void}\n     */\n    preventDefault() {\n        setCancelFlag(pd(this));\n    },\n\n    /**\n     * The flag to indicate cancellation state.\n     * @type {boolean}\n     */\n    get defaultPrevented() {\n        return pd(this).canceled\n    },\n\n    /**\n     * The flag to be composed.\n     * @type {boolean}\n     */\n    get composed() {\n        return Boolean(pd(this).event.composed)\n    },\n\n    /**\n     * The unix time of this event.\n     * @type {number}\n     */\n    get timeStamp() {\n        return pd(this).timeStamp\n    },\n\n    /**\n     * The target of this event.\n     * @type {EventTarget}\n     * @deprecated\n     */\n    get srcElement() {\n        return pd(this).eventTarget\n    },\n\n    /**\n     * The flag to stop event bubbling.\n     * @type {boolean}\n     * @deprecated\n     */\n    get cancelBubble() {\n        return pd(this).stopped\n    },\n    set cancelBubble(value) {\n        if (!value) {\n            return\n        }\n        const data = pd(this);\n\n        data.stopped = true;\n        if (typeof data.event.cancelBubble === \"boolean\") {\n            data.event.cancelBubble = true;\n        }\n    },\n\n    /**\n     * The flag to indicate cancellation state.\n     * @type {boolean}\n     * @deprecated\n     */\n    get returnValue() {\n        return !pd(this).canceled\n    },\n    set returnValue(value) {\n        if (!value) {\n            setCancelFlag(pd(this));\n        }\n    },\n\n    /**\n     * Initialize this event object. But do nothing under event dispatching.\n     * @param {string} type The event type.\n     * @param {boolean} [bubbles=false] The flag to be possible to bubble up.\n     * @param {boolean} [cancelable=false] The flag to be possible to cancel.\n     * @deprecated\n     */\n    initEvent() {\n        // Do nothing.\n    },\n};\n\n// `constructor` is not enumerable.\nObject.defineProperty(Event.prototype, \"constructor\", {\n    value: Event,\n    configurable: true,\n    writable: true,\n});\n\n// Ensure `event instanceof window.Event` is `true`.\nif (typeof window !== \"undefined\" && typeof window.Event !== \"undefined\") {\n    Object.setPrototypeOf(Event.prototype, window.Event.prototype);\n\n    // Make association for wrappers.\n    wrappers.set(window.Event.prototype, Event);\n}\n\n/**\n * Get the property descriptor to redirect a given property.\n * @param {string} key Property name to define property descriptor.\n * @returns {PropertyDescriptor} The property descriptor to redirect the property.\n * @private\n */\nfunction defineRedirectDescriptor(key) {\n    return {\n        get() {\n            return pd(this).event[key]\n        },\n        set(value) {\n            pd(this).event[key] = value;\n        },\n        configurable: true,\n        enumerable: true,\n    }\n}\n\n/**\n * Get the property descriptor to call a given method property.\n * @param {string} key Property name to define property descriptor.\n * @returns {PropertyDescriptor} The property descriptor to call the method property.\n * @private\n */\nfunction defineCallDescriptor(key) {\n    return {\n        value() {\n            const event = pd(this).event;\n            return event[key].apply(event, arguments)\n        },\n        configurable: true,\n        enumerable: true,\n    }\n}\n\n/**\n * Define new wrapper class.\n * @param {Function} BaseEvent The base wrapper class.\n * @param {Object} proto The prototype of the original event.\n * @returns {Function} The defined wrapper class.\n * @private\n */\nfunction defineWrapper(BaseEvent, proto) {\n    const keys = Object.keys(proto);\n    if (keys.length === 0) {\n        return BaseEvent\n    }\n\n    /** CustomEvent */\n    function CustomEvent(eventTarget, event) {\n        BaseEvent.call(this, eventTarget, event);\n    }\n\n    CustomEvent.prototype = Object.create(BaseEvent.prototype, {\n        constructor: { value: CustomEvent, configurable: true, writable: true },\n    });\n\n    // Define accessors.\n    for (let i = 0; i < keys.length; ++i) {\n        const key = keys[i];\n        if (!(key in BaseEvent.prototype)) {\n            const descriptor = Object.getOwnPropertyDescriptor(proto, key);\n            const isFunc = typeof descriptor.value === \"function\";\n            Object.defineProperty(\n                CustomEvent.prototype,\n                key,\n                isFunc\n                    ? defineCallDescriptor(key)\n                    : defineRedirectDescriptor(key)\n            );\n        }\n    }\n\n    return CustomEvent\n}\n\n/**\n * Get the wrapper class of a given prototype.\n * @param {Object} proto The prototype of the original event to get its wrapper.\n * @returns {Function} The wrapper class.\n * @private\n */\nfunction getWrapper(proto) {\n    if (proto == null || proto === Object.prototype) {\n        return Event\n    }\n\n    let wrapper = wrappers.get(proto);\n    if (wrapper == null) {\n        wrapper = defineWrapper(getWrapper(Object.getPrototypeOf(proto)), proto);\n        wrappers.set(proto, wrapper);\n    }\n    return wrapper\n}\n\n/**\n * Wrap a given event to management a dispatching.\n * @param {EventTarget} eventTarget The event target of this dispatching.\n * @param {Object} event The event to wrap.\n * @returns {Event} The wrapper instance.\n * @private\n */\nfunction wrapEvent(eventTarget, event) {\n    const Wrapper = getWrapper(Object.getPrototypeOf(event));\n    return new Wrapper(eventTarget, event)\n}\n\n/**\n * Get the immediateStopped flag of a given event.\n * @param {Event} event The event to get.\n * @returns {boolean} The flag to stop propagation immediately.\n * @private\n */\nfunction isStopped(event) {\n    return pd(event).immediateStopped\n}\n\n/**\n * Set the current event phase of a given event.\n * @param {Event} event The event to set current target.\n * @param {number} eventPhase New event phase.\n * @returns {void}\n * @private\n */\nfunction setEventPhase(event, eventPhase) {\n    pd(event).eventPhase = eventPhase;\n}\n\n/**\n * Set the current target of a given event.\n * @param {Event} event The event to set current target.\n * @param {EventTarget|null} currentTarget New current target.\n * @returns {void}\n * @private\n */\nfunction setCurrentTarget(event, currentTarget) {\n    pd(event).currentTarget = currentTarget;\n}\n\n/**\n * Set a passive listener of a given event.\n * @param {Event} event The event to set current target.\n * @param {Function|null} passiveListener New passive listener.\n * @returns {void}\n * @private\n */\nfunction setPassiveListener(event, passiveListener) {\n    pd(event).passiveListener = passiveListener;\n}\n\n/**\n * @typedef {object} ListenerNode\n * @property {Function} listener\n * @property {1|2|3} listenerType\n * @property {boolean} passive\n * @property {boolean} once\n * @property {ListenerNode|null} next\n * @private\n */\n\n/**\n * @type {WeakMap<object, Map<string, ListenerNode>>}\n * @private\n */\nconst listenersMap = new WeakMap();\n\n// Listener types\nconst CAPTURE = 1;\nconst BUBBLE = 2;\nconst ATTRIBUTE = 3;\n\n/**\n * Check whether a given value is an object or not.\n * @param {any} x The value to check.\n * @returns {boolean} `true` if the value is an object.\n */\nfunction isObject(x) {\n    return x !== null && typeof x === \"object\" //eslint-disable-line no-restricted-syntax\n}\n\n/**\n * Get listeners.\n * @param {EventTarget} eventTarget The event target to get.\n * @returns {Map<string, ListenerNode>} The listeners.\n * @private\n */\nfunction getListeners(eventTarget) {\n    const listeners = listenersMap.get(eventTarget);\n    if (listeners == null) {\n        throw new TypeError(\n            \"'this' is expected an EventTarget object, but got another value.\"\n        )\n    }\n    return listeners\n}\n\n/**\n * Get the property descriptor for the event attribute of a given event.\n * @param {string} eventName The event name to get property descriptor.\n * @returns {PropertyDescriptor} The property descriptor.\n * @private\n */\nfunction defineEventAttributeDescriptor(eventName) {\n    return {\n        get() {\n            const listeners = getListeners(this);\n            let node = listeners.get(eventName);\n            while (node != null) {\n                if (node.listenerType === ATTRIBUTE) {\n                    return node.listener\n                }\n                node = node.next;\n            }\n            return null\n        },\n\n        set(listener) {\n            if (typeof listener !== \"function\" && !isObject(listener)) {\n                listener = null; // eslint-disable-line no-param-reassign\n            }\n            const listeners = getListeners(this);\n\n            // Traverse to the tail while removing old value.\n            let prev = null;\n            let node = listeners.get(eventName);\n            while (node != null) {\n                if (node.listenerType === ATTRIBUTE) {\n                    // Remove old value.\n                    if (prev !== null) {\n                        prev.next = node.next;\n                    } else if (node.next !== null) {\n                        listeners.set(eventName, node.next);\n                    } else {\n                        listeners.delete(eventName);\n                    }\n                } else {\n                    prev = node;\n                }\n\n                node = node.next;\n            }\n\n            // Add new value.\n            if (listener !== null) {\n                const newNode = {\n                    listener,\n                    listenerType: ATTRIBUTE,\n                    passive: false,\n                    once: false,\n                    next: null,\n                };\n                if (prev === null) {\n                    listeners.set(eventName, newNode);\n                } else {\n                    prev.next = newNode;\n                }\n            }\n        },\n        configurable: true,\n        enumerable: true,\n    }\n}\n\n/**\n * Define an event attribute (e.g. `eventTarget.onclick`).\n * @param {Object} eventTargetPrototype The event target prototype to define an event attrbite.\n * @param {string} eventName The event name to define.\n * @returns {void}\n */\nfunction defineEventAttribute(eventTargetPrototype, eventName) {\n    Object.defineProperty(\n        eventTargetPrototype,\n        `on${eventName}`,\n        defineEventAttributeDescriptor(eventName)\n    );\n}\n\n/**\n * Define a custom EventTarget with event attributes.\n * @param {string[]} eventNames Event names for event attributes.\n * @returns {EventTarget} The custom EventTarget.\n * @private\n */\nfunction defineCustomEventTarget(eventNames) {\n    /** CustomEventTarget */\n    function CustomEventTarget() {\n        EventTarget.call(this);\n    }\n\n    CustomEventTarget.prototype = Object.create(EventTarget.prototype, {\n        constructor: {\n            value: CustomEventTarget,\n            configurable: true,\n            writable: true,\n        },\n    });\n\n    for (let i = 0; i < eventNames.length; ++i) {\n        defineEventAttribute(CustomEventTarget.prototype, eventNames[i]);\n    }\n\n    return CustomEventTarget\n}\n\n/**\n * EventTarget.\n *\n * - This is constructor if no arguments.\n * - This is a function which returns a CustomEventTarget constructor if there are arguments.\n *\n * For example:\n *\n *     class A extends EventTarget {}\n *     class B extends EventTarget(\"message\") {}\n *     class C extends EventTarget(\"message\", \"error\") {}\n *     class D extends EventTarget([\"message\", \"error\"]) {}\n */\nfunction EventTarget() {\n    /*eslint-disable consistent-return */\n    if (this instanceof EventTarget) {\n        listenersMap.set(this, new Map());\n        return\n    }\n    if (arguments.length === 1 && Array.isArray(arguments[0])) {\n        return defineCustomEventTarget(arguments[0])\n    }\n    if (arguments.length > 0) {\n        const types = new Array(arguments.length);\n        for (let i = 0; i < arguments.length; ++i) {\n            types[i] = arguments[i];\n        }\n        return defineCustomEventTarget(types)\n    }\n    throw new TypeError(\"Cannot call a class as a function\")\n    /*eslint-enable consistent-return */\n}\n\n// Should be enumerable, but class methods are not enumerable.\nEventTarget.prototype = {\n    /**\n     * Add a given listener to this event target.\n     * @param {string} eventName The event name to add.\n     * @param {Function} listener The listener to add.\n     * @param {boolean|{capture?:boolean,passive?:boolean,once?:boolean}} [options] The options for this listener.\n     * @returns {void}\n     */\n    addEventListener(eventName, listener, options) {\n        if (listener == null) {\n            return\n        }\n        if (typeof listener !== \"function\" && !isObject(listener)) {\n            throw new TypeError(\"'listener' should be a function or an object.\")\n        }\n\n        const listeners = getListeners(this);\n        const optionsIsObj = isObject(options);\n        const capture = optionsIsObj\n            ? Boolean(options.capture)\n            : Boolean(options);\n        const listenerType = capture ? CAPTURE : BUBBLE;\n        const newNode = {\n            listener,\n            listenerType,\n            passive: optionsIsObj && Boolean(options.passive),\n            once: optionsIsObj && Boolean(options.once),\n            next: null,\n        };\n\n        // Set it as the first node if the first node is null.\n        let node = listeners.get(eventName);\n        if (node === undefined) {\n            listeners.set(eventName, newNode);\n            return\n        }\n\n        // Traverse to the tail while checking duplication..\n        let prev = null;\n        while (node != null) {\n            if (\n                node.listener === listener &&\n                node.listenerType === listenerType\n            ) {\n                // Should ignore duplication.\n                return\n            }\n            prev = node;\n            node = node.next;\n        }\n\n        // Add it.\n        prev.next = newNode;\n    },\n\n    /**\n     * Remove a given listener from this event target.\n     * @param {string} eventName The event name to remove.\n     * @param {Function} listener The listener to remove.\n     * @param {boolean|{capture?:boolean,passive?:boolean,once?:boolean}} [options] The options for this listener.\n     * @returns {void}\n     */\n    removeEventListener(eventName, listener, options) {\n        if (listener == null) {\n            return\n        }\n\n        const listeners = getListeners(this);\n        const capture = isObject(options)\n            ? Boolean(options.capture)\n            : Boolean(options);\n        const listenerType = capture ? CAPTURE : BUBBLE;\n\n        let prev = null;\n        let node = listeners.get(eventName);\n        while (node != null) {\n            if (\n                node.listener === listener &&\n                node.listenerType === listenerType\n            ) {\n                if (prev !== null) {\n                    prev.next = node.next;\n                } else if (node.next !== null) {\n                    listeners.set(eventName, node.next);\n                } else {\n                    listeners.delete(eventName);\n                }\n                return\n            }\n\n            prev = node;\n            node = node.next;\n        }\n    },\n\n    /**\n     * Dispatch a given event.\n     * @param {Event|{type:string}} event The event to dispatch.\n     * @returns {boolean} `false` if canceled.\n     */\n    dispatchEvent(event) {\n        if (event == null || typeof event.type !== \"string\") {\n            throw new TypeError('\"event.type\" should be a string.')\n        }\n\n        // If listeners aren't registered, terminate.\n        const listeners = getListeners(this);\n        const eventName = event.type;\n        let node = listeners.get(eventName);\n        if (node == null) {\n            return true\n        }\n\n        // Since we cannot rewrite several properties, so wrap object.\n        const wrappedEvent = wrapEvent(this, event);\n\n        // This doesn't process capturing phase and bubbling phase.\n        // This isn't participating in a tree.\n        let prev = null;\n        while (node != null) {\n            // Remove this listener if it's once\n            if (node.once) {\n                if (prev !== null) {\n                    prev.next = node.next;\n                } else if (node.next !== null) {\n                    listeners.set(eventName, node.next);\n                } else {\n                    listeners.delete(eventName);\n                }\n            } else {\n                prev = node;\n            }\n\n            // Call this listener\n            setPassiveListener(\n                wrappedEvent,\n                node.passive ? node.listener : null\n            );\n            if (typeof node.listener === \"function\") {\n                try {\n                    node.listener.call(this, wrappedEvent);\n                } catch (err) {\n                    if (\n                        typeof console !== \"undefined\" &&\n                        typeof console.error === \"function\"\n                    ) {\n                        console.error(err);\n                    }\n                }\n            } else if (\n                node.listenerType !== ATTRIBUTE &&\n                typeof node.listener.handleEvent === \"function\"\n            ) {\n                node.listener.handleEvent(wrappedEvent);\n            }\n\n            // Break if `event.stopImmediatePropagation` was called.\n            if (isStopped(wrappedEvent)) {\n                break\n            }\n\n            node = node.next;\n        }\n        setPassiveListener(wrappedEvent, null);\n        setEventPhase(wrappedEvent, 0);\n        setCurrentTarget(wrappedEvent, null);\n\n        return !wrappedEvent.defaultPrevented\n    },\n};\n\n// `constructor` is not enumerable.\nObject.defineProperty(EventTarget.prototype, \"constructor\", {\n    value: EventTarget,\n    configurable: true,\n    writable: true,\n});\n\n// Ensure `eventTarget instanceof window.EventTarget` is `true`.\nif (\n    typeof window !== \"undefined\" &&\n    typeof window.EventTarget !== \"undefined\"\n) {\n    Object.setPrototypeOf(EventTarget.prototype, window.EventTarget.prototype);\n}\n\nexport default EventTarget;\nexport { defineEventAttribute, EventTarget };\n//# sourceMappingURL=event-target-shim.mjs.map\n","/**\n * @author Toru Nagashima <https://github.com/mysticatea>\n * See LICENSE file in root directory for full license.\n */\nimport { EventTarget, defineEventAttribute } from 'event-target-shim';\n\n/**\n * The signal class.\n * @see https://dom.spec.whatwg.org/#abortsignal\n */\nclass AbortSignal extends EventTarget {\n    /**\n     * AbortSignal cannot be constructed directly.\n     */\n    constructor() {\n        super();\n        throw new TypeError(\"AbortSignal cannot be constructed directly\");\n    }\n    /**\n     * Returns `true` if this `AbortSignal`'s `AbortController` has signaled to abort, and `false` otherwise.\n     */\n    get aborted() {\n        const aborted = abortedFlags.get(this);\n        if (typeof aborted !== \"boolean\") {\n            throw new TypeError(`Expected 'this' to be an 'AbortSignal' object, but got ${this === null ? \"null\" : typeof this}`);\n        }\n        return aborted;\n    }\n}\ndefineEventAttribute(AbortSignal.prototype, \"abort\");\n/**\n * Create an AbortSignal object.\n */\nfunction createAbortSignal() {\n    const signal = Object.create(AbortSignal.prototype);\n    EventTarget.call(signal);\n    abortedFlags.set(signal, false);\n    return signal;\n}\n/**\n * Abort a given signal.\n */\nfunction abortSignal(signal) {\n    if (abortedFlags.get(signal) !== false) {\n        return;\n    }\n    abortedFlags.set(signal, true);\n    signal.dispatchEvent({ type: \"abort\" });\n}\n/**\n * Aborted flag for each instances.\n */\nconst abortedFlags = new WeakMap();\n// Properties should be enumerable.\nObject.defineProperties(AbortSignal.prototype, {\n    aborted: { enumerable: true },\n});\n// `toString()` should return `\"[object AbortSignal]\"`\nif (typeof Symbol === \"function\" && typeof Symbol.toStringTag === \"symbol\") {\n    Object.defineProperty(AbortSignal.prototype, Symbol.toStringTag, {\n        configurable: true,\n        value: \"AbortSignal\",\n    });\n}\n\n/**\n * The AbortController.\n * @see https://dom.spec.whatwg.org/#abortcontroller\n */\nclass AbortController {\n    /**\n     * Initialize this controller.\n     */\n    constructor() {\n        signals.set(this, createAbortSignal());\n    }\n    /**\n     * Returns the `AbortSignal` object associated with this object.\n     */\n    get signal() {\n        return getSignal(this);\n    }\n    /**\n     * Abort and signal to any observers that the associated activity is to be aborted.\n     */\n    abort() {\n        abortSignal(getSignal(this));\n    }\n}\n/**\n * Associated signals.\n */\nconst signals = new WeakMap();\n/**\n * Get the associated signal of a given controller.\n */\nfunction getSignal(controller) {\n    const signal = signals.get(controller);\n    if (signal == null) {\n        throw new TypeError(`Expected 'this' to be an 'AbortController' object, but got ${controller === null ? \"null\" : typeof controller}`);\n    }\n    return signal;\n}\n// Properties should be enumerable.\nObject.defineProperties(AbortController.prototype, {\n    signal: { enumerable: true },\n    abort: { enumerable: true },\n});\nif (typeof Symbol === \"function\" && typeof Symbol.toStringTag === \"symbol\") {\n    Object.defineProperty(AbortController.prototype, Symbol.toStringTag, {\n        configurable: true,\n        value: \"AbortController\",\n    });\n}\n\nexport default AbortController;\nexport { AbortController, AbortSignal };\n//# sourceMappingURL=abort-controller.mjs.map\n","(function (global, factory) {\n\ttypeof exports === 'object' && typeof module !== 'undefined' ? module.exports = factory() :\n\ttypeof define === 'function' && define.amd ? define(factory) :\n\t(global = typeof globalThis !== 'undefined' ? globalThis : global || self, global.ky = factory());\n}(this, (function () { 'use strict';\n\n\t/*! MIT License  Sindre Sorhus */\n\n\tconst globals = {};\n\n\tconst getGlobal = property => {\n\t\t/* istanbul ignore next */\n\t\tif (typeof self !== 'undefined' && self && property in self) {\n\t\t\treturn self;\n\t\t}\n\n\t\t/* istanbul ignore next */\n\t\tif (typeof window !== 'undefined' && window && property in window) {\n\t\t\treturn window;\n\t\t}\n\n\t\tif (typeof global !== 'undefined' && global && property in global) {\n\t\t\treturn global;\n\t\t}\n\n\t\t/* istanbul ignore next */\n\t\tif (typeof globalThis !== 'undefined' && globalThis) {\n\t\t\treturn globalThis;\n\t\t}\n\t};\n\n\tconst globalProperties = [\n\t\t'Headers',\n\t\t'Request',\n\t\t'Response',\n\t\t'ReadableStream',\n\t\t'fetch',\n\t\t'AbortController',\n\t\t'FormData'\n\t];\n\n\tfor (const property of globalProperties) {\n\t\tObject.defineProperty(globals, property, {\n\t\t\tget() {\n\t\t\t\tconst globalObject = getGlobal(property);\n\t\t\t\tconst value = globalObject && globalObject[property];\n\t\t\t\treturn typeof value === 'function' ? value.bind(globalObject) : value;\n\t\t\t}\n\t\t});\n\t}\n\n\tconst isObject = value => value !== null && typeof value === 'object';\n\tconst supportsAbortController = typeof globals.AbortController === 'function';\n\tconst supportsStreams = typeof globals.ReadableStream === 'function';\n\tconst supportsFormData = typeof globals.FormData === 'function';\n\n\tconst mergeHeaders = (source1, source2) => {\n\t\tconst result = new globals.Headers(source1 || {});\n\t\tconst isHeadersInstance = source2 instanceof globals.Headers;\n\t\tconst source = new globals.Headers(source2 || {});\n\n\t\tfor (const [key, value] of source) {\n\t\t\tif ((isHeadersInstance && value === 'undefined') || value === undefined) {\n\t\t\t\tresult.delete(key);\n\t\t\t} else {\n\t\t\t\tresult.set(key, value);\n\t\t\t}\n\t\t}\n\n\t\treturn result;\n\t};\n\n\tconst deepMerge = (...sources) => {\n\t\tlet returnValue = {};\n\t\tlet headers = {};\n\n\t\tfor (const source of sources) {\n\t\t\tif (Array.isArray(source)) {\n\t\t\t\tif (!(Array.isArray(returnValue))) {\n\t\t\t\t\treturnValue = [];\n\t\t\t\t}\n\n\t\t\t\treturnValue = [...returnValue, ...source];\n\t\t\t} else if (isObject(source)) {\n\t\t\t\tfor (let [key, value] of Object.entries(source)) {\n\t\t\t\t\tif (isObject(value) && (key in returnValue)) {\n\t\t\t\t\t\tvalue = deepMerge(returnValue[key], value);\n\t\t\t\t\t}\n\n\t\t\t\t\treturnValue = {...returnValue, [key]: value};\n\t\t\t\t}\n\n\t\t\t\tif (isObject(source.headers)) {\n\t\t\t\t\theaders = mergeHeaders(headers, source.headers);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturnValue.headers = headers;\n\t\t}\n\n\t\treturn returnValue;\n\t};\n\n\tconst requestMethods = [\n\t\t'get',\n\t\t'post',\n\t\t'put',\n\t\t'patch',\n\t\t'head',\n\t\t'delete'\n\t];\n\n\tconst responseTypes = {\n\t\tjson: 'application/json',\n\t\ttext: 'text/*',\n\t\tformData: 'multipart/form-data',\n\t\tarrayBuffer: '*/*',\n\t\tblob: '*/*'\n\t};\n\n\tconst retryMethods = [\n\t\t'get',\n\t\t'put',\n\t\t'head',\n\t\t'delete',\n\t\t'options',\n\t\t'trace'\n\t];\n\n\tconst retryStatusCodes = [\n\t\t408,\n\t\t413,\n\t\t429,\n\t\t500,\n\t\t502,\n\t\t503,\n\t\t504\n\t];\n\n\tconst retryAfterStatusCodes = [\n\t\t413,\n\t\t429,\n\t\t503\n\t];\n\n\tconst stop = Symbol('stop');\n\n\tclass HTTPError extends Error {\n\t\tconstructor(response) {\n\t\t\t// Set the message to the status text, such as Unauthorized,\n\t\t\t// with some fallbacks. This message should never be undefined.\n\t\t\tsuper(\n\t\t\t\tresponse.statusText ||\n\t\t\t\tString(\n\t\t\t\t\t(response.status === 0 || response.status) ?\n\t\t\t\t\t\tresponse.status : 'Unknown response error'\n\t\t\t\t)\n\t\t\t);\n\t\t\tthis.name = 'HTTPError';\n\t\t\tthis.response = response;\n\t\t}\n\t}\n\n\tclass TimeoutError extends Error {\n\t\tconstructor(request) {\n\t\t\tsuper('Request timed out');\n\t\t\tthis.name = 'TimeoutError';\n\t\t\tthis.request = request;\n\t\t}\n\t}\n\n\tconst delay = ms => new Promise(resolve => setTimeout(resolve, ms));\n\n\t// `Promise.race()` workaround (#91)\n\tconst timeout = (request, abortController, options) =>\n\t\tnew Promise((resolve, reject) => {\n\t\t\tconst timeoutID = setTimeout(() => {\n\t\t\t\tif (abortController) {\n\t\t\t\t\tabortController.abort();\n\t\t\t\t}\n\n\t\t\t\treject(new TimeoutError(request));\n\t\t\t}, options.timeout);\n\n\t\t\t/* eslint-disable promise/prefer-await-to-then */\n\t\t\toptions.fetch(request)\n\t\t\t\t.then(resolve)\n\t\t\t\t.catch(reject)\n\t\t\t\t.then(() => {\n\t\t\t\t\tclearTimeout(timeoutID);\n\t\t\t\t});\n\t\t\t/* eslint-enable promise/prefer-await-to-then */\n\t\t});\n\n\tconst normalizeRequestMethod = input => requestMethods.includes(input) ? input.toUpperCase() : input;\n\n\tconst defaultRetryOptions = {\n\t\tlimit: 2,\n\t\tmethods: retryMethods,\n\t\tstatusCodes: retryStatusCodes,\n\t\tafterStatusCodes: retryAfterStatusCodes\n\t};\n\n\tconst normalizeRetryOptions = (retry = {}) => {\n\t\tif (typeof retry === 'number') {\n\t\t\treturn {\n\t\t\t\t...defaultRetryOptions,\n\t\t\t\tlimit: retry\n\t\t\t};\n\t\t}\n\n\t\tif (retry.methods && !Array.isArray(retry.methods)) {\n\t\t\tthrow new Error('retry.methods must be an array');\n\t\t}\n\n\t\tif (retry.statusCodes && !Array.isArray(retry.statusCodes)) {\n\t\t\tthrow new Error('retry.statusCodes must be an array');\n\t\t}\n\n\t\treturn {\n\t\t\t...defaultRetryOptions,\n\t\t\t...retry,\n\t\t\tafterStatusCodes: retryAfterStatusCodes\n\t\t};\n\t};\n\n\t// The maximum value of a 32bit int (see issue #117)\n\tconst maxSafeTimeout = 2147483647;\n\n\tclass Ky {\n\t\tconstructor(input, options = {}) {\n\t\t\tthis._retryCount = 0;\n\t\t\tthis._input = input;\n\t\t\tthis._options = {\n\t\t\t\t// TODO: credentials can be removed when the spec change is implemented in all browsers. Context: https://www.chromestatus.com/feature/4539473312350208\n\t\t\t\tcredentials: this._input.credentials || 'same-origin',\n\t\t\t\t...options,\n\t\t\t\theaders: mergeHeaders(this._input.headers, options.headers),\n\t\t\t\thooks: deepMerge({\n\t\t\t\t\tbeforeRequest: [],\n\t\t\t\t\tbeforeRetry: [],\n\t\t\t\t\tafterResponse: []\n\t\t\t\t}, options.hooks),\n\t\t\t\tmethod: normalizeRequestMethod(options.method || this._input.method),\n\t\t\t\tprefixUrl: String(options.prefixUrl || ''),\n\t\t\t\tretry: normalizeRetryOptions(options.retry),\n\t\t\t\tthrowHttpErrors: options.throwHttpErrors !== false,\n\t\t\t\ttimeout: typeof options.timeout === 'undefined' ? 10000 : options.timeout,\n\t\t\t\tfetch: options.fetch || globals.fetch\n\t\t\t};\n\n\t\t\tif (typeof this._input !== 'string' && !(this._input instanceof URL || this._input instanceof globals.Request)) {\n\t\t\t\tthrow new TypeError('`input` must be a string, URL, or Request');\n\t\t\t}\n\n\t\t\tif (this._options.prefixUrl && typeof this._input === 'string') {\n\t\t\t\tif (this._input.startsWith('/')) {\n\t\t\t\t\tthrow new Error('`input` must not begin with a slash when using `prefixUrl`');\n\t\t\t\t}\n\n\t\t\t\tif (!this._options.prefixUrl.endsWith('/')) {\n\t\t\t\t\tthis._options.prefixUrl += '/';\n\t\t\t\t}\n\n\t\t\t\tthis._input = this._options.prefixUrl + this._input;\n\t\t\t}\n\n\t\t\tif (supportsAbortController) {\n\t\t\t\tthis.abortController = new globals.AbortController();\n\t\t\t\tif (this._options.signal) {\n\t\t\t\t\tthis._options.signal.addEventListener('abort', () => {\n\t\t\t\t\t\tthis.abortController.abort();\n\t\t\t\t\t});\n\t\t\t\t}\n\n\t\t\t\tthis._options.signal = this.abortController.signal;\n\t\t\t}\n\n\t\t\tthis.request = new globals.Request(this._input, this._options);\n\n\t\t\tif (this._options.searchParams) {\n\t\t\t\tconst searchParams = '?' + new URLSearchParams(this._options.searchParams).toString();\n\t\t\t\tconst url = this.request.url.replace(/(?:\\?.*?)?(?=#|$)/, searchParams);\n\n\t\t\t\t// To provide correct form boundary, Content-Type header should be deleted each time when new Request instantiated from another one\n\t\t\t\tif (((supportsFormData && this._options.body instanceof globals.FormData) || this._options.body instanceof URLSearchParams) && !(this._options.headers && this._options.headers['content-type'])) {\n\t\t\t\t\tthis.request.headers.delete('content-type');\n\t\t\t\t}\n\n\t\t\t\tthis.request = new globals.Request(new globals.Request(url, this.request), this._options);\n\t\t\t}\n\n\t\t\tif (this._options.json !== undefined) {\n\t\t\t\tthis._options.body = JSON.stringify(this._options.json);\n\t\t\t\tthis.request.headers.set('content-type', 'application/json');\n\t\t\t\tthis.request = new globals.Request(this.request, {body: this._options.body});\n\t\t\t}\n\n\t\t\tconst fn = async () => {\n\t\t\t\tif (this._options.timeout > maxSafeTimeout) {\n\t\t\t\t\tthrow new RangeError(`The \\`timeout\\` option cannot be greater than ${maxSafeTimeout}`);\n\t\t\t\t}\n\n\t\t\t\tawait delay(1);\n\t\t\t\tlet response = await this._fetch();\n\n\t\t\t\tfor (const hook of this._options.hooks.afterResponse) {\n\t\t\t\t\t// eslint-disable-next-line no-await-in-loop\n\t\t\t\t\tconst modifiedResponse = await hook(\n\t\t\t\t\t\tthis.request,\n\t\t\t\t\t\tthis._options,\n\t\t\t\t\t\tthis._decorateResponse(response.clone())\n\t\t\t\t\t);\n\n\t\t\t\t\tif (modifiedResponse instanceof globals.Response) {\n\t\t\t\t\t\tresponse = modifiedResponse;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tthis._decorateResponse(response);\n\n\t\t\t\tif (!response.ok && this._options.throwHttpErrors) {\n\t\t\t\t\tthrow new HTTPError(response);\n\t\t\t\t}\n\n\t\t\t\t// If `onDownloadProgress` is passed, it uses the stream API internally\n\t\t\t\t/* istanbul ignore next */\n\t\t\t\tif (this._options.onDownloadProgress) {\n\t\t\t\t\tif (typeof this._options.onDownloadProgress !== 'function') {\n\t\t\t\t\t\tthrow new TypeError('The `onDownloadProgress` option must be a function');\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!supportsStreams) {\n\t\t\t\t\t\tthrow new Error('Streams are not supported in your environment. `ReadableStream` is missing.');\n\t\t\t\t\t}\n\n\t\t\t\t\treturn this._stream(response.clone(), this._options.onDownloadProgress);\n\t\t\t\t}\n\n\t\t\t\treturn response;\n\t\t\t};\n\n\t\t\tconst isRetriableMethod = this._options.retry.methods.includes(this.request.method.toLowerCase());\n\t\t\tconst result = isRetriableMethod ? this._retry(fn) : fn();\n\n\t\t\tfor (const [type, mimeType] of Object.entries(responseTypes)) {\n\t\t\t\tresult[type] = async () => {\n\t\t\t\t\tthis.request.headers.set('accept', this.request.headers.get('accept') || mimeType);\n\n\t\t\t\t\tconst response = (await result).clone();\n\n\t\t\t\t\tif (type === 'json') {\n\t\t\t\t\t\tif (response.status === 204) {\n\t\t\t\t\t\t\treturn '';\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (options.parseJson) {\n\t\t\t\t\t\t\treturn options.parseJson(await response.text());\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\treturn response[type]();\n\t\t\t\t};\n\t\t\t}\n\n\t\t\treturn result;\n\t\t}\n\n\t\t_calculateRetryDelay(error) {\n\t\t\tthis._retryCount++;\n\n\t\t\tif (this._retryCount < this._options.retry.limit && !(error instanceof TimeoutError)) {\n\t\t\t\tif (error instanceof HTTPError) {\n\t\t\t\t\tif (!this._options.retry.statusCodes.includes(error.response.status)) {\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\n\t\t\t\t\tconst retryAfter = error.response.headers.get('Retry-After');\n\t\t\t\t\tif (retryAfter && this._options.retry.afterStatusCodes.includes(error.response.status)) {\n\t\t\t\t\t\tlet after = Number(retryAfter);\n\t\t\t\t\t\tif (Number.isNaN(after)) {\n\t\t\t\t\t\t\tafter = Date.parse(retryAfter) - Date.now();\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tafter *= 1000;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (typeof this._options.retry.maxRetryAfter !== 'undefined' && after > this._options.retry.maxRetryAfter) {\n\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn after;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (error.response.status === 413) {\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tconst BACKOFF_FACTOR = 0.3;\n\t\t\t\treturn BACKOFF_FACTOR * (2 ** (this._retryCount - 1)) * 1000;\n\t\t\t}\n\n\t\t\treturn 0;\n\t\t}\n\n\t\t_decorateResponse(response) {\n\t\t\tif (this._options.parseJson) {\n\t\t\t\tresponse.json = async () => {\n\t\t\t\t\treturn this._options.parseJson(await response.text());\n\t\t\t\t};\n\t\t\t}\n\n\t\t\treturn response;\n\t\t}\n\n\t\tasync _retry(fn) {\n\t\t\ttry {\n\t\t\t\treturn await fn();\n\t\t\t} catch (error) {\n\t\t\t\tconst ms = Math.min(this._calculateRetryDelay(error), maxSafeTimeout);\n\t\t\t\tif (ms !== 0 && this._retryCount > 0) {\n\t\t\t\t\tawait delay(ms);\n\n\t\t\t\t\tfor (const hook of this._options.hooks.beforeRetry) {\n\t\t\t\t\t\t// eslint-disable-next-line no-await-in-loop\n\t\t\t\t\t\tconst hookResult = await hook({\n\t\t\t\t\t\t\trequest: this.request,\n\t\t\t\t\t\t\toptions: this._options,\n\t\t\t\t\t\t\terror,\n\t\t\t\t\t\t\tretryCount: this._retryCount\n\t\t\t\t\t\t});\n\n\t\t\t\t\t\t// If `stop` is returned from the hook, the retry process is stopped\n\t\t\t\t\t\tif (hookResult === stop) {\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\treturn this._retry(fn);\n\t\t\t\t}\n\n\t\t\t\tif (this._options.throwHttpErrors) {\n\t\t\t\t\tthrow error;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tasync _fetch() {\n\t\t\tfor (const hook of this._options.hooks.beforeRequest) {\n\t\t\t\t// eslint-disable-next-line no-await-in-loop\n\t\t\t\tconst result = await hook(this.request, this._options);\n\n\t\t\t\tif (result instanceof Request) {\n\t\t\t\t\tthis.request = result;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tif (result instanceof Response) {\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (this._options.timeout === false) {\n\t\t\t\treturn this._options.fetch(this.request.clone());\n\t\t\t}\n\n\t\t\treturn timeout(this.request.clone(), this.abortController, this._options);\n\t\t}\n\n\t\t/* istanbul ignore next */\n\t\t_stream(response, onDownloadProgress) {\n\t\t\tconst totalBytes = Number(response.headers.get('content-length')) || 0;\n\t\t\tlet transferredBytes = 0;\n\n\t\t\treturn new globals.Response(\n\t\t\t\tnew globals.ReadableStream({\n\t\t\t\t\tstart(controller) {\n\t\t\t\t\t\tconst reader = response.body.getReader();\n\n\t\t\t\t\t\tif (onDownloadProgress) {\n\t\t\t\t\t\t\tonDownloadProgress({percent: 0, transferredBytes: 0, totalBytes}, new Uint8Array());\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tasync function read() {\n\t\t\t\t\t\t\tconst {done, value} = await reader.read();\n\t\t\t\t\t\t\tif (done) {\n\t\t\t\t\t\t\t\tcontroller.close();\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (onDownloadProgress) {\n\t\t\t\t\t\t\t\ttransferredBytes += value.byteLength;\n\t\t\t\t\t\t\t\tconst percent = totalBytes === 0 ? 0 : transferredBytes / totalBytes;\n\t\t\t\t\t\t\t\tonDownloadProgress({percent, transferredBytes, totalBytes}, value);\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tcontroller.enqueue(value);\n\t\t\t\t\t\t\tread();\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tread();\n\t\t\t\t\t}\n\t\t\t\t})\n\t\t\t);\n\t\t}\n\t}\n\n\tconst validateAndMerge = (...sources) => {\n\t\tfor (const source of sources) {\n\t\t\tif ((!isObject(source) || Array.isArray(source)) && typeof source !== 'undefined') {\n\t\t\t\tthrow new TypeError('The `options` argument must be an object');\n\t\t\t}\n\t\t}\n\n\t\treturn deepMerge({}, ...sources);\n\t};\n\n\tconst createInstance = defaults => {\n\t\tconst ky = (input, options) => new Ky(input, validateAndMerge(defaults, options));\n\n\t\tfor (const method of requestMethods) {\n\t\t\tky[method] = (input, options) => new Ky(input, validateAndMerge(defaults, options, {method}));\n\t\t}\n\n\t\tky.HTTPError = HTTPError;\n\t\tky.TimeoutError = TimeoutError;\n\t\tky.create = newDefaults => createInstance(validateAndMerge(newDefaults));\n\t\tky.extend = newDefaults => createInstance(validateAndMerge(defaults, newDefaults));\n\t\tky.stop = stop;\n\n\t\treturn ky;\n\t};\n\n\tvar index = createInstance();\n\n\treturn index;\n\n})));\n","'use strict';\nconst fetch = require('node-fetch');\nconst AbortController = require('abort-controller');\n\nconst TEN_MEGABYTES = 1000 * 1000 * 10;\n\nif (!global.fetch) {\n\tglobal.fetch = (url, options) => fetch(url, {highWaterMark: TEN_MEGABYTES, ...options});\n}\n\nif (!global.Headers) {\n\tglobal.Headers = fetch.Headers;\n}\n\nif (!global.Request) {\n\tglobal.Request = fetch.Request;\n}\n\nif (!global.Response) {\n\tglobal.Response = fetch.Response;\n}\n\nif (!global.AbortController) {\n\tglobal.AbortController = AbortController;\n}\n\nif (!global.ReadableStream) {\n\ttry {\n\t\tglobal.ReadableStream = require('web-streams-polyfill/ponyfill/es2018');\n\t} catch (_) {}\n}\n\nmodule.exports = require('ky/umd');\n","/*!\n * Copyright (c) 2020 Digital Bazaar, Inc. All rights reserved.\n */\nimport kyOriginal from 'ky-universal';\n\nexport const DEFAULT_HEADERS = {\n  Accept: 'application/ld+json, application/json'\n};\n\nconst ky = kyOriginal.create({headers: DEFAULT_HEADERS});\n\nconst proxyMethods = new Set([\n  'get', 'post', 'push', 'patch', 'head', 'delete'\n]);\n\nexport const httpClient = new Proxy(ky, {\n  apply: _handleResponse,\n  get(target, propKey) {\n    const propValue = target[propKey];\n\n    // only intercept particular methods\n    if(!proxyMethods.has(propKey)) {\n      return propValue;\n    }\n    return async function() {\n      return _handleResponse(propValue, this, arguments);\n    };\n  }\n});\n\nasync function _handleResponse(target, thisArg, args) {\n  let response;\n  try {\n    response = await target.apply(thisArg, args);\n  } catch(e) {\n    return _handleError(e);\n  }\n  const {parseBody = true} = args[1] || {};\n  if(parseBody) {\n    // a 204 will not include a content-type header\n    const contentType = response.headers.get('content-type');\n    if(contentType && contentType.includes('json')) {\n      response.data = await response.json();\n    }\n  }\n  return response;\n}\n\nasync function _handleError(e) {\n  // handle network errors that do not have a response\n  if(!e.response) {\n    if(e.message === 'Failed to fetch') {\n      e.message = `${e.message}. Possible CORS error.`;\n    }\n    throw e;\n  }\n\n  // always move status up to the root of e\n  e.status = e.response.status;\n\n  const contentType = e.response.headers.get('content-type');\n  if(contentType && contentType.includes('json')) {\n    const errorBody = await e.response.json();\n    // the HTTPError received from ky has a generic message based on status\n    // use that if the JSON body does not include a message\n    e.message = errorBody.message || e.message;\n    e.data = errorBody;\n  }\n  throw e;\n}\n\nexport default {\n  httpClient,\n  ky: kyOriginal,\n  DEFAULT_HEADERS,\n};\n","/*\n * Copyright (c) 2017-2021 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst https = require('https');\nconst {parseLinkHeader, buildHeaders} = require('../util');\nconst {LINK_HEADER_CONTEXT} = require('../constants');\nconst JsonLdError = require('../JsonLdError');\nconst RequestQueue = require('../RequestQueue');\nconst {prependBase} = require('../url');\nconst {httpClient} = require('@digitalbazaar/http-client');\n\n/**\n * Creates a built-in node document loader.\n *\n * @param options the options to use:\n *          [secure]: require all URLs to use HTTPS. (default: false)\n *          [strictSSL]: true to require SSL certificates to be valid,\n *            false not to. (default: true)\n *          [maxRedirects]: the maximum number of redirects to permit.\n *            (default: none)\n *          [headers]: an object (map) of headers which will be passed as\n *            request headers for the requested document. Accept is not\n *            allowed. (default: none).\n *          [httpAgent]: a Node.js `http.Agent` to use with 'http' requests.\n *            (default: none)\n *          [httpsAgent]: a Node.js `https.Agent` to use with 'https' requests.\n *            (default: An agent with rejectUnauthorized to the strictSSL\n *            value)\n *\n * @return the node document loader.\n */\nmodule.exports = ({\n  secure,\n  strictSSL = true,\n  maxRedirects = -1,\n  headers = {},\n  httpAgent,\n  httpsAgent\n} = {strictSSL: true, maxRedirects: -1, headers: {}}) => {\n  headers = buildHeaders(headers);\n  // if no default user-agent header, copy headers and set one\n  if(!('user-agent' in headers)) {\n    headers = Object.assign({}, headers, {\n      'user-agent': 'jsonld.js'\n    });\n  }\n  const http = require('http');\n\n  const queue = new RequestQueue();\n  return queue.wrapLoader(function(url) {\n    return loadDocument(url, []);\n  });\n\n  async function loadDocument(url, redirects) {\n    const isHttp = url.startsWith('http:');\n    const isHttps = url.startsWith('https:');\n    if(!isHttp && !isHttps) {\n      throw new JsonLdError(\n        'URL could not be dereferenced; only \"http\" and \"https\" URLs are ' +\n        'supported.',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url});\n    }\n    if(secure && !isHttps) {\n      throw new JsonLdError(\n        'URL could not be dereferenced; secure mode is enabled and ' +\n        'the URL\\'s scheme is not \"https\".',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url});\n    }\n    // TODO: disable cache until HTTP caching implemented\n    let doc = null;//cache.get(url);\n    if(doc !== null) {\n      return doc;\n    }\n\n    let alternate = null;\n\n    const {res, body} = await _fetch({\n      url, headers, strictSSL, httpAgent, httpsAgent\n    });\n    doc = {contextUrl: null, documentUrl: url, document: body || null};\n    // handle error\n    const statusText = http.STATUS_CODES[res.status];\n    if(res.status >= 400) {\n      throw new JsonLdError(\n        `URL \"${url}\" could not be dereferenced: ${statusText}`,\n        'jsonld.InvalidUrl', {\n          code: 'loading document failed',\n          url,\n          httpStatusCode: res.status\n        });\n    }\n    const link = res.headers.get('link');\n    const contentType = res.headers.get('content-type');\n    // handle Link Header\n    if(link && contentType !== 'application/ld+json') {\n      // only 1 related link header permitted\n      const linkHeaders = parseLinkHeader(link);\n      const linkedContext = linkHeaders[LINK_HEADER_CONTEXT];\n      if(Array.isArray(linkedContext)) {\n        throw new JsonLdError(\n          'URL could not be dereferenced, it has more than one associated ' +\n          'HTTP Link Header.',\n          'jsonld.InvalidUrl',\n          {code: 'multiple context link headers', url});\n      }\n      if(linkedContext) {\n        doc.contextUrl = linkedContext.target;\n      }\n\n      // \"alternate\" link header is a redirect\n      alternate = linkHeaders['alternate'];\n      if(alternate &&\n        alternate.type == 'application/ld+json' &&\n        !(contentType || '')\n          .match(/^application\\/(\\w*\\+)?json$/)) {\n        res.headers.set('location', prependBase(url, alternate.target));\n      }\n    }\n    const location = res.headers.get('location');\n    // handle redirect\n    if((alternate ||\n      res.status >= 300 && res.status < 400) && location) {\n      if(redirects.length === maxRedirects) {\n        throw new JsonLdError(\n          'URL could not be dereferenced; there were too many redirects.',\n          'jsonld.TooManyRedirects', {\n            code: 'loading document failed',\n            url,\n            httpStatusCode: res.status,\n            redirects\n          });\n      }\n      if(redirects.indexOf(url) !== -1) {\n        throw new JsonLdError(\n          'URL could not be dereferenced; infinite redirection was detected.',\n          'jsonld.InfiniteRedirectDetected', {\n            code: 'recursive context inclusion',\n            url,\n            httpStatusCode: res.status,\n            redirects\n          });\n      }\n      redirects.push(url);\n      return loadDocument(location, redirects);\n    }\n\n    // cache for each redirected URL\n    redirects.push(url);\n    // TODO: disable cache until HTTP caching implemented\n    /*\n    for(let i = 0; i < redirects.length; ++i) {\n      cache.set(\n        redirects[i],\n        {contextUrl: null, documentUrl: redirects[i], document: body});\n    }\n    */\n\n    return doc;\n  }\n};\n\nasync function _fetch({url, headers, strictSSL, httpAgent, httpsAgent}) {\n  try {\n    const options = {headers, redirect: 'manual'};\n    const isHttps = url.startsWith('https:');\n    if(isHttps) {\n      options.agent =\n        httpsAgent || new https.Agent({rejectUnauthorized: strictSSL});\n    } else {\n      if(httpAgent) {\n        options.agent = httpAgent;\n      }\n    }\n    const res = await httpClient.get(url, options);\n    return {res, body: res.data};\n  } catch(e) {\n    // HTTP errors have a response in them\n    // ky considers redirects HTTP errors\n    if(e.response) {\n      return {res: e.response, body: null};\n    }\n    throw new JsonLdError(\n      'URL could not be dereferenced, an error occurred.',\n      'jsonld.LoadDocumentError',\n      {code: 'loading document failed', url, cause: e});\n  }\n}\n","/*\n * Copyright (c) 2021 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst nodeLoader = require('./documentLoaders/node');\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Setup Node.js document loaders.\n *\n * @param jsonld the jsonld api.\n */\napi.setupDocumentLoaders = function(jsonld) {\n  jsonld.documentLoaders.node = nodeLoader;\n  // use node document loader by default\n  jsonld.useDocumentLoader('node');\n};\n\n/**\n * Setup Node.js globals.\n *\n * @param jsonld the jsonld api.\n */\n/* eslint-disable-next-line no-unused-vars */\napi.setupGlobals = function(jsonld) {\n  // none for Node.js\n};\n","'use strict'\nmodule.exports = function (Yallist) {\n  Yallist.prototype[Symbol.iterator] = function* () {\n    for (let walker = this.head; walker; walker = walker.next) {\n      yield walker.value\n    }\n  }\n}\n","'use strict'\nmodule.exports = Yallist\n\nYallist.Node = Node\nYallist.create = Yallist\n\nfunction Yallist (list) {\n  var self = this\n  if (!(self instanceof Yallist)) {\n    self = new Yallist()\n  }\n\n  self.tail = null\n  self.head = null\n  self.length = 0\n\n  if (list && typeof list.forEach === 'function') {\n    list.forEach(function (item) {\n      self.push(item)\n    })\n  } else if (arguments.length > 0) {\n    for (var i = 0, l = arguments.length; i < l; i++) {\n      self.push(arguments[i])\n    }\n  }\n\n  return self\n}\n\nYallist.prototype.removeNode = function (node) {\n  if (node.list !== this) {\n    throw new Error('removing node which does not belong to this list')\n  }\n\n  var next = node.next\n  var prev = node.prev\n\n  if (next) {\n    next.prev = prev\n  }\n\n  if (prev) {\n    prev.next = next\n  }\n\n  if (node === this.head) {\n    this.head = next\n  }\n  if (node === this.tail) {\n    this.tail = prev\n  }\n\n  node.list.length--\n  node.next = null\n  node.prev = null\n  node.list = null\n\n  return next\n}\n\nYallist.prototype.unshiftNode = function (node) {\n  if (node === this.head) {\n    return\n  }\n\n  if (node.list) {\n    node.list.removeNode(node)\n  }\n\n  var head = this.head\n  node.list = this\n  node.next = head\n  if (head) {\n    head.prev = node\n  }\n\n  this.head = node\n  if (!this.tail) {\n    this.tail = node\n  }\n  this.length++\n}\n\nYallist.prototype.pushNode = function (node) {\n  if (node === this.tail) {\n    return\n  }\n\n  if (node.list) {\n    node.list.removeNode(node)\n  }\n\n  var tail = this.tail\n  node.list = this\n  node.prev = tail\n  if (tail) {\n    tail.next = node\n  }\n\n  this.tail = node\n  if (!this.head) {\n    this.head = node\n  }\n  this.length++\n}\n\nYallist.prototype.push = function () {\n  for (var i = 0, l = arguments.length; i < l; i++) {\n    push(this, arguments[i])\n  }\n  return this.length\n}\n\nYallist.prototype.unshift = function () {\n  for (var i = 0, l = arguments.length; i < l; i++) {\n    unshift(this, arguments[i])\n  }\n  return this.length\n}\n\nYallist.prototype.pop = function () {\n  if (!this.tail) {\n    return undefined\n  }\n\n  var res = this.tail.value\n  this.tail = this.tail.prev\n  if (this.tail) {\n    this.tail.next = null\n  } else {\n    this.head = null\n  }\n  this.length--\n  return res\n}\n\nYallist.prototype.shift = function () {\n  if (!this.head) {\n    return undefined\n  }\n\n  var res = this.head.value\n  this.head = this.head.next\n  if (this.head) {\n    this.head.prev = null\n  } else {\n    this.tail = null\n  }\n  this.length--\n  return res\n}\n\nYallist.prototype.forEach = function (fn, thisp) {\n  thisp = thisp || this\n  for (var walker = this.head, i = 0; walker !== null; i++) {\n    fn.call(thisp, walker.value, i, this)\n    walker = walker.next\n  }\n}\n\nYallist.prototype.forEachReverse = function (fn, thisp) {\n  thisp = thisp || this\n  for (var walker = this.tail, i = this.length - 1; walker !== null; i--) {\n    fn.call(thisp, walker.value, i, this)\n    walker = walker.prev\n  }\n}\n\nYallist.prototype.get = function (n) {\n  for (var i = 0, walker = this.head; walker !== null && i < n; i++) {\n    // abort out of the list early if we hit a cycle\n    walker = walker.next\n  }\n  if (i === n && walker !== null) {\n    return walker.value\n  }\n}\n\nYallist.prototype.getReverse = function (n) {\n  for (var i = 0, walker = this.tail; walker !== null && i < n; i++) {\n    // abort out of the list early if we hit a cycle\n    walker = walker.prev\n  }\n  if (i === n && walker !== null) {\n    return walker.value\n  }\n}\n\nYallist.prototype.map = function (fn, thisp) {\n  thisp = thisp || this\n  var res = new Yallist()\n  for (var walker = this.head; walker !== null;) {\n    res.push(fn.call(thisp, walker.value, this))\n    walker = walker.next\n  }\n  return res\n}\n\nYallist.prototype.mapReverse = function (fn, thisp) {\n  thisp = thisp || this\n  var res = new Yallist()\n  for (var walker = this.tail; walker !== null;) {\n    res.push(fn.call(thisp, walker.value, this))\n    walker = walker.prev\n  }\n  return res\n}\n\nYallist.prototype.reduce = function (fn, initial) {\n  var acc\n  var walker = this.head\n  if (arguments.length > 1) {\n    acc = initial\n  } else if (this.head) {\n    walker = this.head.next\n    acc = this.head.value\n  } else {\n    throw new TypeError('Reduce of empty list with no initial value')\n  }\n\n  for (var i = 0; walker !== null; i++) {\n    acc = fn(acc, walker.value, i)\n    walker = walker.next\n  }\n\n  return acc\n}\n\nYallist.prototype.reduceReverse = function (fn, initial) {\n  var acc\n  var walker = this.tail\n  if (arguments.length > 1) {\n    acc = initial\n  } else if (this.tail) {\n    walker = this.tail.prev\n    acc = this.tail.value\n  } else {\n    throw new TypeError('Reduce of empty list with no initial value')\n  }\n\n  for (var i = this.length - 1; walker !== null; i--) {\n    acc = fn(acc, walker.value, i)\n    walker = walker.prev\n  }\n\n  return acc\n}\n\nYallist.prototype.toArray = function () {\n  var arr = new Array(this.length)\n  for (var i = 0, walker = this.head; walker !== null; i++) {\n    arr[i] = walker.value\n    walker = walker.next\n  }\n  return arr\n}\n\nYallist.prototype.toArrayReverse = function () {\n  var arr = new Array(this.length)\n  for (var i = 0, walker = this.tail; walker !== null; i++) {\n    arr[i] = walker.value\n    walker = walker.prev\n  }\n  return arr\n}\n\nYallist.prototype.slice = function (from, to) {\n  to = to || this.length\n  if (to < 0) {\n    to += this.length\n  }\n  from = from || 0\n  if (from < 0) {\n    from += this.length\n  }\n  var ret = new Yallist()\n  if (to < from || to < 0) {\n    return ret\n  }\n  if (from < 0) {\n    from = 0\n  }\n  if (to > this.length) {\n    to = this.length\n  }\n  for (var i = 0, walker = this.head; walker !== null && i < from; i++) {\n    walker = walker.next\n  }\n  for (; walker !== null && i < to; i++, walker = walker.next) {\n    ret.push(walker.value)\n  }\n  return ret\n}\n\nYallist.prototype.sliceReverse = function (from, to) {\n  to = to || this.length\n  if (to < 0) {\n    to += this.length\n  }\n  from = from || 0\n  if (from < 0) {\n    from += this.length\n  }\n  var ret = new Yallist()\n  if (to < from || to < 0) {\n    return ret\n  }\n  if (from < 0) {\n    from = 0\n  }\n  if (to > this.length) {\n    to = this.length\n  }\n  for (var i = this.length, walker = this.tail; walker !== null && i > to; i--) {\n    walker = walker.prev\n  }\n  for (; walker !== null && i > from; i--, walker = walker.prev) {\n    ret.push(walker.value)\n  }\n  return ret\n}\n\nYallist.prototype.splice = function (start, deleteCount, ...nodes) {\n  if (start > this.length) {\n    start = this.length - 1\n  }\n  if (start < 0) {\n    start = this.length + start;\n  }\n\n  for (var i = 0, walker = this.head; walker !== null && i < start; i++) {\n    walker = walker.next\n  }\n\n  var ret = []\n  for (var i = 0; walker && i < deleteCount; i++) {\n    ret.push(walker.value)\n    walker = this.removeNode(walker)\n  }\n  if (walker === null) {\n    walker = this.tail\n  }\n\n  if (walker !== this.head && walker !== this.tail) {\n    walker = walker.prev\n  }\n\n  for (var i = 0; i < nodes.length; i++) {\n    walker = insert(this, walker, nodes[i])\n  }\n  return ret;\n}\n\nYallist.prototype.reverse = function () {\n  var head = this.head\n  var tail = this.tail\n  for (var walker = head; walker !== null; walker = walker.prev) {\n    var p = walker.prev\n    walker.prev = walker.next\n    walker.next = p\n  }\n  this.head = tail\n  this.tail = head\n  return this\n}\n\nfunction insert (self, node, value) {\n  var inserted = node === self.head ?\n    new Node(value, null, node, self) :\n    new Node(value, node, node.next, self)\n\n  if (inserted.next === null) {\n    self.tail = inserted\n  }\n  if (inserted.prev === null) {\n    self.head = inserted\n  }\n\n  self.length++\n\n  return inserted\n}\n\nfunction push (self, item) {\n  self.tail = new Node(item, self.tail, null, self)\n  if (!self.head) {\n    self.head = self.tail\n  }\n  self.length++\n}\n\nfunction unshift (self, item) {\n  self.head = new Node(item, null, self.head, self)\n  if (!self.tail) {\n    self.tail = self.head\n  }\n  self.length++\n}\n\nfunction Node (value, prev, next, list) {\n  if (!(this instanceof Node)) {\n    return new Node(value, prev, next, list)\n  }\n\n  this.list = list\n  this.value = value\n\n  if (prev) {\n    prev.next = this\n    this.prev = prev\n  } else {\n    this.prev = null\n  }\n\n  if (next) {\n    next.prev = this\n    this.next = next\n  } else {\n    this.next = null\n  }\n}\n\ntry {\n  // add if support for Symbol.iterator is present\n  require('./iterator.js')(Yallist)\n} catch (er) {}\n","'use strict'\n\n// A linked list to keep track of recently-used-ness\nconst Yallist = require('yallist')\n\nconst MAX = Symbol('max')\nconst LENGTH = Symbol('length')\nconst LENGTH_CALCULATOR = Symbol('lengthCalculator')\nconst ALLOW_STALE = Symbol('allowStale')\nconst MAX_AGE = Symbol('maxAge')\nconst DISPOSE = Symbol('dispose')\nconst NO_DISPOSE_ON_SET = Symbol('noDisposeOnSet')\nconst LRU_LIST = Symbol('lruList')\nconst CACHE = Symbol('cache')\nconst UPDATE_AGE_ON_GET = Symbol('updateAgeOnGet')\n\nconst naiveLength = () => 1\n\n// lruList is a yallist where the head is the youngest\n// item, and the tail is the oldest.  the list contains the Hit\n// objects as the entries.\n// Each Hit object has a reference to its Yallist.Node.  This\n// never changes.\n//\n// cache is a Map (or PseudoMap) that matches the keys to\n// the Yallist.Node object.\nclass LRUCache {\n  constructor (options) {\n    if (typeof options === 'number')\n      options = { max: options }\n\n    if (!options)\n      options = {}\n\n    if (options.max && (typeof options.max !== 'number' || options.max < 0))\n      throw new TypeError('max must be a non-negative number')\n    // Kind of weird to have a default max of Infinity, but oh well.\n    const max = this[MAX] = options.max || Infinity\n\n    const lc = options.length || naiveLength\n    this[LENGTH_CALCULATOR] = (typeof lc !== 'function') ? naiveLength : lc\n    this[ALLOW_STALE] = options.stale || false\n    if (options.maxAge && typeof options.maxAge !== 'number')\n      throw new TypeError('maxAge must be a number')\n    this[MAX_AGE] = options.maxAge || 0\n    this[DISPOSE] = options.dispose\n    this[NO_DISPOSE_ON_SET] = options.noDisposeOnSet || false\n    this[UPDATE_AGE_ON_GET] = options.updateAgeOnGet || false\n    this.reset()\n  }\n\n  // resize the cache when the max changes.\n  set max (mL) {\n    if (typeof mL !== 'number' || mL < 0)\n      throw new TypeError('max must be a non-negative number')\n\n    this[MAX] = mL || Infinity\n    trim(this)\n  }\n  get max () {\n    return this[MAX]\n  }\n\n  set allowStale (allowStale) {\n    this[ALLOW_STALE] = !!allowStale\n  }\n  get allowStale () {\n    return this[ALLOW_STALE]\n  }\n\n  set maxAge (mA) {\n    if (typeof mA !== 'number')\n      throw new TypeError('maxAge must be a non-negative number')\n\n    this[MAX_AGE] = mA\n    trim(this)\n  }\n  get maxAge () {\n    return this[MAX_AGE]\n  }\n\n  // resize the cache when the lengthCalculator changes.\n  set lengthCalculator (lC) {\n    if (typeof lC !== 'function')\n      lC = naiveLength\n\n    if (lC !== this[LENGTH_CALCULATOR]) {\n      this[LENGTH_CALCULATOR] = lC\n      this[LENGTH] = 0\n      this[LRU_LIST].forEach(hit => {\n        hit.length = this[LENGTH_CALCULATOR](hit.value, hit.key)\n        this[LENGTH] += hit.length\n      })\n    }\n    trim(this)\n  }\n  get lengthCalculator () { return this[LENGTH_CALCULATOR] }\n\n  get length () { return this[LENGTH] }\n  get itemCount () { return this[LRU_LIST].length }\n\n  rforEach (fn, thisp) {\n    thisp = thisp || this\n    for (let walker = this[LRU_LIST].tail; walker !== null;) {\n      const prev = walker.prev\n      forEachStep(this, fn, walker, thisp)\n      walker = prev\n    }\n  }\n\n  forEach (fn, thisp) {\n    thisp = thisp || this\n    for (let walker = this[LRU_LIST].head; walker !== null;) {\n      const next = walker.next\n      forEachStep(this, fn, walker, thisp)\n      walker = next\n    }\n  }\n\n  keys () {\n    return this[LRU_LIST].toArray().map(k => k.key)\n  }\n\n  values () {\n    return this[LRU_LIST].toArray().map(k => k.value)\n  }\n\n  reset () {\n    if (this[DISPOSE] &&\n        this[LRU_LIST] &&\n        this[LRU_LIST].length) {\n      this[LRU_LIST].forEach(hit => this[DISPOSE](hit.key, hit.value))\n    }\n\n    this[CACHE] = new Map() // hash of items by key\n    this[LRU_LIST] = new Yallist() // list of items in order of use recency\n    this[LENGTH] = 0 // length of items in the list\n  }\n\n  dump () {\n    return this[LRU_LIST].map(hit =>\n      isStale(this, hit) ? false : {\n        k: hit.key,\n        v: hit.value,\n        e: hit.now + (hit.maxAge || 0)\n      }).toArray().filter(h => h)\n  }\n\n  dumpLru () {\n    return this[LRU_LIST]\n  }\n\n  set (key, value, maxAge) {\n    maxAge = maxAge || this[MAX_AGE]\n\n    if (maxAge && typeof maxAge !== 'number')\n      throw new TypeError('maxAge must be a number')\n\n    const now = maxAge ? Date.now() : 0\n    const len = this[LENGTH_CALCULATOR](value, key)\n\n    if (this[CACHE].has(key)) {\n      if (len > this[MAX]) {\n        del(this, this[CACHE].get(key))\n        return false\n      }\n\n      const node = this[CACHE].get(key)\n      const item = node.value\n\n      // dispose of the old one before overwriting\n      // split out into 2 ifs for better coverage tracking\n      if (this[DISPOSE]) {\n        if (!this[NO_DISPOSE_ON_SET])\n          this[DISPOSE](key, item.value)\n      }\n\n      item.now = now\n      item.maxAge = maxAge\n      item.value = value\n      this[LENGTH] += len - item.length\n      item.length = len\n      this.get(key)\n      trim(this)\n      return true\n    }\n\n    const hit = new Entry(key, value, len, now, maxAge)\n\n    // oversized objects fall out of cache automatically.\n    if (hit.length > this[MAX]) {\n      if (this[DISPOSE])\n        this[DISPOSE](key, value)\n\n      return false\n    }\n\n    this[LENGTH] += hit.length\n    this[LRU_LIST].unshift(hit)\n    this[CACHE].set(key, this[LRU_LIST].head)\n    trim(this)\n    return true\n  }\n\n  has (key) {\n    if (!this[CACHE].has(key)) return false\n    const hit = this[CACHE].get(key).value\n    return !isStale(this, hit)\n  }\n\n  get (key) {\n    return get(this, key, true)\n  }\n\n  peek (key) {\n    return get(this, key, false)\n  }\n\n  pop () {\n    const node = this[LRU_LIST].tail\n    if (!node)\n      return null\n\n    del(this, node)\n    return node.value\n  }\n\n  del (key) {\n    del(this, this[CACHE].get(key))\n  }\n\n  load (arr) {\n    // reset the cache\n    this.reset()\n\n    const now = Date.now()\n    // A previous serialized cache has the most recent items first\n    for (let l = arr.length - 1; l >= 0; l--) {\n      const hit = arr[l]\n      const expiresAt = hit.e || 0\n      if (expiresAt === 0)\n        // the item was created without expiration in a non aged cache\n        this.set(hit.k, hit.v)\n      else {\n        const maxAge = expiresAt - now\n        // dont add already expired items\n        if (maxAge > 0) {\n          this.set(hit.k, hit.v, maxAge)\n        }\n      }\n    }\n  }\n\n  prune () {\n    this[CACHE].forEach((value, key) => get(this, key, false))\n  }\n}\n\nconst get = (self, key, doUse) => {\n  const node = self[CACHE].get(key)\n  if (node) {\n    const hit = node.value\n    if (isStale(self, hit)) {\n      del(self, node)\n      if (!self[ALLOW_STALE])\n        return undefined\n    } else {\n      if (doUse) {\n        if (self[UPDATE_AGE_ON_GET])\n          node.value.now = Date.now()\n        self[LRU_LIST].unshiftNode(node)\n      }\n    }\n    return hit.value\n  }\n}\n\nconst isStale = (self, hit) => {\n  if (!hit || (!hit.maxAge && !self[MAX_AGE]))\n    return false\n\n  const diff = Date.now() - hit.now\n  return hit.maxAge ? diff > hit.maxAge\n    : self[MAX_AGE] && (diff > self[MAX_AGE])\n}\n\nconst trim = self => {\n  if (self[LENGTH] > self[MAX]) {\n    for (let walker = self[LRU_LIST].tail;\n      self[LENGTH] > self[MAX] && walker !== null;) {\n      // We know that we're about to delete this one, and also\n      // what the next least recently used key will be, so just\n      // go ahead and set it now.\n      const prev = walker.prev\n      del(self, walker)\n      walker = prev\n    }\n  }\n}\n\nconst del = (self, node) => {\n  if (node) {\n    const hit = node.value\n    if (self[DISPOSE])\n      self[DISPOSE](hit.key, hit.value)\n\n    self[LENGTH] -= hit.length\n    self[CACHE].delete(hit.key)\n    self[LRU_LIST].removeNode(node)\n  }\n}\n\nclass Entry {\n  constructor (key, value, length, now, maxAge) {\n    this.key = key\n    this.value = value\n    this.length = length\n    this.now = now\n    this.maxAge = maxAge || 0\n  }\n}\n\nconst forEachStep = (self, fn, node, thisp) => {\n  let hit = node.value\n  if (isStale(self, hit)) {\n    del(self, node)\n    if (!self[ALLOW_STALE])\n      hit = undefined\n  }\n  if (hit)\n    fn.call(thisp, hit.value, hit.key, self)\n}\n\nmodule.exports = LRUCache\n","/*\n * Copyright (c) 2019 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst LRU = require('lru-cache');\n\nconst MAX_ACTIVE_CONTEXTS = 10;\n\nmodule.exports = class ResolvedContext {\n  /**\n   * Creates a ResolvedContext.\n   *\n   * @param document the context document.\n   */\n  constructor({document}) {\n    this.document = document;\n    // TODO: enable customization of processed context cache\n    // TODO: limit based on size of processed contexts vs. number of them\n    this.cache = new LRU({max: MAX_ACTIVE_CONTEXTS});\n  }\n\n  getProcessed(activeCtx) {\n    return this.cache.get(activeCtx);\n  }\n\n  setProcessed(activeCtx, processedCtx) {\n    this.cache.set(activeCtx, processedCtx);\n  }\n};\n","/*\n * Copyright (c) 2019 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isString: _isString,\n} = require('./types');\nconst {\n  asArray: _asArray\n} = require('./util');\nconst {prependBase} = require('./url');\nconst JsonLdError = require('./JsonLdError');\nconst ResolvedContext = require('./ResolvedContext');\n\nconst MAX_CONTEXT_URLS = 10;\n\nmodule.exports = class ContextResolver {\n  /**\n   * Creates a ContextResolver.\n   *\n   * @param sharedCache a shared LRU cache with `get` and `set` APIs.\n   */\n  constructor({sharedCache}) {\n    this.perOpCache = new Map();\n    this.sharedCache = sharedCache;\n  }\n\n  async resolve({\n    activeCtx, context, documentLoader, base, cycles = new Set()\n  }) {\n    // process `@context`\n    if(context && _isObject(context) && context['@context']) {\n      context = context['@context'];\n    }\n\n    // context is one or more contexts\n    context = _asArray(context);\n\n    // resolve each context in the array\n    const allResolved = [];\n    for(const ctx of context) {\n      if(_isString(ctx)) {\n        // see if `ctx` has been resolved before...\n        let resolved = this._get(ctx);\n        if(!resolved) {\n          // not resolved yet, resolve\n          resolved = await this._resolveRemoteContext(\n            {activeCtx, url: ctx, documentLoader, base, cycles});\n        }\n\n        // add to output and continue\n        if(_isArray(resolved)) {\n          allResolved.push(...resolved);\n        } else {\n          allResolved.push(resolved);\n        }\n        continue;\n      }\n      if(ctx === null) {\n        // handle `null` context, nothing to cache\n        allResolved.push(new ResolvedContext({document: null}));\n        continue;\n      }\n      if(!_isObject(ctx)) {\n        _throwInvalidLocalContext(context);\n      }\n      // context is an object, get/create `ResolvedContext` for it\n      const key = JSON.stringify(ctx);\n      let resolved = this._get(key);\n      if(!resolved) {\n        // create a new static `ResolvedContext` and cache it\n        resolved = new ResolvedContext({document: ctx});\n        this._cacheResolvedContext({key, resolved, tag: 'static'});\n      }\n      allResolved.push(resolved);\n    }\n\n    return allResolved;\n  }\n\n  _get(key) {\n    // get key from per operation cache; no `tag` is used with this cache so\n    // any retrieved context will always be the same during a single operation\n    let resolved = this.perOpCache.get(key);\n    if(!resolved) {\n      // see if the shared cache has a `static` entry for this URL\n      const tagMap = this.sharedCache.get(key);\n      if(tagMap) {\n        resolved = tagMap.get('static');\n        if(resolved) {\n          this.perOpCache.set(key, resolved);\n        }\n      }\n    }\n    return resolved;\n  }\n\n  _cacheResolvedContext({key, resolved, tag}) {\n    this.perOpCache.set(key, resolved);\n    if(tag !== undefined) {\n      let tagMap = this.sharedCache.get(key);\n      if(!tagMap) {\n        tagMap = new Map();\n        this.sharedCache.set(key, tagMap);\n      }\n      tagMap.set(tag, resolved);\n    }\n    return resolved;\n  }\n\n  async _resolveRemoteContext({activeCtx, url, documentLoader, base, cycles}) {\n    // resolve relative URL and fetch context\n    url = prependBase(base, url);\n    const {context, remoteDoc} = await this._fetchContext(\n      {activeCtx, url, documentLoader, cycles});\n\n    // update base according to remote document and resolve any relative URLs\n    base = remoteDoc.documentUrl || url;\n    _resolveContextUrls({context, base});\n\n    // resolve, cache, and return context\n    const resolved = await this.resolve(\n      {activeCtx, context, documentLoader, base, cycles});\n    this._cacheResolvedContext({key: url, resolved, tag: remoteDoc.tag});\n    return resolved;\n  }\n\n  async _fetchContext({activeCtx, url, documentLoader, cycles}) {\n    // check for max context URLs fetched during a resolve operation\n    if(cycles.size > MAX_CONTEXT_URLS) {\n      throw new JsonLdError(\n        'Maximum number of @context URLs exceeded.',\n        'jsonld.ContextUrlError',\n        {\n          code: activeCtx.processingMode === 'json-ld-1.0' ?\n            'loading remote context failed' :\n            'context overflow',\n          max: MAX_CONTEXT_URLS\n        });\n    }\n\n    // check for context URL cycle\n    // shortcut to avoid extra work that would eventually hit the max above\n    if(cycles.has(url)) {\n      throw new JsonLdError(\n        'Cyclical @context URLs detected.',\n        'jsonld.ContextUrlError',\n        {\n          code: activeCtx.processingMode === 'json-ld-1.0' ?\n            'recursive context inclusion' :\n            'context overflow',\n          url\n        });\n    }\n\n    // track cycles\n    cycles.add(url);\n\n    let context;\n    let remoteDoc;\n\n    try {\n      remoteDoc = await documentLoader(url);\n      context = remoteDoc.document || null;\n      // parse string context as JSON\n      if(_isString(context)) {\n        context = JSON.parse(context);\n      }\n    } catch(e) {\n      throw new JsonLdError(\n        'Dereferencing a URL did not result in a valid JSON-LD object. ' +\n        'Possible causes are an inaccessible URL perhaps due to ' +\n        'a same-origin policy (ensure the server uses CORS if you are ' +\n        'using client-side JavaScript), too many redirects, a ' +\n        'non-JSON response, or more than one HTTP Link Header was ' +\n        'provided for a remote context.',\n        'jsonld.InvalidUrl',\n        {code: 'loading remote context failed', url, cause: e});\n    }\n\n    // ensure ctx is an object\n    if(!_isObject(context)) {\n      throw new JsonLdError(\n        'Dereferencing a URL did not result in a JSON object. The ' +\n        'response was valid JSON, but it was not a JSON object.',\n        'jsonld.InvalidUrl', {code: 'invalid remote context', url});\n    }\n\n    // use empty context if no @context key is present\n    if(!('@context' in context)) {\n      context = {'@context': {}};\n    } else {\n      context = {'@context': context['@context']};\n    }\n\n    // append @context URL to context if given\n    if(remoteDoc.contextUrl) {\n      if(!_isArray(context['@context'])) {\n        context['@context'] = [context['@context']];\n      }\n      context['@context'].push(remoteDoc.contextUrl);\n    }\n\n    return {context, remoteDoc};\n  }\n};\n\nfunction _throwInvalidLocalContext(ctx) {\n  throw new JsonLdError(\n    'Invalid JSON-LD syntax; @context must be an object.',\n    'jsonld.SyntaxError', {\n      code: 'invalid local context', context: ctx\n    });\n}\n\n/**\n * Resolve all relative `@context` URLs in the given context by inline\n * replacing them with absolute URLs.\n *\n * @param context the context.\n * @param base the base IRI to use to resolve relative IRIs.\n */\nfunction _resolveContextUrls({context, base}) {\n  if(!context) {\n    return;\n  }\n\n  const ctx = context['@context'];\n\n  if(_isString(ctx)) {\n    context['@context'] = prependBase(base, ctx);\n    return;\n  }\n\n  if(_isArray(ctx)) {\n    for(let i = 0; i < ctx.length; ++i) {\n      const element = ctx[i];\n      if(_isString(element)) {\n        ctx[i] = prependBase(base, element);\n        continue;\n      }\n      if(_isObject(element)) {\n        _resolveContextUrls({context: {'@context': element}, base});\n      }\n    }\n    return;\n  }\n\n  if(!_isObject(ctx)) {\n    // no @context URLs can be found in non-object\n    return;\n  }\n\n  // ctx is an object, resolve any context URLs in terms\n  for(const term in ctx) {\n    _resolveContextUrls({context: ctx[term], base});\n  }\n}\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\n// TODO: move `NQuads` to its own package\nmodule.exports = require('rdf-canonize').NQuads;\n","/*\n * Copyright (c) 2017-2019 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst util = require('./util');\nconst JsonLdError = require('./JsonLdError');\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isString: _isString,\n  isUndefined: _isUndefined\n} = require('./types');\n\nconst {\n  isAbsolute: _isAbsoluteIri,\n  isRelative: _isRelativeIri,\n  prependBase\n} = require('./url');\n\nconst {\n  asArray: _asArray,\n  compareShortestLeast: _compareShortestLeast\n} = require('./util');\n\nconst INITIAL_CONTEXT_CACHE = new Map();\nconst INITIAL_CONTEXT_CACHE_MAX_SIZE = 10000;\nconst KEYWORD_PATTERN = /^@[a-zA-Z]+$/;\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Processes a local context and returns a new active context.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context to process.\n * @param options the context processing options.\n * @param propagate `true` if `false`, retains any previously defined term,\n *   which can be rolled back when the descending into a new node object.\n * @param overrideProtected `false` allows protected terms to be modified.\n *\n * @return a Promise that resolves to the new active context.\n */\napi.process = async ({\n  activeCtx, localCtx, options,\n  propagate = true,\n  overrideProtected = false,\n  cycles = new Set()\n}) => {\n  // normalize local context to an array of @context objects\n  if(_isObject(localCtx) && '@context' in localCtx &&\n    _isArray(localCtx['@context'])) {\n    localCtx = localCtx['@context'];\n  }\n  const ctxs = _asArray(localCtx);\n\n  // no contexts in array, return current active context w/o changes\n  if(ctxs.length === 0) {\n    return activeCtx;\n  }\n\n  // resolve contexts\n  const resolved = await options.contextResolver.resolve({\n    activeCtx,\n    context: localCtx,\n    documentLoader: options.documentLoader,\n    base: options.base\n  });\n\n  // override propagate if first resolved context has `@propagate`\n  if(_isObject(resolved[0].document) &&\n    typeof resolved[0].document['@propagate'] === 'boolean') {\n    // retrieve early, error checking done later\n    propagate = resolved[0].document['@propagate'];\n  }\n\n  // process each context in order, update active context\n  // on each iteration to ensure proper caching\n  let rval = activeCtx;\n\n  // track the previous context\n  // if not propagating, make sure rval has a previous context\n  if(!propagate && !rval.previousContext) {\n    // clone `rval` context before updating\n    rval = rval.clone();\n    rval.previousContext = activeCtx;\n  }\n\n  for(const resolvedContext of resolved) {\n    let {document: ctx} = resolvedContext;\n\n    // update active context to one computed from last iteration\n    activeCtx = rval;\n\n    // reset to initial context\n    if(ctx === null) {\n      // We can't nullify if there are protected terms and we're\n      // not allowing overrides (e.g. processing a property term scoped context)\n      if(!overrideProtected &&\n        Object.keys(activeCtx.protected).length !== 0) {\n        const protectedMode = (options && options.protectedMode) || 'error';\n        if(protectedMode === 'error') {\n          throw new JsonLdError(\n            'Tried to nullify a context with protected terms outside of ' +\n            'a term definition.',\n            'jsonld.SyntaxError',\n            {code: 'invalid context nullification'});\n        } else if(protectedMode === 'warn') {\n          // FIXME: remove logging and use a handler\n          console.warn('WARNING: invalid context nullification');\n\n          // get processed context from cache if available\n          const processed = resolvedContext.getProcessed(activeCtx);\n          if(processed) {\n            rval = activeCtx = processed;\n            continue;\n          }\n\n          const oldActiveCtx = activeCtx;\n          // copy all protected term definitions to fresh initial context\n          rval = activeCtx = api.getInitialContext(options).clone();\n          for(const [term, _protected] of\n            Object.entries(oldActiveCtx.protected)) {\n            if(_protected) {\n              activeCtx.mappings[term] =\n                util.clone(oldActiveCtx.mappings[term]);\n            }\n          }\n          activeCtx.protected = util.clone(oldActiveCtx.protected);\n\n          // cache processed result\n          resolvedContext.setProcessed(oldActiveCtx, rval);\n          continue;\n        }\n        throw new JsonLdError(\n          'Invalid protectedMode.',\n          'jsonld.SyntaxError',\n          {code: 'invalid protected mode', context: localCtx, protectedMode});\n      }\n      rval = activeCtx = api.getInitialContext(options).clone();\n      continue;\n    }\n\n    // get processed context from cache if available\n    const processed = resolvedContext.getProcessed(activeCtx);\n    if(processed) {\n      rval = activeCtx = processed;\n      continue;\n    }\n\n    // dereference @context key if present\n    if(_isObject(ctx) && '@context' in ctx) {\n      ctx = ctx['@context'];\n    }\n\n    // context must be an object by now, all URLs retrieved before this call\n    if(!_isObject(ctx)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context must be an object.',\n        'jsonld.SyntaxError', {code: 'invalid local context', context: ctx});\n    }\n\n    // TODO: there is likely a `previousContext` cloning optimization that\n    // could be applied here (no need to copy it under certain conditions)\n\n    // clone context before updating it\n    rval = rval.clone();\n\n    // define context mappings for keys in local context\n    const defined = new Map();\n\n    // handle @version\n    if('@version' in ctx) {\n      if(ctx['@version'] !== 1.1) {\n        throw new JsonLdError(\n          'Unsupported JSON-LD version: ' + ctx['@version'],\n          'jsonld.UnsupportedVersion',\n          {code: 'invalid @version value', context: ctx});\n      }\n      if(activeCtx.processingMode &&\n        activeCtx.processingMode === 'json-ld-1.0') {\n        throw new JsonLdError(\n          '@version: ' + ctx['@version'] + ' not compatible with ' +\n          activeCtx.processingMode,\n          'jsonld.ProcessingModeConflict',\n          {code: 'processing mode conflict', context: ctx});\n      }\n      rval.processingMode = 'json-ld-1.1';\n      rval['@version'] = ctx['@version'];\n      defined.set('@version', true);\n    }\n\n    // if not set explicitly, set processingMode to \"json-ld-1.1\"\n    rval.processingMode =\n      rval.processingMode || activeCtx.processingMode;\n\n    // handle @base\n    if('@base' in ctx) {\n      let base = ctx['@base'];\n\n      if(base === null || _isAbsoluteIri(base)) {\n        // no action\n      } else if(_isRelativeIri(base)) {\n        base = prependBase(rval['@base'], base);\n      } else {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@base\" in a ' +\n          '@context must be an absolute IRI, a relative IRI, or null.',\n          'jsonld.SyntaxError', {code: 'invalid base IRI', context: ctx});\n      }\n\n      rval['@base'] = base;\n      defined.set('@base', true);\n    }\n\n    // handle @vocab\n    if('@vocab' in ctx) {\n      const value = ctx['@vocab'];\n      if(value === null) {\n        delete rval['@vocab'];\n      } else if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@vocab\" in a ' +\n          '@context must be a string or null.',\n          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});\n      } else if(!_isAbsoluteIri(value) && api.processingMode(rval, 1.0)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@vocab\" in a ' +\n          '@context must be an absolute IRI.',\n          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});\n      } else {\n        rval['@vocab'] = _expandIri(rval, value, {vocab: true, base: true},\n          undefined, undefined, options);\n      }\n      defined.set('@vocab', true);\n    }\n\n    // handle @language\n    if('@language' in ctx) {\n      const value = ctx['@language'];\n      if(value === null) {\n        delete rval['@language'];\n      } else if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@language\" in a ' +\n          '@context must be a string or null.',\n          'jsonld.SyntaxError',\n          {code: 'invalid default language', context: ctx});\n      } else {\n        rval['@language'] = value.toLowerCase();\n      }\n      defined.set('@language', true);\n    }\n\n    // handle @direction\n    if('@direction' in ctx) {\n      const value = ctx['@direction'];\n      if(activeCtx.processingMode === 'json-ld-1.0') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @direction not compatible with ' +\n          activeCtx.processingMode,\n          'jsonld.SyntaxError',\n          {code: 'invalid context member', context: ctx});\n      }\n      if(value === null) {\n        delete rval['@direction'];\n      } else if(value !== 'ltr' && value !== 'rtl') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@direction\" in a ' +\n          '@context must be null, \"ltr\", or \"rtl\".',\n          'jsonld.SyntaxError',\n          {code: 'invalid base direction', context: ctx});\n      } else {\n        rval['@direction'] = value;\n      }\n      defined.set('@direction', true);\n    }\n\n    // handle @propagate\n    // note: we've already extracted it, here we just do error checking\n    if('@propagate' in ctx) {\n      const value = ctx['@propagate'];\n      if(activeCtx.processingMode === 'json-ld-1.0') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @propagate not compatible with ' +\n          activeCtx.processingMode,\n          'jsonld.SyntaxError',\n          {code: 'invalid context entry', context: ctx});\n      }\n      if(typeof value !== 'boolean') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @propagate value must be a boolean.',\n          'jsonld.SyntaxError',\n          {code: 'invalid @propagate value', context: localCtx});\n      }\n      defined.set('@propagate', true);\n    }\n\n    // handle @import\n    if('@import' in ctx) {\n      const value = ctx['@import'];\n      if(activeCtx.processingMode === 'json-ld-1.0') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @import not compatible with ' +\n          activeCtx.processingMode,\n          'jsonld.SyntaxError',\n          {code: 'invalid context entry', context: ctx});\n      }\n      if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @import must be a string.',\n          'jsonld.SyntaxError',\n          {code: 'invalid @import value', context: localCtx});\n      }\n\n      // resolve contexts\n      const resolvedImport = await options.contextResolver.resolve({\n        activeCtx,\n        context: value,\n        documentLoader: options.documentLoader,\n        base: options.base\n      });\n      if(resolvedImport.length !== 1) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @import must reference a single context.',\n          'jsonld.SyntaxError',\n          {code: 'invalid remote context', context: localCtx});\n      }\n      const processedImport = resolvedImport[0].getProcessed(activeCtx);\n      if(processedImport) {\n        // Note: if the same context were used in this active context\n        // as a reference context, then processed_input might not\n        // be a dict.\n        ctx = processedImport;\n      } else {\n        const importCtx = resolvedImport[0].document;\n        if('@import' in importCtx) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax: ' +\n            'imported context must not include @import.',\n            'jsonld.SyntaxError',\n            {code: 'invalid context entry', context: localCtx});\n        }\n\n        // merge ctx into importCtx and replace rval with the result\n        for(const key in importCtx) {\n          if(!ctx.hasOwnProperty(key)) {\n            ctx[key] = importCtx[key];\n          }\n        }\n\n        // Note: this could potenially conflict if the import\n        // were used in the same active context as a referenced\n        // context and an import. In this case, we\n        // could override the cached result, but seems unlikely.\n        resolvedImport[0].setProcessed(activeCtx, ctx);\n      }\n\n      defined.set('@import', true);\n    }\n\n    // handle @protected; determine whether this sub-context is declaring\n    // all its terms to be \"protected\" (exceptions can be made on a\n    // per-definition basis)\n    defined.set('@protected', ctx['@protected'] || false);\n\n    // process all other keys\n    for(const key in ctx) {\n      api.createTermDefinition({\n        activeCtx: rval,\n        localCtx: ctx,\n        term: key,\n        defined,\n        options,\n        overrideProtected\n      });\n\n      if(_isObject(ctx[key]) && '@context' in ctx[key]) {\n        const keyCtx = ctx[key]['@context'];\n        let process = true;\n        if(_isString(keyCtx)) {\n          const url = prependBase(options.base, keyCtx);\n          // track processed contexts to avoid scoped context recursion\n          if(cycles.has(url)) {\n            process = false;\n          } else {\n            cycles.add(url);\n          }\n        }\n        // parse context to validate\n        if(process) {\n          try {\n            await api.process({\n              activeCtx: rval.clone(),\n              localCtx: ctx[key]['@context'],\n              overrideProtected: true,\n              options,\n              cycles\n            });\n          } catch(e) {\n            throw new JsonLdError(\n              'Invalid JSON-LD syntax; invalid scoped context.',\n              'jsonld.SyntaxError',\n              {\n                code: 'invalid scoped context',\n                context: ctx[key]['@context'],\n                term: key\n              });\n          }\n        }\n      }\n    }\n\n    // cache processed result\n    resolvedContext.setProcessed(activeCtx, rval);\n  }\n\n  return rval;\n};\n\n/**\n * Creates a term definition during context processing.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context being processed.\n * @param term the term in the local context to define the mapping for.\n * @param defined a map of defining/defined keys to detect cycles and prevent\n *          double definitions.\n * @param {Object} [options] - creation options.\n * @param {string} [options.protectedMode=\"error\"] - \"error\" to throw error\n *   on `@protected` constraint violation, \"warn\" to allow violations and\n *   signal a warning.\n * @param overrideProtected `false` allows protected terms to be modified.\n */\napi.createTermDefinition = ({\n  activeCtx,\n  localCtx,\n  term,\n  defined,\n  options,\n  overrideProtected = false,\n}) => {\n  if(defined.has(term)) {\n    // term already defined\n    if(defined.get(term)) {\n      return;\n    }\n    // cycle detected\n    throw new JsonLdError(\n      'Cyclical context definition detected.',\n      'jsonld.CyclicalContext',\n      {code: 'cyclic IRI mapping', context: localCtx, term});\n  }\n\n  // now defining term\n  defined.set(term, false);\n\n  // get context term value\n  let value;\n  if(localCtx.hasOwnProperty(term)) {\n    value = localCtx[term];\n  }\n\n  if(term === '@type' &&\n     _isObject(value) &&\n     (value['@container'] || '@set') === '@set' &&\n     api.processingMode(activeCtx, 1.1)) {\n\n    const validKeys = ['@container', '@id', '@protected'];\n    const keys = Object.keys(value);\n    if(keys.length === 0 || keys.some(k => !validKeys.includes(k))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; keywords cannot be overridden.',\n        'jsonld.SyntaxError',\n        {code: 'keyword redefinition', context: localCtx, term});\n    }\n  } else if(api.isKeyword(term)) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; keywords cannot be overridden.',\n      'jsonld.SyntaxError',\n      {code: 'keyword redefinition', context: localCtx, term});\n  } else if(term.match(KEYWORD_PATTERN)) {\n    // FIXME: remove logging and use a handler\n    console.warn('WARNING: terms beginning with \"@\" are reserved' +\n      ' for future use and ignored', {term});\n    return;\n  } else if(term === '') {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; a term cannot be an empty string.',\n      'jsonld.SyntaxError',\n      {code: 'invalid term definition', context: localCtx});\n  }\n\n  // keep reference to previous mapping for potential `@protected` check\n  const previousMapping = activeCtx.mappings.get(term);\n\n  // remove old mapping\n  if(activeCtx.mappings.has(term)) {\n    activeCtx.mappings.delete(term);\n  }\n\n  // convert short-hand value to object w/@id\n  let simpleTerm = false;\n  if(_isString(value) || value === null) {\n    simpleTerm = true;\n    value = {'@id': value};\n  }\n\n  if(!_isObject(value)) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; @context term values must be ' +\n      'strings or objects.',\n      'jsonld.SyntaxError',\n      {code: 'invalid term definition', context: localCtx});\n  }\n\n  // create new mapping\n  const mapping = {};\n  activeCtx.mappings.set(term, mapping);\n  mapping.reverse = false;\n\n  // make sure term definition only has expected keywords\n  const validKeys = ['@container', '@id', '@language', '@reverse', '@type'];\n\n  // JSON-LD 1.1 support\n  if(api.processingMode(activeCtx, 1.1)) {\n    validKeys.push(\n      '@context', '@direction', '@index', '@nest', '@prefix', '@protected');\n  }\n\n  for(const kw in value) {\n    if(!validKeys.includes(kw)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a term definition must not contain ' + kw,\n        'jsonld.SyntaxError',\n        {code: 'invalid term definition', context: localCtx});\n    }\n  }\n\n  // always compute whether term has a colon as an optimization for\n  // _compactIri\n  const colon = term.indexOf(':');\n  mapping._termHasColon = (colon > 0);\n\n  if('@reverse' in value) {\n    if('@id' in value) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @reverse term definition must not ' +\n        'contain @id.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n    if('@nest' in value) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @reverse term definition must not ' +\n        'contain @nest.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n    const reverse = value['@reverse'];\n    if(!_isString(reverse)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @reverse value must be a string.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n\n    if(!api.isKeyword(reverse) && reverse.match(KEYWORD_PATTERN)) {\n      // FIXME: remove logging and use a handler\n      console.warn('WARNING: values beginning with \"@\" are reserved' +\n        ' for future use and ignored', {reverse});\n      if(previousMapping) {\n        activeCtx.mappings.set(term, previousMapping);\n      } else {\n        activeCtx.mappings.delete(term);\n      }\n      return;\n    }\n\n    // expand and add @id mapping\n    const id = _expandIri(\n      activeCtx, reverse, {vocab: true, base: false}, localCtx, defined,\n      options);\n    if(!_isAbsoluteIri(id)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @reverse value must be an ' +\n        'absolute IRI or a blank node identifier.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n\n    mapping['@id'] = id;\n    mapping.reverse = true;\n  } else if('@id' in value) {\n    let id = value['@id'];\n    if(id && !_isString(id)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @id value must be an array ' +\n        'of strings or a string.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n    if(id === null) {\n      // reserve a null term, which may be protected\n      mapping['@id'] = null;\n    } else if(!api.isKeyword(id) && id.match(KEYWORD_PATTERN)) {\n      // FIXME: remove logging and use a handler\n      console.warn('WARNING: values beginning with \"@\" are reserved' +\n        ' for future use and ignored', {id});\n      if(previousMapping) {\n        activeCtx.mappings.set(term, previousMapping);\n      } else {\n        activeCtx.mappings.delete(term);\n      }\n      return;\n    } else if(id !== term) {\n      // expand and add @id mapping\n      id = _expandIri(\n        activeCtx, id, {vocab: true, base: false}, localCtx, defined, options);\n      if(!_isAbsoluteIri(id) && !api.isKeyword(id)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; a @context @id value must be an ' +\n          'absolute IRI, a blank node identifier, or a keyword.',\n          'jsonld.SyntaxError',\n          {code: 'invalid IRI mapping', context: localCtx});\n      }\n\n      // if term has the form of an IRI it must map the same\n      if(term.match(/(?::[^:])|\\//)) {\n        const termDefined = new Map(defined).set(term, true);\n        const termIri = _expandIri(\n          activeCtx, term, {vocab: true, base: false},\n          localCtx, termDefined, options);\n        if(termIri !== id) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; term in form of IRI must ' +\n            'expand to definition.',\n            'jsonld.SyntaxError',\n            {code: 'invalid IRI mapping', context: localCtx});\n        }\n      }\n\n      mapping['@id'] = id;\n      // indicate if this term may be used as a compact IRI prefix\n      mapping._prefix = (simpleTerm &&\n        !mapping._termHasColon &&\n        id.match(/[:\\/\\?#\\[\\]@]$/));\n    }\n  }\n\n  if(!('@id' in mapping)) {\n    // see if the term has a prefix\n    if(mapping._termHasColon) {\n      const prefix = term.substr(0, colon);\n      if(localCtx.hasOwnProperty(prefix)) {\n        // define parent prefix\n        api.createTermDefinition({\n          activeCtx, localCtx, term: prefix, defined, options\n        });\n      }\n\n      if(activeCtx.mappings.has(prefix)) {\n        // set @id based on prefix parent\n        const suffix = term.substr(colon + 1);\n        mapping['@id'] = activeCtx.mappings.get(prefix)['@id'] + suffix;\n      } else {\n        // term is an absolute IRI\n        mapping['@id'] = term;\n      }\n    } else if(term === '@type') {\n      // Special case, were we've previously determined that container is @set\n      mapping['@id'] = term;\n    } else {\n      // non-IRIs *must* define @ids if @vocab is not available\n      if(!('@vocab' in activeCtx)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @context terms must define an @id.',\n          'jsonld.SyntaxError',\n          {code: 'invalid IRI mapping', context: localCtx, term});\n      }\n      // prepend vocab to term\n      mapping['@id'] = activeCtx['@vocab'] + term;\n    }\n  }\n\n  // Handle term protection\n  if(value['@protected'] === true ||\n    (defined.get('@protected') === true && value['@protected'] !== false)) {\n    activeCtx.protected[term] = true;\n    mapping.protected = true;\n  }\n\n  // IRI mapping now defined\n  defined.set(term, true);\n\n  if('@type' in value) {\n    let type = value['@type'];\n    if(!_isString(type)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an @context @type value must be a string.',\n        'jsonld.SyntaxError',\n        {code: 'invalid type mapping', context: localCtx});\n    }\n\n    if((type === '@json' || type === '@none')) {\n      if(api.processingMode(activeCtx, 1.0)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; an @context @type value must not be ' +\n          `\"${type}\" in JSON-LD 1.0 mode.`,\n          'jsonld.SyntaxError',\n          {code: 'invalid type mapping', context: localCtx});\n      }\n    } else if(type !== '@id' && type !== '@vocab') {\n      // expand @type to full IRI\n      type = _expandIri(\n        activeCtx, type, {vocab: true, base: false}, localCtx, defined,\n        options);\n      if(!_isAbsoluteIri(type)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; an @context @type value must be an ' +\n          'absolute IRI.',\n          'jsonld.SyntaxError',\n          {code: 'invalid type mapping', context: localCtx});\n      }\n      if(type.indexOf('_:') === 0) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; an @context @type value must be an IRI, ' +\n          'not a blank node identifier.',\n          'jsonld.SyntaxError',\n          {code: 'invalid type mapping', context: localCtx});\n      }\n    }\n\n    // add @type to mapping\n    mapping['@type'] = type;\n  }\n\n  if('@container' in value) {\n    // normalize container to an array form\n    const container = _isString(value['@container']) ?\n      [value['@container']] : (value['@container'] || []);\n    const validContainers = ['@list', '@set', '@index', '@language'];\n    let isValid = true;\n    const hasSet = container.includes('@set');\n\n    // JSON-LD 1.1 support\n    if(api.processingMode(activeCtx, 1.1)) {\n      validContainers.push('@graph', '@id', '@type');\n\n      // check container length\n      if(container.includes('@list')) {\n        if(container.length !== 1) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; @context @container with @list must ' +\n            'have no other values',\n            'jsonld.SyntaxError',\n            {code: 'invalid container mapping', context: localCtx});\n        }\n      } else if(container.includes('@graph')) {\n        if(container.some(key =>\n          key !== '@graph' && key !== '@id' && key !== '@index' &&\n          key !== '@set')) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; @context @container with @graph must ' +\n            'have no other values other than @id, @index, and @set',\n            'jsonld.SyntaxError',\n            {code: 'invalid container mapping', context: localCtx});\n        }\n      } else {\n        // otherwise, container may also include @set\n        isValid &= container.length <= (hasSet ? 2 : 1);\n      }\n\n      if(container.includes('@type')) {\n        // If mapping does not have an @type,\n        // set it to @id\n        mapping['@type'] = mapping['@type'] || '@id';\n\n        // type mapping must be either @id or @vocab\n        if(!['@id', '@vocab'].includes(mapping['@type'])) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; container: @type requires @type to be ' +\n            '@id or @vocab.',\n            'jsonld.SyntaxError',\n            {code: 'invalid type mapping', context: localCtx});\n        }\n      }\n    } else {\n      // in JSON-LD 1.0, container must not be an array (it must be a string,\n      // which is one of the validContainers)\n      isValid &= !_isArray(value['@container']);\n\n      // check container length\n      isValid &= container.length <= 1;\n    }\n\n    // check against valid containers\n    isValid &= container.every(c => validContainers.includes(c));\n\n    // @set not allowed with @list\n    isValid &= !(hasSet && container.includes('@list'));\n\n    if(!isValid) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @container value must be ' +\n        'one of the following: ' + validContainers.join(', '),\n        'jsonld.SyntaxError',\n        {code: 'invalid container mapping', context: localCtx});\n    }\n\n    if(mapping.reverse &&\n      !container.every(c => ['@index', '@set'].includes(c))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @container value for a @reverse ' +\n        'type definition must be @index or @set.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n\n    // add @container to mapping\n    mapping['@container'] = container;\n  }\n\n  // property indexing\n  if('@index' in value) {\n    if(!('@container' in value) || !mapping['@container'].includes('@index')) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @index without @index in @container: ' +\n        `\"${value['@index']}\" on term \"${term}\".`, 'jsonld.SyntaxError',\n        {code: 'invalid term definition', context: localCtx});\n    }\n    if(!_isString(value['@index']) || value['@index'].indexOf('@') === 0) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @index must expand to an IRI: ' +\n        `\"${value['@index']}\" on term \"${term}\".`, 'jsonld.SyntaxError',\n        {code: 'invalid term definition', context: localCtx});\n    }\n    mapping['@index'] = value['@index'];\n  }\n\n  // scoped contexts\n  if('@context' in value) {\n    mapping['@context'] = value['@context'];\n  }\n\n  if('@language' in value && !('@type' in value)) {\n    let language = value['@language'];\n    if(language !== null && !_isString(language)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @language value must be ' +\n        'a string or null.', 'jsonld.SyntaxError',\n        {code: 'invalid language mapping', context: localCtx});\n    }\n\n    // add @language to mapping\n    if(language !== null) {\n      language = language.toLowerCase();\n    }\n    mapping['@language'] = language;\n  }\n\n  // term may be used as a prefix\n  if('@prefix' in value) {\n    if(term.match(/:|\\//)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @prefix used on a compact IRI term',\n        'jsonld.SyntaxError',\n        {code: 'invalid term definition', context: localCtx});\n    }\n    if(api.isKeyword(mapping['@id'])) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; keywords may not be used as prefixes',\n        'jsonld.SyntaxError',\n        {code: 'invalid term definition', context: localCtx});\n    }\n    if(typeof value['@prefix'] === 'boolean') {\n      mapping._prefix = value['@prefix'] === true;\n    } else {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context value for @prefix must be boolean',\n        'jsonld.SyntaxError',\n        {code: 'invalid @prefix value', context: localCtx});\n    }\n  }\n\n  if('@direction' in value) {\n    const direction = value['@direction'];\n    if(direction !== null && direction !== 'ltr' && direction !== 'rtl') {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @direction value must be ' +\n        'null, \"ltr\", or \"rtl\".',\n        'jsonld.SyntaxError',\n        {code: 'invalid base direction', context: localCtx});\n    }\n    mapping['@direction'] = direction;\n  }\n\n  if('@nest' in value) {\n    const nest = value['@nest'];\n    if(!_isString(nest) || (nest !== '@nest' && nest.indexOf('@') === 0)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @nest value must be ' +\n        'a string which is not a keyword other than @nest.',\n        'jsonld.SyntaxError',\n        {code: 'invalid @nest value', context: localCtx});\n    }\n    mapping['@nest'] = nest;\n  }\n\n  // disallow aliasing @context and @preserve\n  const id = mapping['@id'];\n  if(id === '@context' || id === '@preserve') {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; @context and @preserve cannot be aliased.',\n      'jsonld.SyntaxError', {code: 'invalid keyword alias', context: localCtx});\n  }\n\n  // Check for overriding protected terms\n  if(previousMapping && previousMapping.protected && !overrideProtected) {\n    // force new term to continue to be protected and see if the mappings would\n    // be equal\n    activeCtx.protected[term] = true;\n    mapping.protected = true;\n    if(!_deepCompare(previousMapping, mapping)) {\n      const protectedMode = (options && options.protectedMode) || 'error';\n      if(protectedMode === 'error') {\n        throw new JsonLdError(\n          `Invalid JSON-LD syntax; tried to redefine \"${term}\" which is a ` +\n          'protected term.',\n          'jsonld.SyntaxError',\n          {code: 'protected term redefinition', context: localCtx, term});\n      } else if(protectedMode === 'warn') {\n        // FIXME: remove logging and use a handler\n        console.warn('WARNING: protected term redefinition', {term});\n        return;\n      }\n      throw new JsonLdError(\n        'Invalid protectedMode.',\n        'jsonld.SyntaxError',\n        {code: 'invalid protected mode', context: localCtx, term,\n          protectedMode});\n    }\n  }\n};\n\n/**\n * Expands a string to a full IRI. The string may be a term, a prefix, a\n * relative IRI, or an absolute IRI. The associated absolute IRI will be\n * returned.\n *\n * @param activeCtx the current active context.\n * @param value the string to expand.\n * @param relativeTo options for how to resolve relative IRIs:\n *          base: true to resolve against the base IRI, false not to.\n *          vocab: true to concatenate after @vocab, false not to.\n * @param {Object} [options] - processing options.\n *\n * @return the expanded value.\n */\napi.expandIri = (activeCtx, value, relativeTo, options) => {\n  return _expandIri(activeCtx, value, relativeTo, undefined, undefined,\n    options);\n};\n\n/**\n * Expands a string to a full IRI. The string may be a term, a prefix, a\n * relative IRI, or an absolute IRI. The associated absolute IRI will be\n * returned.\n *\n * @param activeCtx the current active context.\n * @param value the string to expand.\n * @param relativeTo options for how to resolve relative IRIs:\n *          base: true to resolve against the base IRI, false not to.\n *          vocab: true to concatenate after @vocab, false not to.\n * @param localCtx the local context being processed (only given if called\n *          during context processing).\n * @param defined a map for tracking cycles in context definitions (only given\n *          if called during context processing).\n * @param {Object} [options] - processing options.\n *\n * @return the expanded value.\n */\nfunction _expandIri(activeCtx, value, relativeTo, localCtx, defined, options) {\n  // already expanded\n  if(value === null || !_isString(value) || api.isKeyword(value)) {\n    return value;\n  }\n\n  // ignore non-keyword things that look like a keyword\n  if(value.match(KEYWORD_PATTERN)) {\n    return null;\n  }\n\n  // define term dependency if not defined\n  if(localCtx && localCtx.hasOwnProperty(value) &&\n    defined.get(value) !== true) {\n    api.createTermDefinition({\n      activeCtx, localCtx, term: value, defined, options\n    });\n  }\n\n  relativeTo = relativeTo || {};\n  if(relativeTo.vocab) {\n    const mapping = activeCtx.mappings.get(value);\n\n    // value is explicitly ignored with a null mapping\n    if(mapping === null) {\n      return null;\n    }\n\n    if(_isObject(mapping) && '@id' in mapping) {\n      // value is a term\n      return mapping['@id'];\n    }\n  }\n\n  // split value into prefix:suffix\n  const colon = value.indexOf(':');\n  if(colon > 0) {\n    const prefix = value.substr(0, colon);\n    const suffix = value.substr(colon + 1);\n\n    // do not expand blank nodes (prefix of '_') or already-absolute\n    // IRIs (suffix of '//')\n    if(prefix === '_' || suffix.indexOf('//') === 0) {\n      return value;\n    }\n\n    // prefix dependency not defined, define it\n    if(localCtx && localCtx.hasOwnProperty(prefix)) {\n      api.createTermDefinition({\n        activeCtx, localCtx, term: prefix, defined, options\n      });\n    }\n\n    // use mapping if prefix is defined\n    const mapping = activeCtx.mappings.get(prefix);\n    if(mapping && mapping._prefix) {\n      return mapping['@id'] + suffix;\n    }\n\n    // already absolute IRI\n    if(_isAbsoluteIri(value)) {\n      return value;\n    }\n  }\n\n  // prepend vocab\n  if(relativeTo.vocab && '@vocab' in activeCtx) {\n    return activeCtx['@vocab'] + value;\n  }\n\n  // prepend base\n  if(relativeTo.base && '@base' in activeCtx) {\n    if(activeCtx['@base']) {\n      // The null case preserves value as potentially relative\n      return prependBase(prependBase(options.base, activeCtx['@base']), value);\n    }\n  } else if(relativeTo.base) {\n    return prependBase(options.base, value);\n  }\n\n  return value;\n}\n\n/**\n * Gets the initial context.\n *\n * @param options the options to use:\n *          [base] the document base IRI.\n *\n * @return the initial context.\n */\napi.getInitialContext = options => {\n  const key = JSON.stringify({processingMode: options.processingMode});\n  const cached = INITIAL_CONTEXT_CACHE.get(key);\n  if(cached) {\n    return cached;\n  }\n\n  const initialContext = {\n    processingMode: options.processingMode,\n    mappings: new Map(),\n    inverse: null,\n    getInverse: _createInverseContext,\n    clone: _cloneActiveContext,\n    revertToPreviousContext: _revertToPreviousContext,\n    protected: {}\n  };\n  // TODO: consider using LRU cache instead\n  if(INITIAL_CONTEXT_CACHE.size === INITIAL_CONTEXT_CACHE_MAX_SIZE) {\n    // clear whole cache -- assumes scenario where the cache fills means\n    // the cache isn't being used very efficiently anyway\n    INITIAL_CONTEXT_CACHE.clear();\n  }\n  INITIAL_CONTEXT_CACHE.set(key, initialContext);\n  return initialContext;\n\n  /**\n   * Generates an inverse context for use in the compaction algorithm, if\n   * not already generated for the given active context.\n   *\n   * @return the inverse context.\n   */\n  function _createInverseContext() {\n    const activeCtx = this;\n\n    // lazily create inverse\n    if(activeCtx.inverse) {\n      return activeCtx.inverse;\n    }\n    const inverse = activeCtx.inverse = {};\n\n    // variables for building fast CURIE map\n    const fastCurieMap = activeCtx.fastCurieMap = {};\n    const irisToTerms = {};\n\n    // handle default language\n    const defaultLanguage = (activeCtx['@language'] || '@none').toLowerCase();\n\n    // handle default direction\n    const defaultDirection = activeCtx['@direction'];\n\n    // create term selections for each mapping in the context, ordered by\n    // shortest and then lexicographically least\n    const mappings = activeCtx.mappings;\n    const terms = [...mappings.keys()].sort(_compareShortestLeast);\n    for(const term of terms) {\n      const mapping = mappings.get(term);\n      if(mapping === null) {\n        continue;\n      }\n\n      let container = mapping['@container'] || '@none';\n      container = [].concat(container).sort().join('');\n\n      if(mapping['@id'] === null) {\n        continue;\n      }\n      // iterate over every IRI in the mapping\n      const ids = _asArray(mapping['@id']);\n      for(const iri of ids) {\n        let entry = inverse[iri];\n        const isKeyword = api.isKeyword(iri);\n\n        if(!entry) {\n          // initialize entry\n          inverse[iri] = entry = {};\n\n          if(!isKeyword && !mapping._termHasColon) {\n            // init IRI to term map and fast CURIE prefixes\n            irisToTerms[iri] = [term];\n            const fastCurieEntry = {iri, terms: irisToTerms[iri]};\n            if(iri[0] in fastCurieMap) {\n              fastCurieMap[iri[0]].push(fastCurieEntry);\n            } else {\n              fastCurieMap[iri[0]] = [fastCurieEntry];\n            }\n          }\n        } else if(!isKeyword && !mapping._termHasColon) {\n          // add IRI to term match\n          irisToTerms[iri].push(term);\n        }\n\n        // add new entry\n        if(!entry[container]) {\n          entry[container] = {\n            '@language': {},\n            '@type': {},\n            '@any': {}\n          };\n        }\n        entry = entry[container];\n        _addPreferredTerm(term, entry['@any'], '@none');\n\n        if(mapping.reverse) {\n          // term is preferred for values using @reverse\n          _addPreferredTerm(term, entry['@type'], '@reverse');\n        } else if(mapping['@type'] === '@none') {\n          _addPreferredTerm(term, entry['@any'], '@none');\n          _addPreferredTerm(term, entry['@language'], '@none');\n          _addPreferredTerm(term, entry['@type'], '@none');\n        } else if('@type' in mapping) {\n          // term is preferred for values using specific type\n          _addPreferredTerm(term, entry['@type'], mapping['@type']);\n        } else if('@language' in mapping && '@direction' in mapping) {\n          // term is preferred for values using specific language and direction\n          const language = mapping['@language'];\n          const direction = mapping['@direction'];\n          if(language && direction) {\n            _addPreferredTerm(term, entry['@language'],\n              `${language}_${direction}`.toLowerCase());\n          } else if(language) {\n            _addPreferredTerm(term, entry['@language'], language.toLowerCase());\n          } else if(direction) {\n            _addPreferredTerm(term, entry['@language'], `_${direction}`);\n          } else {\n            _addPreferredTerm(term, entry['@language'], '@null');\n          }\n        } else if('@language' in mapping) {\n          _addPreferredTerm(term, entry['@language'],\n            (mapping['@language'] || '@null').toLowerCase());\n        } else if('@direction' in mapping) {\n          if(mapping['@direction']) {\n            _addPreferredTerm(term, entry['@language'],\n              `_${mapping['@direction']}`);\n          } else {\n            _addPreferredTerm(term, entry['@language'], '@none');\n          }\n        } else if(defaultDirection) {\n          _addPreferredTerm(term, entry['@language'], `_${defaultDirection}`);\n          _addPreferredTerm(term, entry['@language'], '@none');\n          _addPreferredTerm(term, entry['@type'], '@none');\n        } else {\n          // add entries for no type and no language\n          _addPreferredTerm(term, entry['@language'], defaultLanguage);\n          _addPreferredTerm(term, entry['@language'], '@none');\n          _addPreferredTerm(term, entry['@type'], '@none');\n        }\n      }\n    }\n\n    // build fast CURIE map\n    for(const key in fastCurieMap) {\n      _buildIriMap(fastCurieMap, key, 1);\n    }\n\n    return inverse;\n  }\n\n  /**\n   * Runs a recursive algorithm to build a lookup map for quickly finding\n   * potential CURIEs.\n   *\n   * @param iriMap the map to build.\n   * @param key the current key in the map to work on.\n   * @param idx the index into the IRI to compare.\n   */\n  function _buildIriMap(iriMap, key, idx) {\n    const entries = iriMap[key];\n    const next = iriMap[key] = {};\n\n    let iri;\n    let letter;\n    for(const entry of entries) {\n      iri = entry.iri;\n      if(idx >= iri.length) {\n        letter = '';\n      } else {\n        letter = iri[idx];\n      }\n      if(letter in next) {\n        next[letter].push(entry);\n      } else {\n        next[letter] = [entry];\n      }\n    }\n\n    for(const key in next) {\n      if(key === '') {\n        continue;\n      }\n      _buildIriMap(next, key, idx + 1);\n    }\n  }\n\n  /**\n   * Adds the term for the given entry if not already added.\n   *\n   * @param term the term to add.\n   * @param entry the inverse context typeOrLanguage entry to add to.\n   * @param typeOrLanguageValue the key in the entry to add to.\n   */\n  function _addPreferredTerm(term, entry, typeOrLanguageValue) {\n    if(!entry.hasOwnProperty(typeOrLanguageValue)) {\n      entry[typeOrLanguageValue] = term;\n    }\n  }\n\n  /**\n   * Clones an active context, creating a child active context.\n   *\n   * @return a clone (child) of the active context.\n   */\n  function _cloneActiveContext() {\n    const child = {};\n    child.mappings = util.clone(this.mappings);\n    child.clone = this.clone;\n    child.inverse = null;\n    child.getInverse = this.getInverse;\n    child.protected = util.clone(this.protected);\n    if(this.previousContext) {\n      child.previousContext = this.previousContext.clone();\n    }\n    child.revertToPreviousContext = this.revertToPreviousContext;\n    if('@base' in this) {\n      child['@base'] = this['@base'];\n    }\n    if('@language' in this) {\n      child['@language'] = this['@language'];\n    }\n    if('@vocab' in this) {\n      child['@vocab'] = this['@vocab'];\n    }\n    return child;\n  }\n\n  /**\n   * Reverts any type-scoped context in this active context to the previous\n   * context.\n   */\n  function _revertToPreviousContext() {\n    if(!this.previousContext) {\n      return this;\n    }\n    return this.previousContext.clone();\n  }\n};\n\n/**\n * Gets the value for the given active context key and type, null if none is\n * set or undefined if none is set and type is '@context'.\n *\n * @param ctx the active context.\n * @param key the context key.\n * @param [type] the type of value to get (eg: '@id', '@type'), if not\n *          specified gets the entire entry for a key, null if not found.\n *\n * @return the value, null, or undefined.\n */\napi.getContextValue = (ctx, key, type) => {\n  // invalid key\n  if(key === null) {\n    if(type === '@context') {\n      return undefined;\n    }\n    return null;\n  }\n\n  // get specific entry information\n  if(ctx.mappings.has(key)) {\n    const entry = ctx.mappings.get(key);\n\n    if(_isUndefined(type)) {\n      // return whole entry\n      return entry;\n    }\n    if(entry.hasOwnProperty(type)) {\n      // return entry value for type\n      return entry[type];\n    }\n  }\n\n  // get default language\n  if(type === '@language' && type in ctx) {\n    return ctx[type];\n  }\n\n  // get default direction\n  if(type === '@direction' && type in ctx) {\n    return ctx[type];\n  }\n\n  if(type === '@context') {\n    return undefined;\n  }\n  return null;\n};\n\n/**\n * Processing Mode check.\n *\n * @param activeCtx the current active context.\n * @param version the string or numeric version to check.\n *\n * @return boolean.\n */\napi.processingMode = (activeCtx, version) => {\n  if(version.toString() >= '1.1') {\n    return !activeCtx.processingMode ||\n      activeCtx.processingMode >= 'json-ld-' + version.toString();\n  } else {\n    return activeCtx.processingMode === 'json-ld-1.0';\n  }\n};\n\n/**\n * Returns whether or not the given value is a keyword.\n *\n * @param v the value to check.\n *\n * @return true if the value is a keyword, false if not.\n */\napi.isKeyword = v => {\n  if(!_isString(v) || v[0] !== '@') {\n    return false;\n  }\n  switch(v) {\n    case '@base':\n    case '@container':\n    case '@context':\n    case '@default':\n    case '@direction':\n    case '@embed':\n    case '@explicit':\n    case '@graph':\n    case '@id':\n    case '@included':\n    case '@index':\n    case '@json':\n    case '@language':\n    case '@list':\n    case '@nest':\n    case '@none':\n    case '@omitDefault':\n    case '@prefix':\n    case '@preserve':\n    case '@protected':\n    case '@requireAll':\n    case '@reverse':\n    case '@set':\n    case '@type':\n    case '@value':\n    case '@version':\n    case '@vocab':\n      return true;\n  }\n  return false;\n};\n\nfunction _deepCompare(x1, x2) {\n  // compare `null` or primitive types directly\n  if((!(x1 && typeof x1 === 'object')) ||\n     (!(x2 && typeof x2 === 'object'))) {\n    return x1 === x2;\n  }\n  // x1 and x2 are objects (also potentially arrays)\n  const x1Array = Array.isArray(x1);\n  if(x1Array !== Array.isArray(x2)) {\n    return false;\n  }\n  if(x1Array) {\n    if(x1.length !== x2.length) {\n      return false;\n    }\n    for(let i = 0; i < x1.length; ++i) {\n      if(!_deepCompare(x1[i], x2[i])) {\n        return false;\n      }\n    }\n    return true;\n  }\n  // x1 and x2 are non-array objects\n  const k1s = Object.keys(x1);\n  const k2s = Object.keys(x2);\n  if(k1s.length !== k2s.length) {\n    return false;\n  }\n  for(const k1 in x1) {\n    let v1 = x1[k1];\n    let v2 = x2[k1];\n    // special case: `@container` can be in any order\n    if(k1 === '@container') {\n      if(Array.isArray(v1) && Array.isArray(v2)) {\n        v1 = v1.slice().sort();\n        v2 = v2.slice().sort();\n      }\n    }\n    if(!_deepCompare(v1, v2)) {\n      return false;\n    }\n  }\n  return true;\n}\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst JsonLdError = require('./JsonLdError');\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isEmptyObject: _isEmptyObject,\n  isString: _isString,\n  isUndefined: _isUndefined\n} = require('./types');\n\nconst {\n  isList: _isList,\n  isValue: _isValue,\n  isGraph: _isGraph,\n  isSubject: _isSubject\n} = require('./graphTypes');\n\nconst {\n  expandIri: _expandIri,\n  getContextValue: _getContextValue,\n  isKeyword: _isKeyword,\n  process: _processContext,\n  processingMode: _processingMode\n} = require('./context');\n\nconst {\n  isAbsolute: _isAbsoluteIri\n} = require('./url');\n\nconst {\n  addValue: _addValue,\n  asArray: _asArray,\n  getValues: _getValues,\n  validateTypeValue: _validateTypeValue\n} = require('./util');\n\nconst api = {};\nmodule.exports = api;\nconst REGEX_BCP47 = /^[a-zA-Z]{1,8}(-[a-zA-Z0-9]{1,8})*$/;\n\n/**\n * Recursively expands an element using the given context. Any context in\n * the element will be removed. All context URLs must have been retrieved\n * before calling this method.\n *\n * @param activeCtx the context to use.\n * @param activeProperty the property for the element, null for none.\n * @param element the element to expand.\n * @param options the expansion options.\n * @param insideList true if the element is a list, false if not.\n * @param insideIndex true if the element is inside an index container,\n *          false if not.\n * @param typeScopedContext an optional type-scoped active context for\n *          expanding values of nodes that were expressed according to\n *          a type-scoped context.\n * @param expansionMap(info) a function that can be used to custom map\n *          unmappable values (or to throw an error when they are detected);\n *          if this function returns `undefined` then the default behavior\n *          will be used.\n *\n * @return a Promise that resolves to the expanded value.\n */\napi.expand = async ({\n  activeCtx,\n  activeProperty = null,\n  element,\n  options = {},\n  insideList = false,\n  insideIndex = false,\n  typeScopedContext = null,\n  expansionMap = () => undefined\n}) => {\n  // nothing to expand\n  if(element === null || element === undefined) {\n    return null;\n  }\n\n  // disable framing if activeProperty is @default\n  if(activeProperty === '@default') {\n    options = Object.assign({}, options, {isFrame: false});\n  }\n\n  if(!_isArray(element) && !_isObject(element)) {\n    // drop free-floating scalars that are not in lists unless custom mapped\n    if(!insideList && (activeProperty === null ||\n      _expandIri(activeCtx, activeProperty, {vocab: true},\n        options) === '@graph')) {\n      const mapped = await expansionMap({\n        unmappedValue: element,\n        activeCtx,\n        activeProperty,\n        options,\n        insideList\n      });\n      if(mapped === undefined) {\n        return null;\n      }\n      return mapped;\n    }\n\n    // expand element according to value expansion rules\n    return _expandValue({activeCtx, activeProperty, value: element, options});\n  }\n\n  // recursively expand array\n  if(_isArray(element)) {\n    let rval = [];\n    const container = _getContextValue(\n      activeCtx, activeProperty, '@container') || [];\n    insideList = insideList || container.includes('@list');\n    for(let i = 0; i < element.length; ++i) {\n      // expand element\n      let e = await api.expand({\n        activeCtx,\n        activeProperty,\n        element: element[i],\n        options,\n        expansionMap,\n        insideIndex,\n        typeScopedContext\n      });\n      if(insideList && _isArray(e)) {\n        e = {'@list': e};\n      }\n\n      if(e === null) {\n        e = await expansionMap({\n          unmappedValue: element[i],\n          activeCtx,\n          activeProperty,\n          parent: element,\n          index: i,\n          options,\n          expandedParent: rval,\n          insideList\n        });\n        if(e === undefined) {\n          continue;\n        }\n      }\n\n      if(_isArray(e)) {\n        rval = rval.concat(e);\n      } else {\n        rval.push(e);\n      }\n    }\n    return rval;\n  }\n\n  // recursively expand object:\n\n  // first, expand the active property\n  const expandedActiveProperty = _expandIri(\n    activeCtx, activeProperty, {vocab: true}, options);\n\n  // Get any property-scoped context for activeProperty\n  const propertyScopedCtx =\n    _getContextValue(activeCtx, activeProperty, '@context');\n\n  // second, determine if any type-scoped context should be reverted; it\n  // should only be reverted when the following are all true:\n  // 1. `element` is not a value or subject reference\n  // 2. `insideIndex` is false\n  typeScopedContext = typeScopedContext ||\n    (activeCtx.previousContext ? activeCtx : null);\n  let keys = Object.keys(element).sort();\n  let mustRevert = !insideIndex;\n  if(mustRevert && typeScopedContext && keys.length <= 2 &&\n    !keys.includes('@context')) {\n    for(const key of keys) {\n      const expandedProperty = _expandIri(\n        typeScopedContext, key, {vocab: true}, options);\n      if(expandedProperty === '@value') {\n        // value found, ensure type-scoped context is used to expand it\n        mustRevert = false;\n        activeCtx = typeScopedContext;\n        break;\n      }\n      if(expandedProperty === '@id' && keys.length === 1) {\n        // subject reference found, do not revert\n        mustRevert = false;\n        break;\n      }\n    }\n  }\n\n  if(mustRevert) {\n    // revert type scoped context\n    activeCtx = activeCtx.revertToPreviousContext();\n  }\n\n  // apply property-scoped context after reverting term-scoped context\n  if(!_isUndefined(propertyScopedCtx)) {\n    activeCtx = await _processContext({\n      activeCtx,\n      localCtx: propertyScopedCtx,\n      propagate: true,\n      overrideProtected: true,\n      options\n    });\n  }\n\n  // if element has a context, process it\n  if('@context' in element) {\n    activeCtx = await _processContext(\n      {activeCtx, localCtx: element['@context'], options});\n  }\n\n  // set the type-scoped context to the context on input, for use later\n  typeScopedContext = activeCtx;\n\n  // Remember the first key found expanding to @type\n  let typeKey = null;\n\n  // look for scoped contexts on `@type`\n  for(const key of keys) {\n    const expandedProperty = _expandIri(activeCtx, key, {vocab: true}, options);\n    if(expandedProperty === '@type') {\n      // set scoped contexts from @type\n      // avoid sorting if possible\n      typeKey = typeKey || key;\n      const value = element[key];\n      const types =\n        Array.isArray(value) ?\n          (value.length > 1 ? value.slice().sort() : value) : [value];\n      for(const type of types) {\n        const ctx = _getContextValue(typeScopedContext, type, '@context');\n        if(!_isUndefined(ctx)) {\n          activeCtx = await _processContext({\n            activeCtx,\n            localCtx: ctx,\n            options,\n            propagate: false\n          });\n        }\n      }\n    }\n  }\n\n  // process each key and value in element, ignoring @nest content\n  let rval = {};\n  await _expandObject({\n    activeCtx,\n    activeProperty,\n    expandedActiveProperty,\n    element,\n    expandedParent: rval,\n    options,\n    insideList,\n    typeKey,\n    typeScopedContext,\n    expansionMap});\n\n  // get property count on expanded output\n  keys = Object.keys(rval);\n  let count = keys.length;\n\n  if('@value' in rval) {\n    // @value must only have @language or @type\n    if('@type' in rval && ('@language' in rval || '@direction' in rval)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an element containing \"@value\" may not ' +\n        'contain both \"@type\" and either \"@language\" or \"@direction\".',\n        'jsonld.SyntaxError', {code: 'invalid value object', element: rval});\n    }\n    let validCount = count - 1;\n    if('@type' in rval) {\n      validCount -= 1;\n    }\n    if('@index' in rval) {\n      validCount -= 1;\n    }\n    if('@language' in rval) {\n      validCount -= 1;\n    }\n    if('@direction' in rval) {\n      validCount -= 1;\n    }\n    if(validCount !== 0) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an element containing \"@value\" may only ' +\n        'have an \"@index\" property and either \"@type\" ' +\n        'or either or both \"@language\" or \"@direction\".',\n        'jsonld.SyntaxError', {code: 'invalid value object', element: rval});\n    }\n    const values = rval['@value'] === null ? [] : _asArray(rval['@value']);\n    const types = _getValues(rval, '@type');\n\n    // drop null @values unless custom mapped\n    if(_processingMode(activeCtx, 1.1) && types.includes('@json') &&\n      types.length === 1) {\n      // Any value of @value is okay if @type: @json\n    } else if(values.length === 0) {\n      const mapped = await expansionMap({\n        unmappedValue: rval,\n        activeCtx,\n        activeProperty,\n        element,\n        options,\n        insideList\n      });\n      if(mapped !== undefined) {\n        rval = mapped;\n      } else {\n        rval = null;\n      }\n    } else if(!values.every(v => (_isString(v) || _isEmptyObject(v))) &&\n      '@language' in rval) {\n      // if @language is present, @value must be a string\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; only strings may be language-tagged.',\n        'jsonld.SyntaxError',\n        {code: 'invalid language-tagged value', element: rval});\n    } else if(!types.every(t =>\n      (_isAbsoluteIri(t) && !(_isString(t) && t.indexOf('_:') === 0) ||\n      _isEmptyObject(t)))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an element containing \"@value\" and \"@type\" ' +\n        'must have an absolute IRI for the value of \"@type\".',\n        'jsonld.SyntaxError', {code: 'invalid typed value', element: rval});\n    }\n  } else if('@type' in rval && !_isArray(rval['@type'])) {\n    // convert @type to an array\n    rval['@type'] = [rval['@type']];\n  } else if('@set' in rval || '@list' in rval) {\n    // handle @set and @list\n    if(count > 1 && !(count === 2 && '@index' in rval)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; if an element has the property \"@set\" ' +\n        'or \"@list\", then it can have at most one other property that is ' +\n        '\"@index\".', 'jsonld.SyntaxError',\n        {code: 'invalid set or list object', element: rval});\n    }\n    // optimize away @set\n    if('@set' in rval) {\n      rval = rval['@set'];\n      keys = Object.keys(rval);\n      count = keys.length;\n    }\n  } else if(count === 1 && '@language' in rval) {\n    // drop objects with only @language unless custom mapped\n    const mapped = await expansionMap(rval, {\n      unmappedValue: rval,\n      activeCtx,\n      activeProperty,\n      element,\n      options,\n      insideList\n    });\n    if(mapped !== undefined) {\n      rval = mapped;\n    } else {\n      rval = null;\n    }\n  }\n\n  // drop certain top-level objects that do not occur in lists, unless custom\n  // mapped\n  if(_isObject(rval) &&\n    !options.keepFreeFloatingNodes && !insideList &&\n    (activeProperty === null || expandedActiveProperty === '@graph')) {\n    // drop empty object, top-level @value/@list, or object with only @id\n    if(count === 0 || '@value' in rval || '@list' in rval ||\n      (count === 1 && '@id' in rval)) {\n      const mapped = await expansionMap({\n        unmappedValue: rval,\n        activeCtx,\n        activeProperty,\n        element,\n        options,\n        insideList\n      });\n      if(mapped !== undefined) {\n        rval = mapped;\n      } else {\n        rval = null;\n      }\n    }\n  }\n\n  return rval;\n};\n\n/**\n * Expand each key and value of element adding to result\n *\n * @param activeCtx the context to use.\n * @param activeProperty the property for the element.\n * @param expandedActiveProperty the expansion of activeProperty\n * @param element the element to expand.\n * @param expandedParent the expanded result into which to add values.\n * @param options the expansion options.\n * @param insideList true if the element is a list, false if not.\n * @param typeKey first key found expanding to @type.\n * @param typeScopedContext the context before reverting.\n * @param expansionMap(info) a function that can be used to custom map\n *          unmappable values (or to throw an error when they are detected);\n *          if this function returns `undefined` then the default behavior\n *          will be used.\n */\nasync function _expandObject({\n  activeCtx,\n  activeProperty,\n  expandedActiveProperty,\n  element,\n  expandedParent,\n  options = {},\n  insideList,\n  typeKey,\n  typeScopedContext,\n  expansionMap\n}) {\n  const keys = Object.keys(element).sort();\n  const nests = [];\n  let unexpandedValue;\n\n  // Figure out if this is the type for a JSON literal\n  const isJsonType = element[typeKey] &&\n    _expandIri(activeCtx,\n      (_isArray(element[typeKey]) ? element[typeKey][0] : element[typeKey]),\n      {vocab: true}, options) === '@json';\n\n  for(const key of keys) {\n    let value = element[key];\n    let expandedValue;\n\n    // skip @context\n    if(key === '@context') {\n      continue;\n    }\n\n    // expand property\n    let expandedProperty = _expandIri(activeCtx, key, {vocab: true}, options);\n\n    // drop non-absolute IRI keys that aren't keywords unless custom mapped\n    if(expandedProperty === null ||\n      !(_isAbsoluteIri(expandedProperty) || _isKeyword(expandedProperty))) {\n      // TODO: use `await` to support async\n      expandedProperty = expansionMap({\n        unmappedProperty: key,\n        activeCtx,\n        activeProperty,\n        parent: element,\n        options,\n        insideList,\n        value,\n        expandedParent\n      });\n      if(expandedProperty === undefined) {\n        continue;\n      }\n    }\n\n    if(_isKeyword(expandedProperty)) {\n      if(expandedActiveProperty === '@reverse') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; a keyword cannot be used as a @reverse ' +\n          'property.', 'jsonld.SyntaxError',\n          {code: 'invalid reverse property map', value});\n      }\n      if(expandedProperty in expandedParent &&\n         expandedProperty !== '@included' &&\n         expandedProperty !== '@type') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; colliding keywords detected.',\n          'jsonld.SyntaxError',\n          {code: 'colliding keywords', keyword: expandedProperty});\n      }\n    }\n\n    // syntax error if @id is not a string\n    if(expandedProperty === '@id') {\n      if(!_isString(value)) {\n        if(!options.isFrame) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; \"@id\" value must a string.',\n            'jsonld.SyntaxError', {code: 'invalid @id value', value});\n        }\n        if(_isObject(value)) {\n          // empty object is a wildcard\n          if(!_isEmptyObject(value)) {\n            throw new JsonLdError(\n              'Invalid JSON-LD syntax; \"@id\" value an empty object or array ' +\n              'of strings, if framing',\n              'jsonld.SyntaxError', {code: 'invalid @id value', value});\n          }\n        } else if(_isArray(value)) {\n          if(!value.every(v => _isString(v))) {\n            throw new JsonLdError(\n              'Invalid JSON-LD syntax; \"@id\" value an empty object or array ' +\n              'of strings, if framing',\n              'jsonld.SyntaxError', {code: 'invalid @id value', value});\n          }\n        } else {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; \"@id\" value an empty object or array ' +\n            'of strings, if framing',\n            'jsonld.SyntaxError', {code: 'invalid @id value', value});\n        }\n      }\n\n      _addValue(\n        expandedParent, '@id',\n        _asArray(value).map(v =>\n          _isString(v) ? _expandIri(activeCtx, v, {base: true}, options) : v),\n        {propertyIsArray: options.isFrame});\n      continue;\n    }\n\n    if(expandedProperty === '@type') {\n      // if framing, can be a default object, but need to expand\n      // key to determine that\n      if(_isObject(value)) {\n        value = Object.fromEntries(Object.entries(value).map(([k, v]) => [\n          _expandIri(typeScopedContext, k, {vocab: true}),\n          _asArray(v).map(vv =>\n            _expandIri(typeScopedContext, vv, {base: true, vocab: true})\n          )\n        ]));\n      }\n      _validateTypeValue(value, options.isFrame);\n      _addValue(\n        expandedParent, '@type',\n        _asArray(value).map(v =>\n          _isString(v) ?\n            _expandIri(typeScopedContext, v,\n              {base: true, vocab: true}, options) : v),\n        {propertyIsArray: options.isFrame});\n      continue;\n    }\n\n    // Included blocks are treated as an array of separate object nodes sharing\n    // the same referencing active_property.\n    // For 1.0, it is skipped as are other unknown keywords\n    if(expandedProperty === '@included' && _processingMode(activeCtx, 1.1)) {\n      const includedResult = _asArray(await api.expand({\n        activeCtx,\n        activeProperty,\n        element: value,\n        options,\n        expansionMap\n      }));\n\n      // Expanded values must be node objects\n      if(!includedResult.every(v => _isSubject(v))) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; ' +\n          'values of @included must expand to node objects.',\n          'jsonld.SyntaxError', {code: 'invalid @included value', value});\n      }\n\n      _addValue(\n        expandedParent, '@included', includedResult, {propertyIsArray: true});\n      continue;\n    }\n\n    // @graph must be an array or an object\n    if(expandedProperty === '@graph' &&\n      !(_isObject(value) || _isArray(value))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; \"@graph\" value must not be an ' +\n        'object or an array.',\n        'jsonld.SyntaxError', {code: 'invalid @graph value', value});\n    }\n\n    if(expandedProperty === '@value') {\n      // capture value for later\n      // \"colliding keywords\" check prevents this from being set twice\n      unexpandedValue = value;\n      if(isJsonType && _processingMode(activeCtx, 1.1)) {\n        // no coercion to array, and retain all values\n        expandedParent['@value'] = value;\n      } else {\n        _addValue(\n          expandedParent, '@value', value, {propertyIsArray: options.isFrame});\n      }\n      continue;\n    }\n\n    // @language must be a string\n    // it should match BCP47\n    if(expandedProperty === '@language') {\n      if(value === null) {\n        // drop null @language values, they expand as if they didn't exist\n        continue;\n      }\n      if(!_isString(value) && !options.isFrame) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@language\" value must be a string.',\n          'jsonld.SyntaxError',\n          {code: 'invalid language-tagged string', value});\n      }\n      // ensure language value is lowercase\n      value = _asArray(value).map(v => _isString(v) ? v.toLowerCase() : v);\n\n      // ensure language tag matches BCP47\n      for(const lang of value) {\n        if(_isString(lang) && !lang.match(REGEX_BCP47)) {\n          console.warn(`@language must be valid BCP47: ${lang}`);\n        }\n      }\n\n      _addValue(\n        expandedParent, '@language', value, {propertyIsArray: options.isFrame});\n      continue;\n    }\n\n    // @direction must be \"ltr\" or \"rtl\"\n    if(expandedProperty === '@direction') {\n      if(!_isString(value) && !options.isFrame) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@direction\" value must be a string.',\n          'jsonld.SyntaxError',\n          {code: 'invalid base direction', value});\n      }\n\n      value = _asArray(value);\n\n      // ensure direction is \"ltr\" or \"rtl\"\n      for(const dir of value) {\n        if(_isString(dir) && dir !== 'ltr' && dir !== 'rtl') {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; \"@direction\" must be \"ltr\" or \"rtl\".',\n            'jsonld.SyntaxError',\n            {code: 'invalid base direction', value});\n        }\n      }\n\n      _addValue(\n        expandedParent, '@direction', value,\n        {propertyIsArray: options.isFrame});\n      continue;\n    }\n\n    // @index must be a string\n    if(expandedProperty === '@index') {\n      if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@index\" value must be a string.',\n          'jsonld.SyntaxError',\n          {code: 'invalid @index value', value});\n      }\n      _addValue(expandedParent, '@index', value);\n      continue;\n    }\n\n    // @reverse must be an object\n    if(expandedProperty === '@reverse') {\n      if(!_isObject(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@reverse\" value must be an object.',\n          'jsonld.SyntaxError', {code: 'invalid @reverse value', value});\n      }\n\n      expandedValue = await api.expand({\n        activeCtx,\n        activeProperty:\n        '@reverse',\n        element: value,\n        options,\n        expansionMap\n      });\n      // properties double-reversed\n      if('@reverse' in expandedValue) {\n        for(const property in expandedValue['@reverse']) {\n          _addValue(\n            expandedParent, property, expandedValue['@reverse'][property],\n            {propertyIsArray: true});\n        }\n      }\n\n      // FIXME: can this be merged with code below to simplify?\n      // merge in all reversed properties\n      let reverseMap = expandedParent['@reverse'] || null;\n      for(const property in expandedValue) {\n        if(property === '@reverse') {\n          continue;\n        }\n        if(reverseMap === null) {\n          reverseMap = expandedParent['@reverse'] = {};\n        }\n        _addValue(reverseMap, property, [], {propertyIsArray: true});\n        const items = expandedValue[property];\n        for(let ii = 0; ii < items.length; ++ii) {\n          const item = items[ii];\n          if(_isValue(item) || _isList(item)) {\n            throw new JsonLdError(\n              'Invalid JSON-LD syntax; \"@reverse\" value must not be a ' +\n              '@value or an @list.', 'jsonld.SyntaxError',\n              {code: 'invalid reverse property value', value: expandedValue});\n          }\n          _addValue(reverseMap, property, item, {propertyIsArray: true});\n        }\n      }\n\n      continue;\n    }\n\n    // nested keys\n    if(expandedProperty === '@nest') {\n      nests.push(key);\n      continue;\n    }\n\n    // use potential scoped context for key\n    let termCtx = activeCtx;\n    const ctx = _getContextValue(activeCtx, key, '@context');\n    if(!_isUndefined(ctx)) {\n      termCtx = await _processContext({\n        activeCtx,\n        localCtx: ctx,\n        propagate: true,\n        overrideProtected: true,\n        options\n      });\n    }\n\n    const container = _getContextValue(termCtx, key, '@container') || [];\n\n    if(container.includes('@language') && _isObject(value)) {\n      const direction = _getContextValue(termCtx, key, '@direction');\n      // handle language map container (skip if value is not an object)\n      expandedValue = _expandLanguageMap(termCtx, value, direction, options);\n    } else if(container.includes('@index') && _isObject(value)) {\n      // handle index container (skip if value is not an object)\n      const asGraph = container.includes('@graph');\n      const indexKey = _getContextValue(termCtx, key, '@index') || '@index';\n      const propertyIndex = indexKey !== '@index' &&\n        _expandIri(activeCtx, indexKey, {vocab: true}, options);\n\n      expandedValue = await _expandIndexMap({\n        activeCtx: termCtx,\n        options,\n        activeProperty: key,\n        value,\n        expansionMap,\n        asGraph,\n        indexKey,\n        propertyIndex\n      });\n    } else if(container.includes('@id') && _isObject(value)) {\n      // handle id container (skip if value is not an object)\n      const asGraph = container.includes('@graph');\n      expandedValue = await _expandIndexMap({\n        activeCtx: termCtx,\n        options,\n        activeProperty: key,\n        value,\n        expansionMap,\n        asGraph,\n        indexKey: '@id'\n      });\n    } else if(container.includes('@type') && _isObject(value)) {\n      // handle type container (skip if value is not an object)\n      expandedValue = await _expandIndexMap({\n        // since container is `@type`, revert type scoped context when expanding\n        activeCtx: termCtx.revertToPreviousContext(),\n        options,\n        activeProperty: key,\n        value,\n        expansionMap,\n        asGraph: false,\n        indexKey: '@type'\n      });\n    } else {\n      // recurse into @list or @set\n      const isList = (expandedProperty === '@list');\n      if(isList || expandedProperty === '@set') {\n        let nextActiveProperty = activeProperty;\n        if(isList && expandedActiveProperty === '@graph') {\n          nextActiveProperty = null;\n        }\n        expandedValue = await api.expand({\n          activeCtx: termCtx,\n          activeProperty: nextActiveProperty,\n          element: value,\n          options,\n          insideList: isList,\n          expansionMap\n        });\n      } else if(\n        _getContextValue(activeCtx, key, '@type') === '@json') {\n        expandedValue = {\n          '@type': '@json',\n          '@value': value\n        };\n      } else {\n        // recursively expand value with key as new active property\n        expandedValue = await api.expand({\n          activeCtx: termCtx,\n          activeProperty: key,\n          element: value,\n          options,\n          insideList: false,\n          expansionMap\n        });\n      }\n    }\n\n    // drop null values if property is not @value\n    if(expandedValue === null && expandedProperty !== '@value') {\n      // TODO: use `await` to support async\n      expandedValue = expansionMap({\n        unmappedValue: value,\n        expandedProperty,\n        activeCtx: termCtx,\n        activeProperty,\n        parent: element,\n        options,\n        insideList,\n        key,\n        expandedParent\n      });\n      if(expandedValue === undefined) {\n        continue;\n      }\n    }\n\n    // convert expanded value to @list if container specifies it\n    if(expandedProperty !== '@list' && !_isList(expandedValue) &&\n      container.includes('@list')) {\n      // ensure expanded value in @list is an array\n      expandedValue = {'@list': _asArray(expandedValue)};\n    }\n\n    // convert expanded value to @graph if container specifies it\n    // and value is not, itself, a graph\n    // index cases handled above\n    if(container.includes('@graph') &&\n      !container.some(key => key === '@id' || key === '@index')) {\n      // ensure expanded values are arrays\n      expandedValue = _asArray(expandedValue)\n        .map(v => ({'@graph': _asArray(v)}));\n    }\n\n    // FIXME: can this be merged with code above to simplify?\n    // merge in reverse properties\n    if(termCtx.mappings.has(key) && termCtx.mappings.get(key).reverse) {\n      const reverseMap =\n        expandedParent['@reverse'] = expandedParent['@reverse'] || {};\n      expandedValue = _asArray(expandedValue);\n      for(let ii = 0; ii < expandedValue.length; ++ii) {\n        const item = expandedValue[ii];\n        if(_isValue(item) || _isList(item)) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; \"@reverse\" value must not be a ' +\n            '@value or an @list.', 'jsonld.SyntaxError',\n            {code: 'invalid reverse property value', value: expandedValue});\n        }\n        _addValue(reverseMap, expandedProperty, item, {propertyIsArray: true});\n      }\n      continue;\n    }\n\n    // add value for property\n    // special keywords handled above\n    _addValue(expandedParent, expandedProperty, expandedValue, {\n      propertyIsArray: true\n    });\n  }\n\n  // @value must not be an object or an array (unless framing) or if @type is\n  // @json\n  if('@value' in expandedParent) {\n    if(expandedParent['@type'] === '@json' && _processingMode(activeCtx, 1.1)) {\n      // allow any value, to be verified when the object is fully expanded and\n      // the @type is @json.\n    } else if((_isObject(unexpandedValue) || _isArray(unexpandedValue)) &&\n      !options.isFrame) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; \"@value\" value must not be an ' +\n        'object or an array.',\n        'jsonld.SyntaxError',\n        {code: 'invalid value object value', value: unexpandedValue});\n    }\n  }\n\n  // expand each nested key\n  for(const key of nests) {\n    const nestedValues = _isArray(element[key]) ? element[key] : [element[key]];\n    for(const nv of nestedValues) {\n      if(!_isObject(nv) || Object.keys(nv).some(k =>\n        _expandIri(activeCtx, k, {vocab: true}, options) === '@value')) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; nested value must be a node object.',\n          'jsonld.SyntaxError',\n          {code: 'invalid @nest value', value: nv});\n      }\n      await _expandObject({\n        activeCtx,\n        activeProperty,\n        expandedActiveProperty,\n        element: nv,\n        expandedParent,\n        options,\n        insideList,\n        typeScopedContext,\n        typeKey,\n        expansionMap});\n    }\n  }\n}\n\n/**\n * Expands the given value by using the coercion and keyword rules in the\n * given context.\n *\n * @param activeCtx the active context to use.\n * @param activeProperty the active property the value is associated with.\n * @param value the value to expand.\n * @param {Object} [options] - processing options.\n *\n * @return the expanded value.\n */\nfunction _expandValue({activeCtx, activeProperty, value, options}) {\n  // nothing to expand\n  if(value === null || value === undefined) {\n    return null;\n  }\n\n  // special-case expand @id and @type (skips '@id' expansion)\n  const expandedProperty = _expandIri(\n    activeCtx, activeProperty, {vocab: true}, options);\n  if(expandedProperty === '@id') {\n    return _expandIri(activeCtx, value, {base: true}, options);\n  } else if(expandedProperty === '@type') {\n    return _expandIri(activeCtx, value, {vocab: true, base: true}, options);\n  }\n\n  // get type definition from context\n  const type = _getContextValue(activeCtx, activeProperty, '@type');\n\n  // do @id expansion (automatic for @graph)\n  if((type === '@id' || expandedProperty === '@graph') && _isString(value)) {\n    return {'@id': _expandIri(activeCtx, value, {base: true}, options)};\n  }\n  // do @id expansion w/vocab\n  if(type === '@vocab' && _isString(value)) {\n    return {\n      '@id': _expandIri(activeCtx, value, {vocab: true, base: true}, options)\n    };\n  }\n\n  // do not expand keyword values\n  if(_isKeyword(expandedProperty)) {\n    return value;\n  }\n\n  const rval = {};\n\n  if(type && !['@id', '@vocab', '@none'].includes(type)) {\n    // other type\n    rval['@type'] = type;\n  } else if(_isString(value)) {\n    // check for language tagging for strings\n    const language = _getContextValue(activeCtx, activeProperty, '@language');\n    if(language !== null) {\n      rval['@language'] = language;\n    }\n    const direction = _getContextValue(activeCtx, activeProperty, '@direction');\n    if(direction !== null) {\n      rval['@direction'] = direction;\n    }\n  }\n  // do conversion of values that aren't basic JSON types to strings\n  if(!['boolean', 'number', 'string'].includes(typeof value)) {\n    value = value.toString();\n  }\n  rval['@value'] = value;\n\n  return rval;\n}\n\n/**\n * Expands a language map.\n *\n * @param activeCtx the active context to use.\n * @param languageMap the language map to expand.\n * @param direction the direction to apply to values.\n * @param {Object} [options] - processing options.\n *\n * @return the expanded language map.\n */\nfunction _expandLanguageMap(activeCtx, languageMap, direction, options) {\n  const rval = [];\n  const keys = Object.keys(languageMap).sort();\n  for(const key of keys) {\n    const expandedKey = _expandIri(activeCtx, key, {vocab: true}, options);\n    let val = languageMap[key];\n    if(!_isArray(val)) {\n      val = [val];\n    }\n    for(const item of val) {\n      if(item === null) {\n        // null values are allowed (8.5) but ignored (3.1)\n        continue;\n      }\n      if(!_isString(item)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; language map values must be strings.',\n          'jsonld.SyntaxError',\n          {code: 'invalid language map value', languageMap});\n      }\n      const val = {'@value': item};\n      if(expandedKey !== '@none') {\n        val['@language'] = key.toLowerCase();\n      }\n      if(direction) {\n        val['@direction'] = direction;\n      }\n      rval.push(val);\n    }\n  }\n  return rval;\n}\n\nasync function _expandIndexMap(\n  {activeCtx, options, activeProperty, value, expansionMap, asGraph,\n    indexKey, propertyIndex}) {\n  const rval = [];\n  const keys = Object.keys(value).sort();\n  const isTypeIndex = indexKey === '@type';\n  for(let key of keys) {\n    // if indexKey is @type, there may be a context defined for it\n    if(isTypeIndex) {\n      const ctx = _getContextValue(activeCtx, key, '@context');\n      if(!_isUndefined(ctx)) {\n        activeCtx = await _processContext({\n          activeCtx,\n          localCtx: ctx,\n          propagate: false,\n          options\n        });\n      }\n    }\n\n    let val = value[key];\n    if(!_isArray(val)) {\n      val = [val];\n    }\n\n    val = await api.expand({\n      activeCtx,\n      activeProperty,\n      element: val,\n      options,\n      insideList: false,\n      insideIndex: true,\n      expansionMap\n    });\n\n    // expand for @type, but also for @none\n    let expandedKey;\n    if(propertyIndex) {\n      if(key === '@none') {\n        expandedKey = '@none';\n      } else {\n        expandedKey = _expandValue(\n          {activeCtx, activeProperty: indexKey, value: key, options});\n      }\n    } else {\n      expandedKey = _expandIri(activeCtx, key, {vocab: true}, options);\n    }\n\n    if(indexKey === '@id') {\n      // expand document relative\n      key = _expandIri(activeCtx, key, {base: true}, options);\n    } else if(isTypeIndex) {\n      key = expandedKey;\n    }\n\n    for(let item of val) {\n      // If this is also a @graph container, turn items into graphs\n      if(asGraph && !_isGraph(item)) {\n        item = {'@graph': [item]};\n      }\n      if(indexKey === '@type') {\n        if(expandedKey === '@none') {\n          // ignore @none\n        } else if(item['@type']) {\n          item['@type'] = [key].concat(item['@type']);\n        } else {\n          item['@type'] = [key];\n        }\n      } else if(_isValue(item) &&\n        !['@language', '@type', '@index'].includes(indexKey)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; Attempt to add illegal key to value ' +\n          `object: \"${indexKey}\".`,\n          'jsonld.SyntaxError',\n          {code: 'invalid value object', value: item});\n      } else if(propertyIndex) {\n        // index is a property to be expanded, and values interpreted for that\n        // property\n        if(expandedKey !== '@none') {\n          // expand key as a value\n          _addValue(item, propertyIndex, expandedKey, {\n            propertyIsArray: true,\n            prependValue: true\n          });\n        }\n      } else if(expandedKey !== '@none' && !(indexKey in item)) {\n        item[indexKey] = key;\n      }\n      rval.push(item);\n    }\n  }\n  return rval;\n}\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst {isKeyword} = require('./context');\nconst graphTypes = require('./graphTypes');\nconst types = require('./types');\nconst util = require('./util');\nconst JsonLdError = require('./JsonLdError');\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Creates a merged JSON-LD node map (node ID => node).\n *\n * @param input the expanded JSON-LD to create a node map of.\n * @param [options] the options to use:\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *\n * @return the node map.\n */\napi.createMergedNodeMap = (input, options) => {\n  options = options || {};\n\n  // produce a map of all subjects and name each bnode\n  const issuer = options.issuer || new util.IdentifierIssuer('_:b');\n  const graphs = {'@default': {}};\n  api.createNodeMap(input, graphs, '@default', issuer);\n\n  // add all non-default graphs to default graph\n  return api.mergeNodeMaps(graphs);\n};\n\n/**\n * Recursively flattens the subjects in the given JSON-LD expanded input\n * into a node map.\n *\n * @param input the JSON-LD expanded input.\n * @param graphs a map of graph name to subject map.\n * @param graph the name of the current graph.\n * @param issuer the blank node identifier issuer.\n * @param name the name assigned to the current input if it is a bnode.\n * @param list the list to append to, null for none.\n */\napi.createNodeMap = (input, graphs, graph, issuer, name, list) => {\n  // recurse through array\n  if(types.isArray(input)) {\n    for(const node of input) {\n      api.createNodeMap(node, graphs, graph, issuer, undefined, list);\n    }\n    return;\n  }\n\n  // add non-object to list\n  if(!types.isObject(input)) {\n    if(list) {\n      list.push(input);\n    }\n    return;\n  }\n\n  // add values to list\n  if(graphTypes.isValue(input)) {\n    if('@type' in input) {\n      let type = input['@type'];\n      // rename @type blank node\n      if(type.indexOf('_:') === 0) {\n        input['@type'] = type = issuer.getId(type);\n      }\n    }\n    if(list) {\n      list.push(input);\n    }\n    return;\n  } else if(list && graphTypes.isList(input)) {\n    const _list = [];\n    api.createNodeMap(input['@list'], graphs, graph, issuer, name, _list);\n    list.push({'@list': _list});\n    return;\n  }\n\n  // Note: At this point, input must be a subject.\n\n  // spec requires @type to be named first, so assign names early\n  if('@type' in input) {\n    const types = input['@type'];\n    for(const type of types) {\n      if(type.indexOf('_:') === 0) {\n        issuer.getId(type);\n      }\n    }\n  }\n\n  // get name for subject\n  if(types.isUndefined(name)) {\n    name = graphTypes.isBlankNode(input) ?\n      issuer.getId(input['@id']) : input['@id'];\n  }\n\n  // add subject reference to list\n  if(list) {\n    list.push({'@id': name});\n  }\n\n  // create new subject or merge into existing one\n  const subjects = graphs[graph];\n  const subject = subjects[name] = subjects[name] || {};\n  subject['@id'] = name;\n  const properties = Object.keys(input).sort();\n  for(let property of properties) {\n    // skip @id\n    if(property === '@id') {\n      continue;\n    }\n\n    // handle reverse properties\n    if(property === '@reverse') {\n      const referencedNode = {'@id': name};\n      const reverseMap = input['@reverse'];\n      for(const reverseProperty in reverseMap) {\n        const items = reverseMap[reverseProperty];\n        for(const item of items) {\n          let itemName = item['@id'];\n          if(graphTypes.isBlankNode(item)) {\n            itemName = issuer.getId(itemName);\n          }\n          api.createNodeMap(item, graphs, graph, issuer, itemName);\n          util.addValue(\n            subjects[itemName], reverseProperty, referencedNode,\n            {propertyIsArray: true, allowDuplicate: false});\n        }\n      }\n      continue;\n    }\n\n    // recurse into graph\n    if(property === '@graph') {\n      // add graph subjects map entry\n      if(!(name in graphs)) {\n        graphs[name] = {};\n      }\n      api.createNodeMap(input[property], graphs, name, issuer);\n      continue;\n    }\n\n    // recurse into included\n    if(property === '@included') {\n      api.createNodeMap(input[property], graphs, graph, issuer);\n      continue;\n    }\n\n    // copy non-@type keywords\n    if(property !== '@type' && isKeyword(property)) {\n      if(property === '@index' && property in subject &&\n        (input[property] !== subject[property] ||\n        input[property]['@id'] !== subject[property]['@id'])) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; conflicting @index property detected.',\n          'jsonld.SyntaxError',\n          {code: 'conflicting indexes', subject});\n      }\n      subject[property] = input[property];\n      continue;\n    }\n\n    // iterate over objects\n    const objects = input[property];\n\n    // if property is a bnode, assign it a new id\n    if(property.indexOf('_:') === 0) {\n      property = issuer.getId(property);\n    }\n\n    // ensure property is added for empty arrays\n    if(objects.length === 0) {\n      util.addValue(subject, property, [], {propertyIsArray: true});\n      continue;\n    }\n    for(let o of objects) {\n      if(property === '@type') {\n        // rename @type blank nodes\n        o = (o.indexOf('_:') === 0) ? issuer.getId(o) : o;\n      }\n\n      // handle embedded subject or subject reference\n      if(graphTypes.isSubject(o) || graphTypes.isSubjectReference(o)) {\n        // skip null @id\n        if('@id' in o && !o['@id']) {\n          continue;\n        }\n\n        // relabel blank node @id\n        const id = graphTypes.isBlankNode(o) ?\n          issuer.getId(o['@id']) : o['@id'];\n\n        // add reference and recurse\n        util.addValue(\n          subject, property, {'@id': id},\n          {propertyIsArray: true, allowDuplicate: false});\n        api.createNodeMap(o, graphs, graph, issuer, id);\n      } else if(graphTypes.isValue(o)) {\n        util.addValue(\n          subject, property, o,\n          {propertyIsArray: true, allowDuplicate: false});\n      } else if(graphTypes.isList(o)) {\n        // handle @list\n        const _list = [];\n        api.createNodeMap(o['@list'], graphs, graph, issuer, name, _list);\n        o = {'@list': _list};\n        util.addValue(\n          subject, property, o,\n          {propertyIsArray: true, allowDuplicate: false});\n      } else {\n        // handle @value\n        api.createNodeMap(o, graphs, graph, issuer, name);\n        util.addValue(\n          subject, property, o, {propertyIsArray: true, allowDuplicate: false});\n      }\n    }\n  }\n};\n\n/**\n * Merge separate named graphs into a single merged graph including\n * all nodes from the default graph and named graphs.\n *\n * @param graphs a map of graph name to subject map.\n *\n * @return the merged graph map.\n */\napi.mergeNodeMapGraphs = graphs => {\n  const merged = {};\n  for(const name of Object.keys(graphs).sort()) {\n    for(const id of Object.keys(graphs[name]).sort()) {\n      const node = graphs[name][id];\n      if(!(id in merged)) {\n        merged[id] = {'@id': id};\n      }\n      const mergedNode = merged[id];\n\n      for(const property of Object.keys(node).sort()) {\n        if(isKeyword(property) && property !== '@type') {\n          // copy keywords\n          mergedNode[property] = util.clone(node[property]);\n        } else {\n          // merge objects\n          for(const value of node[property]) {\n            util.addValue(\n              mergedNode, property, util.clone(value),\n              {propertyIsArray: true, allowDuplicate: false});\n          }\n        }\n      }\n    }\n  }\n\n  return merged;\n};\n\napi.mergeNodeMaps = graphs => {\n  // add all non-default graphs to default graph\n  const defaultGraph = graphs['@default'];\n  const graphNames = Object.keys(graphs).sort();\n  for(const graphName of graphNames) {\n    if(graphName === '@default') {\n      continue;\n    }\n    const nodeMap = graphs[graphName];\n    let subject = defaultGraph[graphName];\n    if(!subject) {\n      defaultGraph[graphName] = subject = {\n        '@id': graphName,\n        '@graph': []\n      };\n    } else if(!('@graph' in subject)) {\n      subject['@graph'] = [];\n    }\n    const graph = subject['@graph'];\n    for(const id of Object.keys(nodeMap).sort()) {\n      const node = nodeMap[id];\n      // only add full subjects\n      if(!graphTypes.isSubjectReference(node)) {\n        graph.push(node);\n      }\n    }\n  }\n  return defaultGraph;\n};\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst {\n  isSubjectReference: _isSubjectReference\n} = require('./graphTypes');\n\nconst {\n  createMergedNodeMap: _createMergedNodeMap\n} = require('./nodeMap');\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Performs JSON-LD flattening.\n *\n * @param input the expanded JSON-LD to flatten.\n *\n * @return the flattened output.\n */\napi.flatten = input => {\n  const defaultGraph = _createMergedNodeMap(input);\n\n  // produce flattened output\n  const flattened = [];\n  const keys = Object.keys(defaultGraph).sort();\n  for(let ki = 0; ki < keys.length; ++ki) {\n    const node = defaultGraph[keys[ki]];\n    // only add full subjects to top-level\n    if(!_isSubjectReference(node)) {\n      flattened.push(node);\n    }\n  }\n  return flattened;\n};\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst JsonLdError = require('./JsonLdError');\nconst graphTypes = require('./graphTypes');\nconst types = require('./types');\nconst util = require('./util');\n\n// constants\nconst {\n  // RDF,\n  RDF_LIST,\n  RDF_FIRST,\n  RDF_REST,\n  RDF_NIL,\n  RDF_TYPE,\n  // RDF_PLAIN_LITERAL,\n  // RDF_XML_LITERAL,\n  RDF_JSON_LITERAL,\n  // RDF_OBJECT,\n  // RDF_LANGSTRING,\n\n  // XSD,\n  XSD_BOOLEAN,\n  XSD_DOUBLE,\n  XSD_INTEGER,\n  XSD_STRING,\n} = require('./constants');\n\nconst REGEX_BCP47 = /^[a-zA-Z]{1,8}(-[a-zA-Z0-9]{1,8})*$/;\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Converts an RDF dataset to JSON-LD.\n *\n * @param dataset the RDF dataset.\n * @param options the RDF serialization options.\n *\n * @return a Promise that resolves to the JSON-LD output.\n */\napi.fromRDF = async (\n  dataset,\n  {\n    useRdfType = false,\n    useNativeTypes = false,\n    rdfDirection = null\n  }\n) => {\n  const defaultGraph = {};\n  const graphMap = {'@default': defaultGraph};\n  const referencedOnce = {};\n\n  for(const quad of dataset) {\n    // TODO: change 'name' to 'graph'\n    const name = (quad.graph.termType === 'DefaultGraph') ?\n      '@default' : quad.graph.value;\n    if(!(name in graphMap)) {\n      graphMap[name] = {};\n    }\n    if(name !== '@default' && !(name in defaultGraph)) {\n      defaultGraph[name] = {'@id': name};\n    }\n\n    const nodeMap = graphMap[name];\n\n    // get subject, predicate, object\n    const s = quad.subject.value;\n    const p = quad.predicate.value;\n    const o = quad.object;\n\n    if(!(s in nodeMap)) {\n      nodeMap[s] = {'@id': s};\n    }\n    const node = nodeMap[s];\n\n    const objectIsNode = o.termType.endsWith('Node');\n    if(objectIsNode && !(o.value in nodeMap)) {\n      nodeMap[o.value] = {'@id': o.value};\n    }\n\n    if(p === RDF_TYPE && !useRdfType && objectIsNode) {\n      util.addValue(node, '@type', o.value, {propertyIsArray: true});\n      continue;\n    }\n\n    const value = _RDFToObject(o, useNativeTypes, rdfDirection);\n    util.addValue(node, p, value, {propertyIsArray: true});\n\n    // object may be an RDF list/partial list node but we can't know easily\n    // until all triples are read\n    if(objectIsNode) {\n      if(o.value === RDF_NIL) {\n        // track rdf:nil uniquely per graph\n        const object = nodeMap[o.value];\n        if(!('usages' in object)) {\n          object.usages = [];\n        }\n        object.usages.push({\n          node,\n          property: p,\n          value\n        });\n      } else if(o.value in referencedOnce) {\n        // object referenced more than once\n        referencedOnce[o.value] = false;\n      } else {\n        // keep track of single reference\n        referencedOnce[o.value] = {\n          node,\n          property: p,\n          value\n        };\n      }\n    }\n  }\n\n  /*\n  for(let name in dataset) {\n    const graph = dataset[name];\n    if(!(name in graphMap)) {\n      graphMap[name] = {};\n    }\n    if(name !== '@default' && !(name in defaultGraph)) {\n      defaultGraph[name] = {'@id': name};\n    }\n    const nodeMap = graphMap[name];\n    for(let ti = 0; ti < graph.length; ++ti) {\n      const triple = graph[ti];\n\n      // get subject, predicate, object\n      const s = triple.subject.value;\n      const p = triple.predicate.value;\n      const o = triple.object;\n\n      if(!(s in nodeMap)) {\n        nodeMap[s] = {'@id': s};\n      }\n      const node = nodeMap[s];\n\n      const objectIsId = (o.type === 'IRI' || o.type === 'blank node');\n      if(objectIsId && !(o.value in nodeMap)) {\n        nodeMap[o.value] = {'@id': o.value};\n      }\n\n      if(p === RDF_TYPE && !useRdfType && objectIsId) {\n        util.addValue(node, '@type', o.value, {propertyIsArray: true});\n        continue;\n      }\n\n      const value = _RDFToObject(o, useNativeTypes);\n      util.addValue(node, p, value, {propertyIsArray: true});\n\n      // object may be an RDF list/partial list node but we can't know easily\n      // until all triples are read\n      if(objectIsId) {\n        if(o.value === RDF_NIL) {\n          // track rdf:nil uniquely per graph\n          const object = nodeMap[o.value];\n          if(!('usages' in object)) {\n            object.usages = [];\n          }\n          object.usages.push({\n            node: node,\n            property: p,\n            value: value\n          });\n        } else if(o.value in referencedOnce) {\n          // object referenced more than once\n          referencedOnce[o.value] = false;\n        } else {\n          // keep track of single reference\n          referencedOnce[o.value] = {\n            node: node,\n            property: p,\n            value: value\n          };\n        }\n      }\n    }\n  }*/\n\n  // convert linked lists to @list arrays\n  for(const name in graphMap) {\n    const graphObject = graphMap[name];\n\n    // no @lists to be converted, continue\n    if(!(RDF_NIL in graphObject)) {\n      continue;\n    }\n\n    // iterate backwards through each RDF list\n    const nil = graphObject[RDF_NIL];\n    if(!nil.usages) {\n      continue;\n    }\n    for(let usage of nil.usages) {\n      let node = usage.node;\n      let property = usage.property;\n      let head = usage.value;\n      const list = [];\n      const listNodes = [];\n\n      // ensure node is a well-formed list node; it must:\n      // 1. Be referenced only once.\n      // 2. Have an array for rdf:first that has 1 item.\n      // 3. Have an array for rdf:rest that has 1 item.\n      // 4. Have no keys other than: @id, rdf:first, rdf:rest, and,\n      //   optionally, @type where the value is rdf:List.\n      let nodeKeyCount = Object.keys(node).length;\n      while(property === RDF_REST &&\n        types.isObject(referencedOnce[node['@id']]) &&\n        types.isArray(node[RDF_FIRST]) && node[RDF_FIRST].length === 1 &&\n        types.isArray(node[RDF_REST]) && node[RDF_REST].length === 1 &&\n        (nodeKeyCount === 3 ||\n          (nodeKeyCount === 4 && types.isArray(node['@type']) &&\n          node['@type'].length === 1 && node['@type'][0] === RDF_LIST))) {\n        list.push(node[RDF_FIRST][0]);\n        listNodes.push(node['@id']);\n\n        // get next node, moving backwards through list\n        usage = referencedOnce[node['@id']];\n        node = usage.node;\n        property = usage.property;\n        head = usage.value;\n        nodeKeyCount = Object.keys(node).length;\n\n        // if node is not a blank node, then list head found\n        if(!graphTypes.isBlankNode(node)) {\n          break;\n        }\n      }\n\n      // transform list into @list object\n      delete head['@id'];\n      head['@list'] = list.reverse();\n      for(const listNode of listNodes) {\n        delete graphObject[listNode];\n      }\n    }\n\n    delete nil.usages;\n  }\n\n  const result = [];\n  const subjects = Object.keys(defaultGraph).sort();\n  for(const subject of subjects) {\n    const node = defaultGraph[subject];\n    if(subject in graphMap) {\n      const graph = node['@graph'] = [];\n      const graphObject = graphMap[subject];\n      const graphSubjects = Object.keys(graphObject).sort();\n      for(const graphSubject of graphSubjects) {\n        const node = graphObject[graphSubject];\n        // only add full subjects to top-level\n        if(!graphTypes.isSubjectReference(node)) {\n          graph.push(node);\n        }\n      }\n    }\n    // only add full subjects to top-level\n    if(!graphTypes.isSubjectReference(node)) {\n      result.push(node);\n    }\n  }\n\n  return result;\n};\n\n/**\n * Converts an RDF triple object to a JSON-LD object.\n *\n * @param o the RDF triple object to convert.\n * @param useNativeTypes true to output native types, false not to.\n *\n * @return the JSON-LD object.\n */\nfunction _RDFToObject(o, useNativeTypes, rdfDirection) {\n  // convert NamedNode/BlankNode object to JSON-LD\n  if(o.termType.endsWith('Node')) {\n    return {'@id': o.value};\n  }\n\n  // convert literal to JSON-LD\n  const rval = {'@value': o.value};\n\n  // add language\n  if(o.language) {\n    rval['@language'] = o.language;\n  } else {\n    let type = o.datatype.value;\n    if(!type) {\n      type = XSD_STRING;\n    }\n    if(type === RDF_JSON_LITERAL) {\n      type = '@json';\n      try {\n        rval['@value'] = JSON.parse(rval['@value']);\n      } catch(e) {\n        throw new JsonLdError(\n          'JSON literal could not be parsed.',\n          'jsonld.InvalidJsonLiteral',\n          {code: 'invalid JSON literal', value: rval['@value'], cause: e});\n      }\n    }\n    // use native types for certain xsd types\n    if(useNativeTypes) {\n      if(type === XSD_BOOLEAN) {\n        if(rval['@value'] === 'true') {\n          rval['@value'] = true;\n        } else if(rval['@value'] === 'false') {\n          rval['@value'] = false;\n        }\n      } else if(types.isNumeric(rval['@value'])) {\n        if(type === XSD_INTEGER) {\n          const i = parseInt(rval['@value'], 10);\n          if(i.toFixed(0) === rval['@value']) {\n            rval['@value'] = i;\n          }\n        } else if(type === XSD_DOUBLE) {\n          rval['@value'] = parseFloat(rval['@value']);\n        }\n      }\n      // do not add native type\n      if(![XSD_BOOLEAN, XSD_INTEGER, XSD_DOUBLE, XSD_STRING].includes(type)) {\n        rval['@type'] = type;\n      }\n    } else if(rdfDirection === 'i18n-datatype' &&\n      type.startsWith('https://www.w3.org/ns/i18n#')) {\n      const [, language, direction] = type.split(/[#_]/);\n      if(language.length > 0) {\n        rval['@language'] = language;\n        if(!language.match(REGEX_BCP47)) {\n          console.warn(`@language must be valid BCP47: ${language}`);\n        }\n      }\n      rval['@direction'] = direction;\n    } else if(type !== XSD_STRING) {\n      rval['@type'] = type;\n    }\n  }\n\n  return rval;\n}\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst {createNodeMap} = require('./nodeMap');\nconst {isKeyword} = require('./context');\nconst graphTypes = require('./graphTypes');\nconst jsonCanonicalize = require('canonicalize');\nconst types = require('./types');\nconst util = require('./util');\n\nconst {\n  // RDF,\n  // RDF_LIST,\n  RDF_FIRST,\n  RDF_REST,\n  RDF_NIL,\n  RDF_TYPE,\n  // RDF_PLAIN_LITERAL,\n  // RDF_XML_LITERAL,\n  RDF_JSON_LITERAL,\n  // RDF_OBJECT,\n  RDF_LANGSTRING,\n\n  // XSD,\n  XSD_BOOLEAN,\n  XSD_DOUBLE,\n  XSD_INTEGER,\n  XSD_STRING,\n} = require('./constants');\n\nconst {\n  isAbsolute: _isAbsoluteIri\n} = require('./url');\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Outputs an RDF dataset for the expanded JSON-LD input.\n *\n * @param input the expanded JSON-LD input.\n * @param options the RDF serialization options.\n *\n * @return the RDF dataset.\n */\napi.toRDF = (input, options) => {\n  // create node map for default graph (and any named graphs)\n  const issuer = new util.IdentifierIssuer('_:b');\n  const nodeMap = {'@default': {}};\n  createNodeMap(input, nodeMap, '@default', issuer);\n\n  const dataset = [];\n  const graphNames = Object.keys(nodeMap).sort();\n  for(const graphName of graphNames) {\n    let graphTerm;\n    if(graphName === '@default') {\n      graphTerm = {termType: 'DefaultGraph', value: ''};\n    } else if(_isAbsoluteIri(graphName)) {\n      if(graphName.startsWith('_:')) {\n        graphTerm = {termType: 'BlankNode'};\n      } else {\n        graphTerm = {termType: 'NamedNode'};\n      }\n      graphTerm.value = graphName;\n    } else {\n      // skip relative IRIs (not valid RDF)\n      continue;\n    }\n    _graphToRDF(dataset, nodeMap[graphName], graphTerm, issuer, options);\n  }\n\n  return dataset;\n};\n\n/**\n * Adds RDF quads for a particular graph to the given dataset.\n *\n * @param dataset the dataset to append RDF quads to.\n * @param graph the graph to create RDF quads for.\n * @param graphTerm the graph term for each quad.\n * @param issuer a IdentifierIssuer for assigning blank node names.\n * @param options the RDF serialization options.\n *\n * @return the array of RDF triples for the given graph.\n */\nfunction _graphToRDF(dataset, graph, graphTerm, issuer, options) {\n  const ids = Object.keys(graph).sort();\n  for(const id of ids) {\n    const node = graph[id];\n    const properties = Object.keys(node).sort();\n    for(let property of properties) {\n      const items = node[property];\n      if(property === '@type') {\n        property = RDF_TYPE;\n      } else if(isKeyword(property)) {\n        continue;\n      }\n\n      for(const item of items) {\n        // RDF subject\n        const subject = {\n          termType: id.startsWith('_:') ? 'BlankNode' : 'NamedNode',\n          value: id\n        };\n\n        // skip relative IRI subjects (not valid RDF)\n        if(!_isAbsoluteIri(id)) {\n          continue;\n        }\n\n        // RDF predicate\n        const predicate = {\n          termType: property.startsWith('_:') ? 'BlankNode' : 'NamedNode',\n          value: property\n        };\n\n        // skip relative IRI predicates (not valid RDF)\n        if(!_isAbsoluteIri(property)) {\n          continue;\n        }\n\n        // skip blank node predicates unless producing generalized RDF\n        if(predicate.termType === 'BlankNode' &&\n          !options.produceGeneralizedRdf) {\n          continue;\n        }\n\n        // convert list, value or node object to triple\n        const object =\n          _objectToRDF(item, issuer, dataset, graphTerm, options.rdfDirection);\n        // skip null objects (they are relative IRIs)\n        if(object) {\n          dataset.push({\n            subject,\n            predicate,\n            object,\n            graph: graphTerm\n          });\n        }\n      }\n    }\n  }\n}\n\n/**\n * Converts a @list value into linked list of blank node RDF quads\n * (an RDF collection).\n *\n * @param list the @list value.\n * @param issuer a IdentifierIssuer for assigning blank node names.\n * @param dataset the array of quads to append to.\n * @param graphTerm the graph term for each quad.\n *\n * @return the head of the list.\n */\nfunction _listToRDF(list, issuer, dataset, graphTerm, rdfDirection) {\n  const first = {termType: 'NamedNode', value: RDF_FIRST};\n  const rest = {termType: 'NamedNode', value: RDF_REST};\n  const nil = {termType: 'NamedNode', value: RDF_NIL};\n\n  const last = list.pop();\n  // Result is the head of the list\n  const result = last ? {termType: 'BlankNode', value: issuer.getId()} : nil;\n  let subject = result;\n\n  for(const item of list) {\n    const object = _objectToRDF(item, issuer, dataset, graphTerm, rdfDirection);\n    const next = {termType: 'BlankNode', value: issuer.getId()};\n    dataset.push({\n      subject,\n      predicate: first,\n      object,\n      graph: graphTerm\n    });\n    dataset.push({\n      subject,\n      predicate: rest,\n      object: next,\n      graph: graphTerm\n    });\n    subject = next;\n  }\n\n  // Tail of list\n  if(last) {\n    const object = _objectToRDF(last, issuer, dataset, graphTerm, rdfDirection);\n    dataset.push({\n      subject,\n      predicate: first,\n      object,\n      graph: graphTerm\n    });\n    dataset.push({\n      subject,\n      predicate: rest,\n      object: nil,\n      graph: graphTerm\n    });\n  }\n\n  return result;\n}\n\n/**\n * Converts a JSON-LD value object to an RDF literal or a JSON-LD string,\n * node object to an RDF resource, or adds a list.\n *\n * @param item the JSON-LD value or node object.\n * @param issuer a IdentifierIssuer for assigning blank node names.\n * @param dataset the dataset to append RDF quads to.\n * @param graphTerm the graph term for each quad.\n *\n * @return the RDF literal or RDF resource.\n */\nfunction _objectToRDF(item, issuer, dataset, graphTerm, rdfDirection) {\n  const object = {};\n\n  // convert value object to RDF\n  if(graphTypes.isValue(item)) {\n    object.termType = 'Literal';\n    object.value = undefined;\n    object.datatype = {\n      termType: 'NamedNode'\n    };\n    let value = item['@value'];\n    const datatype = item['@type'] || null;\n\n    // convert to XSD/JSON datatypes as appropriate\n    if(datatype === '@json') {\n      object.value = jsonCanonicalize(value);\n      object.datatype.value = RDF_JSON_LITERAL;\n    } else if(types.isBoolean(value)) {\n      object.value = value.toString();\n      object.datatype.value = datatype || XSD_BOOLEAN;\n    } else if(types.isDouble(value) || datatype === XSD_DOUBLE) {\n      if(!types.isDouble(value)) {\n        value = parseFloat(value);\n      }\n      // canonical double representation\n      object.value = value.toExponential(15).replace(/(\\d)0*e\\+?/, '$1E');\n      object.datatype.value = datatype || XSD_DOUBLE;\n    } else if(types.isNumber(value)) {\n      object.value = value.toFixed(0);\n      object.datatype.value = datatype || XSD_INTEGER;\n    } else if(rdfDirection === 'i18n-datatype' &&\n      '@direction' in item) {\n      const datatype = 'https://www.w3.org/ns/i18n#' +\n        (item['@language'] || '') +\n        `_${item['@direction']}`;\n      object.datatype.value = datatype;\n      object.value = value;\n    } else if('@language' in item) {\n      object.value = value;\n      object.datatype.value = datatype || RDF_LANGSTRING;\n      object.language = item['@language'];\n    } else {\n      object.value = value;\n      object.datatype.value = datatype || XSD_STRING;\n    }\n  } else if(graphTypes.isList(item)) {\n    const _list =\n      _listToRDF(item['@list'], issuer, dataset, graphTerm, rdfDirection);\n    object.termType = _list.termType;\n    object.value = _list.value;\n  } else {\n    // convert string/node object to RDF\n    const id = types.isObject(item) ? item['@id'] : item;\n    object.termType = id.startsWith('_:') ? 'BlankNode' : 'NamedNode';\n    object.value = id;\n  }\n\n  // skip relative IRIs, not valid RDF\n  if(object.termType === 'NamedNode' && !_isAbsoluteIri(object.value)) {\n    return null;\n  }\n\n  return object;\n}\n","/* jshint esversion: 6 */\n/* jslint node: true */\n'use strict';\n\nmodule.exports = function serialize (object) {\n  if (object === null || typeof object !== 'object' || object.toJSON != null) {\n    return JSON.stringify(object);\n  }\n\n  if (Array.isArray(object)) {\n    return '[' + object.reduce((t, cv, ci) => {\n      const comma = ci === 0 ? '' : ',';\n      const value = cv === undefined || typeof cv === 'symbol' ? null : cv;\n      return t + comma + serialize(value);\n    }, '') + ']';\n  }\n\n  return '{' + Object.keys(object).sort().reduce((t, cv, ci) => {\n    if (object[cv] === undefined ||\n        typeof object[cv] === 'symbol') {\n      return t;\n    }\n    const comma = t.length === 0 ? '' : ',';\n    return t + comma + serialize(cv) + ':' + serialize(object[cv]);\n  }, '') + '}';\n};\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst {isKeyword} = require('./context');\nconst graphTypes = require('./graphTypes');\nconst types = require('./types');\nconst util = require('./util');\nconst url = require('./url');\nconst JsonLdError = require('./JsonLdError');\nconst {\n  createNodeMap: _createNodeMap,\n  mergeNodeMapGraphs: _mergeNodeMapGraphs\n} = require('./nodeMap');\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Performs JSON-LD `merged` framing.\n *\n * @param input the expanded JSON-LD to frame.\n * @param frame the expanded JSON-LD frame to use.\n * @param options the framing options.\n *\n * @return the framed output.\n */\napi.frameMergedOrDefault = (input, frame, options) => {\n  // create framing state\n  const state = {\n    options,\n    embedded: false,\n    graph: '@default',\n    graphMap: {'@default': {}},\n    subjectStack: [],\n    link: {},\n    bnodeMap: {}\n  };\n\n  // produce a map of all graphs and name each bnode\n  // FIXME: currently uses subjects from @merged graph only\n  const issuer = new util.IdentifierIssuer('_:b');\n  _createNodeMap(input, state.graphMap, '@default', issuer);\n  if(options.merged) {\n    state.graphMap['@merged'] = _mergeNodeMapGraphs(state.graphMap);\n    state.graph = '@merged';\n  }\n  state.subjects = state.graphMap[state.graph];\n\n  // frame the subjects\n  const framed = [];\n  api.frame(state, Object.keys(state.subjects).sort(), frame, framed);\n\n  // If pruning blank nodes, find those to prune\n  if(options.pruneBlankNodeIdentifiers) {\n    // remove all blank nodes appearing only once, done in compaction\n    options.bnodesToClear =\n      Object.keys(state.bnodeMap).filter(id => state.bnodeMap[id].length === 1);\n  }\n\n  // remove @preserve from results\n  options.link = {};\n  return _cleanupPreserve(framed, options);\n};\n\n/**\n * Frames subjects according to the given frame.\n *\n * @param state the current framing state.\n * @param subjects the subjects to filter.\n * @param frame the frame.\n * @param parent the parent subject or top-level array.\n * @param property the parent property, initialized to null.\n */\napi.frame = (state, subjects, frame, parent, property = null) => {\n  // validate the frame\n  _validateFrame(frame);\n  frame = frame[0];\n\n  // get flags for current frame\n  const options = state.options;\n  const flags = {\n    embed: _getFrameFlag(frame, options, 'embed'),\n    explicit: _getFrameFlag(frame, options, 'explicit'),\n    requireAll: _getFrameFlag(frame, options, 'requireAll')\n  };\n\n  // get link for current graph\n  if(!state.link.hasOwnProperty(state.graph)) {\n    state.link[state.graph] = {};\n  }\n  const link = state.link[state.graph];\n\n  // filter out subjects that match the frame\n  const matches = _filterSubjects(state, subjects, frame, flags);\n\n  // add matches to output\n  const ids = Object.keys(matches).sort();\n  for(const id of ids) {\n    const subject = matches[id];\n\n    /* Note: In order to treat each top-level match as a compartmentalized\n    result, clear the unique embedded subjects map when the property is null,\n    which only occurs at the top-level. */\n    if(property === null) {\n      state.uniqueEmbeds = {[state.graph]: {}};\n    } else {\n      state.uniqueEmbeds[state.graph] = state.uniqueEmbeds[state.graph] || {};\n    }\n\n    if(flags.embed === '@link' && id in link) {\n      // TODO: may want to also match an existing linked subject against\n      // the current frame ... so different frames could produce different\n      // subjects that are only shared in-memory when the frames are the same\n\n      // add existing linked subject\n      _addFrameOutput(parent, property, link[id]);\n      continue;\n    }\n\n    // start output for subject\n    const output = {'@id': id};\n    if(id.indexOf('_:') === 0) {\n      util.addValue(state.bnodeMap, id, output, {propertyIsArray: true});\n    }\n    link[id] = output;\n\n    // validate @embed\n    if((flags.embed === '@first' || flags.embed === '@last') && state.is11) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; invalid value of @embed.',\n        'jsonld.SyntaxError', {code: 'invalid @embed value', frame});\n    }\n\n    if(!state.embedded && state.uniqueEmbeds[state.graph].hasOwnProperty(id)) {\n      // skip adding this node object to the top level, as it was\n      // already included in another node object\n      continue;\n    }\n\n    // if embed is @never or if a circular reference would be created by an\n    // embed, the subject cannot be embedded, just add the reference;\n    // note that a circular reference won't occur when the embed flag is\n    // `@link` as the above check will short-circuit before reaching this point\n    if(state.embedded &&\n      (flags.embed === '@never' ||\n      _createsCircularReference(subject, state.graph, state.subjectStack))) {\n      _addFrameOutput(parent, property, output);\n      continue;\n    }\n\n    // if only the first (or once) should be embedded\n    if(state.embedded &&\n       (flags.embed == '@first' || flags.embed == '@once') &&\n       state.uniqueEmbeds[state.graph].hasOwnProperty(id)) {\n      _addFrameOutput(parent, property, output);\n      continue;\n    }\n\n    // if only the last match should be embedded\n    if(flags.embed === '@last') {\n      // remove any existing embed\n      if(id in state.uniqueEmbeds[state.graph]) {\n        _removeEmbed(state, id);\n      }\n    }\n\n    state.uniqueEmbeds[state.graph][id] = {parent, property};\n\n    // push matching subject onto stack to enable circular embed checks\n    state.subjectStack.push({subject, graph: state.graph});\n\n    // subject is also the name of a graph\n    if(id in state.graphMap) {\n      let recurse = false;\n      let subframe = null;\n      if(!('@graph' in frame)) {\n        recurse = state.graph !== '@merged';\n        subframe = {};\n      } else {\n        subframe = frame['@graph'][0];\n        recurse = !(id === '@merged' || id === '@default');\n        if(!types.isObject(subframe)) {\n          subframe = {};\n        }\n      }\n\n      if(recurse) {\n        // recurse into graph\n        api.frame(\n          {...state, graph: id, embedded: false},\n          Object.keys(state.graphMap[id]).sort(), [subframe], output, '@graph');\n      }\n    }\n\n    // if frame has @included, recurse over its sub-frame\n    if('@included' in frame) {\n      api.frame(\n        {...state, embedded: false},\n        subjects, frame['@included'], output, '@included');\n    }\n\n    // iterate over subject properties\n    for(const prop of Object.keys(subject).sort()) {\n      // copy keywords to output\n      if(isKeyword(prop)) {\n        output[prop] = util.clone(subject[prop]);\n\n        if(prop === '@type') {\n          // count bnode values of @type\n          for(const type of subject['@type']) {\n            if(type.indexOf('_:') === 0) {\n              util.addValue(\n                state.bnodeMap, type, output, {propertyIsArray: true});\n            }\n          }\n        }\n        continue;\n      }\n\n      // explicit is on and property isn't in the frame, skip processing\n      if(flags.explicit && !(prop in frame)) {\n        continue;\n      }\n\n      // add objects\n      for(const o of subject[prop]) {\n        const subframe = (prop in frame ?\n          frame[prop] : _createImplicitFrame(flags));\n\n        // recurse into list\n        if(graphTypes.isList(o)) {\n          const subframe =\n            (frame[prop] && frame[prop][0] && frame[prop][0]['@list']) ?\n              frame[prop][0]['@list'] :\n              _createImplicitFrame(flags);\n\n          // add empty list\n          const list = {'@list': []};\n          _addFrameOutput(output, prop, list);\n\n          // add list objects\n          const src = o['@list'];\n          for(const oo of src) {\n            if(graphTypes.isSubjectReference(oo)) {\n              // recurse into subject reference\n              api.frame(\n                {...state, embedded: true},\n                [oo['@id']], subframe, list, '@list');\n            } else {\n              // include other values automatically\n              _addFrameOutput(list, '@list', util.clone(oo));\n            }\n          }\n        } else if(graphTypes.isSubjectReference(o)) {\n          // recurse into subject reference\n          api.frame(\n            {...state, embedded: true},\n            [o['@id']], subframe, output, prop);\n        } else if(_valueMatch(subframe[0], o)) {\n          // include other values, if they match\n          _addFrameOutput(output, prop, util.clone(o));\n        }\n      }\n    }\n\n    // handle defaults\n    for(const prop of Object.keys(frame).sort()) {\n      // skip keywords\n      if(prop === '@type') {\n        if(!types.isObject(frame[prop][0]) ||\n           !('@default' in frame[prop][0])) {\n          continue;\n        }\n        // allow through default types\n      } else if(isKeyword(prop)) {\n        continue;\n      }\n\n      // if omit default is off, then include default values for properties\n      // that appear in the next frame but are not in the matching subject\n      const next = frame[prop][0] || {};\n      const omitDefaultOn = _getFrameFlag(next, options, 'omitDefault');\n      if(!omitDefaultOn && !(prop in output)) {\n        let preserve = '@null';\n        if('@default' in next) {\n          preserve = util.clone(next['@default']);\n        }\n        if(!types.isArray(preserve)) {\n          preserve = [preserve];\n        }\n        output[prop] = [{'@preserve': preserve}];\n      }\n    }\n\n    // if embed reverse values by finding nodes having this subject as a value\n    // of the associated property\n    for(const reverseProp of Object.keys(frame['@reverse'] || {}).sort()) {\n      const subframe = frame['@reverse'][reverseProp];\n      for(const subject of Object.keys(state.subjects)) {\n        const nodeValues =\n          util.getValues(state.subjects[subject], reverseProp);\n        if(nodeValues.some(v => v['@id'] === id)) {\n          // node has property referencing this subject, recurse\n          output['@reverse'] = output['@reverse'] || {};\n          util.addValue(\n            output['@reverse'], reverseProp, [], {propertyIsArray: true});\n          api.frame(\n            {...state, embedded: true},\n            [subject], subframe, output['@reverse'][reverseProp],\n            property);\n        }\n      }\n    }\n\n    // add output to parent\n    _addFrameOutput(parent, property, output);\n\n    // pop matching subject from circular ref-checking stack\n    state.subjectStack.pop();\n  }\n};\n\n/**\n * Replace `@null` with `null`, removing it from arrays.\n *\n * @param input the framed, compacted output.\n * @param options the framing options used.\n *\n * @return the resulting output.\n */\napi.cleanupNull = (input, options) => {\n  // recurse through arrays\n  if(types.isArray(input)) {\n    const noNulls = input.map(v => api.cleanupNull(v, options));\n    return noNulls.filter(v => v); // removes nulls from array\n  }\n\n  if(input === '@null') {\n    return null;\n  }\n\n  if(types.isObject(input)) {\n    // handle in-memory linked nodes\n    if('@id' in input) {\n      const id = input['@id'];\n      if(options.link.hasOwnProperty(id)) {\n        const idx = options.link[id].indexOf(input);\n        if(idx !== -1) {\n          // already visited\n          return options.link[id][idx];\n        }\n        // prevent circular visitation\n        options.link[id].push(input);\n      } else {\n        // prevent circular visitation\n        options.link[id] = [input];\n      }\n    }\n\n    for(const key in input) {\n      input[key] = api.cleanupNull(input[key], options);\n    }\n  }\n  return input;\n};\n\n/**\n * Creates an implicit frame when recursing through subject matches. If\n * a frame doesn't have an explicit frame for a particular property, then\n * a wildcard child frame will be created that uses the same flags that the\n * parent frame used.\n *\n * @param flags the current framing flags.\n *\n * @return the implicit frame.\n */\nfunction _createImplicitFrame(flags) {\n  const frame = {};\n  for(const key in flags) {\n    if(flags[key] !== undefined) {\n      frame['@' + key] = [flags[key]];\n    }\n  }\n  return [frame];\n}\n\n/**\n * Checks the current subject stack to see if embedding the given subject\n * would cause a circular reference.\n *\n * @param subjectToEmbed the subject to embed.\n * @param graph the graph the subject to embed is in.\n * @param subjectStack the current stack of subjects.\n *\n * @return true if a circular reference would be created, false if not.\n */\nfunction _createsCircularReference(subjectToEmbed, graph, subjectStack) {\n  for(let i = subjectStack.length - 1; i >= 0; --i) {\n    const subject = subjectStack[i];\n    if(subject.graph === graph &&\n      subject.subject['@id'] === subjectToEmbed['@id']) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Gets the frame flag value for the given flag name.\n *\n * @param frame the frame.\n * @param options the framing options.\n * @param name the flag name.\n *\n * @return the flag value.\n */\nfunction _getFrameFlag(frame, options, name) {\n  const flag = '@' + name;\n  let rval = (flag in frame ? frame[flag][0] : options[name]);\n  if(name === 'embed') {\n    // default is \"@last\"\n    // backwards-compatibility support for \"embed\" maps:\n    // true => \"@last\"\n    // false => \"@never\"\n    if(rval === true) {\n      rval = '@once';\n    } else if(rval === false) {\n      rval = '@never';\n    } else if(rval !== '@always' && rval !== '@never' && rval !== '@link' &&\n      rval !== '@first' && rval !== '@last' && rval !== '@once') {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; invalid value of @embed.',\n        'jsonld.SyntaxError', {code: 'invalid @embed value', frame});\n    }\n  }\n  return rval;\n}\n\n/**\n * Validates a JSON-LD frame, throwing an exception if the frame is invalid.\n *\n * @param frame the frame to validate.\n */\nfunction _validateFrame(frame) {\n  if(!types.isArray(frame) || frame.length !== 1 || !types.isObject(frame[0])) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; a JSON-LD frame must be a single object.',\n      'jsonld.SyntaxError', {frame});\n  }\n\n  if('@id' in frame[0]) {\n    for(const id of util.asArray(frame[0]['@id'])) {\n      // @id must be wildcard or an IRI\n      if(!(types.isObject(id) || url.isAbsolute(id)) ||\n        (types.isString(id) && id.indexOf('_:') === 0)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; invalid @id in frame.',\n          'jsonld.SyntaxError', {code: 'invalid frame', frame});\n      }\n    }\n  }\n\n  if('@type' in frame[0]) {\n    for(const type of util.asArray(frame[0]['@type'])) {\n      // @id must be wildcard or an IRI\n      if(!(types.isObject(type) || url.isAbsolute(type)) ||\n        (types.isString(type) && type.indexOf('_:') === 0)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; invalid @type in frame.',\n          'jsonld.SyntaxError', {code: 'invalid frame', frame});\n      }\n    }\n  }\n}\n\n/**\n * Returns a map of all of the subjects that match a parsed frame.\n *\n * @param state the current framing state.\n * @param subjects the set of subjects to filter.\n * @param frame the parsed frame.\n * @param flags the frame flags.\n *\n * @return all of the matched subjects.\n */\nfunction _filterSubjects(state, subjects, frame, flags) {\n  // filter subjects in @id order\n  const rval = {};\n  for(const id of subjects) {\n    const subject = state.graphMap[state.graph][id];\n    if(_filterSubject(state, subject, frame, flags)) {\n      rval[id] = subject;\n    }\n  }\n  return rval;\n}\n\n/**\n * Returns true if the given subject matches the given frame.\n *\n * Matches either based on explicit type inclusion where the node has any\n * type listed in the frame. If the frame has empty types defined matches\n * nodes not having a @type. If the frame has a type of {} defined matches\n * nodes having any type defined.\n *\n * Otherwise, does duck typing, where the node must have all of the\n * properties defined in the frame.\n *\n * @param state the current framing state.\n * @param subject the subject to check.\n * @param frame the frame to check.\n * @param flags the frame flags.\n *\n * @return true if the subject matches, false if not.\n */\nfunction _filterSubject(state, subject, frame, flags) {\n  // check ducktype\n  let wildcard = true;\n  let matchesSome = false;\n\n  for(const key in frame) {\n    let matchThis = false;\n    const nodeValues = util.getValues(subject, key);\n    const isEmpty = util.getValues(frame, key).length === 0;\n\n    if(key === '@id') {\n      // match on no @id or any matching @id, including wildcard\n      if(types.isEmptyObject(frame['@id'][0] || {})) {\n        matchThis = true;\n      } else if(frame['@id'].length >= 0) {\n        matchThis = frame['@id'].includes(nodeValues[0]);\n      }\n      if(!flags.requireAll) {\n        return matchThis;\n      }\n    } else if(key === '@type') {\n      // check @type (object value means 'any' type,\n      // fall through to ducktyping)\n      wildcard = false;\n      if(isEmpty) {\n        if(nodeValues.length > 0) {\n          // don't match on no @type\n          return false;\n        }\n        matchThis = true;\n      } else if(frame['@type'].length === 1 &&\n        types.isEmptyObject(frame['@type'][0])) {\n        // match on wildcard @type if there is a type\n        matchThis = nodeValues.length > 0;\n      } else {\n        // match on a specific @type\n        for(const type of frame['@type']) {\n          if(types.isObject(type) && '@default' in type) {\n            // match on default object\n            matchThis = true;\n          } else {\n            matchThis = matchThis || nodeValues.some(tt => tt === type);\n          }\n        }\n      }\n      if(!flags.requireAll) {\n        return matchThis;\n      }\n    } else if(isKeyword(key)) {\n      continue;\n    } else {\n      // Force a copy of this frame entry so it can be manipulated\n      const thisFrame = util.getValues(frame, key)[0];\n      let hasDefault = false;\n      if(thisFrame) {\n        _validateFrame([thisFrame]);\n        hasDefault = '@default' in thisFrame;\n      }\n\n      // no longer a wildcard pattern if frame has any non-keyword properties\n      wildcard = false;\n\n      // skip, but allow match if node has no value for property, and frame has\n      // a default value\n      if(nodeValues.length === 0 && hasDefault) {\n        continue;\n      }\n\n      // if frame value is empty, don't match if subject has any value\n      if(nodeValues.length > 0 && isEmpty) {\n        return false;\n      }\n\n      if(thisFrame === undefined) {\n        // node does not match if values is not empty and the value of property\n        // in frame is match none.\n        if(nodeValues.length > 0) {\n          return false;\n        }\n        matchThis = true;\n      } else {\n        if(graphTypes.isList(thisFrame)) {\n          const listValue = thisFrame['@list'][0];\n          if(graphTypes.isList(nodeValues[0])) {\n            const nodeListValues = nodeValues[0]['@list'];\n\n            if(graphTypes.isValue(listValue)) {\n              // match on any matching value\n              matchThis = nodeListValues.some(lv => _valueMatch(listValue, lv));\n            } else if(graphTypes.isSubject(listValue) ||\n              graphTypes.isSubjectReference(listValue)) {\n              matchThis = nodeListValues.some(lv => _nodeMatch(\n                state, listValue, lv, flags));\n            }\n          }\n        } else if(graphTypes.isValue(thisFrame)) {\n          matchThis = nodeValues.some(nv => _valueMatch(thisFrame, nv));\n        } else if(graphTypes.isSubjectReference(thisFrame)) {\n          matchThis =\n            nodeValues.some(nv => _nodeMatch(state, thisFrame, nv, flags));\n        } else if(types.isObject(thisFrame)) {\n          matchThis = nodeValues.length > 0;\n        } else {\n          matchThis = false;\n        }\n      }\n    }\n\n    // all non-defaulted values must match if requireAll is set\n    if(!matchThis && flags.requireAll) {\n      return false;\n    }\n\n    matchesSome = matchesSome || matchThis;\n  }\n\n  // return true if wildcard or subject matches some properties\n  return wildcard || matchesSome;\n}\n\n/**\n * Removes an existing embed.\n *\n * @param state the current framing state.\n * @param id the @id of the embed to remove.\n */\nfunction _removeEmbed(state, id) {\n  // get existing embed\n  const embeds = state.uniqueEmbeds[state.graph];\n  const embed = embeds[id];\n  const parent = embed.parent;\n  const property = embed.property;\n\n  // create reference to replace embed\n  const subject = {'@id': id};\n\n  // remove existing embed\n  if(types.isArray(parent)) {\n    // replace subject with reference\n    for(let i = 0; i < parent.length; ++i) {\n      if(util.compareValues(parent[i], subject)) {\n        parent[i] = subject;\n        break;\n      }\n    }\n  } else {\n    // replace subject with reference\n    const useArray = types.isArray(parent[property]);\n    util.removeValue(parent, property, subject, {propertyIsArray: useArray});\n    util.addValue(parent, property, subject, {propertyIsArray: useArray});\n  }\n\n  // recursively remove dependent dangling embeds\n  const removeDependents = id => {\n    // get embed keys as a separate array to enable deleting keys in map\n    const ids = Object.keys(embeds);\n    for(const next of ids) {\n      if(next in embeds && types.isObject(embeds[next].parent) &&\n        embeds[next].parent['@id'] === id) {\n        delete embeds[next];\n        removeDependents(next);\n      }\n    }\n  };\n  removeDependents(id);\n}\n\n/**\n * Removes the @preserve keywords from expanded result of framing.\n *\n * @param input the framed, framed output.\n * @param options the framing options used.\n *\n * @return the resulting output.\n */\nfunction _cleanupPreserve(input, options) {\n  // recurse through arrays\n  if(types.isArray(input)) {\n    return input.map(value => _cleanupPreserve(value, options));\n  }\n\n  if(types.isObject(input)) {\n    // remove @preserve\n    if('@preserve' in input) {\n      return input['@preserve'][0];\n    }\n\n    // skip @values\n    if(graphTypes.isValue(input)) {\n      return input;\n    }\n\n    // recurse through @lists\n    if(graphTypes.isList(input)) {\n      input['@list'] = _cleanupPreserve(input['@list'], options);\n      return input;\n    }\n\n    // handle in-memory linked nodes\n    if('@id' in input) {\n      const id = input['@id'];\n      if(options.link.hasOwnProperty(id)) {\n        const idx = options.link[id].indexOf(input);\n        if(idx !== -1) {\n          // already visited\n          return options.link[id][idx];\n        }\n        // prevent circular visitation\n        options.link[id].push(input);\n      } else {\n        // prevent circular visitation\n        options.link[id] = [input];\n      }\n    }\n\n    // recurse through properties\n    for(const prop in input) {\n      // potentially remove the id, if it is an unreference bnode\n      if(prop === '@id' && options.bnodesToClear.includes(input[prop])) {\n        delete input['@id'];\n        continue;\n      }\n\n      input[prop] = _cleanupPreserve(input[prop], options);\n    }\n  }\n  return input;\n}\n\n/**\n * Adds framing output to the given parent.\n *\n * @param parent the parent to add to.\n * @param property the parent property.\n * @param output the output to add.\n */\nfunction _addFrameOutput(parent, property, output) {\n  if(types.isObject(parent)) {\n    util.addValue(parent, property, output, {propertyIsArray: true});\n  } else {\n    parent.push(output);\n  }\n}\n\n/**\n * Node matches if it is a node, and matches the pattern as a frame.\n *\n * @param state the current framing state.\n * @param pattern used to match value\n * @param value to check\n * @param flags the frame flags.\n */\nfunction _nodeMatch(state, pattern, value, flags) {\n  if(!('@id' in value)) {\n    return false;\n  }\n  const nodeObject = state.subjects[value['@id']];\n  return nodeObject && _filterSubject(state, nodeObject, pattern, flags);\n}\n\n/**\n * Value matches if it is a value and matches the value pattern\n *\n * * `pattern` is empty\n * * @values are the same, or `pattern[@value]` is a wildcard, and\n * * @types are the same or `value[@type]` is not null\n *   and `pattern[@type]` is `{}`, or `value[@type]` is null\n *   and `pattern[@type]` is null or `[]`, and\n * * @languages are the same or `value[@language]` is not null\n *   and `pattern[@language]` is `{}`, or `value[@language]` is null\n *   and `pattern[@language]` is null or `[]`.\n *\n * @param pattern used to match value\n * @param value to check\n */\nfunction _valueMatch(pattern, value) {\n  const v1 = value['@value'];\n  const t1 = value['@type'];\n  const l1 = value['@language'];\n  const v2 = pattern['@value'] ?\n    (types.isArray(pattern['@value']) ?\n      pattern['@value'] : [pattern['@value']]) :\n    [];\n  const t2 = pattern['@type'] ?\n    (types.isArray(pattern['@type']) ?\n      pattern['@type'] : [pattern['@type']]) :\n    [];\n  const l2 = pattern['@language'] ?\n    (types.isArray(pattern['@language']) ?\n      pattern['@language'] : [pattern['@language']]) :\n    [];\n\n  if(v2.length === 0 && t2.length === 0 && l2.length === 0) {\n    return true;\n  }\n  if(!(v2.includes(v1) || types.isEmptyObject(v2[0]))) {\n    return false;\n  }\n  if(!(!t1 && t2.length === 0 || t2.includes(t1) || t1 &&\n    types.isEmptyObject(t2[0]))) {\n    return false;\n  }\n  if(!(!l1 && l2.length === 0 || l2.includes(l1) || l1 &&\n    types.isEmptyObject(l2[0]))) {\n    return false;\n  }\n  return true;\n}\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst JsonLdError = require('./JsonLdError');\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isString: _isString,\n  isUndefined: _isUndefined\n} = require('./types');\n\nconst {\n  isList: _isList,\n  isValue: _isValue,\n  isGraph: _isGraph,\n  isSimpleGraph: _isSimpleGraph,\n  isSubjectReference: _isSubjectReference\n} = require('./graphTypes');\n\nconst {\n  expandIri: _expandIri,\n  getContextValue: _getContextValue,\n  isKeyword: _isKeyword,\n  process: _processContext,\n  processingMode: _processingMode\n} = require('./context');\n\nconst {\n  removeBase: _removeBase,\n  prependBase: _prependBase\n} = require('./url');\n\nconst {\n  addValue: _addValue,\n  asArray: _asArray,\n  compareShortestLeast: _compareShortestLeast\n} = require('./util');\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Recursively compacts an element using the given active context. All values\n * must be in expanded form before this method is called.\n *\n * @param activeCtx the active context to use.\n * @param activeProperty the compacted property associated with the element\n *          to compact, null for none.\n * @param element the element to compact.\n * @param options the compaction options.\n * @param compactionMap the compaction map to use.\n *\n * @return a promise that resolves to the compacted value.\n */\napi.compact = async ({\n  activeCtx,\n  activeProperty = null,\n  element,\n  options = {},\n  compactionMap = () => undefined\n}) => {\n  // recursively compact array\n  if(_isArray(element)) {\n    let rval = [];\n    for(let i = 0; i < element.length; ++i) {\n      // compact, dropping any null values unless custom mapped\n      let compacted = await api.compact({\n        activeCtx,\n        activeProperty,\n        element: element[i],\n        options,\n        compactionMap\n      });\n      if(compacted === null) {\n        compacted = await compactionMap({\n          unmappedValue: element[i],\n          activeCtx,\n          activeProperty,\n          parent: element,\n          index: i,\n          options\n        });\n        if(compacted === undefined) {\n          continue;\n        }\n      }\n      rval.push(compacted);\n    }\n    if(options.compactArrays && rval.length === 1) {\n      // use single element if no container is specified\n      const container = _getContextValue(\n        activeCtx, activeProperty, '@container') || [];\n      if(container.length === 0) {\n        rval = rval[0];\n      }\n    }\n    return rval;\n  }\n\n  // use any scoped context on activeProperty\n  const ctx = _getContextValue(activeCtx, activeProperty, '@context');\n  if(!_isUndefined(ctx)) {\n    activeCtx = await _processContext({\n      activeCtx,\n      localCtx: ctx,\n      propagate: true,\n      overrideProtected: true,\n      options\n    });\n  }\n\n  // recursively compact object\n  if(_isObject(element)) {\n    if(options.link && '@id' in element &&\n      options.link.hasOwnProperty(element['@id'])) {\n      // check for a linked element to reuse\n      const linked = options.link[element['@id']];\n      for(let i = 0; i < linked.length; ++i) {\n        if(linked[i].expanded === element) {\n          return linked[i].compacted;\n        }\n      }\n    }\n\n    // do value compaction on @values and subject references\n    if(_isValue(element) || _isSubjectReference(element)) {\n      const rval =\n        api.compactValue({activeCtx, activeProperty, value: element, options});\n      if(options.link && _isSubjectReference(element)) {\n        // store linked element\n        if(!(options.link.hasOwnProperty(element['@id']))) {\n          options.link[element['@id']] = [];\n        }\n        options.link[element['@id']].push({expanded: element, compacted: rval});\n      }\n      return rval;\n    }\n\n    // if expanded property is @list and we're contained within a list\n    // container, recursively compact this item to an array\n    if(_isList(element)) {\n      const container = _getContextValue(\n        activeCtx, activeProperty, '@container') || [];\n      if(container.includes('@list')) {\n        return api.compact({\n          activeCtx,\n          activeProperty,\n          element: element['@list'],\n          options,\n          compactionMap\n        });\n      }\n    }\n\n    // FIXME: avoid misuse of active property as an expanded property?\n    const insideReverse = (activeProperty === '@reverse');\n\n    const rval = {};\n\n    // original context before applying property-scoped and local contexts\n    const inputCtx = activeCtx;\n\n    // revert to previous context, if there is one,\n    // and element is not a value object or a node reference\n    if(!_isValue(element) && !_isSubjectReference(element)) {\n      activeCtx = activeCtx.revertToPreviousContext();\n    }\n\n    // apply property-scoped context after reverting term-scoped context\n    const propertyScopedCtx =\n      _getContextValue(inputCtx, activeProperty, '@context');\n    if(!_isUndefined(propertyScopedCtx)) {\n      activeCtx = await _processContext({\n        activeCtx,\n        localCtx: propertyScopedCtx,\n        propagate: true,\n        overrideProtected: true,\n        options\n      });\n    }\n\n    if(options.link && '@id' in element) {\n      // store linked element\n      if(!options.link.hasOwnProperty(element['@id'])) {\n        options.link[element['@id']] = [];\n      }\n      options.link[element['@id']].push({expanded: element, compacted: rval});\n    }\n\n    // apply any context defined on an alias of @type\n    // if key is @type and any compacted value is a term having a local\n    // context, overlay that context\n    let types = element['@type'] || [];\n    if(types.length > 1) {\n      types = Array.from(types).sort();\n    }\n    // find all type-scoped contexts based on current context, prior to\n    // updating it\n    const typeContext = activeCtx;\n    for(const type of types) {\n      const compactedType = api.compactIri(\n        {activeCtx: typeContext, iri: type, relativeTo: {vocab: true}});\n\n      // Use any type-scoped context defined on this value\n      const ctx = _getContextValue(inputCtx, compactedType, '@context');\n      if(!_isUndefined(ctx)) {\n        activeCtx = await _processContext({\n          activeCtx,\n          localCtx: ctx,\n          options,\n          propagate: false\n        });\n      }\n    }\n\n    // process element keys in order\n    const keys = Object.keys(element).sort();\n    for(const expandedProperty of keys) {\n      const expandedValue = element[expandedProperty];\n\n      // compact @id\n      if(expandedProperty === '@id') {\n        let compactedValue = _asArray(expandedValue).map(\n          expandedIri => api.compactIri({\n            activeCtx,\n            iri: expandedIri,\n            relativeTo: {vocab: false},\n            base: options.base\n          }));\n        if(compactedValue.length === 1) {\n          compactedValue = compactedValue[0];\n        }\n\n        // use keyword alias and add value\n        const alias = api.compactIri(\n          {activeCtx, iri: '@id', relativeTo: {vocab: true}});\n\n        rval[alias] = compactedValue;\n        continue;\n      }\n\n      // compact @type(s)\n      if(expandedProperty === '@type') {\n        // resolve type values against previous context\n        let compactedValue = _asArray(expandedValue).map(\n          expandedIri => api.compactIri({\n            activeCtx: inputCtx,\n            iri: expandedIri,\n            relativeTo: {vocab: true}\n          }));\n        if(compactedValue.length === 1) {\n          compactedValue = compactedValue[0];\n        }\n\n        // use keyword alias and add value\n        const alias = api.compactIri(\n          {activeCtx, iri: '@type', relativeTo: {vocab: true}});\n        const container = _getContextValue(\n          activeCtx, alias, '@container') || [];\n\n        // treat as array for @type if @container includes @set\n        const typeAsSet =\n          container.includes('@set') &&\n          _processingMode(activeCtx, 1.1);\n        const isArray =\n          typeAsSet || (_isArray(compactedValue) && expandedValue.length === 0);\n        _addValue(rval, alias, compactedValue, {propertyIsArray: isArray});\n        continue;\n      }\n\n      // handle @reverse\n      if(expandedProperty === '@reverse') {\n        // recursively compact expanded value\n        const compactedValue = await api.compact({\n          activeCtx,\n          activeProperty: '@reverse',\n          element: expandedValue,\n          options,\n          compactionMap\n        });\n\n        // handle double-reversed properties\n        for(const compactedProperty in compactedValue) {\n          if(activeCtx.mappings.has(compactedProperty) &&\n            activeCtx.mappings.get(compactedProperty).reverse) {\n            const value = compactedValue[compactedProperty];\n            const container = _getContextValue(\n              activeCtx, compactedProperty, '@container') || [];\n            const useArray = (\n              container.includes('@set') || !options.compactArrays);\n            _addValue(\n              rval, compactedProperty, value, {propertyIsArray: useArray});\n            delete compactedValue[compactedProperty];\n          }\n        }\n\n        if(Object.keys(compactedValue).length > 0) {\n          // use keyword alias and add value\n          const alias = api.compactIri({\n            activeCtx,\n            iri: expandedProperty,\n            relativeTo: {vocab: true}\n          });\n          _addValue(rval, alias, compactedValue);\n        }\n\n        continue;\n      }\n\n      if(expandedProperty === '@preserve') {\n        // compact using activeProperty\n        const compactedValue = await api.compact({\n          activeCtx,\n          activeProperty,\n          element: expandedValue,\n          options,\n          compactionMap\n        });\n\n        if(!(_isArray(compactedValue) && compactedValue.length === 0)) {\n          _addValue(rval, expandedProperty, compactedValue);\n        }\n        continue;\n      }\n\n      // handle @index property\n      if(expandedProperty === '@index') {\n        // drop @index if inside an @index container\n        const container = _getContextValue(\n          activeCtx, activeProperty, '@container') || [];\n        if(container.includes('@index')) {\n          continue;\n        }\n\n        // use keyword alias and add value\n        const alias = api.compactIri({\n          activeCtx,\n          iri: expandedProperty,\n          relativeTo: {vocab: true}\n        });\n        _addValue(rval, alias, expandedValue);\n        continue;\n      }\n\n      // skip array processing for keywords that aren't\n      // @graph, @list, or @included\n      if(expandedProperty !== '@graph' && expandedProperty !== '@list' &&\n        expandedProperty !== '@included' &&\n        _isKeyword(expandedProperty)) {\n        // use keyword alias and add value as is\n        const alias = api.compactIri({\n          activeCtx,\n          iri: expandedProperty,\n          relativeTo: {vocab: true}\n        });\n        _addValue(rval, alias, expandedValue);\n        continue;\n      }\n\n      // Note: expanded value must be an array due to expansion algorithm.\n      if(!_isArray(expandedValue)) {\n        throw new JsonLdError(\n          'JSON-LD expansion error; expanded value must be an array.',\n          'jsonld.SyntaxError');\n      }\n\n      // preserve empty arrays\n      if(expandedValue.length === 0) {\n        const itemActiveProperty = api.compactIri({\n          activeCtx,\n          iri: expandedProperty,\n          value: expandedValue,\n          relativeTo: {vocab: true},\n          reverse: insideReverse\n        });\n        const nestProperty = activeCtx.mappings.has(itemActiveProperty) ?\n          activeCtx.mappings.get(itemActiveProperty)['@nest'] : null;\n        let nestResult = rval;\n        if(nestProperty) {\n          _checkNestProperty(activeCtx, nestProperty, options);\n          if(!_isObject(rval[nestProperty])) {\n            rval[nestProperty] = {};\n          }\n          nestResult = rval[nestProperty];\n        }\n        _addValue(\n          nestResult, itemActiveProperty, expandedValue, {\n            propertyIsArray: true\n          });\n      }\n\n      // recusively process array values\n      for(const expandedItem of expandedValue) {\n        // compact property and get container type\n        const itemActiveProperty = api.compactIri({\n          activeCtx,\n          iri: expandedProperty,\n          value: expandedItem,\n          relativeTo: {vocab: true},\n          reverse: insideReverse\n        });\n\n        // if itemActiveProperty is a @nest property, add values to nestResult,\n        // otherwise rval\n        const nestProperty = activeCtx.mappings.has(itemActiveProperty) ?\n          activeCtx.mappings.get(itemActiveProperty)['@nest'] : null;\n        let nestResult = rval;\n        if(nestProperty) {\n          _checkNestProperty(activeCtx, nestProperty, options);\n          if(!_isObject(rval[nestProperty])) {\n            rval[nestProperty] = {};\n          }\n          nestResult = rval[nestProperty];\n        }\n\n        const container = _getContextValue(\n          activeCtx, itemActiveProperty, '@container') || [];\n\n        // get simple @graph or @list value if appropriate\n        const isGraph = _isGraph(expandedItem);\n        const isList = _isList(expandedItem);\n        let inner;\n        if(isList) {\n          inner = expandedItem['@list'];\n        } else if(isGraph) {\n          inner = expandedItem['@graph'];\n        }\n\n        // recursively compact expanded item\n        let compactedItem = await api.compact({\n          activeCtx,\n          activeProperty: itemActiveProperty,\n          element: (isList || isGraph) ? inner : expandedItem,\n          options,\n          compactionMap\n        });\n\n        // handle @list\n        if(isList) {\n          // ensure @list value is an array\n          if(!_isArray(compactedItem)) {\n            compactedItem = [compactedItem];\n          }\n\n          if(!container.includes('@list')) {\n            // wrap using @list alias\n            compactedItem = {\n              [api.compactIri({\n                activeCtx,\n                iri: '@list',\n                relativeTo: {vocab: true}\n              })]: compactedItem\n            };\n\n            // include @index from expanded @list, if any\n            if('@index' in expandedItem) {\n              compactedItem[api.compactIri({\n                activeCtx,\n                iri: '@index',\n                relativeTo: {vocab: true}\n              })] = expandedItem['@index'];\n            }\n          } else {\n            _addValue(nestResult, itemActiveProperty, compactedItem, {\n              valueIsArray: true,\n              allowDuplicate: true\n            });\n            continue;\n          }\n        }\n\n        // Graph object compaction cases\n        if(isGraph) {\n          if(container.includes('@graph') && (container.includes('@id') ||\n            container.includes('@index') && _isSimpleGraph(expandedItem))) {\n            // get or create the map object\n            let mapObject;\n            if(nestResult.hasOwnProperty(itemActiveProperty)) {\n              mapObject = nestResult[itemActiveProperty];\n            } else {\n              nestResult[itemActiveProperty] = mapObject = {};\n            }\n\n            // index on @id or @index or alias of @none\n            const key = (container.includes('@id') ?\n              expandedItem['@id'] : expandedItem['@index']) ||\n              api.compactIri({activeCtx, iri: '@none',\n                relativeTo: {vocab: true}});\n            // add compactedItem to map, using value of `@id` or a new blank\n            // node identifier\n\n            _addValue(\n              mapObject, key, compactedItem, {\n                propertyIsArray:\n                  (!options.compactArrays || container.includes('@set'))\n              });\n          } else if(container.includes('@graph') &&\n            _isSimpleGraph(expandedItem)) {\n            // container includes @graph but not @id or @index and value is a\n            // simple graph object add compact value\n            // if compactedItem contains multiple values, it is wrapped in\n            // `@included`\n            if(_isArray(compactedItem) && compactedItem.length > 1) {\n              compactedItem = {'@included': compactedItem};\n            }\n            _addValue(\n              nestResult, itemActiveProperty, compactedItem, {\n                propertyIsArray:\n                  (!options.compactArrays || container.includes('@set'))\n              });\n          } else {\n            // wrap using @graph alias, remove array if only one item and\n            // compactArrays not set\n            if(_isArray(compactedItem) && compactedItem.length === 1 &&\n              options.compactArrays) {\n              compactedItem = compactedItem[0];\n            }\n            compactedItem = {\n              [api.compactIri({\n                activeCtx,\n                iri: '@graph',\n                relativeTo: {vocab: true}\n              })]: compactedItem\n            };\n\n            // include @id from expanded graph, if any\n            if('@id' in expandedItem) {\n              compactedItem[api.compactIri({\n                activeCtx,\n                iri: '@id',\n                relativeTo: {vocab: true}\n              })] = expandedItem['@id'];\n            }\n\n            // include @index from expanded graph, if any\n            if('@index' in expandedItem) {\n              compactedItem[api.compactIri({\n                activeCtx,\n                iri: '@index',\n                relativeTo: {vocab: true}\n              })] = expandedItem['@index'];\n            }\n            _addValue(\n              nestResult, itemActiveProperty, compactedItem, {\n                propertyIsArray:\n                  (!options.compactArrays || container.includes('@set'))\n              });\n          }\n        } else if(container.includes('@language') ||\n          container.includes('@index') || container.includes('@id') ||\n          container.includes('@type')) {\n          // handle language and index maps\n          // get or create the map object\n          let mapObject;\n          if(nestResult.hasOwnProperty(itemActiveProperty)) {\n            mapObject = nestResult[itemActiveProperty];\n          } else {\n            nestResult[itemActiveProperty] = mapObject = {};\n          }\n\n          let key;\n          if(container.includes('@language')) {\n          // if container is a language map, simplify compacted value to\n          // a simple string\n            if(_isValue(compactedItem)) {\n              compactedItem = compactedItem['@value'];\n            }\n            key = expandedItem['@language'];\n          } else if(container.includes('@index')) {\n            const indexKey = _getContextValue(\n              activeCtx, itemActiveProperty, '@index') || '@index';\n            const containerKey = api.compactIri(\n              {activeCtx, iri: indexKey, relativeTo: {vocab: true}});\n            if(indexKey === '@index') {\n              key = expandedItem['@index'];\n              delete compactedItem[containerKey];\n            } else {\n              let others;\n              [key, ...others] = _asArray(compactedItem[indexKey] || []);\n              if(!_isString(key)) {\n                // Will use @none if it isn't a string.\n                key = null;\n              } else {\n                switch(others.length) {\n                  case 0:\n                    delete compactedItem[indexKey];\n                    break;\n                  case 1:\n                    compactedItem[indexKey] = others[0];\n                    break;\n                  default:\n                    compactedItem[indexKey] = others;\n                    break;\n                }\n              }\n            }\n          } else if(container.includes('@id')) {\n            const idKey = api.compactIri({activeCtx, iri: '@id',\n              relativeTo: {vocab: true}});\n            key = compactedItem[idKey];\n            delete compactedItem[idKey];\n          } else if(container.includes('@type')) {\n            const typeKey = api.compactIri({\n              activeCtx,\n              iri: '@type',\n              relativeTo: {vocab: true}\n            });\n            let types;\n            [key, ...types] = _asArray(compactedItem[typeKey] || []);\n            switch(types.length) {\n              case 0:\n                delete compactedItem[typeKey];\n                break;\n              case 1:\n                compactedItem[typeKey] = types[0];\n                break;\n              default:\n                compactedItem[typeKey] = types;\n                break;\n            }\n\n            // If compactedItem contains a single entry\n            // whose key maps to @id, recompact without @type\n            if(Object.keys(compactedItem).length === 1 &&\n              '@id' in expandedItem) {\n              compactedItem = await api.compact({\n                activeCtx,\n                activeProperty: itemActiveProperty,\n                element: {'@id': expandedItem['@id']},\n                options,\n                compactionMap\n              });\n            }\n          }\n\n          // if compacting this value which has no key, index on @none\n          if(!key) {\n            key = api.compactIri({activeCtx, iri: '@none',\n              relativeTo: {vocab: true}});\n          }\n          // add compact value to map object using key from expanded value\n          // based on the container type\n          _addValue(\n            mapObject, key, compactedItem, {\n              propertyIsArray: container.includes('@set')\n            });\n        } else {\n          // use an array if: compactArrays flag is false,\n          // @container is @set or @list , value is an empty\n          // array, or key is @graph\n          const isArray = (!options.compactArrays ||\n            container.includes('@set') || container.includes('@list') ||\n            (_isArray(compactedItem) && compactedItem.length === 0) ||\n            expandedProperty === '@list' || expandedProperty === '@graph');\n\n          // add compact value\n          _addValue(\n            nestResult, itemActiveProperty, compactedItem,\n            {propertyIsArray: isArray});\n        }\n      }\n    }\n\n    return rval;\n  }\n\n  // only primitives remain which are already compact\n  return element;\n};\n\n/**\n * Compacts an IRI or keyword into a term or prefix if it can be. If the\n * IRI has an associated value it may be passed.\n *\n * @param activeCtx the active context to use.\n * @param iri the IRI to compact.\n * @param value the value to check or null.\n * @param relativeTo options for how to compact IRIs:\n *          vocab: true to split after @vocab, false not to.\n * @param reverse true if a reverse property is being compacted, false if not.\n * @param base the absolute URL to use for compacting document-relative IRIs.\n *\n * @return the compacted term, prefix, keyword alias, or the original IRI.\n */\napi.compactIri = ({\n  activeCtx,\n  iri,\n  value = null,\n  relativeTo = {vocab: false},\n  reverse = false,\n  base = null\n}) => {\n  // can't compact null\n  if(iri === null) {\n    return iri;\n  }\n\n  // if context is from a property term scoped context composed with a\n  // type-scoped context, then use the previous context instead\n  if(activeCtx.isPropertyTermScoped && activeCtx.previousContext) {\n    activeCtx = activeCtx.previousContext;\n  }\n\n  const inverseCtx = activeCtx.getInverse();\n\n  // if term is a keyword, it may be compacted to a simple alias\n  if(_isKeyword(iri) &&\n    iri in inverseCtx &&\n    '@none' in inverseCtx[iri] &&\n    '@type' in inverseCtx[iri]['@none'] &&\n    '@none' in inverseCtx[iri]['@none']['@type']) {\n    return inverseCtx[iri]['@none']['@type']['@none'];\n  }\n\n  // use inverse context to pick a term if iri is relative to vocab\n  if(relativeTo.vocab && iri in inverseCtx) {\n    const defaultLanguage = activeCtx['@language'] || '@none';\n\n    // prefer @index if available in value\n    const containers = [];\n    if(_isObject(value) && '@index' in value && !('@graph' in value)) {\n      containers.push('@index', '@index@set');\n    }\n\n    // if value is a preserve object, use its value\n    if(_isObject(value) && '@preserve' in value) {\n      value = value['@preserve'][0];\n    }\n\n    // prefer most specific container including @graph, prefering @set\n    // variations\n    if(_isGraph(value)) {\n      // favor indexmap if the graph is indexed\n      if('@index' in value) {\n        containers.push(\n          '@graph@index', '@graph@index@set', '@index', '@index@set');\n      }\n      // favor idmap if the graph is has an @id\n      if('@id' in value) {\n        containers.push(\n          '@graph@id', '@graph@id@set');\n      }\n      containers.push('@graph', '@graph@set', '@set');\n      // allow indexmap if the graph is not indexed\n      if(!('@index' in value)) {\n        containers.push(\n          '@graph@index', '@graph@index@set', '@index', '@index@set');\n      }\n      // allow idmap if the graph does not have an @id\n      if(!('@id' in value)) {\n        containers.push('@graph@id', '@graph@id@set');\n      }\n    } else if(_isObject(value) && !_isValue(value)) {\n      containers.push('@id', '@id@set', '@type', '@set@type');\n    }\n\n    // defaults for term selection based on type/language\n    let typeOrLanguage = '@language';\n    let typeOrLanguageValue = '@null';\n\n    if(reverse) {\n      typeOrLanguage = '@type';\n      typeOrLanguageValue = '@reverse';\n      containers.push('@set');\n    } else if(_isList(value)) {\n      // choose the most specific term that works for all elements in @list\n      // only select @list containers if @index is NOT in value\n      if(!('@index' in value)) {\n        containers.push('@list');\n      }\n      const list = value['@list'];\n      if(list.length === 0) {\n        // any empty list can be matched against any term that uses the\n        // @list container regardless of @type or @language\n        typeOrLanguage = '@any';\n        typeOrLanguageValue = '@none';\n      } else {\n        let commonLanguage = (list.length === 0) ? defaultLanguage : null;\n        let commonType = null;\n        for(let i = 0; i < list.length; ++i) {\n          const item = list[i];\n          let itemLanguage = '@none';\n          let itemType = '@none';\n          if(_isValue(item)) {\n            if('@direction' in item) {\n              const lang = (item['@language'] || '').toLowerCase();\n              const dir = item['@direction'];\n              itemLanguage = `${lang}_${dir}`;\n            } else if('@language' in item) {\n              itemLanguage = item['@language'].toLowerCase();\n            } else if('@type' in item) {\n              itemType = item['@type'];\n            } else {\n              // plain literal\n              itemLanguage = '@null';\n            }\n          } else {\n            itemType = '@id';\n          }\n          if(commonLanguage === null) {\n            commonLanguage = itemLanguage;\n          } else if(itemLanguage !== commonLanguage && _isValue(item)) {\n            commonLanguage = '@none';\n          }\n          if(commonType === null) {\n            commonType = itemType;\n          } else if(itemType !== commonType) {\n            commonType = '@none';\n          }\n          // there are different languages and types in the list, so choose\n          // the most generic term, no need to keep iterating the list\n          if(commonLanguage === '@none' && commonType === '@none') {\n            break;\n          }\n        }\n        commonLanguage = commonLanguage || '@none';\n        commonType = commonType || '@none';\n        if(commonType !== '@none') {\n          typeOrLanguage = '@type';\n          typeOrLanguageValue = commonType;\n        } else {\n          typeOrLanguageValue = commonLanguage;\n        }\n      }\n    } else {\n      if(_isValue(value)) {\n        if('@language' in value && !('@index' in value)) {\n          containers.push('@language', '@language@set');\n          typeOrLanguageValue = value['@language'];\n          const dir = value['@direction'];\n          if(dir) {\n            typeOrLanguageValue = `${typeOrLanguageValue}_${dir}`;\n          }\n        } else if('@direction' in value && !('@index' in value)) {\n          typeOrLanguageValue = `_${value['@direction']}`;\n        } else if('@type' in value) {\n          typeOrLanguage = '@type';\n          typeOrLanguageValue = value['@type'];\n        }\n      } else {\n        typeOrLanguage = '@type';\n        typeOrLanguageValue = '@id';\n      }\n      containers.push('@set');\n    }\n\n    // do term selection\n    containers.push('@none');\n\n    // an index map can be used to index values using @none, so add as a low\n    // priority\n    if(_isObject(value) && !('@index' in value)) {\n      // allow indexing even if no @index present\n      containers.push('@index', '@index@set');\n    }\n\n    // values without type or language can use @language map\n    if(_isValue(value) && Object.keys(value).length === 1) {\n      // allow indexing even if no @index present\n      containers.push('@language', '@language@set');\n    }\n\n    const term = _selectTerm(\n      activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue);\n    if(term !== null) {\n      return term;\n    }\n  }\n\n  // no term match, use @vocab if available\n  if(relativeTo.vocab) {\n    if('@vocab' in activeCtx) {\n      // determine if vocab is a prefix of the iri\n      const vocab = activeCtx['@vocab'];\n      if(iri.indexOf(vocab) === 0 && iri !== vocab) {\n        // use suffix as relative iri if it is not a term in the active context\n        const suffix = iri.substr(vocab.length);\n        if(!activeCtx.mappings.has(suffix)) {\n          return suffix;\n        }\n      }\n    }\n  }\n\n  // no term or @vocab match, check for possible CURIEs\n  let choice = null;\n  // TODO: make FastCurieMap a class with a method to do this lookup\n  const partialMatches = [];\n  let iriMap = activeCtx.fastCurieMap;\n  // check for partial matches of against `iri`, which means look until\n  // iri.length - 1, not full length\n  const maxPartialLength = iri.length - 1;\n  for(let i = 0; i < maxPartialLength && iri[i] in iriMap; ++i) {\n    iriMap = iriMap[iri[i]];\n    if('' in iriMap) {\n      partialMatches.push(iriMap[''][0]);\n    }\n  }\n  // check partial matches in reverse order to prefer longest ones first\n  for(let i = partialMatches.length - 1; i >= 0; --i) {\n    const entry = partialMatches[i];\n    const terms = entry.terms;\n    for(const term of terms) {\n      // a CURIE is usable if:\n      // 1. it has no mapping, OR\n      // 2. value is null, which means we're not compacting an @value, AND\n      //   the mapping matches the IRI\n      const curie = term + ':' + iri.substr(entry.iri.length);\n      const isUsableCurie = (activeCtx.mappings.get(term)._prefix &&\n        (!activeCtx.mappings.has(curie) ||\n        (value === null && activeCtx.mappings.get(curie)['@id'] === iri)));\n\n      // select curie if it is shorter or the same length but lexicographically\n      // less than the current choice\n      if(isUsableCurie && (choice === null ||\n        _compareShortestLeast(curie, choice) < 0)) {\n        choice = curie;\n      }\n    }\n  }\n\n  // return chosen curie\n  if(choice !== null) {\n    return choice;\n  }\n\n  // If iri could be confused with a compact IRI using a term in this context,\n  // signal an error\n  for(const [term, td] of activeCtx.mappings) {\n    if(td && td._prefix && iri.startsWith(term + ':')) {\n      throw new JsonLdError(\n        `Absolute IRI \"${iri}\" confused with prefix \"${term}\".`,\n        'jsonld.SyntaxError',\n        {code: 'IRI confused with prefix', context: activeCtx});\n    }\n  }\n\n  // compact IRI relative to base\n  if(!relativeTo.vocab) {\n    if('@base' in activeCtx) {\n      if(!activeCtx['@base']) {\n        // The None case preserves rval as potentially relative\n        return iri;\n      } else {\n        return _removeBase(_prependBase(base, activeCtx['@base']), iri);\n      }\n    } else {\n      return _removeBase(base, iri);\n    }\n  }\n\n  // return IRI as is\n  return iri;\n};\n\n/**\n * Performs value compaction on an object with '@value' or '@id' as the only\n * property.\n *\n * @param activeCtx the active context.\n * @param activeProperty the active property that points to the value.\n * @param value the value to compact.\n * @param {Object} [options] - processing options.\n *\n * @return the compaction result.\n */\napi.compactValue = ({activeCtx, activeProperty, value, options}) => {\n  // value is a @value\n  if(_isValue(value)) {\n    // get context rules\n    const type = _getContextValue(activeCtx, activeProperty, '@type');\n    const language = _getContextValue(activeCtx, activeProperty, '@language');\n    const direction = _getContextValue(activeCtx, activeProperty, '@direction');\n    const container =\n      _getContextValue(activeCtx, activeProperty, '@container') || [];\n\n    // whether or not the value has an @index that must be preserved\n    const preserveIndex = '@index' in value && !container.includes('@index');\n\n    // if there's no @index to preserve ...\n    if(!preserveIndex && type !== '@none') {\n      // matching @type or @language specified in context, compact value\n      if(value['@type'] === type) {\n        return value['@value'];\n      }\n      if('@language' in value && value['@language'] === language &&\n         '@direction' in value && value['@direction'] === direction) {\n        return value['@value'];\n      }\n      if('@language' in value && value['@language'] === language) {\n        return value['@value'];\n      }\n      if('@direction' in value && value['@direction'] === direction) {\n        return value['@value'];\n      }\n    }\n\n    // return just the value of @value if all are true:\n    // 1. @value is the only key or @index isn't being preserved\n    // 2. there is no default language or @value is not a string or\n    //   the key has a mapping with a null @language\n    const keyCount = Object.keys(value).length;\n    const isValueOnlyKey = (keyCount === 1 ||\n      (keyCount === 2 && '@index' in value && !preserveIndex));\n    const hasDefaultLanguage = ('@language' in activeCtx);\n    const isValueString = _isString(value['@value']);\n    const hasNullMapping = (activeCtx.mappings.has(activeProperty) &&\n      activeCtx.mappings.get(activeProperty)['@language'] === null);\n    if(isValueOnlyKey &&\n      type !== '@none' &&\n      (!hasDefaultLanguage || !isValueString || hasNullMapping)) {\n      return value['@value'];\n    }\n\n    const rval = {};\n\n    // preserve @index\n    if(preserveIndex) {\n      rval[api.compactIri({\n        activeCtx,\n        iri: '@index',\n        relativeTo: {vocab: true}\n      })] = value['@index'];\n    }\n\n    if('@type' in value) {\n      // compact @type IRI\n      rval[api.compactIri({\n        activeCtx,\n        iri: '@type',\n        relativeTo: {vocab: true}\n      })] = api.compactIri(\n        {activeCtx, iri: value['@type'], relativeTo: {vocab: true}});\n    } else if('@language' in value) {\n      // alias @language\n      rval[api.compactIri({\n        activeCtx,\n        iri: '@language',\n        relativeTo: {vocab: true}\n      })] = value['@language'];\n    }\n\n    if('@direction' in value) {\n      // alias @direction\n      rval[api.compactIri({\n        activeCtx,\n        iri: '@direction',\n        relativeTo: {vocab: true}\n      })] = value['@direction'];\n    }\n\n    // alias @value\n    rval[api.compactIri({\n      activeCtx,\n      iri: '@value',\n      relativeTo: {vocab: true}\n    })] = value['@value'];\n\n    return rval;\n  }\n\n  // value is a subject reference\n  const expandedProperty = _expandIri(activeCtx, activeProperty, {vocab: true},\n    options);\n  const type = _getContextValue(activeCtx, activeProperty, '@type');\n  const compacted = api.compactIri({\n    activeCtx,\n    iri: value['@id'],\n    relativeTo: {vocab: type === '@vocab'},\n    base: options.base});\n\n  // compact to scalar\n  if(type === '@id' || type === '@vocab' || expandedProperty === '@graph') {\n    return compacted;\n  }\n\n  return {\n    [api.compactIri({\n      activeCtx,\n      iri: '@id',\n      relativeTo: {vocab: true}\n    })]: compacted\n  };\n};\n\n/**\n * Picks the preferred compaction term from the given inverse context entry.\n *\n * @param activeCtx the active context.\n * @param iri the IRI to pick the term for.\n * @param value the value to pick the term for.\n * @param containers the preferred containers.\n * @param typeOrLanguage either '@type' or '@language'.\n * @param typeOrLanguageValue the preferred value for '@type' or '@language'.\n *\n * @return the preferred term.\n */\nfunction _selectTerm(\n  activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue) {\n  if(typeOrLanguageValue === null) {\n    typeOrLanguageValue = '@null';\n  }\n\n  // preferences for the value of @type or @language\n  const prefs = [];\n\n  // determine prefs for @id based on whether or not value compacts to a term\n  if((typeOrLanguageValue === '@id' || typeOrLanguageValue === '@reverse') &&\n    _isObject(value) && '@id' in value) {\n    // prefer @reverse first\n    if(typeOrLanguageValue === '@reverse') {\n      prefs.push('@reverse');\n    }\n    // try to compact value to a term\n    const term = api.compactIri(\n      {activeCtx, iri: value['@id'], relativeTo: {vocab: true}});\n    if(activeCtx.mappings.has(term) &&\n      activeCtx.mappings.get(term) &&\n      activeCtx.mappings.get(term)['@id'] === value['@id']) {\n      // prefer @vocab\n      prefs.push.apply(prefs, ['@vocab', '@id']);\n    } else {\n      // prefer @id\n      prefs.push.apply(prefs, ['@id', '@vocab']);\n    }\n  } else {\n    prefs.push(typeOrLanguageValue);\n\n    // consider direction only\n    const langDir = prefs.find(el => el.includes('_'));\n    if(langDir) {\n      // consider _dir portion\n      prefs.push(langDir.replace(/^[^_]+_/, '_'));\n    }\n  }\n  prefs.push('@none');\n\n  const containerMap = activeCtx.inverse[iri];\n  for(const container of containers) {\n    // if container not available in the map, continue\n    if(!(container in containerMap)) {\n      continue;\n    }\n\n    const typeOrLanguageValueMap = containerMap[container][typeOrLanguage];\n    for(const pref of prefs) {\n      // if type/language option not available in the map, continue\n      if(!(pref in typeOrLanguageValueMap)) {\n        continue;\n      }\n\n      // select term\n      return typeOrLanguageValueMap[pref];\n    }\n  }\n\n  return null;\n}\n\n/**\n * The value of `@nest` in the term definition must either be `@nest`, or a term\n * which resolves to `@nest`.\n *\n * @param activeCtx the active context.\n * @param nestProperty a term in the active context or `@nest`.\n * @param {Object} [options] - processing options.\n */\nfunction _checkNestProperty(activeCtx, nestProperty, options) {\n  if(_expandIri(activeCtx, nestProperty, {vocab: true}, options) !== '@nest') {\n    throw new JsonLdError(\n      'JSON-LD compact error; nested property must have an @nest value ' +\n      'resolving to @nest.',\n      'jsonld.SyntaxError', {code: 'invalid @nest value'});\n  }\n}\n","/**\n * A JavaScript implementation of the JSON-LD API.\n *\n * @author Dave Longley\n *\n * @license BSD 3-Clause License\n * Copyright (c) 2011-2019 Digital Bazaar, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * Redistributions of source code must retain the above copyright notice,\n * this list of conditions and the following disclaimer.\n *\n * Redistributions in binary form must reproduce the above copyright\n * notice, this list of conditions and the following disclaimer in the\n * documentation and/or other materials provided with the distribution.\n *\n * Neither the name of the Digital Bazaar, Inc. nor the names of its\n * contributors may be used to endorse or promote products derived from\n * this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\n * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\nconst canonize = require('rdf-canonize');\nconst platform = require('./platform');\nconst util = require('./util');\nconst ContextResolver = require('./ContextResolver');\nconst IdentifierIssuer = util.IdentifierIssuer;\nconst JsonLdError = require('./JsonLdError');\nconst LRU = require('lru-cache');\nconst NQuads = require('./NQuads');\n\nconst {expand: _expand} = require('./expand');\nconst {flatten: _flatten} = require('./flatten');\nconst {fromRDF: _fromRDF} = require('./fromRdf');\nconst {toRDF: _toRDF} = require('./toRdf');\n\nconst {\n  frameMergedOrDefault: _frameMergedOrDefault,\n  cleanupNull: _cleanupNull\n} = require('./frame');\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isString: _isString\n} = require('./types');\n\nconst {\n  isSubjectReference: _isSubjectReference,\n} = require('./graphTypes');\n\nconst {\n  expandIri: _expandIri,\n  getInitialContext: _getInitialContext,\n  process: _processContext,\n  processingMode: _processingMode\n} = require('./context');\n\nconst {\n  compact: _compact,\n  compactIri: _compactIri\n} = require('./compact');\n\nconst {\n  createNodeMap: _createNodeMap,\n  createMergedNodeMap: _createMergedNodeMap,\n  mergeNodeMaps: _mergeNodeMaps\n} = require('./nodeMap');\n\n/* eslint-disable indent */\n// attaches jsonld API to the given object\nconst wrapper = function(jsonld) {\n\n/** Registered RDF dataset parsers hashed by content-type. */\nconst _rdfParsers = {};\n\n// resolved context cache\n// TODO: consider basing max on context size rather than number\nconst RESOLVED_CONTEXT_CACHE_MAX_SIZE = 100;\nconst _resolvedContextCache = new LRU({max: RESOLVED_CONTEXT_CACHE_MAX_SIZE});\n\n/* Core API */\n\n/**\n * Performs JSON-LD compaction.\n *\n * @param input the JSON-LD input to compact.\n * @param ctx the context to compact with.\n * @param [options] options to use:\n *          [base] the base IRI to use.\n *          [compactArrays] true to compact arrays to single values when\n *            appropriate, false not to (default: true).\n *          [compactToRelative] true to compact IRIs to be relative to document\n *            base, false to keep absolute (default: true)\n *          [graph] true to always output a top-level graph (default: false).\n *          [expandContext] a context to expand with.\n *          [skipExpansion] true to assume the input is expanded and skip\n *            expansion, false not to, defaults to false.\n *          [documentLoader(url, options)] the document loader.\n *          [expansionMap(info)] a function that can be used to custom map\n *            unmappable values (or to throw an error when they are detected);\n *            if this function returns `undefined` then the default behavior\n *            will be used.\n *          [framing] true if compaction is occuring during a framing operation.\n *          [compactionMap(info)] a function that can be used to custom map\n *            unmappable values (or to throw an error when they are detected);\n *            if this function returns `undefined` then the default behavior\n *            will be used.\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the compacted output.\n */\njsonld.compact = async function(input, ctx, options) {\n  if(arguments.length < 2) {\n    throw new TypeError('Could not compact, too few arguments.');\n  }\n\n  if(ctx === null) {\n    throw new JsonLdError(\n      'The compaction context must not be null.',\n      'jsonld.CompactError', {code: 'invalid local context'});\n  }\n\n  // nothing to compact\n  if(input === null) {\n    return null;\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    compactArrays: true,\n    compactToRelative: true,\n    graph: false,\n    skipExpansion: false,\n    link: false,\n    issuer: new IdentifierIssuer('_:b'),\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n  if(options.link) {\n    // force skip expansion when linking, \"link\" is not part of the public\n    // API, it should only be called from framing\n    options.skipExpansion = true;\n  }\n  if(!options.compactToRelative) {\n    delete options.base;\n  }\n\n  // expand input\n  let expanded;\n  if(options.skipExpansion) {\n    expanded = input;\n  } else {\n    expanded = await jsonld.expand(input, options);\n  }\n\n  // process context\n  const activeCtx = await jsonld.processContext(\n    _getInitialContext(options), ctx, options);\n\n  // do compaction\n  let compacted = await _compact({\n    activeCtx,\n    element: expanded,\n    options,\n    compactionMap: options.compactionMap\n  });\n\n  // perform clean up\n  if(options.compactArrays && !options.graph && _isArray(compacted)) {\n    if(compacted.length === 1) {\n      // simplify to a single item\n      compacted = compacted[0];\n    } else if(compacted.length === 0) {\n      // simplify to an empty object\n      compacted = {};\n    }\n  } else if(options.graph && _isObject(compacted)) {\n    // always use array if graph option is on\n    compacted = [compacted];\n  }\n\n  // follow @context key\n  if(_isObject(ctx) && '@context' in ctx) {\n    ctx = ctx['@context'];\n  }\n\n  // build output context\n  ctx = util.clone(ctx);\n  if(!_isArray(ctx)) {\n    ctx = [ctx];\n  }\n  // remove empty contexts\n  const tmp = ctx;\n  ctx = [];\n  for(let i = 0; i < tmp.length; ++i) {\n    if(!_isObject(tmp[i]) || Object.keys(tmp[i]).length > 0) {\n      ctx.push(tmp[i]);\n    }\n  }\n\n  // remove array if only one context\n  const hasContext = (ctx.length > 0);\n  if(ctx.length === 1) {\n    ctx = ctx[0];\n  }\n\n  // add context and/or @graph\n  if(_isArray(compacted)) {\n    // use '@graph' keyword\n    const graphAlias = _compactIri({\n      activeCtx, iri: '@graph', relativeTo: {vocab: true}\n    });\n    const graph = compacted;\n    compacted = {};\n    if(hasContext) {\n      compacted['@context'] = ctx;\n    }\n    compacted[graphAlias] = graph;\n  } else if(_isObject(compacted) && hasContext) {\n    // reorder keys so @context is first\n    const graph = compacted;\n    compacted = {'@context': ctx};\n    for(const key in graph) {\n      compacted[key] = graph[key];\n    }\n  }\n\n  return compacted;\n};\n\n/**\n * Performs JSON-LD expansion.\n *\n * @param input the JSON-LD input to expand.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [keepFreeFloatingNodes] true to keep free-floating nodes,\n *            false not to, defaults to false.\n *          [documentLoader(url, options)] the document loader.\n *          [expansionMap(info)] a function that can be used to custom map\n *            unmappable values (or to throw an error when they are detected);\n *            if this function returns `undefined` then the default behavior\n *            will be used.\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the expanded output.\n */\njsonld.expand = async function(input, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not expand, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    keepFreeFloatingNodes: false,\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n  if(options.expansionMap === false) {\n    options.expansionMap = undefined;\n  }\n\n  // build set of objects that may have @contexts to resolve\n  const toResolve = {};\n\n  // build set of contexts to process prior to expansion\n  const contextsToProcess = [];\n\n  // if an `expandContext` has been given ensure it gets resolved\n  if('expandContext' in options) {\n    const expandContext = util.clone(options.expandContext);\n    if(_isObject(expandContext) && '@context' in expandContext) {\n      toResolve.expandContext = expandContext;\n    } else {\n      toResolve.expandContext = {'@context': expandContext};\n    }\n    contextsToProcess.push(toResolve.expandContext);\n  }\n\n  // if input is a string, attempt to dereference remote document\n  let defaultBase;\n  if(!_isString(input)) {\n    // input is not a URL, do not need to retrieve it first\n    toResolve.input = util.clone(input);\n  } else {\n    // load remote doc\n    const remoteDoc = await jsonld.get(input, options);\n    defaultBase = remoteDoc.documentUrl;\n    toResolve.input = remoteDoc.document;\n    if(remoteDoc.contextUrl) {\n      // context included in HTTP link header and must be resolved\n      toResolve.remoteContext = {'@context': remoteDoc.contextUrl};\n      contextsToProcess.push(toResolve.remoteContext);\n    }\n  }\n\n  // set default base\n  if(!('base' in options)) {\n    options.base = defaultBase || '';\n  }\n\n  // process any additional contexts\n  let activeCtx = _getInitialContext(options);\n  for(const localCtx of contextsToProcess) {\n    activeCtx = await _processContext({activeCtx, localCtx, options});\n  }\n\n  // expand resolved input\n  let expanded = await _expand({\n    activeCtx,\n    element: toResolve.input,\n    options,\n    expansionMap: options.expansionMap\n  });\n\n  // optimize away @graph with no other properties\n  if(_isObject(expanded) && ('@graph' in expanded) &&\n    Object.keys(expanded).length === 1) {\n    expanded = expanded['@graph'];\n  } else if(expanded === null) {\n    expanded = [];\n  }\n\n  // normalize to an array\n  if(!_isArray(expanded)) {\n    expanded = [expanded];\n  }\n\n  return expanded;\n};\n\n/**\n * Performs JSON-LD flattening.\n *\n * @param input the JSON-LD to flatten.\n * @param ctx the context to use to compact the flattened output, or null.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [documentLoader(url, options)] the document loader.\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the flattened output.\n */\njsonld.flatten = async function(input, ctx, options) {\n  if(arguments.length < 1) {\n    return new TypeError('Could not flatten, too few arguments.');\n  }\n\n  if(typeof ctx === 'function') {\n    ctx = null;\n  } else {\n    ctx = ctx || null;\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // expand input\n  const expanded = await jsonld.expand(input, options);\n\n  // do flattening\n  const flattened = _flatten(expanded);\n\n  if(ctx === null) {\n    // no compaction required\n    return flattened;\n  }\n\n  // compact result (force @graph option to true, skip expansion)\n  options.graph = true;\n  options.skipExpansion = true;\n  const compacted = await jsonld.compact(flattened, ctx, options);\n\n  return compacted;\n};\n\n/**\n * Performs JSON-LD framing.\n *\n * @param input the JSON-LD input to frame.\n * @param frame the JSON-LD frame to use.\n * @param [options] the framing options.\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [embed] default @embed flag: '@last', '@always', '@never', '@link'\n *            (default: '@last').\n *          [explicit] default @explicit flag (default: false).\n *          [requireAll] default @requireAll flag (default: true).\n *          [omitDefault] default @omitDefault flag (default: false).\n *          [documentLoader(url, options)] the document loader.\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the framed output.\n */\njsonld.frame = async function(input, frame, options) {\n  if(arguments.length < 2) {\n    throw new TypeError('Could not frame, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    embed: '@once',\n    explicit: false,\n    requireAll: false,\n    omitDefault: false,\n    bnodesToClear: [],\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // if frame is a string, attempt to dereference remote document\n  if(_isString(frame)) {\n    // load remote doc\n    const remoteDoc = await jsonld.get(frame, options);\n    frame = remoteDoc.document;\n\n    if(remoteDoc.contextUrl) {\n      // inject link header @context into frame\n      let ctx = frame['@context'];\n      if(!ctx) {\n        ctx = remoteDoc.contextUrl;\n      } else if(_isArray(ctx)) {\n        ctx.push(remoteDoc.contextUrl);\n      } else {\n        ctx = [ctx, remoteDoc.contextUrl];\n      }\n      frame['@context'] = ctx;\n    }\n  }\n\n  const frameContext = frame ? frame['@context'] || {} : {};\n\n  // process context\n  const activeCtx = await jsonld.processContext(\n    _getInitialContext(options), frameContext, options);\n\n  // mode specific defaults\n  if(!options.hasOwnProperty('omitGraph')) {\n    options.omitGraph = _processingMode(activeCtx, 1.1);\n  }\n  if(!options.hasOwnProperty('pruneBlankNodeIdentifiers')) {\n    options.pruneBlankNodeIdentifiers = _processingMode(activeCtx, 1.1);\n  }\n\n  // expand input\n  const expanded = await jsonld.expand(input, options);\n\n  // expand frame\n  const opts = {...options};\n  opts.isFrame = true;\n  opts.keepFreeFloatingNodes = true;\n  const expandedFrame = await jsonld.expand(frame, opts);\n\n  // if the unexpanded frame includes a key expanding to @graph, frame the\n  // default graph, otherwise, the merged graph\n  const frameKeys = Object.keys(frame)\n    .map(key => _expandIri(activeCtx, key, {vocab: true}));\n  opts.merged = !frameKeys.includes('@graph');\n  opts.is11 = _processingMode(activeCtx, 1.1);\n\n  // do framing\n  const framed = _frameMergedOrDefault(expanded, expandedFrame, opts);\n\n  opts.graph = !options.omitGraph;\n  opts.skipExpansion = true;\n  opts.link = {};\n  opts.framing = true;\n  let compacted = await jsonld.compact(framed, frameContext, opts);\n\n  // replace @null with null, compacting arrays\n  opts.link = {};\n  compacted = _cleanupNull(compacted, opts);\n\n  return compacted;\n};\n\n/**\n * **Experimental**\n *\n * Links a JSON-LD document's nodes in memory.\n *\n * @param input the JSON-LD document to link.\n * @param [ctx] the JSON-LD context to apply.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [documentLoader(url, options)] the document loader.\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the linked output.\n */\njsonld.link = async function(input, ctx, options) {\n  // API matches running frame with a wildcard frame and embed: '@link'\n  // get arguments\n  const frame = {};\n  if(ctx) {\n    frame['@context'] = ctx;\n  }\n  frame['@embed'] = '@link';\n  return jsonld.frame(input, frame, options);\n};\n\n/**\n * Performs RDF dataset normalization on the given input. The input is JSON-LD\n * unless the 'inputFormat' option is used. The output is an RDF dataset\n * unless the 'format' option is used.\n *\n * @param input the input to normalize as JSON-LD or as a format specified by\n *          the 'inputFormat' option.\n * @param [options] the options to use:\n *          [algorithm] the normalization algorithm to use, `URDNA2015` or\n *            `URGNA2012` (default: `URDNA2015`).\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [skipExpansion] true to assume the input is expanded and skip\n *            expansion, false not to, defaults to false.\n *          [inputFormat] the format if input is not JSON-LD:\n *            'application/n-quads' for N-Quads.\n *          [format] the format if output is a string:\n *            'application/n-quads' for N-Quads.\n *          [documentLoader(url, options)] the document loader.\n *          [useNative] true to use a native canonize algorithm\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the normalized output.\n */\njsonld.normalize = jsonld.canonize = async function(input, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not canonize, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    algorithm: 'URDNA2015',\n    skipExpansion: false,\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n  if('inputFormat' in options) {\n    if(options.inputFormat !== 'application/n-quads' &&\n      options.inputFormat !== 'application/nquads') {\n      throw new JsonLdError(\n        'Unknown canonicalization input format.',\n        'jsonld.CanonizeError');\n    }\n    // TODO: `await` for async parsers\n    const parsedInput = NQuads.parse(input);\n\n    // do canonicalization\n    return canonize.canonize(parsedInput, options);\n  }\n\n  // convert to RDF dataset then do normalization\n  const opts = {...options};\n  delete opts.format;\n  opts.produceGeneralizedRdf = false;\n  const dataset = await jsonld.toRDF(input, opts);\n\n  // do canonicalization\n  return canonize.canonize(dataset, options);\n};\n\n/**\n * Converts an RDF dataset to JSON-LD.\n *\n * @param dataset a serialized string of RDF in a format specified by the\n *          format option or an RDF dataset to convert.\n * @param [options] the options to use:\n *          [format] the format if dataset param must first be parsed:\n *            'application/n-quads' for N-Quads (default).\n *          [rdfParser] a custom RDF-parser to use to parse the dataset.\n *          [useRdfType] true to use rdf:type, false to use @type\n *            (default: false).\n *          [useNativeTypes] true to convert XSD types into native types\n *            (boolean, integer, double), false not to (default: false).\n *\n * @return a Promise that resolves to the JSON-LD document.\n */\njsonld.fromRDF = async function(dataset, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not convert from RDF, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    format: _isString(dataset) ? 'application/n-quads' : undefined\n  });\n\n  const {format} = options;\n  let {rdfParser} = options;\n\n  // handle special format\n  if(format) {\n    // check supported formats\n    rdfParser = rdfParser || _rdfParsers[format];\n    if(!rdfParser) {\n      throw new JsonLdError(\n        'Unknown input format.',\n        'jsonld.UnknownFormat', {format});\n    }\n  } else {\n    // no-op parser, assume dataset already parsed\n    rdfParser = () => dataset;\n  }\n\n  // rdfParser must be synchronous or return a promise, no callback support\n  const parsedDataset = await rdfParser(dataset);\n  return _fromRDF(parsedDataset, options);\n};\n\n/**\n * Outputs the RDF dataset found in the given JSON-LD object.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [skipExpansion] true to assume the input is expanded and skip\n *            expansion, false not to, defaults to false.\n *          [format] the format to use to output a string:\n *            'application/n-quads' for N-Quads.\n *          [produceGeneralizedRdf] true to output generalized RDF, false\n *            to produce only standard RDF (default: false).\n *          [documentLoader(url, options)] the document loader.\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the RDF dataset.\n */\njsonld.toRDF = async function(input, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not convert to RDF, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    skipExpansion: false,\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // TODO: support toRDF custom map?\n  let expanded;\n  if(options.skipExpansion) {\n    expanded = input;\n  } else {\n    // expand input\n    expanded = await jsonld.expand(input, options);\n  }\n\n  // output RDF dataset\n  const dataset = _toRDF(expanded, options);\n  if(options.format) {\n    if(options.format === 'application/n-quads' ||\n      options.format === 'application/nquads') {\n      return NQuads.serialize(dataset);\n    }\n    throw new JsonLdError(\n      'Unknown output format.',\n      'jsonld.UnknownFormat', {format: options.format});\n  }\n\n  return dataset;\n};\n\n/**\n * **Experimental**\n *\n * Recursively flattens the nodes in the given JSON-LD input into a merged\n * map of node ID => node. All graphs will be merged into the default graph.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [documentLoader(url, options)] the document loader.\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the merged node map.\n */\njsonld.createNodeMap = async function(input, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not create node map, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // expand input\n  const expanded = await jsonld.expand(input, options);\n\n  return _createMergedNodeMap(expanded, options);\n};\n\n/**\n * **Experimental**\n *\n * Merges two or more JSON-LD documents into a single flattened document.\n *\n * @param docs the JSON-LD documents to merge together.\n * @param ctx the context to use to compact the merged result, or null.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [mergeNodes] true to merge properties for nodes with the same ID,\n *            false to ignore new properties for nodes with the same ID once\n *            the ID has been defined; note that this may not prevent merging\n *            new properties where a node is in the `object` position\n *            (default: true).\n *          [documentLoader(url, options)] the document loader.\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the merged output.\n */\njsonld.merge = async function(docs, ctx, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not merge, too few arguments.');\n  }\n  if(!_isArray(docs)) {\n    throw new TypeError('Could not merge, \"docs\" must be an array.');\n  }\n\n  if(typeof ctx === 'function') {\n    ctx = null;\n  } else {\n    ctx = ctx || null;\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // expand all documents\n  const expanded = await Promise.all(docs.map(doc => {\n    const opts = {...options};\n    return jsonld.expand(doc, opts);\n  }));\n\n  let mergeNodes = true;\n  if('mergeNodes' in options) {\n    mergeNodes = options.mergeNodes;\n  }\n\n  const issuer = options.issuer || new IdentifierIssuer('_:b');\n  const graphs = {'@default': {}};\n\n  for(let i = 0; i < expanded.length; ++i) {\n    // uniquely relabel blank nodes\n    const doc = util.relabelBlankNodes(expanded[i], {\n      issuer: new IdentifierIssuer('_:b' + i + '-')\n    });\n\n    // add nodes to the shared node map graphs if merging nodes, to a\n    // separate graph set if not\n    const _graphs = (mergeNodes || i === 0) ? graphs : {'@default': {}};\n    _createNodeMap(doc, _graphs, '@default', issuer);\n\n    if(_graphs !== graphs) {\n      // merge document graphs but don't merge existing nodes\n      for(const graphName in _graphs) {\n        const _nodeMap = _graphs[graphName];\n        if(!(graphName in graphs)) {\n          graphs[graphName] = _nodeMap;\n          continue;\n        }\n        const nodeMap = graphs[graphName];\n        for(const key in _nodeMap) {\n          if(!(key in nodeMap)) {\n            nodeMap[key] = _nodeMap[key];\n          }\n        }\n      }\n    }\n  }\n\n  // add all non-default graphs to default graph\n  const defaultGraph = _mergeNodeMaps(graphs);\n\n  // produce flattened output\n  const flattened = [];\n  const keys = Object.keys(defaultGraph).sort();\n  for(let ki = 0; ki < keys.length; ++ki) {\n    const node = defaultGraph[keys[ki]];\n    // only add full subjects to top-level\n    if(!_isSubjectReference(node)) {\n      flattened.push(node);\n    }\n  }\n\n  if(ctx === null) {\n    return flattened;\n  }\n\n  // compact result (force @graph option to true, skip expansion)\n  options.graph = true;\n  options.skipExpansion = true;\n  const compacted = await jsonld.compact(flattened, ctx, options);\n\n  return compacted;\n};\n\n/**\n * The default document loader for external documents.\n *\n * @param url the URL to load.\n *\n * @return a promise that resolves to the remote document.\n */\nObject.defineProperty(jsonld, 'documentLoader', {\n  get: () => jsonld._documentLoader,\n  set: v => jsonld._documentLoader = v\n});\n// default document loader not implemented\njsonld.documentLoader = async url => {\n  throw new JsonLdError(\n    'Could not retrieve a JSON-LD document from the URL. URL ' +\n    'dereferencing not implemented.', 'jsonld.LoadDocumentError',\n    {code: 'loading document failed', url});\n};\n\n/**\n * Gets a remote JSON-LD document using the default document loader or\n * one given in the passed options.\n *\n * @param url the URL to fetch.\n * @param [options] the options to use:\n *          [documentLoader] the document loader to use.\n *\n * @return a Promise that resolves to the retrieved remote document.\n */\njsonld.get = async function(url, options) {\n  let load;\n  if(typeof options.documentLoader === 'function') {\n    load = options.documentLoader;\n  } else {\n    load = jsonld.documentLoader;\n  }\n\n  const remoteDoc = await load(url);\n\n  try {\n    if(!remoteDoc.document) {\n      throw new JsonLdError(\n        'No remote document found at the given URL.',\n        'jsonld.NullRemoteDocument');\n    }\n    if(_isString(remoteDoc.document)) {\n      remoteDoc.document = JSON.parse(remoteDoc.document);\n    }\n  } catch(e) {\n    throw new JsonLdError(\n      'Could not retrieve a JSON-LD document from the URL.',\n      'jsonld.LoadDocumentError', {\n        code: 'loading document failed',\n        cause: e,\n        remoteDoc\n      });\n  }\n\n  return remoteDoc;\n};\n\n/**\n * Processes a local context, resolving any URLs as necessary, and returns a\n * new active context.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context to process.\n * @param [options] the options to use:\n *          [documentLoader(url, options)] the document loader.\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the new active context.\n */\njsonld.processContext = async function(\n  activeCtx, localCtx, options) {\n  // set default options\n  options = _setDefaults(options, {\n    base: '',\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // return initial context early for null context\n  if(localCtx === null) {\n    return _getInitialContext(options);\n  }\n\n  // get URLs in localCtx\n  localCtx = util.clone(localCtx);\n  if(!(_isObject(localCtx) && '@context' in localCtx)) {\n    localCtx = {'@context': localCtx};\n  }\n\n  return _processContext({activeCtx, localCtx, options});\n};\n\n// backwards compatibility\njsonld.getContextValue = require('./context').getContextValue;\n\n/**\n * Document loaders.\n */\njsonld.documentLoaders = {};\n\n/**\n * Assigns the default document loader for external document URLs to a built-in\n * default. Supported types currently include: 'xhr' and 'node'.\n *\n * @param type the type to set.\n * @param [params] the parameters required to use the document loader.\n */\njsonld.useDocumentLoader = function(type) {\n  if(!(type in jsonld.documentLoaders)) {\n    throw new JsonLdError(\n      'Unknown document loader type: \"' + type + '\"',\n      'jsonld.UnknownDocumentLoader',\n      {type});\n  }\n\n  // set document loader\n  jsonld.documentLoader = jsonld.documentLoaders[type].apply(\n    jsonld, Array.prototype.slice.call(arguments, 1));\n};\n\n/**\n * Registers an RDF dataset parser by content-type, for use with\n * jsonld.fromRDF. An RDF dataset parser will always be given one parameter,\n * a string of input. An RDF dataset parser can be synchronous or\n * asynchronous (by returning a promise).\n *\n * @param contentType the content-type for the parser.\n * @param parser(input) the parser function (takes a string as a parameter\n *          and either returns an RDF dataset or a Promise that resolves to one.\n */\njsonld.registerRDFParser = function(contentType, parser) {\n  _rdfParsers[contentType] = parser;\n};\n\n/**\n * Unregisters an RDF dataset parser by content-type.\n *\n * @param contentType the content-type for the parser.\n */\njsonld.unregisterRDFParser = function(contentType) {\n  delete _rdfParsers[contentType];\n};\n\n// register the N-Quads RDF parser\njsonld.registerRDFParser('application/n-quads', NQuads.parse);\njsonld.registerRDFParser('application/nquads', NQuads.parse);\n\n/* URL API */\njsonld.url = require('./url');\n\n/* Utility API */\njsonld.util = util;\n// backwards compatibility\nObject.assign(jsonld, util);\n\n// reexpose API as jsonld.promises for backwards compatability\njsonld.promises = jsonld;\n\n// backwards compatibility\njsonld.RequestQueue = require('./RequestQueue');\n\n/* WebIDL API */\njsonld.JsonLdProcessor = require('./JsonLdProcessor')(jsonld);\n\nplatform.setupGlobals(jsonld);\nplatform.setupDocumentLoaders(jsonld);\n\nfunction _setDefaults(options, {\n  documentLoader = jsonld.documentLoader,\n  ...defaults\n}) {\n  return Object.assign({}, {documentLoader}, defaults, options);\n}\n\n// end of jsonld API `wrapper` factory\nreturn jsonld;\n};\n\n// external APIs:\n\n// used to generate a new jsonld API instance\nconst factory = function() {\n  return wrapper(function() {\n    return factory();\n  });\n};\n\n// wrap the main jsonld API instance\nwrapper(factory);\n// export API\nmodule.exports = factory;\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nmodule.exports = jsonld => {\n  class JsonLdProcessor {\n    toString() {\n      return '[object JsonLdProcessor]';\n    }\n  }\n  Object.defineProperty(JsonLdProcessor, 'prototype', {\n    writable: false,\n    enumerable: false\n  });\n  Object.defineProperty(JsonLdProcessor.prototype, 'constructor', {\n    writable: true,\n    enumerable: false,\n    configurable: true,\n    value: JsonLdProcessor\n  });\n\n  // The Web IDL test harness will check the number of parameters defined in\n  // the functions below. The number of parameters must exactly match the\n  // required (non-optional) parameters of the JsonLdProcessor interface as\n  // defined here:\n  // https://www.w3.org/TR/json-ld-api/#the-jsonldprocessor-interface\n\n  JsonLdProcessor.compact = function(input, ctx) {\n    if(arguments.length < 2) {\n      return Promise.reject(\n        new TypeError('Could not compact, too few arguments.'));\n    }\n    return jsonld.compact(input, ctx);\n  };\n  JsonLdProcessor.expand = function(input) {\n    if(arguments.length < 1) {\n      return Promise.reject(\n        new TypeError('Could not expand, too few arguments.'));\n    }\n    return jsonld.expand(input);\n  };\n  JsonLdProcessor.flatten = function(input) {\n    if(arguments.length < 1) {\n      return Promise.reject(\n        new TypeError('Could not flatten, too few arguments.'));\n    }\n    return jsonld.flatten(input);\n  };\n\n  return JsonLdProcessor;\n};\n","(function (root) {\n    'use strict';\n\n    /**\n     * charMap\n     * @type {Object}\n     */\n    var charMap = {\n\n        // latin\n        '': 'A',\n        '': 'A',\n        '': 'A',\n        '': 'A',\n        '': 'Ae',\n        '': 'A',\n        '': 'AE',\n        '': 'C',\n        '': 'E',\n        '': 'E',\n        '': 'E',\n        '': 'E',\n        '': 'I',\n        '': 'I',\n        '': 'I',\n        '': 'I',\n        '': 'D',\n        '': 'N',\n        '': 'O',\n        '': 'O',\n        '': 'O',\n        '': 'O',\n        '': 'Oe',\n        '': 'O',\n        '': 'O',\n        '': 'U',\n        '': 'U',\n        '': 'U',\n        '': 'Ue',\n        '': 'U',\n        '': 'Y',\n        '': 'TH',\n        '': 'ss',\n        '': 'a',\n        '': 'a',\n        '': 'a',\n        '': 'a',\n        '': 'ae',\n        '': 'a',\n        '': 'ae',\n        '': 'c',\n        '': 'e',\n        '': 'e',\n        '': 'e',\n        '': 'e',\n        '': 'i',\n        '': 'i',\n        '': 'i',\n        '': 'i',\n        '': 'd',\n        '': 'n',\n        '': 'o',\n        '': 'o',\n        '': 'o',\n        '': 'o',\n        '': 'oe',\n        '': 'o',\n        '': 'o',\n        '': 'u',\n        '': 'u',\n        '': 'u',\n        '': 'ue',\n        '': 'u',\n        '': 'y',\n        '': 'th',\n        '': 'y',\n        '': 'SS',\n\n        // language specific\n\n        // Arabic\n        '': 'a',\n        '': 'a',\n        '': 'i',\n        '': 'aa',\n        '': 'u',\n        '': 'e',\n        '': 'a',\n        '': 'b',\n        '': 't',\n        '': 'th',\n        '': 'j',\n        '': 'h',\n        '': 'kh',\n        '': 'd',\n        '': 'th',\n        '': 'r',\n        '': 'z',\n        '': 's',\n        '': 'sh',\n        '': 's',\n        '': 'dh',\n        '': 't',\n        '': 'z',\n        '': 'a',\n        '': 'gh',\n        '': 'f',\n        '': 'q',\n        '': 'k',\n        '': 'l',\n        '': 'm',\n        '': 'n',\n        '': 'h',\n        '': 'w',\n        '': 'y',\n        '': 'a',\n        '': 'h',\n        '': 'la',\n        '': 'laa',\n        '': 'lai',\n        '': 'laa',\n\n        // Persian additional characters than Arabic\n        '': 'g',\n        '': 'ch',\n        '': 'p',\n        '': 'zh',\n        '': 'k',\n        '': 'y',\n\n        // Arabic diactrics\n        '': 'a',\n        '': 'an',\n        '': 'e',\n        '': 'en',\n        '': 'u',\n        '': 'on',\n        '': '',\n\n        // Arabic numbers\n        '': '0',\n        '': '1',\n        '': '2',\n        '': '3',\n        '': '4',\n        '': '5',\n        '': '6',\n        '': '7',\n        '': '8',\n        '': '9',\n\n        // Persian numbers\n        '': '0',\n        '': '1',\n        '': '2',\n        '': '3',\n        '': '4',\n        '': '5',\n        '': '6',\n        '': '7',\n        '': '8',\n        '': '9',\n\n        // Burmese consonants\n        '': 'k',\n        '': 'kh',\n        '': 'g',\n        '': 'ga',\n        '': 'ng',\n        '': 's',\n        '': 'sa',\n        '': 'z',\n        '': 'za',\n        '': 'ny',\n        '': 't',\n        '': 'ta',\n        '': 'd',\n        '': 'da',\n        '': 'na',\n        '': 't',\n        '': 'ta',\n        '': 'd',\n        '': 'da',\n        '': 'n',\n        '': 'p',\n        '': 'pa',\n        '': 'b',\n        '': 'ba',\n        '': 'm',\n        '': 'y',\n        '': 'ya',\n        '': 'l',\n        '': 'w',\n        '': 'th',\n        '': 'h',\n        '': 'la',\n        '': 'a',\n        // consonant character combos\n        '': 'y',\n        '': 'ya',\n        '': 'w',\n        '': 'yw',\n        '': 'ywa',\n        '': 'h',\n        // independent vowels\n        '': 'e',\n        '': '-e',\n        '': 'i',\n        '': '-i',\n        '': 'u',\n        '': '-u',\n        '': 'aw',\n        '': 'aw',\n        '': 'aw',\n        // numbers\n        '': '0',\n        '': '1',\n        '': '2',\n        '': '3',\n        '': '4',\n        '': '5',\n        '': '6',\n        '': '7',\n        '': '8',\n        '': '9',\n        // virama and tone marks which are silent in transliteration\n        '': '',\n        '': '',\n        '': '',\n\n        // Czech\n        '': 'c',\n        '': 'd',\n        '': 'e',\n        '': 'n',\n        '': 'r',\n        '': 's',\n        '': 't',\n        '': 'u',\n        '': 'z',\n        '': 'C',\n        '': 'D',\n        '': 'E',\n        '': 'N',\n        '': 'R',\n        '': 'S',\n        '': 'T',\n        '': 'U',\n        '': 'Z',\n\n        // Dhivehi\n        '': 'h',\n        '': 'sh',\n        '': 'n',\n        '': 'r',\n        '': 'b',\n        '': 'lh',\n        '': 'k',\n        '': 'a',\n        '': 'v',\n        '': 'm',\n        '': 'f',\n        '': 'dh',\n        '': 'th',\n        '': 'l',\n        '': 'g',\n        '': 'gn',\n        '': 's',\n        '': 'd',\n        '': 'z',\n        '': 't',\n        '': 'y',\n        '': 'p',\n        '': 'j',\n        '': 'ch',\n        '': 'tt',\n        '': 'hh',\n        '': 'kh',\n        '': 'th',\n        '': 'z',\n        '': 'sh',\n        '': 's',\n        '': 'd',\n        '': 't',\n        '': 'z',\n        '': 'a',\n        '': 'gh',\n        '': 'q',\n        '': 'w',\n        '': 'a',\n        '': 'aa',\n        '': 'i',\n        '': 'ee',\n        '': 'u',\n        '': 'oo',\n        '': 'e',\n        '': 'ey',\n        '': 'o',\n        '': 'oa',\n        '': '',\n\n        // Georgian https://en.wikipedia.org/wiki/Romanization_of_Georgian\n        // National system (2002)\n        '': 'a',\n        '': 'b',\n        '': 'g',\n        '': 'd',\n        '': 'e',\n        '': 'v',\n        '': 'z',\n        '': 't',\n        '': 'i',\n        '': 'k',\n        '': 'l',\n        '': 'm',\n        '': 'n',\n        '': 'o',\n        '': 'p',\n        '': 'zh',\n        '': 'r',\n        '': 's',\n        '': 't',\n        '': 'u',\n        '': 'p',\n        '': 'k',\n        '': 'gh',\n        '': 'q',\n        '': 'sh',\n        '': 'ch',\n        '': 'ts',\n        '': 'dz',\n        '': 'ts',\n        '': 'ch',\n        '': 'kh',\n        '': 'j',\n        '': 'h',\n\n        // Greek\n        '': 'a',\n        '': 'v',\n        '': 'g',\n        '': 'd',\n        '': 'e',\n        '': 'z',\n        '': 'i',\n        '': 'th',\n        '': 'i',\n        '': 'k',\n        '': 'l',\n        '': 'm',\n        '': 'n',\n        '': 'ks',\n        '': 'o',\n        '': 'p',\n        '': 'r',\n        '': 's',\n        '': 't',\n        '': 'y',\n        '': 'f',\n        '': 'x',\n        '': 'ps',\n        '': 'o',\n        '': 'a',\n        '': 'e',\n        '': 'i',\n        '': 'o',\n        '': 'y',\n        '': 'i',\n        '': 'o',\n        '': 's',\n        '': 'i',\n        '': 'y',\n        '': 'y',\n        '': 'i',\n        '': 'A',\n        '': 'B',\n        '': 'G',\n        '': 'D',\n        '': 'E',\n        '': 'Z',\n        '': 'I',\n        '': 'TH',\n        '': 'I',\n        '': 'K',\n        '': 'L',\n        '': 'M',\n        '': 'N',\n        '': 'KS',\n        '': 'O',\n        '': 'P',\n        '': 'R',\n        '': 'S',\n        '': 'T',\n        '': 'Y',\n        '': 'F',\n        '': 'X',\n        '': 'PS',\n        '': 'O',\n        '': 'A',\n        '': 'E',\n        '': 'I',\n        '': 'O',\n        '': 'Y',\n        '': 'I',\n        '': 'O',\n        '': 'I',\n        '': 'Y',\n\n        // Latvian\n        '': 'a',\n        // '': 'c', // duplicate\n        '': 'e',\n        '': 'g',\n        '': 'i',\n        '': 'k',\n        '': 'l',\n        '': 'n',\n        // '': 's', // duplicate\n        '': 'u',\n        // '': 'z', // duplicate\n        '': 'A',\n        // '': 'C', // duplicate\n        '': 'E',\n        '': 'G',\n        '': 'I',\n        '': 'k',\n        '': 'L',\n        '': 'N',\n        // '': 'S', // duplicate\n        '': 'U',\n        // '': 'Z', // duplicate\n\n        // Macedonian\n        '': 'Kj',\n        '': 'kj',\n        '': 'Lj',\n        '': 'lj',\n        '': 'Nj',\n        '': 'nj',\n        '': 'Ts',\n        '': 'ts',\n\n        // Polish\n        '': 'a',\n        '': 'c',\n        '': 'e',\n        '': 'l',\n        '': 'n',\n        // '': 'o', // duplicate\n        '': 's',\n        '': 'z',\n        '': 'z',\n        '': 'A',\n        '': 'C',\n        '': 'E',\n        '': 'L',\n        '': 'N',\n        '': 'S',\n        '': 'Z',\n        '': 'Z',\n\n        // Ukranian\n        '': 'Ye',\n        '': 'I',\n        '': 'Yi',\n        '': 'G',\n        '': 'ye',\n        '': 'i',\n        '': 'yi',\n        '': 'g',\n\n        // Romanian\n        '': 'a',\n        '': 'A',\n        '': 's',\n        '': 'S',\n        // '': 's', // duplicate\n        // '': 'S', // duplicate\n        '': 't',\n        '': 'T',\n        '': 't',\n        '': 'T',\n\n        // Russian https://en.wikipedia.org/wiki/Romanization_of_Russian\n        // ICAO\n\n        '': 'a',\n        '': 'b',\n        '': 'v',\n        '': 'g',\n        '': 'd',\n        '': 'e',\n        '': 'yo',\n        '': 'zh',\n        '': 'z',\n        '': 'i',\n        '': 'i',\n        '': 'k',\n        '': 'l',\n        '': 'm',\n        '': 'n',\n        '': 'o',\n        '': 'p',\n        '': 'r',\n        '': 's',\n        '': 't',\n        '': 'u',\n        '': 'f',\n        '': 'kh',\n        '': 'c',\n        '': 'ch',\n        '': 'sh',\n        '': 'sh',\n        '': '',\n        '': 'y',\n        '': '',\n        '': 'e',\n        '': 'yu',\n        '': 'ya',\n        '': 'A',\n        '': 'B',\n        '': 'V',\n        '': 'G',\n        '': 'D',\n        '': 'E',\n        '': 'Yo',\n        '': 'Zh',\n        '': 'Z',\n        '': 'I',\n        '': 'I',\n        '': 'K',\n        '': 'L',\n        '': 'M',\n        '': 'N',\n        '': 'O',\n        '': 'P',\n        '': 'R',\n        '': 'S',\n        '': 'T',\n        '': 'U',\n        '': 'F',\n        '': 'Kh',\n        '': 'C',\n        '': 'Ch',\n        '': 'Sh',\n        '': 'Sh',\n        '': '',\n        '': 'Y',\n        '': '',\n        '': 'E',\n        '': 'Yu',\n        '': 'Ya',\n\n        // Serbian\n        '': 'dj',\n        '': 'j',\n        // '': 'lj',  // duplicate\n        // '': 'nj', // duplicate\n        '': 'c',\n        '': 'dz',\n        '': 'Dj',\n        '': 'j',\n        // '': 'Lj', // duplicate\n        // '': 'Nj', // duplicate\n        '': 'C',\n        '': 'Dz',\n\n        // Slovak\n        '': 'l',\n        '': 'l',\n        '': 'r',\n        '': 'L',\n        '': 'L',\n        '': 'R',\n\n        // Turkish\n        '': 's',\n        '': 'S',\n        '': 'i',\n        '': 'I',\n        // '': 'c', // duplicate\n        // '': 'C', // duplicate\n        // '': 'u', // duplicate, see langCharMap\n        // '': 'U', // duplicate, see langCharMap\n        // '': 'o', // duplicate, see langCharMap\n        // '': 'O', // duplicate, see langCharMap\n        '': 'g',\n        '': 'G',\n\n        // Vietnamese\n        '': 'a',\n        '': 'A',\n        '': 'a',\n        '': 'A',\n        '': 'a',\n        '': 'A',\n        '': 'd',\n        '': 'D',\n        '': 'e',\n        '': 'E',\n        '': 'e',\n        '': 'E',\n        '': 'e',\n        '': 'E',\n        '': 'e',\n        '': 'E',\n        '': 'e',\n        '': 'E',\n        '': 'e',\n        '': 'E',\n        '': 'e',\n        '': 'E',\n        '': 'e',\n        '': 'E',\n        '': 'o',\n        '': 'o',\n        '': 'o',\n        '': 'o',\n        '': 'O',\n        '': 'o',\n        '': 'O',\n        '': 'o',\n        '': 'O',\n        '': 'o',\n        '': 'O',\n        '': 'o',\n        '': 'O',\n        '': 'o',\n        '': 'O',\n        '': 'o',\n        '': 'O',\n        '': 'o',\n        '': 'O',\n        '': 'o',\n        '': 'O',\n        '': 'o',\n        '': 'O',\n        '': 'o',\n        '': 'o',\n        '': 'i',\n        '': 'I',\n        '': 'i',\n        '': 'I',\n        '': 'i',\n        '': 'i',\n        '': 'u',\n        '': 'U',\n        '': 'u',\n        '': 'U',\n        '': 'u',\n        '': 'U',\n        '': 'u',\n        '': 'U',\n        '': 'u',\n        '': 'U',\n        '': 'u',\n        '': 'U',\n        '': 'u',\n        '': 'U',\n        '': 'u',\n        '': 'U',\n        '': 'u',\n        '': '',\n        '': 'y',\n        '': 'y',\n        '': 'y',\n        '': 'Y',\n        '': 'y',\n        '': 'Y',\n        '': 'y',\n        '': 'Y',\n        '': 'a',\n        '': 'A',\n        '': 'a',\n        '': 'A',\n        '': 'a',\n        '': 'A',\n        '': 'a',\n        '': 'A',\n        '': 'a',\n        '': 'A',\n        // '': 'a', // duplicate\n        // '': 'A', // duplicate\n        '': 'a',\n        '': 'A',\n        '': 'a',\n        '': 'A',\n        '': 'a',\n        '': 'A',\n        '': 'a',\n        '': 'A',\n        \"\": \"0\",\n        \"\": \"1\",\n        \"\": \"2\",\n        \"\": \"3\",\n        \"\": \"4\",\n        \"\": \"5\",\n        \"\": \"6\",\n        \"\": \"7\",\n        \"\": \"8\",\n        \"\": \"9\",\n        \"\": \"10\",\n        \"\": \"11\",\n        \"\": \"12\",\n        \"\": \"13\",\n        \"\": \"14\",\n        \"\": \"15\",\n        \"\": \"16\",\n        \"\": \"17\",\n        \"\": \"18\",\n        \"\": \"18\",\n        \"\": \"18\",\n\n        \"\": \"1\",\n        \"\": \"2\",\n        \"\": \"3\",\n        \"\": \"4\",\n        \"\": \"5\",\n        \"\": \"6\",\n        \"\": \"7\",\n        \"\": \"8\",\n        \"\": \"9\",\n        \"\": \"10\",\n\n        \"\": \"0\",\n        \"\": \"11\",\n        \"\": \"12\",\n        \"\": \"13\",\n        \"\": \"14\",\n        \"\": \"15\",\n        \"\": \"16\",\n        \"\": \"17\",\n        \"\": \"18\",\n        \"\": \"19\",\n        \"\": \"20\",\n\n        \"\": \"A\",\n        \"\": \"B\",\n        \"\": \"C\",\n        \"\": \"D\",\n        \"\": \"E\",\n        \"\": \"F\",\n        \"\": \"G\",\n        \"\": \"H\",\n        \"\": \"I\",\n        \"\": \"J\",\n        \"\": \"K\",\n        \"\": \"L\",\n        \"\": \"M\",\n        \"\": \"N\",\n        \"\": \"O\",\n        \"\": \"P\",\n        \"\": \"Q\",\n        \"\": \"R\",\n        \"\": \"S\",\n        \"\": \"T\",\n        \"\": \"U\",\n        \"\": \"V\",\n        \"\": \"W\",\n        \"\": \"X\",\n        \"\": \"Y\",\n        \"\": \"Z\",\n\n        \"\": \"a\",\n        \"\": \"b\",\n        \"\": \"c\",\n        \"\": \"d\",\n        \"\": \"e\",\n        \"\": \"f\",\n        \"\": \"g\",\n        \"\": \"h\",\n        \"\": \"i\",\n        \"\": \"j\",\n        \"\": \"k\",\n        \"\": \"l\",\n        \"\": \"m\",\n        \"\": \"n\",\n        \"\": \"o\",\n        \"\": \"p\",\n        \"\": \"q\",\n        \"\": \"r\",\n        \"\": \"s\",\n        \"\": \"t\",\n        \"\": \"u\",\n        \"\": \"v\",\n        \"\": \"w\",\n        \"\": \"x\",\n        \"\": \"y\",\n        \"\": \"z\",\n\n        // symbols\n        '': '\"',\n        '': '\"',\n        '': \"'\",\n        '': \"'\",\n        '': 'd',\n        '': 'f',\n        '': '(TM)',\n        '': '(C)',\n        '': 'oe',\n        '': 'OE',\n        '': '(R)',\n        '': '+',\n        '': '(SM)',\n        '': '...',\n        '': 'o',\n        '': 'o',\n        '': 'a',\n        '': '*',\n        '': ',',\n        '': '.',\n\n        // currency\n        '$': 'USD',\n        '': 'EUR',\n        '': 'BRN',\n        '': 'FRF',\n        '': 'GBP',\n        '': 'ITL',\n        '': 'NGN',\n        '': 'ESP',\n        '': 'KRW',\n        '': 'ILS',\n        '': 'VND',\n        '': 'LAK',\n        '': 'MNT',\n        '': 'GRD',\n        '': 'ARS',\n        '': 'PYG',\n        '': 'ARA',\n        '': 'UAH',\n        '': 'GHS',\n        '': 'cent',\n        '': 'CNY',\n        '': 'CNY',\n        '': 'YEN',\n        '': 'IRR',\n        '': 'EWE',\n        '': 'THB',\n        '': 'INR',\n        '': 'INR',\n        '': 'PF',\n        '': 'TRY',\n        '': 'AFN',\n        '': 'AZN',\n        '': 'BGN',\n        '': 'KHR',\n        '': 'CRC',\n        '': 'KZT',\n        '': 'MKD',\n        'z': 'PLN',\n        '': 'RUB',\n        '': 'GEL'\n\n    };\n\n    /**\n     * special look ahead character array\n     * These characters form with consonants to become 'single'/consonant combo\n     * @type [Array]\n     */\n    var lookAheadCharArray = [\n        // burmese\n        '',\n\n        // Dhivehi\n        ''\n    ];\n\n    /**\n     * diatricMap for languages where transliteration changes entirely as more diatrics are added\n     * @type {Object}\n     */\n    var diatricMap = {\n        // Burmese\n        // dependent vowels\n        '': 'a',\n        '': 'a',\n        '': 'e',\n        '': 'e',\n        '': 'i',\n        '': 'i',\n        '': 'o',\n        '': 'u',\n        '': 'u',\n        '': 'aung',\n        '': 'aw',\n        '': 'aw',\n        '': 'aw',\n        '': 'aw',\n        '': '', // this is special case but the character will be converted to latin in the code\n        '': 'et',\n        '': 'aik',\n        '': 'auk',\n        '': 'in',\n        '': 'aing',\n        '': 'aung',\n        '': 'it',\n        '': 'i',\n        '': 'at',\n        '': 'eik',\n        '': 'ok',\n        '': 'ut',\n        '': 'it',\n        '': 'd',\n        '': 'ok',\n        '': 'ait',\n        '': 'an',\n        '': 'an',\n        '': 'ein',\n        '': 'on',\n        '': 'un',\n        '': 'at',\n        '': 'eik',\n        '': 'ok',\n        '': 'ut',\n        '': 'nub',\n        '': 'an',\n        '': 'ein',\n        '': 'on',\n        '': 'un',\n        '': 'e',\n        '': 'ol',\n        '': 'in',\n        '': 'an',\n        '': 'ein',\n        '': 'on',\n\n        // Dhivehi\n        '': 'ah',\n        '': 'ah'\n    };\n\n    /**\n     * langCharMap language specific characters translations\n     * @type   {Object}\n     */\n    var langCharMap = {\n        'en': {}, // default language\n\n        'az': { // Azerbaijani\n            '': 'c',\n            '': 'e',\n            '': 'g',\n            '': 'i',\n            '': 'o',\n            '': 's',\n            '': 'u',\n            '': 'C',\n            '': 'E',\n            '': 'G',\n            '': 'I',\n            '': 'O',\n            '': 'S',\n            '': 'U'\n        },\n\n        'cs': { // Czech\n            '': 'c',\n            '': 'd',\n            '': 'e',\n            '': 'n',\n            '': 'r',\n            '': 's',\n            '': 't',\n            '': 'u',\n            '': 'z',\n            '': 'C',\n            '': 'D',\n            '': 'E',\n            '': 'N',\n            '': 'R',\n            '': 'S',\n            '': 'T',\n            '': 'U',\n            '': 'Z'\n        },\n\n        'fi': { // Finnish\n            // '': 'a', duplicate see charMap/latin\n            // '': 'A', duplicate see charMap/latin\n            '': 'a', // ok\n            '': 'A', // ok\n            '': 'o', // ok\n            '': 'O' // ok\n        },\n\n        'hu': { // Hungarian\n            '': 'a', // ok\n            '': 'A', // ok\n            // '': 'a', duplicate see charMap/latin\n            // '': 'A', duplicate see charMap/latin\n            '': 'o', // ok\n            '': 'O', // ok\n            // '': 'o', duplicate see charMap/latin\n            // '': 'O', duplicate see charMap/latin\n            '': 'u',\n            '': 'U',\n            '': 'u',\n            '': 'U'\n        },\n\n        'lt': { // Lithuanian\n            '': 'a',\n            '': 'c',\n            '': 'e',\n            '': 'e',\n            '': 'i',\n            '': 's',\n            '': 'u',\n            '': 'u',\n            '': 'z',\n            '': 'A',\n            '': 'C',\n            '': 'E',\n            '': 'E',\n            '': 'I',\n            '': 'S',\n            '': 'U',\n            '': 'U'\n        },\n\n        'lv': { // Latvian\n            '': 'a',\n            '': 'c',\n            '': 'e',\n            '': 'g',\n            '': 'i',\n            '': 'k',\n            '': 'l',\n            '': 'n',\n            '': 's',\n            '': 'u',\n            '': 'z',\n            '': 'A',\n            '': 'C',\n            '': 'E',\n            '': 'G',\n            '': 'i',\n            '': 'k',\n            '': 'L',\n            '': 'N',\n            '': 'S',\n            '': 'u',\n            '': 'Z'\n        },\n\n        'pl': { // Polish\n            '': 'a',\n            '': 'c',\n            '': 'e',\n            '': 'l',\n            '': 'n',\n            '': 'o',\n            '': 's',\n            '': 'z',\n            '': 'z',\n            '': 'A',\n            '': 'C',\n            '': 'e',\n            '': 'L',\n            '': 'N',\n            '': 'O',\n            '': 'S',\n            '': 'Z',\n            '': 'Z'\n        },\n\n        'sv': { // Swedish\n            // '': 'a', duplicate see charMap/latin\n            // '': 'A', duplicate see charMap/latin\n            '': 'a', // ok\n            '': 'A', // ok\n            '': 'o', // ok\n            '': 'O' // ok\n        },\n\n        'sk': { // Slovak\n            '': 'a',\n            '': 'A'\n        },\n\n        'sr': { // Serbian\n            '': 'lj',\n            '': 'nj',\n            '': 'Lj',\n            '': 'Nj',\n            '': 'dj',\n            '': 'Dj'\n        },\n\n        'tr': { // Turkish\n            '': 'U',\n            '': 'O',\n            '': 'u',\n            '': 'o'\n        }\n    };\n\n    /**\n     * symbolMap language specific symbol translations\n     * translations must be transliterated already\n     * @type   {Object}\n     */\n    var symbolMap = {\n        'ar': {\n            '': 'delta',\n            '': 'la-nihaya',\n            '': 'hob',\n            '&': 'wa',\n            '|': 'aw',\n            '<': 'aqal-men',\n            '>': 'akbar-men',\n            '': 'majmou',\n            '': 'omla'\n        },\n\n        'az': {},\n\n        'ca': {\n            '': 'delta',\n            '': 'infinit',\n            '': 'amor',\n            '&': 'i',\n            '|': 'o',\n            '<': 'menys que',\n            '>': 'mes que',\n            '': 'suma dels',\n            '': 'moneda'\n        },\n\n        'cs': {\n            '': 'delta',\n            '': 'nekonecno',\n            '': 'laska',\n            '&': 'a',\n            '|': 'nebo',\n            '<': 'mensi nez',\n            '>': 'vetsi nez',\n            '': 'soucet',\n            '': 'mena'\n        },\n\n        'de': {\n            '': 'delta',\n            '': 'unendlich',\n            '': 'Liebe',\n            '&': 'und',\n            '|': 'oder',\n            '<': 'kleiner als',\n            '>': 'groesser als',\n            '': 'Summe von',\n            '': 'Waehrung'\n        },\n\n        'dv': {\n            '': 'delta',\n            '': 'kolunulaa',\n            '': 'loabi',\n            '&': 'aai',\n            '|': 'noonee',\n            '<': 'ah vure kuda',\n            '>': 'ah vure bodu',\n            '': 'jumula',\n            '': 'faisaa'\n        },\n\n        'en': {\n            '': 'delta',\n            '': 'infinity',\n            '': 'love',\n            '&': 'and',\n            '|': 'or',\n            '<': 'less than',\n            '>': 'greater than',\n            '': 'sum',\n            '': 'currency'\n        },\n\n        'es': {\n            '': 'delta',\n            '': 'infinito',\n            '': 'amor',\n            '&': 'y',\n            '|': 'u',\n            '<': 'menos que',\n            '>': 'mas que',\n            '': 'suma de los',\n            '': 'moneda'\n        },\n\n        'fa': {\n            '': 'delta',\n            '': 'bi-nahayat',\n            '': 'eshgh',\n            '&': 'va',\n            '|': 'ya',\n            '<': 'kamtar-az',\n            '>': 'bishtar-az',\n            '': 'majmooe',\n            '': 'vahed'\n        },\n\n        'fi': {\n            '': 'delta',\n            '': 'aarettomyys',\n            '': 'rakkaus',\n            '&': 'ja',\n            '|': 'tai',\n            '<': 'pienempi kuin',\n            '>': 'suurempi kuin',\n            '': 'summa',\n            '': 'valuutta'\n        },\n\n        'fr': {\n            '': 'delta',\n            '': 'infiniment',\n            '': 'Amour',\n            '&': 'et',\n            '|': 'ou',\n            '<': 'moins que',\n            '>': 'superieure a',\n            '': 'somme des',\n            '': 'monnaie'\n        },\n\n        'ge': {\n            '': 'delta',\n            '': 'usasruloba',\n            '': 'siqvaruli',\n            '&': 'da',\n            '|': 'an',\n            '<': 'naklebi',\n            '>': 'meti',\n            '': 'jami',\n            '': 'valuta'\n        },\n\n        'gr': {},\n\n        'hu': {\n            '': 'delta',\n            '': 'vegtelen',\n            '': 'szerelem',\n            '&': 'es',\n            '|': 'vagy',\n            '<': 'kisebb mint',\n            '>': 'nagyobb mint',\n            '': 'szumma',\n            '': 'penznem'\n        },\n\n        'it': {\n            '': 'delta',\n            '': 'infinito',\n            '': 'amore',\n            '&': 'e',\n            '|': 'o',\n            '<': 'minore di',\n            '>': 'maggiore di',\n            '': 'somma',\n            '': 'moneta'\n        },\n\n        'lt': {\n            '': 'delta',\n            '': 'begalybe',\n            '': 'meile',\n            '&': 'ir',\n            '|': 'ar',\n            '<': 'maziau nei',\n            '>': 'daugiau nei',\n            '': 'suma',\n            '': 'valiuta'\n        },\n\n        'lv': {\n            '': 'delta',\n            '': 'bezgaliba',\n            '': 'milestiba',\n            '&': 'un',\n            '|': 'vai',\n            '<': 'mazak neka',\n            '>': 'lielaks neka',\n            '': 'summa',\n            '': 'valuta'\n        },\n\n        'my': {\n            '': 'kwahkhyaet',\n            '': 'asaonasme',\n            '': 'akhyait',\n            '&': 'nhin',\n            '|': 'tho',\n            '<': 'ngethaw',\n            '>': 'kyithaw',\n            '': 'paungld',\n            '': 'ngwekye'\n        },\n\n        'mk': {},\n\n        'nl': {\n            '': 'delta',\n            '': 'oneindig',\n            '': 'liefde',\n            '&': 'en',\n            '|': 'of',\n            '<': 'kleiner dan',\n            '>': 'groter dan',\n            '': 'som',\n            '': 'valuta'\n        },\n\n        'pl': {\n            '': 'delta',\n            '': 'nieskonczonosc',\n            '': 'milosc',\n            '&': 'i',\n            '|': 'lub',\n            '<': 'mniejsze niz',\n            '>': 'wieksze niz',\n            '': 'suma',\n            '': 'waluta'\n        },\n\n        'pt': {\n            '': 'delta',\n            '': 'infinito',\n            '': 'amor',\n            '&': 'e',\n            '|': 'ou',\n            '<': 'menor que',\n            '>': 'maior que',\n            '': 'soma',\n            '': 'moeda'\n        },\n\n        'ro': {\n            '': 'delta',\n            '': 'infinit',\n            '': 'dragoste',\n            '&': 'si',\n            '|': 'sau',\n            '<': 'mai mic ca',\n            '>': 'mai mare ca',\n            '': 'suma',\n            '': 'valuta'\n        },\n\n        'ru': {\n            '': 'delta',\n            '': 'beskonechno',\n            '': 'lubov',\n            '&': 'i',\n            '|': 'ili',\n            '<': 'menshe',\n            '>': 'bolshe',\n            '': 'summa',\n            '': 'valjuta'\n        },\n\n        'sk': {\n            '': 'delta',\n            '': 'nekonecno',\n            '': 'laska',\n            '&': 'a',\n            '|': 'alebo',\n            '<': 'menej ako',\n            '>': 'viac ako',\n            '': 'sucet',\n            '': 'mena'\n        },\n\n        'sr': {},\n\n        'tr': {\n            '': 'delta',\n            '': 'sonsuzluk',\n            '': 'ask',\n            '&': 've',\n            '|': 'veya',\n            '<': 'kucuktur',\n            '>': 'buyuktur',\n            '': 'toplam',\n            '': 'para birimi'\n        },\n\n        'uk': {\n            '': 'delta',\n            '': 'bezkinechnist',\n            '': 'lubov',\n            '&': 'i',\n            '|': 'abo',\n            '<': 'menshe',\n            '>': 'bilshe',\n            '': 'suma',\n            '': 'valjuta'\n        },\n\n        'vn': {\n            '': 'delta',\n            '': 'vo cuc',\n            '': 'yeu',\n            '&': 'va',\n            '|': 'hoac',\n            '<': 'nho hon',\n            '>': 'lon hon',\n            '': 'tong',\n            '': 'tien te'\n        }\n    };\n\n    var uricChars = [';', '?', ':', '@', '&', '=', '+', '$', ',', '/'].join('');\n\n    var uricNoSlashChars = [';', '?', ':', '@', '&', '=', '+', '$', ','].join('');\n\n    var markChars = ['.', '!', '~', '*', \"'\", '(', ')'].join('');\n\n    /**\n     * getSlug\n     * @param  {string} input input string\n     * @param  {object|string} opts config object or separator string/char\n     * @api    public\n     * @return {string}  sluggified string\n     */\n    var getSlug = function getSlug(input, opts) {\n        var separator = '-';\n        var result = '';\n        var diatricString = '';\n        var convertSymbols = true;\n        var customReplacements = {};\n        var maintainCase;\n        var titleCase;\n        var truncate;\n        var uricFlag;\n        var uricNoSlashFlag;\n        var markFlag;\n        var symbol;\n        var langChar;\n        var lucky;\n        var i;\n        var ch;\n        var l;\n        var lastCharWasSymbol;\n        var lastCharWasDiatric;\n        var allowedChars = '';\n\n        if (typeof input !== 'string') {\n            return '';\n        }\n\n        if (typeof opts === 'string') {\n            separator = opts;\n        }\n\n        symbol = symbolMap.en;\n        langChar = langCharMap.en;\n\n        if (typeof opts === 'object') {\n            maintainCase = opts.maintainCase || false;\n            customReplacements = (opts.custom && typeof opts.custom === 'object') ? opts.custom : customReplacements;\n            truncate = (+opts.truncate > 1 && opts.truncate) || false;\n            uricFlag = opts.uric || false;\n            uricNoSlashFlag = opts.uricNoSlash || false;\n            markFlag = opts.mark || false;\n            convertSymbols = (opts.symbols === false || opts.lang === false) ? false : true;\n            separator = opts.separator || separator;\n\n            if (uricFlag) {\n                allowedChars += uricChars;\n            }\n\n            if (uricNoSlashFlag) {\n                allowedChars += uricNoSlashChars;\n            }\n\n            if (markFlag) {\n                allowedChars += markChars;\n            }\n\n            symbol = (opts.lang && symbolMap[opts.lang] && convertSymbols) ?\n                symbolMap[opts.lang] : (convertSymbols ? symbolMap.en : {});\n\n            langChar = (opts.lang && langCharMap[opts.lang]) ?\n                langCharMap[opts.lang] :\n                opts.lang === false || opts.lang === true ? {} : langCharMap.en;\n\n            // if titleCase config is an Array, rewrite to object format\n            if (opts.titleCase && typeof opts.titleCase.length === 'number' && Array.prototype.toString.call(opts.titleCase)) {\n                opts.titleCase.forEach(function (v) {\n                    customReplacements[v + ''] = v + '';\n                });\n\n                titleCase = true;\n            } else {\n                titleCase = !!opts.titleCase;\n            }\n\n            // if custom config is an Array, rewrite to object format\n            if (opts.custom && typeof opts.custom.length === 'number' && Array.prototype.toString.call(opts.custom)) {\n                opts.custom.forEach(function (v) {\n                    customReplacements[v + ''] = v + '';\n                });\n            }\n\n            // custom replacements\n            Object.keys(customReplacements).forEach(function (v) {\n                var r;\n\n                if (v.length > 1) {\n                    r = new RegExp('\\\\b' + escapeChars(v) + '\\\\b', 'gi');\n                } else {\n                    r = new RegExp(escapeChars(v), 'gi');\n                }\n\n                input = input.replace(r, customReplacements[v]);\n            });\n\n            // add all custom replacement to allowed charlist\n            for (ch in customReplacements) {\n                allowedChars += ch;\n            }\n        }\n\n        allowedChars += separator;\n\n        // escape all necessary chars\n        allowedChars = escapeChars(allowedChars);\n\n        // trim whitespaces\n        input = input.replace(/(^\\s+|\\s+$)/g, '');\n\n        lastCharWasSymbol = false;\n        lastCharWasDiatric = false;\n\n        for (i = 0, l = input.length; i < l; i++) {\n            ch = input[i];\n\n            if (isReplacedCustomChar(ch, customReplacements)) {\n                // don't convert a already converted char\n                lastCharWasSymbol = false;\n            } else if (langChar[ch]) {\n                // process language specific diactrics chars conversion\n                ch = lastCharWasSymbol && langChar[ch].match(/[A-Za-z0-9]/) ? ' ' + langChar[ch] : langChar[ch];\n\n                lastCharWasSymbol = false;\n            } else if (ch in charMap) {\n                // the transliteration changes entirely when some special characters are added\n                if (i + 1 < l && lookAheadCharArray.indexOf(input[i + 1]) >= 0) {\n                    diatricString += ch;\n                    ch = '';\n                } else if (lastCharWasDiatric === true) {\n                    ch = diatricMap[diatricString] + charMap[ch];\n                    diatricString = '';\n                } else {\n                    // process diactrics chars\n                    ch = lastCharWasSymbol && charMap[ch].match(/[A-Za-z0-9]/) ? ' ' + charMap[ch] : charMap[ch];\n                }\n\n                lastCharWasSymbol = false;\n                lastCharWasDiatric = false;\n            } else if (ch in diatricMap) {\n                diatricString += ch;\n                ch = '';\n                // end of string, put the whole meaningful word\n                if (i === l - 1) {\n                    ch = diatricMap[diatricString];\n                }\n                lastCharWasDiatric = true;\n            } else if (\n                // process symbol chars\n                symbol[ch] && !(uricFlag && uricChars\n                    .indexOf(ch) !== -1) && !(uricNoSlashFlag && uricNoSlashChars\n                    // .indexOf(ch) !== -1) && !(markFlag && markChars\n                    .indexOf(ch) !== -1)) {\n                ch = lastCharWasSymbol || result.substr(-1).match(/[A-Za-z0-9]/) ? separator + symbol[ch] : symbol[ch];\n                ch += input[i + 1] !== void 0 && input[i + 1].match(/[A-Za-z0-9]/) ? separator : '';\n\n                lastCharWasSymbol = true;\n            } else {\n                if (lastCharWasDiatric === true) {\n                    ch = diatricMap[diatricString] + ch;\n                    diatricString = '';\n                    lastCharWasDiatric = false;\n                } else if (lastCharWasSymbol && (/[A-Za-z0-9]/.test(ch) || result.substr(-1).match(/A-Za-z0-9]/))) {\n                    // process latin chars\n                    ch = ' ' + ch;\n                }\n                lastCharWasSymbol = false;\n            }\n\n            // add allowed chars\n            result += ch.replace(new RegExp('[^\\\\w\\\\s' + allowedChars + '_-]', 'g'), separator);\n        }\n\n        if (titleCase) {\n            result = result.replace(/(\\w)(\\S*)/g, function (_, i, r) {\n                var j = i.toUpperCase() + (r !== null ? r : '');\n                return (Object.keys(customReplacements).indexOf(j.toLowerCase()) < 0) ? j : j.toLowerCase();\n            });\n        }\n\n        // eliminate duplicate separators\n        // add separator\n        // trim separators from start and end\n        result = result.replace(/\\s+/g, separator)\n            .replace(new RegExp('\\\\' + separator + '+', 'g'), separator)\n            .replace(new RegExp('(^\\\\' + separator + '+|\\\\' + separator + '+$)', 'g'), '');\n\n        if (truncate && result.length > truncate) {\n            lucky = result.charAt(truncate) === separator;\n            result = result.slice(0, truncate);\n\n            if (!lucky) {\n                result = result.slice(0, result.lastIndexOf(separator));\n            }\n        }\n\n        if (!maintainCase && !titleCase) {\n            result = result.toLowerCase();\n        }\n\n        return result;\n    };\n\n    /**\n     * createSlug curried(opts)(input)\n     * @param   {object|string} opts config object or input string\n     * @return  {Function} function getSlugWithConfig()\n     **/\n    var createSlug = function createSlug(opts) {\n\n        /**\n         * getSlugWithConfig\n         * @param   {string} input string\n         * @return  {string} slug string\n         */\n        return function getSlugWithConfig(input) {\n            return getSlug(input, opts);\n        };\n    };\n\n    /**\n     * escape Chars\n     * @param   {string} input string\n     */\n    var escapeChars = function escapeChars(input) {\n        return input.replace(/[-\\\\^$*+?.()|[\\]{}\\/]/g, '\\\\$&');\n    };\n\n    /**\n     * check if the char is an already converted char from custom list\n     * @param   {char} ch character to check\n     * @param   {object} customReplacements custom translation map\n     */\n    var isReplacedCustomChar = function (ch, customReplacements) {\n        for (var c in customReplacements) {\n            if (customReplacements[c] === ch) {\n                return true;\n            }\n        }\n    };\n\n    if (typeof module !== 'undefined' && module.exports) {\n\n        // export functions for use in Node\n        module.exports = getSlug;\n        module.exports.createSlug = createSlug;\n    } else if (typeof define !== 'undefined' && define.amd) {\n\n        // export function for use in AMD\n        define([], function () {\n            return getSlug;\n        });\n    } else {\n\n        // don't overwrite global if exists\n        try {\n            if (root.getSlug || root.createSlug) {\n                throw 'speakingurl: globals exists /(getSlug|createSlug)/';\n            } else {\n                root.getSlug = getSlug;\n                root.createSlug = createSlug;\n            }\n        } catch (e) {}\n    }\n})(this);","module.exports = require('./lib/speakingurl');\n","import React from 'react';\nimport { useGetOne, LinearProgress } from 'react-admin';\nimport { ReferenceArrayField } from '@semapps/semantic-data-provider';\n\nconst CollectionList = ({ collectionUri, resource, children, ...rest }) => {\n  if (React.Children.count(children) !== 1) {\n    throw new Error('<CollectionList> only accepts a single child');\n  }\n\n  // TODO use a simple fetch call, as the resource is not good and it is useless\n  const { data: collection, loading } = useGetOne(resource, collectionUri, { enabled: !!collectionUri });\n\n  if (loading) {\n    return ( <div style={{ marginTop: 8 }}><LinearProgress /></div> );\n  } else if (!collection) {\n    return null;\n  }\n\n  return (\n    <ReferenceArrayField reference={resource} record={collection} source=\"items\" {...rest}>\n      {children}\n    </ReferenceArrayField>\n  );\n};\n\nexport default CollectionList;\n","import React from 'react';\nimport CollectionList from './CollectionList';\n\nconst ReferenceCollectionField = ({ source, record, reference, children, ...rest }) => {\n  if (React.Children.count(children) !== 1) {\n    throw new Error('<ReferenceCollectionField> only accepts a single child');\n  }\n\n  if (!record || !record[source]) return null;\n\n  return (\n    <CollectionList resource={reference} collectionUri={record[source]} {...rest}>\n      {children}\n    </CollectionList>\n  );\n};\n\nReferenceCollectionField.defaultProps = {\n  addLabel: true,\n};\n\nexport default ReferenceCollectionField;\n","import { useCallback, useMemo, useState, useEffect } from 'react';\nimport { useGetIdentity, fetchUtils } from 'react-admin';\n\nconst useCollection = (predicateOrUri) => {\n  const { identity } = useGetIdentity();\n  const [items, setItems] = useState([]);\n  const [loading, setLoading] = useState(false);\n  const [loaded, setLoaded] = useState(false);\n  const [error, setError] = useState(false);\n\n  const collectionUri = useMemo(() => {\n    if (predicateOrUri) {\n      if (predicateOrUri.startsWith('http')) {\n        return predicateOrUri;\n      } else if (identity?.webIdData) {\n        return identity?.webIdData?.[predicateOrUri];\n      }\n    }\n  }, [identity, predicateOrUri]);\n\n  const fetch = useCallback(async () => {\n    if (!collectionUri) return;\n\n    setLoading(true);\n    const headers = new Headers({\n      Accept: 'application/ld+json',\n      Authorization: 'Bearer ' + localStorage.getItem('token'),\n    });\n\n    fetchUtils\n      .fetchJson(collectionUri, { headers })\n      .then(({ json }) => {\n        if (json && json.items) {\n          setItems(json.items);\n        } else {\n          setItems([]);\n        }\n        setError(false);\n        setLoaded(true);\n        setLoading(false);\n      })\n      .catch(() => {\n        setError(true);\n        setLoaded(true);\n        setLoading(false);\n      });\n  }, [setItems, setLoaded, setLoading, setError, collectionUri]);\n\n  useEffect(() => {\n    if (!loading && !loaded && !error) {\n      fetch();\n    }\n  }, [fetch, loading, loaded, error]);\n\n  return { items, loading, loaded, error, refetch: fetch, url: collectionUri, owner: identity?.id };\n};\n\nexport default useCollection;\n","import { useCallback, useMemo } from 'react';\nimport { useGetIdentity, fetchUtils } from 'react-admin';\nimport { buildDereferenceQuery } from '@semapps/semantic-data-provider';\n\nconst useInbox = () => {\n  const { identity } = useGetIdentity();\n\n  const inboxUrl = useMemo(() => {\n    if (identity?.webIdData) {\n      return identity?.webIdData?.inbox;\n    }\n  }, [identity]);\n\n  const sparqlEndpoint = useMemo(() => {\n    if (identity?.webIdData) {\n      return identity?.webIdData?.endpoints?.['void:sparqlEndpoint'];\n    }\n  }, [identity]);\n\n  const fetch = useCallback(\n    async ({ filters }) => {\n      if (!sparqlEndpoint || !inboxUrl) return;\n\n      const token = localStorage.getItem('token');\n      const dereferenceQuery = buildDereferenceQuery(['as:object']);\n\n      let filtersWhereQuery = '';\n      if (filters) {\n        Object.keys(filters).forEach((predicate) => {\n          if (filters[predicate]) {\n            const object = filters[predicate].startsWith('http') ? `<${filters[predicate]}>` : filters[predicate];\n            filtersWhereQuery += `?s1 ${predicate} ${object} .`;\n          }\n        });\n      }\n\n      const query = `\n      PREFIX as: <https://www.w3.org/ns/activitystreams#>\n      CONSTRUCT {\n        ?s1 ?p1 ?o1 .\n        ${dereferenceQuery.construct}\n      }\n      WHERE {\n        <${inboxUrl}> as:items ?s1 .\n        ?s1 ?p1 ?o1 .\n        FILTER( (isIRI(?s1)) ) .\n        ${filtersWhereQuery}\n        ${dereferenceQuery.where}\n      }\n    `;\n\n      const { json } = await fetchUtils.fetchJson(sparqlEndpoint, {\n        method: 'POST',\n        body: query,\n        headers: new Headers({\n          Accept: 'application/ld+json',\n          Authorization: 'Bearer ' + token,\n        }),\n      });\n\n      if (json['@graph']) {\n        return json['@graph'];\n      } else {\n        return null;\n      }\n    },\n    [sparqlEndpoint, inboxUrl]\n  );\n\n  return { fetch, url: inboxUrl, owner: identity?.id };\n};\n\nexport default useInbox;\n","import { useCallback, useMemo } from 'react';\nimport { useGetIdentity, fetchUtils } from 'react-admin';\nimport { buildDereferenceQuery } from '@semapps/semantic-data-provider';\n\nconst useOutbox = () => {\n  const { identity } = useGetIdentity();\n\n  const outboxUrl = useMemo(() => {\n    if (identity?.webIdData) {\n      return identity?.webIdData?.outbox;\n    }\n  }, [identity]);\n\n  const sparqlEndpoint = useMemo(() => {\n    if (identity?.webIdData) {\n      return identity?.webIdData?.endpoints?.['void:sparqlEndpoint'];\n    }\n  }, [identity]);\n\n  // Post an activity to the logged user's outbox and return its URI\n  const post = useCallback(\n    async (activity) => {\n      const token = localStorage.getItem('token');\n      try {\n        const { headers } = await fetchUtils.fetchJson(outboxUrl, {\n          method: 'POST',\n          body: JSON.stringify({\n            '@context': 'https://www.w3.org/ns/activitystreams',\n            ...activity,\n          }),\n          headers: new Headers({\n            'Content-Type': 'application/ld+json',\n            Authorization: `Bearer ${token}`,\n          }),\n        });\n        return headers.get('Location');\n      } catch (e) {\n        return false;\n      }\n    },\n    [outboxUrl]\n  );\n\n  const fetch = useCallback(async () => {\n    if (!sparqlEndpoint || !outboxUrl) return;\n\n    const token = localStorage.getItem('token');\n    const dereferenceQuery = buildDereferenceQuery(['as:object']);\n\n    const query = `\n      PREFIX as: <https://www.w3.org/ns/activitystreams#>\n      CONSTRUCT {\n        ?s1 ?p1 ?o1 .\n        ${dereferenceQuery.construct}\n      }\n      WHERE {\n        <${outboxUrl}> as:items ?s1 .\n        ?s1 ?p1 ?o1 .\n        ${dereferenceQuery.where}\n      }\n    `;\n\n    const { json } = await fetchUtils.fetchJson(sparqlEndpoint, {\n      method: 'POST',\n      body: query,\n      headers: new Headers({\n        Accept: 'application/ld+json',\n        Authorization: 'Bearer ' + token,\n      }),\n    });\n\n    if (json['@graph']) {\n      return json['@graph'];\n    } else {\n      return null;\n    }\n  }, [sparqlEndpoint, outboxUrl]);\n\n  return { post, fetch, url: outboxUrl, owner: identity?.id };\n};\n\nexport default useOutbox;\n","import { useCallback } from 'react';\nimport { fetchUtils } from 'react-admin';\n\nconst useWebfinger = () => {\n  // Post an activity to the logged user's outbox and return its URI\n  const fetch = useCallback(async (id) => {\n    // eslint-disable-next-line\n    const [_, username, host] = id.split('@');\n    const protocol = host.includes(':') ? 'http' : 'https';\n\n    const webfingerUrl = `${protocol}://${host}/.well-known/webfinger?resource=acct:${username}@${host}`;\n\n    try {\n      const { json } = await fetchUtils.fetchJson(webfingerUrl);\n\n      const link = json.links.find((l) => l.type === 'application/activity+json');\n\n      return link ? link.href : null;\n    } catch (e) {\n      return null;\n    }\n  }, []);\n\n  return { fetch };\n};\n\nexport default useWebfinger;\n"],"names":["module","IdentifierIssuer","constructor","prefix","existing","Map","counter","_existing","clone","this","getId","old","get","identifier","set","hasId","has","getOldIds","keys","algorithm","md","crypto","createHash","update","msg","digest","list","current","sort","done","dir","i","length","hasNext","next","rval","slice","k","pos","element","left","swap","RDF_LANGSTRING","RDF","XSD_STRING","REGEX","empty","RegExp","quad","NQuads","input","dataset","graphs","lines","split","eoln","lineNumber","line","test","match","Error","subject","predicate","object","graph","undefined","termType","value","datatype","language","replace","_unescapeRegex","code","u","U","String","fromCharCode","parseInt","unique","quads","q","_compareTriples","push","Array","isArray","legacyDatasetToQuads","serializeQuad","join","s","p","o","g","nquad","_escapeRegex","_escape","termTypeMap","IRI","literal","graphName","forEach","triple","componentName","oldComponent","newComponent","type","startsWith","t1","t2","name","blankNodeInfo","canonicalIssuer","hashAlgorithm","_addBlankNodeQuadInfo","component","hashToBlankNodes","nonNormalized","id","_yield","_hashAndTrackBlankNode","hashes","nonUnique","hash","idList","hashPathList","issuer","result","hashNDegreeQuads","_stringHashCompare","oldIds","normalized","_useCanonicalId","nquads","info","copy","modifyFirstDegreeComponent","MessageDigest","related","position","getRelatedPredicate","hashToRelated","createHashToRelated","chosenIssuer","chosenPath","permuter","Permuter","permutation","issuerCopy","path","recursionList","nextPermutation","Promise","all","_addRelatedBlankNodeHash","hashFirstDegreeQuads","add","Set","hashRelatedBlankNode","entries","resolve","setImmediate","a","b","URDNA2015","key","main","URDNA2015Sync","rdfCanonizeNative","require","e","api","_rdfCanonizeNative","canonize","async","options","useNative","reject","err","canonical","URGNA2012","_canonizeSync","canonizeSync","URGNA2012Sync","isBoolean","v","Object","prototype","toString","call","isDouble","isNumber","indexOf","Math","abs","isEmptyObject","isObject","isNumeric","isNaN","parseFloat","isFinite","isString","isUndefined","isSubject","types","isSubjectReference","isValue","isList","isGraph","filter","isSimpleGraph","isBlankNode","message","details","REGEX_LINK_HEADERS","REGEX_LINK_HEADER","REGEX_LINK_HEADER_PARAMS","DEFAULTS","accept","asArray","buildHeaders","headers","some","h","toLowerCase","RangeError","assign","Accept","parseLinkHeader","header","target","params","exec","rel","hasOwnProperty","validateTypeValue","isFrame","every","vv","JsonLdError","hasProperty","property","hasValue","val","graphTypes","compareValues","addValue","propertyIsArray","valueIsArray","allowDuplicate","prependValue","concat","unshift","getValues","removeProperty","removeValue","values","relabelBlankNodes","_labelBlankNodes","ki","v1","v2","compareShortestLeast","XSD","LINK_HEADER_REL","LINK_HEADER_CONTEXT","RDF_LIST","RDF_FIRST","RDF_REST","RDF_NIL","RDF_TYPE","RDF_PLAIN_LITERAL","RDF_XML_LITERAL","RDF_JSON_LITERAL","RDF_OBJECT","XSD_BOOLEAN","XSD_DOUBLE","XSD_INTEGER","_requests","wrapLoader","loader","self","_loader","apply","arguments","url","promise","parsers","simple","regex","full","parse","str","parser","parsed","m","scheme","port","href","authority","normalizedPath","removeDotSegments","prependBase","base","iri","isAbsolute","transform","protocol","query","substr","lastIndexOf","fragment","removeBase","root","baseSegments","iriSegments","last","shift","pop","output","isAbsoluteRegex","isRelative","uri","TypeError","firstComma","meta","substring","charset","base64","typeFull","encoding","data","unescape","buffer","Buffer","from","Readable","wm","WeakMap","Blob","blobParts","size","parts","map","ArrayBuffer","isView","byteOffset","byteLength","arrayBuffer","Uint8Array","offset","chunk","stream","part","read","start","end","relativeStart","max","min","relativeEnd","span","added","blob","Symbol","toStringTag","hasInstance","defineProperties","enumerable","FetchBaseError","captureStackTrace","FetchError","systemError","errno","erroredSysCall","syscall","NAME","isURLSearchParameters","append","delete","getAll","isBlob","isFormData","dashes","repeat","carriageLength","getFooter","boundary","getHeader","field","INTERNALS","Body","body","isBuffer","isAnyArrayBuffer","Stream","randomBytes","form","formDataIterator","disturbed","error","on","consumeBody","ct","buf","JSON","alloc","accum","accumBytes","destroy","readableEnded","_readableState","ended","c","bodyUsed","json","text","instance","highWaterMark","p1","p2","getBoundary","PassThrough","pipe","extractContentType","request","getTotalBytes","getLengthSync","hasKnownLength","getFormDataLength","validateHeaderName","http","defineProperty","validateHeaderValue","Headers","URLSearchParams","init","raw","isBoxedPrimitive","method","iterator","pair","Proxy","receiver","Reflect","callback","reduce","for","redirectStatus","isRedirect","Response","status","contentType","statusText","ok","redirected","location","URL","isRequest","Request","parsedURL","toUpperCase","inputBody","signal","redirect","follow","compress","agent","insecureHTTPParser","formatUrl","AbortError","supportedSchemas","fetch","options_","contentLengthValue","totalBytes","Number","search","lastOffset","getSearch","pathname","hostname","getNodeRequestOptions","dataUriToBuffer","response","send","https","abort","emit","aborted","abortAndFinalize","finalize","request_","addEventListener","removeEventListener","response_","setTimeout","index","array","fromRawHeaders","rawHeaders","statusCode","locationURL","requestOptions","once","pump","process","version","responseOptions","statusMessage","codings","zlibOptions","flush","zlib","Z_SYNC_FLUSH","finishFlush","createGunzip","createBrotliDecompress","createInflate","createInflateRaw","dest","write","writeToStream","privateData","wrappers","pd","event","retv","console","assert","setCancelFlag","passiveListener","cancelable","canceled","preventDefault","Event","eventTarget","eventPhase","currentTarget","stopped","immediateStopped","timeStamp","Date","now","defineRedirectDescriptor","[object Object]","configurable","defineCallDescriptor","getWrapper","proto","wrapper","BaseEvent","CustomEvent","create","writable","isFunc","getOwnPropertyDescriptor","defineWrapper","getPrototypeOf","isStopped","setPassiveListener","stopPropagation","stopImmediatePropagation","Boolean","bubbles","composed","cancelBubble","window","setPrototypeOf","AbortSignal","EventTarget","abortedFlags","defineEventAttribute","dispatchEvent","globals","getGlobal","global","globalThis","globalProperties","globalObject","bind","supportsAbortController","AbortController","supportsStreams","ReadableStream","supportsFormData","FormData","mergeHeaders","source1","source2","isHeadersInstance","source","deepMerge","sources","returnValue","requestMethods","responseTypes","formData","retryAfterStatusCodes","stop","HTTPError","TimeoutError","delay","ms","normalizeRequestMethod","includes","defaultRetryOptions","limit","methods","statusCodes","afterStatusCodes","normalizeRetryOptions","retry","Ky","_retryCount","_input","_options","credentials","hooks","beforeRequest","beforeRetry","afterResponse","prefixUrl","throwHttpErrors","timeout","endsWith","abortController","searchParams","stringify","fn","_fetch","hook","modifiedResponse","_decorateResponse","onDownloadProgress","_stream","_retry","mimeType","parseJson","_calculateRetryDelay","retryAfter","after","maxRetryAfter","retryCount","timeoutID","then","catch","clearTimeout","transferredBytes","controller","reader","getReader","percent","close","enqueue","validateAndMerge","createInstance","defaults","ky","newDefaults","extend","factory","_","DEFAULT_HEADERS","kyOriginal","proxyMethods","_handleResponse","thisArg","args","errorBody","_handleError","parseBody","propKey","propValue","httpClient","secure","strictSSL","maxRedirects","httpAgent","httpsAgent","RequestQueue","loadDocument","redirects","isHttp","isHttps","doc","alternate","res","Agent","rejectUnauthorized","cause","contextUrl","documentUrl","document","STATUS_CODES","httpStatusCode","link","linkHeaders","linkedContext","setupDocumentLoaders","jsonld","documentLoaders","node","nodeLoader","useDocumentLoader","setupGlobals","Yallist","tail","head","item","l","insert","inserted","Node","prev","removeNode","unshiftNode","pushNode","thisp","walker","forEachReverse","n","getReverse","mapReverse","initial","acc","reduceReverse","toArray","arr","toArrayReverse","to","ret","sliceReverse","splice","deleteCount","nodes","reverse","er","MAX","LENGTH","LENGTH_CALCULATOR","ALLOW_STALE","MAX_AGE","DISPOSE","NO_DISPOSE_ON_SET","LRU_LIST","CACHE","UPDATE_AGE_ON_GET","naiveLength","doUse","hit","isStale","del","maxAge","diff","trim","Entry","forEachStep","Infinity","lc","stale","dispose","noDisposeOnSet","updateAgeOnGet","reset","mL","allowStale","mA","lC","rforEach","dump","dumpLru","len","peek","load","expiresAt","prune","cache","LRU","getProcessed","activeCtx","setProcessed","processedCtx","_isArray","_isObject","_isString","_asArray","sharedCache","perOpCache","context","documentLoader","cycles","allResolved","ctx","resolved","_get","_resolveRemoteContext","ResolvedContext","_throwInvalidLocalContext","_cacheResolvedContext","tag","tagMap","remoteDoc","_fetchContext","_resolveContextUrls","term","processingMode","_isUndefined","_isAbsoluteIri","_isRelativeIri","_compareShortestLeast","INITIAL_CONTEXT_CACHE","KEYWORD_PATTERN","_expandIri","relativeTo","localCtx","defined","isKeyword","createTermDefinition","vocab","mapping","mappings","colon","suffix","_prefix","propagate","overrideProtected","contextResolver","previousContext","resolvedContext","protected","protectedMode","warn","processed","oldActiveCtx","getInitialContext","_protected","util","resolvedImport","processedImport","importCtx","keyCtx","validKeys","previousMapping","simpleTerm","kw","_termHasColon","container","validContainers","isValid","hasSet","direction","nest","_deepCompare","x1","x2","x1Array","k1s","k2s","k1","expandIri","cached","initialContext","inverse","getInverse","fastCurieMap","irisToTerms","defaultLanguage","defaultDirection","terms","ids","entry","fastCurieEntry","_addPreferredTerm","_buildIriMap","child","revertToPreviousContext","clear","iriMap","idx","letter","typeOrLanguageValue","getContextValue","_isEmptyObject","_isList","_isValue","_isGraph","_isSubject","_getContextValue","_isKeyword","_processContext","_processingMode","_addValue","_getValues","_validateTypeValue","REGEX_BCP47","_expandValue","activeProperty","expandedProperty","_expandLanguageMap","languageMap","expandedKey","_expandIndexMap","expansionMap","asGraph","indexKey","propertyIndex","isTypeIndex","expand","insideList","insideIndex","typeScopedContext","mapped","unmappedValue","parent","expandedParent","expandedActiveProperty","propertyScopedCtx","mustRevert","typeKey","_expandObject","nests","unexpandedValue","isJsonType","expandedValue","unmappedProperty","keyword","fromEntries","includedResult","lang","reverseMap","items","ii","termCtx","nextActiveProperty","nestedValues","nv","count","validCount","t","keepFreeFloatingNodes","createMergedNodeMap","createNodeMap","mergeNodeMaps","_list","subjects","properties","referencedNode","reverseProperty","itemName","objects","mergeNodeMapGraphs","merged","mergedNode","defaultGraph","graphNames","nodeMap","_isSubjectReference","_createMergedNodeMap","flatten","flattened","_RDFToObject","useNativeTypes","rdfDirection","toFixed","fromRDF","useRdfType","graphMap","referencedOnce","objectIsNode","usages","graphObject","nil","usage","listNodes","nodeKeyCount","listNode","graphSubjects","graphSubject","_graphToRDF","graphTerm","produceGeneralizedRdf","_objectToRDF","serialize","toJSON","cv","ci","jsonCanonicalize","toExponential","first","rest","_listToRDF","toRDF","_createNodeMap","_mergeNodeMapGraphs","_createImplicitFrame","flags","frame","_createsCircularReference","subjectToEmbed","subjectStack","_getFrameFlag","flag","_validateFrame","_filterSubject","state","wildcard","matchesSome","matchThis","nodeValues","isEmpty","requireAll","tt","thisFrame","hasDefault","listValue","nodeListValues","lv","_valueMatch","_nodeMatch","_removeEmbed","embeds","uniqueEmbeds","embed","useArray","removeDependents","_addFrameOutput","pattern","nodeObject","l1","l2","frameMergedOrDefault","embedded","bnodeMap","framed","pruneBlankNodeIdentifiers","bnodesToClear","_cleanupPreserve","prop","explicit","matches","_filterSubjects","is11","recurse","subframe","src","oo","preserve","reverseProp","cleanupNull","_isSimpleGraph","_removeBase","_prependBase","_checkNestProperty","nestProperty","compact","compactionMap","compacted","compactArrays","linked","expanded","compactValue","insideReverse","inputCtx","typeContext","compactedType","compactIri","alias","itemActiveProperty","nestResult","expandedItem","inner","compactedItem","mapObject","containerKey","others","idKey","compactedValue","compactedProperty","expandedIri","isPropertyTermScoped","inverseCtx","containers","typeOrLanguage","commonLanguage","commonType","itemLanguage","itemType","prefs","langDir","find","el","containerMap","typeOrLanguageValueMap","pref","_selectTerm","choice","partialMatches","maxPartialLength","curie","td","preserveIndex","keyCount","isValueOnlyKey","hasDefaultLanguage","isValueString","hasNullMapping","_expand","_flatten","_fromRDF","_toRDF","_frameMergedOrDefault","_cleanupNull","_getInitialContext","_compact","_compactIri","_mergeNodeMaps","_rdfParsers","_resolvedContextCache","_setDefaults","compactToRelative","skipExpansion","ContextResolver","processContext","tmp","hasContext","graphAlias","toResolve","contextsToProcess","expandContext","defaultBase","remoteContext","omitDefault","frameContext","omitGraph","opts","expandedFrame","frameKeys","framing","normalize","inputFormat","parsedInput","format","rdfParser","parsedDataset","merge","docs","mergeNodes","_graphs","_nodeMap","_documentLoader","registerRDFParser","unregisterRDFParser","promises","JsonLdProcessor","platform","charMap","lookAheadCharArray","diatricMap","langCharMap","symbolMap","uricChars","uricNoSlashChars","markChars","getSlug","maintainCase","titleCase","truncate","uricFlag","uricNoSlashFlag","markFlag","symbol","langChar","lucky","ch","lastCharWasSymbol","lastCharWasDiatric","separator","diatricString","convertSymbols","customReplacements","allowedChars","en","custom","uric","uricNoSlash","mark","symbols","r","escapeChars","isReplacedCustomChar","j","charAt","createSlug","exports","CollectionList","collectionUri","resource","children","React","Children","useGetOne","enabled","collection","loading","style","marginTop","LinearProgress","ReferenceArrayField","reference","record","ReferenceCollectionField","defaultProps","addLabel","useCollection","predicateOrUri","identity","useGetIdentity","useState","setItems","setLoading","loaded","setLoaded","setError","useMemo","webIdData","_identity$webIdData","useCallback","Authorization","localStorage","getItem","fetchUtils","fetchJson","useEffect","refetch","owner","useInbox","inboxUrl","inbox","sparqlEndpoint","_identity$webIdData2","endpoints","_identity$webIdData2$","filters","token","dereferenceQuery","buildDereferenceQuery","filtersWhereQuery","construct","where","useOutbox","outboxUrl","outbox","post","activity","useWebfinger","username","host","webfingerUrl","links"],"mappings":"kjGAKAA,MAAiB,MAAMC,EASrBC,YAAYC,EAAQC,EAAW,IAAIC,IAAOC,EAAU,QAC7CH,OAASA,OACTI,UAAYH,OACZE,QAAUA,EAQjBE,cACQL,OAACA,EAADI,UAASA,EAATD,QAAoBA,GAAWG,YAC9B,IAAIR,EAAiBE,EAAQ,IAAIE,IAAIE,GAAYD,GAW1DI,MAAMC,SAEEP,EAAWO,GAAOF,KAAKF,UAAUK,IAAID,MACxCP,SACMA,QAIHS,EAAaJ,KAAKN,OAASM,KAAKH,oBACjCA,UAGFK,QACIJ,UAAUO,IAAIH,EAAKE,GAGnBA,EAYTE,MAAMJ,UACGF,KAAKF,UAAUS,IAAIL,GAS5BM,kBACS,IAAIR,KAAKF,UAAUW,YCtEb,MAMfhB,YAAYiB,QACLC,GAAKC,EAAOC,WAAWH,GAG9BI,OAAOC,QACAJ,GAAGG,OAAOC,EAAK,QAGtBC,gBACShB,KAAKW,GAAGK,OAAO,WCfT,MAOfvB,YAAYwB,QAELC,QAAUD,EAAKE,YAEfC,MAAO,OAEPC,IAAM,IAAIzB,QACX,IAAI0B,EAAI,EAAGA,EAAIL,EAAKM,SAAUD,OAC3BD,IAAIhB,IAAIY,EAAKK,IAAI,GAS1BE,iBACUxB,KAAKoB,KASfK,aAEQP,QAACA,EAADG,IAAUA,GAAOrB,KACjB0B,EAAOR,EAAQS,YAOjBC,EAAI,KACJC,EAAM,QACJN,EAASL,EAAQK,WACnB,IAAID,EAAI,EAAGA,EAAIC,IAAUD,EAAG,OACxBQ,EAAUZ,EAAQI,GAClBS,EAAOV,EAAIlB,IAAI2B,IACX,OAANF,GAAcE,EAAUF,KACxBG,GAAQT,EAAI,GAAKQ,EAAUZ,EAAQI,EAAI,KACvCS,GAAQT,EAAKC,EAAS,GAAMO,EAAUZ,EAAQI,EAAI,MACpDM,EAAIE,EACJD,EAAMP,MAKD,OAANM,OACIR,MAAO,MACP,OAECY,EAAOX,EAAIlB,IAAIyB,GAAKC,EAAM,EAAIA,EAAM,EAC1CX,EAAQW,GAAOX,EAAQc,GACvBd,EAAQc,GAAQJ,MAGZ,MAAME,KAAWZ,EAChBY,EAAUF,GACXP,EAAIhB,IAAIyB,GAAUT,EAAIlB,IAAI2B,WAKzBJ,IC3EX,MACMO,EAAiBC,wDACjBC,EAAa,0CAQbC,EAAQ,CAiDZA,KAAa,2BACbA,EAAMC,MAAQ,IAAIC,OAAO,aAGzBF,EAAMG,KAAO,IAAID,OACf,8wBAGJ/C,MAAiB,MAAMiD,eAQRC,SAELC,EAAU,GAEVC,EAAS,GAGTC,EAAQH,EAAMI,MAAMT,EAAMU,UAC5BC,EAAa,MACb,MAAMC,KAAQJ,EAAO,IACvBG,IAGGX,EAAMC,MAAMY,KAAKD,kBAKdE,EAAQF,EAAKE,MAAMd,EAAMG,SAClB,OAAVW,QACK,IAAIC,MAAM,+BAAiCJ,EAAa,WAI1DR,EAAO,CAACa,QAAS,KAAMC,UAAW,KAAMC,OAAQ,KAAMC,MAAO,cAGnDC,IAAbN,EAAM,GACPX,EAAKa,QAAU,CAACK,SAnGA,YAmG2BC,MAAOR,EAAM,IAExDX,EAAKa,QAAU,CAACK,SApGA,YAoG2BC,MAAOR,EAAM,IAI1DX,EAAKc,UAAY,CAACI,SAzGA,YAyG2BC,MAAOR,EAAM,SAG1CM,IAAbN,EAAM,GACPX,EAAKe,OAAS,CAACG,SA7GC,YA6G0BC,MAAOR,EAAM,SAClCM,IAAbN,EAAM,GACdX,EAAKe,OAAS,CAACG,SA9GC,YA8G0BC,MAAOR,EAAM,KAEvDX,EAAKe,OAAS,CACZG,SAhHW,UAiHXC,WAAOF,EACPG,SAAU,CACRF,SArHY,mBAwHAD,IAAbN,EAAM,GACPX,EAAKe,OAAOK,SAASD,MAAQR,EAAM,QACdM,IAAbN,EAAM,IACdX,EAAKe,OAAOK,SAASD,MAAQzB,EAC7BM,EAAKe,OAAOM,SAAWV,EAAM,IAE7BX,EAAKe,OAAOK,SAASD,MAAQvB,EAE/BI,EAAKe,OAAOI,MAAkBR,EAAM,GAwOjCW,QAAQC,GAAgB,SAASZ,EAAOa,EAAMC,EAAGC,MACrDF,SACMA,OACA,UAAY,SACZ,UAAY,SACZ,UAAY,SACZ,UAAY,SACZ,UAAY,SACZ,UAAY,QACZ,UAAa,QACb,WAAa,QAGnBC,SACME,OAAOC,aAAaC,SAASJ,EAAG,QAEtCC,QAEK,IAAId,MAAM,iCAtPAK,IAAbN,EAAM,GACPX,EAAKgB,MAAQ,CACXE,SAtIc,YAuIdC,MAAOR,EAAM,SAEOM,IAAdN,EAAM,IACdX,EAAKgB,MAAQ,CACXE,SA1Ic,YA2IdC,MAAOR,EAAM,KAGfX,EAAKgB,MAAQ,CACXE,SA7IiB,eA8IjBC,MAAO,IAKNnB,EAAKgB,MAAMG,SAASf,EAGlB,KACD0B,GAAS,QACPC,EAAQ3B,EAAOJ,EAAKgB,MAAMG,WAC5B,MAAMa,KAAKD,KACVE,EAAgBD,EAAGhC,GAAO,CAC3B8B,GAAS,QAIVA,IACDC,EAAMG,KAAKlC,GACXG,EAAQ+B,KAAKlC,SAbfI,EAAOJ,EAAKgB,MAAMG,OAAS,CAACnB,GAC5BG,EAAQ+B,KAAKlC,UAiBVG,mBAUQA,GACXgC,MAAMC,QAAQjC,KAChBA,EAAUF,EAAOoC,qBAAqBlC,UAElC4B,EAAQ,OACV,MAAM/B,KAAQG,EAChB4B,EAAMG,KAAKjC,EAAOqC,cAActC,WAE3B+B,EAAMnD,OAAO2D,KAAK,yBAUNvC,SACbwC,EAAIxC,EAAKa,QACT4B,EAAIzC,EAAKc,UACT4B,EAAI1C,EAAKe,OACT4B,EAAI3C,EAAKgB,UAEX4B,EAAQ,SA3MQ,cA8MjBJ,EAAEtB,SACH0B,GAAU,IAAGJ,EAAErB,SAEfyB,GAAU,GAAEJ,EAAErB,MAIhByB,GAAU,KAAIH,EAAEtB,UArNI,cAwNjBuB,EAAExB,SACH0B,GAAU,IAAGF,EAAEvB,SAxNG,cAyNVuB,EAAExB,SACV0B,GAASF,EAAEvB,OAEXyB,GAAU,IA0HhB,SAAiBJ,UACRA,EAAElB,QAAQuB,GAAc,SAASlC,UAC/BA,OACA,UAAY,UACZ,WAAa,WACb,WAAa,UACb,WAAa,UAhILmC,CAAQJ,EAAEvB,UACpBuB,EAAEtB,SAASD,QAAUzB,EACnBgD,EAAErB,WACHuB,GAAU,IAAGF,EAAErB,UAETqB,EAAEtB,SAASD,QAAUvB,IAC7BgD,GAAU,MAAKF,EAAEtB,SAASD,WAnOV,cAyOjBwB,EAAEzB,SACH0B,GAAU,KAAID,EAAExB,SAzOE,cA0OVwB,EAAEzB,WACV0B,GAAU,IAAGD,EAAExB,OAGjByB,GAAS,OACFA,8BAWmBzC,SACpB4B,EAAQ,GAERgB,EAAc,cA7PA,YA+PlBC,IAhQkB,YAiQlBC,QA/Pe,eAkQb,MAAMC,KAAa/C,EAAS,CACdA,EAAQ+C,GAChBC,QAAQC,UACRpD,EAAO,OACT,MAAMqD,KAAiBD,EAAQ,OAC3BE,EAAeF,EAAOC,GACtBE,EAAe,CACnBrC,SAAU6B,EAAYO,EAAaE,MACnCrC,MAAOmC,EAAanC,OA1QX,YA4QRoC,EAAarC,WACdqC,EAAanC,SAAW,CACtBF,SAhRU,aAkRT,aAAcoC,IACfC,EAAanC,SAASD,MAAQmC,EAAalC,UAE1C,aAAckC,GACV,aAAcA,IACjBC,EAAanC,SAASD,MAAQzB,GAEhC6D,EAAalC,SAAWiC,EAAajC,UAC3B,aAAciC,IACxBC,EAAanC,SAASD,MAAQvB,IAGlCI,EAAKqD,GAAiBE,EAGtBvD,EAAKgB,MADU,aAAdkC,EACY,CACXhC,SA/Re,eAgSfC,MAAO,IAGI,CACXD,SAAUgC,EAAUO,WAAW,MAtSnB,YADA,YAySZtC,MAAO+B,GAGXnB,EAAMG,KAAKlC,YAIR+B,IAYX,SAASE,EAAgByB,EAAIC,UAEtBD,EAAG7C,QAAQK,WAAayC,EAAG9C,QAAQK,UACtCwC,EAAG3C,OAAOG,WAAayC,EAAG5C,OAAOG,WAI9BwC,EAAG7C,QAAQM,QAAUwC,EAAG9C,QAAQM,OACnCuC,EAAG5C,UAAUK,QAAUwC,EAAG7C,UAAUK,OACpCuC,EAAG3C,OAAOI,QAAUwC,EAAG5C,OAAOI,QAnUb,YAsUhBuC,EAAG3C,OAAOG,UAKVwC,EAAG3C,OAAOK,SAASF,WAAayC,EAAG5C,OAAOK,SAASF,UACnDwC,EAAG3C,OAAOM,WAAasC,EAAG5C,OAAOM,UACjCqC,EAAG3C,OAAOK,SAASD,QAAUwC,EAAG5C,OAAOK,SAASD,QAIrD,MAAM0B,EAAe,aAerB,MAAMtB,EACJ,uECpWFvE,MAAiB,MACfE,mBACO0G,KAAO,iBACPC,cAAgB,IAAIxG,SACpByG,gBAAkB,IAAI7G,EAAiB,eACvC8G,cAAgB,cAChBhC,MAAQ,gBAIJ5B,QACJ4B,MAAQ5B,MAIT,MAAMH,KAAQG,OAIX6D,sBAAsB,CAAChE,KAAAA,EAAMiE,UAAWjE,EAAKa,eAC7CmD,sBAAsB,CAAChE,KAAAA,EAAMiE,UAAWjE,EAAKe,cAC7CiD,sBAAsB,CAAChE,KAAAA,EAAMiE,UAAWjE,EAAKgB,cAkB9CkD,EAAmB,IAAI7G,IACvB8G,EAAgB,IAAI1G,KAAKoG,cAAc3F,YACzCa,EAAI,MACJ,MAAMqF,KAAMD,IAETpF,EAAI,KAAQ,SACTtB,KAAK4G,eAGP5G,KAAK6G,uBAAuB,CAACF,GAAAA,EAAIF,iBAAAA,UAKnCK,EAAS,IAAIL,EAAiBhG,QAAQU,OAEtC4F,EAAY,OACd,MAAMC,KAAQF,EAAQ,OAGlBG,EAASR,EAAiBtG,IAAI6G,MACjCC,EAAO1F,OAAS,EAAG,CACpBwF,EAAUtC,KAAKwC,kBAQXN,EAAKM,EAAO,QACbZ,gBAAgBpG,MAAM0G,OAYzB,MAAMM,KAAUF,EAAW,OAGvBG,EAAe,OAGjB,MAAMP,KAAMM,EAAQ,IAGnBjH,KAAKqG,gBAAgB/F,MAAMqG,kBAMxBQ,EAAS,IAAI3H,EAAiB,OAKpC2H,EAAOlH,MAAM0G,SAIPS,QAAepH,KAAKqH,iBAAiBV,EAAIQ,GAC/CD,EAAazC,KAAK2C,GAKpBF,EAAa/F,KAAKmG,OACd,MAAMF,KAAUF,EAAc,OAM1BK,EAASH,EAAOD,OAAO3G,gBACzB,MAAMmG,KAAMY,OACTlB,gBAAgBpG,MAAM0G,UAW3Ba,EAAa,OACf,MAAMjF,KAAQvC,KAAKsE,MAAO,OAKtBC,EAAI,IAAIhC,GACdgC,EAAEnB,QAAUpD,KAAKyH,gBAAgB,CAACjB,UAAWjC,EAAEnB,UAC/CmB,EAAEjB,OAAStD,KAAKyH,gBAAgB,CAACjB,UAAWjC,EAAEjB,SAC9CiB,EAAEhB,MAAQvD,KAAKyH,gBAAgB,CAACjB,UAAWjC,EAAEhB,QAE7CiE,EAAW/C,KAAKjC,EAAOqC,cAAcN,WAIvCiD,EAAWrG,OAGJqG,EAAW1C,KAAK,+BAIE6B,SAGnBe,EAAS,GAITC,EAAO3H,KAAKoG,cAAcjG,IAAIwG,GAC9BrC,EAAQqD,EAAKrD,UAGf,MAAM/B,KAAQ+B,EAAO,OAMjBsD,EAAO,CACXxE,QAAS,KAAMC,UAAWd,EAAKc,UAAWC,OAAQ,KAAMC,MAAO,MAKjEqE,EAAKxE,QAAUpD,KAAK6H,2BAClBlB,EAAIpE,EAAKa,QAAS,WACpBwE,EAAKtE,OAAStD,KAAK6H,2BACjBlB,EAAIpE,EAAKe,OAAQ,UACnBsE,EAAKrE,MAAQvD,KAAK6H,2BAChBlB,EAAIpE,EAAKgB,MAAO,SAClBmE,EAAOjD,KAAKjC,EAAOqC,cAAc+C,IAInCF,EAAOvG,aAIDR,EAAK,IAAImH,EAAc9H,KAAKsG,mBAC9B,MAAMnB,KAASuC,EACjB/G,EAAGG,OAAOqE,UAEZwC,EAAKX,WAAarG,EAAGK,SACd2G,EAAKX,gCAIae,EAASxF,EAAM4E,EAAQa,OAK5CrB,EAEFA,EADC3G,KAAKqG,gBAAgB/F,MAAMyH,GACvB/H,KAAKqG,gBAAgBpG,MAAM8H,GACxBZ,EAAO7G,MAAMyH,GAChBZ,EAAOlH,MAAM8H,GAEb/H,KAAKoG,cAAcjG,IAAI4H,GAASf,WAKjCrG,EAAK,IAAImH,EAAc9H,KAAKsG,sBAClC3F,EAAGG,OAAOkH,GAIM,MAAbA,GACDrH,EAAGG,OAAOd,KAAKiI,oBAAoB1F,IAIrC5B,EAAGG,OAAO6F,GAIHhG,EAAGK,gCAIW2F,EAAIQ,SAInBxG,EAAK,IAAImH,EAAc9H,KAAKsG,eAC5B4B,QAAsBlI,KAAKmI,oBAAoBxB,EAAIQ,GAOnDL,EAAS,IAAIoB,EAAczH,QAAQU,WACrC,MAAM6F,KAAQF,EAAQ,CAExBnG,EAAGG,OAAOkG,OAMNoB,EAHAC,EAAa,SAMXC,EAAW,IAAIC,EAASL,EAAc/H,IAAI6G,QAC5C1F,EAAI,OACFgH,EAAS9G,WAAW,OAClBgH,EAAcF,EAAS7G,SAExBH,EAAI,GAAM,SACPtB,KAAK4G,aAIT6B,EAAatB,EAAOpH,QAGpB2I,EAAO,SAILC,EAAgB,OAGlBC,GAAkB,MAClB,MAAMb,KAAWS,KAGhBxI,KAAKqG,gBAAgB/F,MAAMyH,GAC5BW,GAAQ1I,KAAKqG,gBAAgBpG,MAAM8H,IAK/BU,EAAWnI,MAAMyH,IACnBY,EAAclE,KAAKsD,GAIrBW,GAAQD,EAAWxI,MAAM8H,IASF,IAAtBM,EAAW9G,QAAgBmH,EAAOL,EAAY,CAC/CO,GAAkB,YAKnBA,OAKC,MAAMb,KAAWY,EAAe,OAI5BvB,QAAepH,KAAKqH,iBAAiBU,EAASU,MAIpDC,GAAQD,EAAWxI,MAAM8H,GAGzBW,GAAS,IAAGtB,EAAOJ,QAInByB,EAAarB,EAAOD,OAQK,IAAtBkB,EAAW9G,QAAgBmH,EAAOL,EAAY,CAC/CO,GAAkB,SAKnBA,IAOsB,IAAtBP,EAAW9G,QAAgBmH,EAAOL,KACnCA,EAAaK,EACbN,EAAeK,IAKnB9H,EAAGG,OAAOuH,GAGVlB,EAASiB,QAKJ,CAACpB,WAAYrG,EAAGK,SAAUmG,OAAAA,GAInCU,2BAA2BlB,EAAIH,SACH,cAAvBA,EAAU/C,SACJ+C,EAOF,CACL/C,SAAU,YACVC,MAAO8C,EAAU9C,QAAUiD,EAAK,MAAQ,OAK5CsB,oBAAoB1F,SACV,IAAGA,EAAKc,UAAUK,mCAIFiD,EAAIQ,SAGtBe,EAAgB,IAAItI,IAIpB0E,EAAQtE,KAAKoG,cAAcjG,IAAIwG,GAAIrC,UAGrChD,EAAI,MACJ,MAAMiB,KAAQ+B,IAEXhD,EAAI,KAAQ,SACTtB,KAAK4G,eAMPiC,QAAQC,IAAI,CAChB9I,KAAK+I,yBAAyB,CAC5BxG,KAAAA,EAAMiE,UAAWjE,EAAKa,QAAS4E,SAAU,IACzCrB,GAAAA,EAAIQ,OAAAA,EAAQe,cAAAA,IAEdlI,KAAK+I,yBAAyB,CAC5BxG,KAAAA,EAAMiE,UAAWjE,EAAKe,OAAQ0E,SAAU,IACxCrB,GAAAA,EAAIQ,OAAAA,EAAQe,cAAAA,IAEdlI,KAAK+I,yBAAyB,CAC5BxG,KAAAA,EAAMiE,UAAWjE,EAAKgB,MAAOyE,SAAU,IACvCrB,GAAAA,EAAIQ,OAAAA,EAAQe,cAAAA,aAKXA,gCAGoBvB,GAACA,EAADF,iBAAKA,UAG1BO,QAAahH,KAAKgJ,qBAAqBrC,GAIvCM,EAASR,EAAiBtG,IAAI6G,GAChCC,EAGFA,EAAOxC,KAAKkC,GAFZF,EAAiBpG,IAAI2G,EAAM,CAACL,IAMhCJ,uBAAsBhE,KAACA,EAADiE,UAAOA,OACD,cAAvBA,EAAU/C,sBAGPkD,EAAKH,EAAU9C,MACfiE,EAAO3H,KAAKoG,cAAcjG,IAAIwG,GACjCgB,EACDA,EAAKrD,MAAM2E,IAAI1G,QAEV6D,cAAc/F,IAAIsG,EAAI,CAACrC,MAAO,IAAI4E,IAAI,CAAC3G,IAAQyE,KAAM,uCAK5DzE,KAACA,EAADiE,UAAOA,EAAPwB,SAAkBA,EAAlBrB,GAA4BA,EAA5BQ,OAAgCA,EAAhCe,cAAwCA,OACZ,cAAvB1B,EAAU/C,UAA4B+C,EAAU9C,QAAUiD,eAQzDoB,EAAUvB,EAAU9C,MACpBsD,QAAahH,KAAKmJ,qBACtBpB,EAASxF,EAAM4E,EAAQa,GAKnBoB,EAAUlB,EAAc/H,IAAI6G,GAC/BoC,EACDA,EAAQ3E,KAAKsD,GAEbG,EAAc7H,IAAI2G,EAAM,CAACe,IAI7BN,iBAAgBjB,UAACA,UACW,cAAvBA,EAAU/C,UACV+C,EAAU9C,MAAMsC,WAAWhG,KAAKqG,gBAAgB3G,QAM5C8G,EALE,CACL/C,SAAU,YACVC,MAAO1D,KAAKqG,gBAAgBpG,MAAMuG,EAAU9C,8BAOzC,IAAImF,QAAQQ,GAAWC,aAAaD,MAI/C,SAAS/B,EAAmBiC,EAAGC,UACtBD,EAAEvC,KAAOwC,EAAExC,MAAQ,EAAIuC,EAAEvC,KAAOwC,EAAExC,KAAO,EAAI,ECrftDzH,MAAiB,cAAwBkK,EACvChK,2BAEO0G,KAAO,iBACPG,cAAgB,OAIvBuB,2BAA2BlB,EAAIH,EAAWkD,SACd,cAAvBlD,EAAU/C,SACJ+C,EAEE,UAARkD,EACM,CACLjG,SAAU,YACVC,MAAO,OAGJ,CACLD,SAAU,YACVC,MAAQ8C,EAAU9C,QAAUiD,EAAK,MAAQ,OAK7CsB,oBAAoB1F,UACXA,EAAKc,UAAUK,gCAIEiD,EAAIQ,SAGtBe,EAAgB,IAAItI,IAIpB0E,EAAQtE,KAAKoG,cAAcjG,IAAIwG,GAAIrC,UAGrChD,EAAI,MACJ,MAAMiB,KAAQ+B,EAAO,KAKnB0D,EACAD,KACyB,cAA1BxF,EAAKa,QAAQK,UAA4BlB,EAAKa,QAAQM,QAAUiD,EACjEoB,EAAUxF,EAAKa,QAAQM,MACvBsE,EAAW,QACN,CAAA,GACoB,cAAzBzF,EAAKe,OAAOG,UAA4BlB,EAAKe,OAAOI,QAAUiD,WAK9DoB,EAAUxF,EAAKe,OAAOI,MACtBsE,EAAW,MAMR1G,EAAI,KAAQ,SACTtB,KAAK4G,eAKPI,QAAahH,KAAKmJ,qBACtBpB,EAASxF,EAAM4E,EAAQa,GACnBoB,EAAUlB,EAAc/H,IAAI6G,GAC/BoC,EACDA,EAAQ3E,KAAKsD,GAEbG,EAAc7H,IAAI2G,EAAM,CAACe,WAItBG,MC7EM,MACfzI,mBACO0G,KAAO,iBACPC,cAAgB,IAAIxG,SACpByG,gBAAkB,IAAI7G,EAAiB,eACvC8G,cAAgB,cAChBhC,MAAQ,KAIfqF,KAAKjH,QACE4B,MAAQ5B,MAIT,MAAMH,KAAQG,OAIX6D,sBAAsB,CAAChE,KAAAA,EAAMiE,UAAWjE,EAAKa,eAC7CmD,sBAAsB,CAAChE,KAAAA,EAAMiE,UAAWjE,EAAKe,cAC7CiD,sBAAsB,CAAChE,KAAAA,EAAMiE,UAAWjE,EAAKgB,cAkB9CkD,EAAmB,IAAI7G,IACvB8G,EAAgB,IAAI1G,KAAKoG,cAAc3F,YACzC,MAAMkG,KAAMD,OAETG,uBAAuB,CAACF,GAAAA,EAAIF,iBAAAA,UAK7BK,EAAS,IAAIL,EAAiBhG,QAAQU,OAEtC4F,EAAY,OACd,MAAMC,KAAQF,EAAQ,OAGlBG,EAASR,EAAiBtG,IAAI6G,MACjCC,EAAO1F,OAAS,EAAG,CACpBwF,EAAUtC,KAAKwC,kBAQXN,EAAKM,EAAO,QACbZ,gBAAgBpG,MAAM0G,OAYzB,MAAMM,KAAUF,EAAW,OAGvBG,EAAe,OAGjB,MAAMP,KAAMM,EAAQ,IAGnBjH,KAAKqG,gBAAgB/F,MAAMqG,kBAMxBQ,EAAS,IAAI3H,EAAiB,OAKpC2H,EAAOlH,MAAM0G,SAIPS,EAASpH,KAAKqH,iBAAiBV,EAAIQ,GACzCD,EAAazC,KAAK2C,GAKpBF,EAAa/F,KAAKmG,OACd,MAAMF,KAAUF,EAAc,OAM1BK,EAASH,EAAOD,OAAO3G,gBACzB,MAAMmG,KAAMY,OACTlB,gBAAgBpG,MAAM0G,UAW3Ba,EAAa,OACf,MAAMjF,KAAQvC,KAAKsE,MAAO,OAKtBC,EAAI,IAAIhC,GACdgC,EAAEnB,QAAUpD,KAAKyH,gBAAgB,CAACjB,UAAWjC,EAAEnB,UAC/CmB,EAAEjB,OAAStD,KAAKyH,gBAAgB,CAACjB,UAAWjC,EAAEjB,SAC9CiB,EAAEhB,MAAQvD,KAAKyH,gBAAgB,CAACjB,UAAWjC,EAAEhB,QAE7CiE,EAAW/C,KAAKjC,EAAOqC,cAAcN,WAIvCiD,EAAWrG,OAGJqG,EAAW1C,KAAK,IAIzBkE,qBAAqBrC,SAGbe,EAAS,GAITC,EAAO3H,KAAKoG,cAAcjG,IAAIwG,GAC9BrC,EAAQqD,EAAKrD,UAGf,MAAM/B,KAAQ+B,EAAO,OAMjBsD,EAAO,CACXxE,QAAS,KAAMC,UAAWd,EAAKc,UAAWC,OAAQ,KAAMC,MAAO,MAKjEqE,EAAKxE,QAAUpD,KAAK6H,2BAClBlB,EAAIpE,EAAKa,QAAS,WACpBwE,EAAKtE,OAAStD,KAAK6H,2BACjBlB,EAAIpE,EAAKe,OAAQ,UACnBsE,EAAKrE,MAAQvD,KAAK6H,2BAChBlB,EAAIpE,EAAKgB,MAAO,SAClBmE,EAAOjD,KAAKjC,EAAOqC,cAAc+C,IAInCF,EAAOvG,aAIDR,EAAK,IAAImH,EAAc9H,KAAKsG,mBAC9B,MAAMnB,KAASuC,EACjB/G,EAAGG,OAAOqE,UAEZwC,EAAKX,KAAOrG,EAAGK,SACR2G,EAAKX,KAIdmC,qBAAqBpB,EAASxF,EAAM4E,EAAQa,OAKtCrB,EAEFA,EADC3G,KAAKqG,gBAAgB/F,MAAMyH,GACvB/H,KAAKqG,gBAAgBpG,MAAM8H,GACxBZ,EAAO7G,MAAMyH,GAChBZ,EAAOlH,MAAM8H,GAEb/H,KAAKoG,cAAcjG,IAAI4H,GAASf,WAKjCrG,EAAK,IAAImH,EAAc9H,KAAKsG,sBAClC3F,EAAGG,OAAOkH,GAIM,MAAbA,GACDrH,EAAGG,OAAOd,KAAKiI,oBAAoB1F,IAIrC5B,EAAGG,OAAO6F,GAIHhG,EAAGK,SAIZqG,iBAAiBV,EAAIQ,SAIbxG,EAAK,IAAImH,EAAc9H,KAAKsG,eAC5B4B,EAAgBlI,KAAKmI,oBAAoBxB,EAAIQ,GAO7CL,EAAS,IAAIoB,EAAczH,QAAQU,WACrC,MAAM6F,KAAQF,EAAQ,CAExBnG,EAAGG,OAAOkG,OAMNoB,EAHAC,EAAa,SAMXC,EAAW,IAAIC,EAASL,EAAc/H,IAAI6G,SAC1CsB,EAAS9G,WAAW,OAClBgH,EAAcF,EAAS7G,WAGzBgH,EAAatB,EAAOpH,QAGpB2I,EAAO,SAILC,EAAgB,OAGlBC,GAAkB,MAClB,MAAMb,KAAWS,KAGhBxI,KAAKqG,gBAAgB/F,MAAMyH,GAC5BW,GAAQ1I,KAAKqG,gBAAgBpG,MAAM8H,IAK/BU,EAAWnI,MAAMyH,IACnBY,EAAclE,KAAKsD,GAIrBW,GAAQD,EAAWxI,MAAM8H,IASF,IAAtBM,EAAW9G,QAAgBmH,EAAOL,EAAY,CAC/CO,GAAkB,YAKnBA,OAKC,MAAMb,KAAWY,EAAe,OAI5BvB,EAASpH,KAAKqH,iBAAiBU,EAASU,MAI9CC,GAAQD,EAAWxI,MAAM8H,GAGzBW,GAAS,IAAGtB,EAAOJ,QAInByB,EAAarB,EAAOD,OAQK,IAAtBkB,EAAW9G,QAAgBmH,EAAOL,EAAY,CAC/CO,GAAkB,SAKnBA,IAOsB,IAAtBP,EAAW9G,QAAgBmH,EAAOL,KACnCA,EAAaK,EACbN,EAAeK,IAKnB9H,EAAGG,OAAOuH,GAGVlB,EAASiB,QAKJ,CAACpB,KAAMrG,EAAGK,SAAUmG,OAAAA,GAI7BU,2BAA2BlB,EAAIH,SACH,cAAvBA,EAAU/C,SACJ+C,EAOF,CACL/C,SAAU,YACVC,MAAO8C,EAAU9C,QAAUiD,EAAK,MAAQ,OAK5CsB,oBAAoB1F,SACV,IAAGA,EAAKc,UAAUK,SAI5ByE,oBAAoBxB,EAAIQ,SAGhBe,EAAgB,IAAItI,IAIpB0E,EAAQtE,KAAKoG,cAAcjG,IAAIwG,GAAIrC,UAGrC,MAAM/B,KAAQ+B,OAKXyE,yBAAyB,CAC5BxG,KAAAA,EAAMiE,UAAWjE,EAAKa,QAAS4E,SAAU,IACzCrB,GAAAA,EAAIQ,OAAAA,EAAQe,cAAAA,SAETa,yBAAyB,CAC5BxG,KAAAA,EAAMiE,UAAWjE,EAAKe,OAAQ0E,SAAU,IACxCrB,GAAAA,EAAIQ,OAAAA,EAAQe,cAAAA,SAETa,yBAAyB,CAC5BxG,KAAAA,EAAMiE,UAAWjE,EAAKgB,MAAOyE,SAAU,IACvCrB,GAAAA,EAAIQ,OAAAA,EAAQe,cAAAA,WAITA,EAGTrB,wBAAuBF,GAACA,EAADF,iBAAKA,UAGpBO,EAAOhH,KAAKgJ,qBAAqBrC,GAIjCM,EAASR,EAAiBtG,IAAI6G,GAChCC,EAGFA,EAAOxC,KAAKkC,GAFZF,EAAiBpG,IAAI2G,EAAM,CAACL,IAMhCJ,uBAAsBhE,KAACA,EAADiE,UAAOA,OACD,cAAvBA,EAAU/C,sBAGPkD,EAAKH,EAAU9C,MACfiE,EAAO3H,KAAKoG,cAAcjG,IAAIwG,GACjCgB,EACDA,EAAKrD,MAAM2E,IAAI1G,QAEV6D,cAAc/F,IAAIsG,EAAI,CAACrC,MAAO,IAAI4E,IAAI,CAAC3G,IAAQyE,KAAM,OAI9D+B,0BACExG,KAACA,EAADiE,UAAOA,EAAPwB,SAAkBA,EAAlBrB,GAA4BA,EAA5BQ,OAAgCA,EAAhCe,cAAwCA,OACZ,cAAvB1B,EAAU/C,UAA4B+C,EAAU9C,QAAUiD,eAQzDoB,EAAUvB,EAAU9C,MACpBsD,EAAOhH,KAAKmJ,qBAAqBpB,EAASxF,EAAM4E,EAAQa,GAKxDoB,EAAUlB,EAAc/H,IAAI6G,GAC/BoC,EACDA,EAAQ3E,KAAKsD,GAEbG,EAAc7H,IAAI2G,EAAM,CAACe,IAI7BN,iBAAgBjB,UAACA,UACW,cAAvBA,EAAU/C,UACV+C,EAAU9C,MAAMsC,WAAWhG,KAAKqG,gBAAgB3G,QAM5C8G,EALE,CACL/C,SAAU,YACVC,MAAO1D,KAAKqG,gBAAgBpG,MAAMuG,EAAU9C,UAOpD,SAAS4D,EAAmBiC,EAAGC,UACtBD,EAAEvC,KAAOwC,EAAExC,MAAQ,EAAIuC,EAAEvC,KAAOwC,EAAExC,KAAO,EAAI,EC/dtDzH,MAAiB,cAA4BqK,EAC3CnK,2BAEO0G,KAAO,iBACPG,cAAgB,OAIvBuB,2BAA2BlB,EAAIH,EAAWkD,SACd,cAAvBlD,EAAU/C,SACJ+C,EAEE,UAARkD,EACM,CACLjG,SAAU,YACVC,MAAO,OAGJ,CACLD,SAAU,YACVC,MAAQ8C,EAAU9C,QAAUiD,EAAK,MAAQ,OAK7CsB,oBAAoB1F,UACXA,EAAKc,UAAUK,MAIxByE,oBAAoBxB,EAAIQ,SAGhBe,EAAgB,IAAItI,IAIpB0E,EAAQtE,KAAKoG,cAAcjG,IAAIwG,GAAIrC,UAGrC,MAAM/B,KAAQ+B,EAAO,KAKnB0D,EACAD,KACyB,cAA1BxF,EAAKa,QAAQK,UAA4BlB,EAAKa,QAAQM,QAAUiD,EACjEoB,EAAUxF,EAAKa,QAAQM,MACvBsE,EAAW,QACN,CAAA,GACoB,cAAzBzF,EAAKe,OAAOG,UAA4BlB,EAAKe,OAAOI,QAAUiD,WAK9DoB,EAAUxF,EAAKe,OAAOI,MACtBsE,EAAW,UAQPhB,EAAOhH,KAAKmJ,qBAAqBpB,EAASxF,EAAM4E,EAAQa,GACxDoB,EAAUlB,EAAc/H,IAAI6G,GAC/BoC,EACDA,EAAQ3E,KAAKsD,GAEbG,EAAc7H,IAAI2G,EAAM,CAACe,WAItBG,ICvCX,IAAI2B,EACJ,IACEA,EAAoBC,EACpB,MAAMC,IAER,MAAMC,EAAM,GACZzK,MAAiByK,EAGjBA,EAAIxH,OAASsH,EACbE,EAAIxK,iBAAmBsK,EASvBE,EAAIC,mBAAqB,SAASD,UAC7BA,IACDH,EAAoBG,GAEfH,GAcTG,EAAIE,SAAWC,eAAezH,EAAS0H,MAEjC1F,MAAMC,QAAQjC,KAChBA,EAAUsH,EAAIxH,OAAOoC,qBAAqBlC,IAGzC0H,EAAQC,UAAW,KAChBR,QACI,IAAI1G,MAAM,4CAGX,IAAI0F,QAAQ,CAACQ,EAASiB,IAC3BT,EAAkBK,SAASxH,EAAS0H,EAAS,CAACG,EAAKC,IACjDD,EAAMD,EAAOC,GAAOlB,EAAQmB,QAGT,cAAtBJ,EAAQ1J,iBACF,IAAI+I,EAAUW,GAAST,KAAKjH,MAEZ,cAAtB0H,EAAQ1J,iBACF,IAAI+J,EAAUL,GAAST,KAAKjH,QAEhC,cAAe0H,SACZ,IAAIjH,MAAM,8DAEZ,IAAIA,MACR,mDAAqDiH,EAAQ1J,YAgBjEsJ,EAAIU,cAAgB,SAAShI,EAAS0H,MAEhC1F,MAAMC,QAAQjC,KAChBA,EAAUsH,EAAIxH,OAAOoC,qBAAqBlC,IAGzC0H,EAAQC,UAAW,IACjBR,SACMA,EAAkBc,aAAajI,EAAS0H,SAE3C,IAAIjH,MAAM,wCAEO,cAAtBiH,EAAQ1J,iBACF,IAAIkJ,EAAcQ,GAAST,KAAKjH,MAEhB,cAAtB0H,EAAQ1J,iBACF,IAAIkK,EAAcR,GAAST,KAAKjH,QAEpC,cAAe0H,SACZ,IAAIjH,MAAM,8DAEZ,IAAIA,MACR,mDAAqDiH,EAAQ1J,YCxIjEnB,MAAiBuK,ECFjB,MAAME,EAAM,GACZzK,MAAiByK,EASjBA,EAAIrF,QAAUD,MAAMC,QASpBqF,EAAIa,UAAYC,GAAmB,kBAANA,GACW,qBAAtCC,OAAOC,UAAUC,SAASC,KAAKJ,GASjCd,EAAImB,SAAWL,GAAKd,EAAIoB,SAASN,MACF,IAA5B5G,OAAO4G,GAAGO,QAAQ,MAAeC,KAAKC,IAAIT,IAAM,MASnDd,EAAIwB,cAAgBV,GAAKd,EAAIyB,SAASX,IAAgC,IAA1BC,OAAOtK,KAAKqK,GAAGvJ,OAS3DyI,EAAIoB,SAAWN,GAAmB,iBAANA,GACY,oBAAtCC,OAAOC,UAAUC,SAASC,KAAKJ,GASjCd,EAAI0B,UAAYZ,IAAMa,MAAMC,WAAWd,KAAOe,SAASf,GASvDd,EAAIyB,SAAWX,GAA2C,oBAAtCC,OAAOC,UAAUC,SAASC,KAAKJ,GASnDd,EAAI8B,SAAWhB,GAAmB,iBAANA,GACY,oBAAtCC,OAAOC,UAAUC,SAASC,KAAKJ,GASjCd,EAAI+B,YAAcjB,QAAkB,IAANA,ECpF9B,MAAMd,GAAM,GACZzK,OAAiByK,GASjBA,GAAIgC,UAAYlB,OAKXmB,EAAMR,SAASX,MACb,WAAYA,GAAO,SAAUA,GAAO,UAAWA,GAAK,QACtCC,OAAOtK,KAAKqK,GAAGvJ,OACb,KAAO,QAASuJ,UAE9B,GAUTd,GAAIkC,mBAAqBpB,GAItBmB,EAAMR,SAASX,IAAgC,IAA1BC,OAAOtK,KAAKqK,GAAGvJ,QAAiB,QAASuJ,EASjEd,GAAImC,QAAUrB,GAIZmB,EAAMR,SAASX,IAAO,WAAYA,EASpCd,GAAIoC,OAAStB,GAIXmB,EAAMR,SAASX,IAAO,UAAWA,EAOnCd,GAAIqC,QAAUvB,GAKLmB,EAAMR,SAASX,IACpB,WAAYA,GAEmD,IAD/DC,OAAOtK,KAAKqK,GACTwB,OAAO5C,GAAe,QAARA,GAAyB,WAARA,GAAkBnI,OAQxDyI,GAAIuC,cAAgBzB,GAKXd,GAAIqC,QAAQvB,MAAQ,QAASA,GAUtCd,GAAIwC,YAAc1B,KAKbmB,EAAMR,SAASX,KACb,QAASA,EACyB,IAA3BA,EAAE,OAAOO,QAAQ,MAEO,IAA1BN,OAAOtK,KAAKqK,GAAGvJ,UAClB,WAAYuJ,GAAO,SAAUA,GAAO,UAAWA,IC9GxDvL,OAAiB,cAA0B4D,MAQzC1D,YACEgN,EAAU,yCACVtG,EAAO,eACPuG,EAAU,UACJD,QACDtG,KAAOA,OACPsG,QAAUA,OACVC,QAAUA,ICZnB,MAAMlN,GAAmBsK,EAAwBtK,iBAI3CmN,GAAqB,+BACrBC,GAAoB,gCACpBC,GACJ,sDAEIC,GACK,CACPC,OAAQ,yCAIN/C,GAAM,GACZzK,OAAiByK,GACjBA,GAAIxK,iBAAmBA,GAUvBwK,GAAIjK,MAAQ,SAAS2D,MAChBA,GAA0B,iBAAVA,EAAoB,KACjChC,KACDuK,EAAMtH,QAAQjB,GAAQ,CACvBhC,EAAO,OACH,IAAIJ,EAAI,EAAGA,EAAIoC,EAAMnC,SAAUD,EACjCI,EAAKJ,GAAK0I,GAAIjK,MAAM2D,EAAMpC,SAEvB,GAAGoC,aAAiB9D,IAAK,CAC9B8B,EAAO,IAAI9B,QACP,MAAOgC,EAAGkJ,KAAMpH,EAClBhC,EAAKrB,IAAIuB,EAAGoI,GAAIjK,MAAM+K,SAEnB,GAAGpH,aAAiBwF,IAAK,CAC9BxH,EAAO,IAAIwH,QACP,MAAM4B,KAAKpH,EACbhC,EAAKuH,IAAIe,GAAIjK,MAAM+K,SAEhB,GAAGmB,EAAMR,SAAS/H,GAAQ,CAC/BhC,EAAO,OACH,MAAMgI,KAAOhG,EACfhC,EAAKgI,GAAOM,GAAIjK,MAAM2D,EAAMgG,SAG9BhI,EAAOgC,EAAMuH,kBAERvJ,SAEFgC,GAWTsG,GAAIgD,QAAU,SAAStJ,UACdgB,MAAMC,QAAQjB,GAASA,EAAQ,CAACA,IAYzCsG,GAAIiD,aAAe,CAACC,EAAU,SACVnC,OAAOtK,KAAKyM,GAASC,KACrCC,GAAyB,WAApBA,EAAEC,qBAGD,IAAIC,WACR,6CACAR,GAAiBC,OAAS,0BAGvBhC,OAAOwC,OAAO,CAACC,OAAQV,GAAiBC,QAASG,IAqB1DlD,GAAIyD,gBAAkBC,UACdhM,EAAO,GAEP0H,EAAUsE,EAAOxK,MAAMyJ,QACzB,IAAIrL,EAAI,EAAGA,EAAI8H,EAAQ7H,SAAUD,EAAG,KAClC4B,EAAQkG,EAAQ9H,GAAG4B,MAAM0J,QACzB1J,iBAGEkE,EAAS,CAACuG,OAAQzK,EAAM,IACxB0K,EAAS1K,EAAM,QACdA,EAAQ2J,GAAyBgB,KAAKD,IAC3CxG,EAAOlE,EAAM,SAAoBM,IAAbN,EAAM,GAAoBA,EAAM,GAAKA,EAAM,SAE3D4K,EAAM1G,EAAM,KAAW,GAC1B1C,MAAMC,QAAQjD,EAAKoM,IACpBpM,EAAKoM,GAAKrJ,KAAK2C,GACP1F,EAAKqM,eAAeD,GAC5BpM,EAAKoM,GAAO,CAACpM,EAAKoM,GAAM1G,GAExB1F,EAAKoM,GAAO1G,SAGT1F,GAQTsI,GAAIgE,kBAAoB,CAAClD,EAAGmD,UACvBhC,EAAMH,SAAShB,IAIfmB,EAAMtH,QAAQmG,IAAMA,EAAEoD,MAAMC,GAAMlC,EAAMH,SAASqC,SAGjDF,GAAWhC,EAAMR,SAASX,UACpBC,OAAOtK,KAAKqK,GAAGvJ,aACf,cAGA,KAEA,aAAcuJ,GACfd,GAAIgD,QAAQlC,EAAE,aAAaoD,MAAMC,GAAMlC,EAAMH,SAASqC,iBAMxD,IAAIC,GACR,kHAEwB,qBACxB,CAACrK,KAAM,qBAAsBL,MAAOoH,MAWxCd,GAAIqE,YAAc,CAACjL,EAASkL,QACvBlL,EAAQ2K,eAAeO,GAAW,OAC7B5K,EAAQN,EAAQkL,UACbrC,EAAMtH,QAAQjB,IAAUA,EAAMnC,OAAS,SAE3C,GAYTyI,GAAIuE,SAAW,CAACnL,EAASkL,EAAU5K,QAC9BsG,GAAIqE,YAAYjL,EAASkL,GAAW,KACjCE,EAAMpL,EAAQkL,SACZlC,EAASqC,GAAWrC,OAAOoC,MAC9BvC,EAAMtH,QAAQ6J,IAAQpC,EAAQ,CAC5BA,IACDoC,EAAMA,EAAI,cAER,IAAIlN,EAAI,EAAGA,EAAIkN,EAAIjN,SAAUD,KAC5B0I,GAAI0E,cAAchL,EAAO8K,EAAIlN,WACvB,OAGN,IAAI2K,EAAMtH,QAAQjB,UAEhBsG,GAAI0E,cAAchL,EAAO8K,UAG7B,GAoBTxE,GAAI2E,SAAW,CAACvL,EAASkL,EAAU5K,EAAO0G,QAEnC,oBADLA,EAAUA,GAAW,MAEnBA,EAAQwE,iBAAkB,GAEvB,iBAAkBxE,IACrBA,EAAQyE,cAAe,GAEpB,mBAAoBzE,IACvBA,EAAQ0E,gBAAiB,GAEtB,iBAAkB1E,IACrBA,EAAQ2E,cAAe,GAGtB3E,EAAQyE,aACTzL,EAAQkL,GAAY5K,OACf,GAAGuI,EAAMtH,QAAQjB,GAAQ,CACV,IAAjBA,EAAMnC,QAAgB6I,EAAQwE,kBAC9BxL,EAAQ2K,eAAeO,KACxBlL,EAAQkL,GAAY,IAEnBlE,EAAQ2E,eACTrL,EAAQA,EAAMsL,OAAO5L,EAAQkL,IAC7BlL,EAAQkL,GAAY,QAElB,IAAIhN,EAAI,EAAGA,EAAIoC,EAAMnC,SAAUD,EACjC0I,GAAI2E,SAASvL,EAASkL,EAAU5K,EAAMpC,GAAI8I,QAEvC,GAAGhH,EAAQ2K,eAAeO,GAAW,OAEpCC,GAAanE,EAAQ0E,gBACzB9E,GAAIuE,SAASnL,EAASkL,EAAU5K,GAG9BuI,EAAMtH,QAAQvB,EAAQkL,KACtBC,IAAYnE,EAAQwE,kBACtBxL,EAAQkL,GAAY,CAAClL,EAAQkL,KAI3BC,IACCnE,EAAQ2E,aACT3L,EAAQkL,GAAUW,QAAQvL,GAE1BN,EAAQkL,GAAU7J,KAAKf,SAK3BN,EAAQkL,GAAYlE,EAAQwE,gBAAkB,CAAClL,GAASA,GAY5DsG,GAAIkF,UAAY,CAAC9L,EAASkL,IAAa,GAAGU,OAAO5L,EAAQkL,IAAa,IAQtEtE,GAAImF,eAAiB,CAAC/L,EAASkL,YACtBlL,EAAQkL,IAajBtE,GAAIoF,YAAc,CAAChM,EAASkL,EAAU5K,EAAO0G,KAEtC,oBADLA,EAAUA,GAAW,MAEnBA,EAAQwE,iBAAkB,SAItBS,EAASrF,GAAIkF,UAAU9L,EAASkL,GAAUhC,OAC9CvC,IAAMC,GAAI0E,cAAc3E,EAAGrG,IAER,IAAlB2L,EAAO9N,OACRyI,GAAImF,eAAe/L,EAASkL,GACF,IAAlBe,EAAO9N,QAAiB6I,EAAQwE,gBAGxCxL,EAAQkL,GAAYe,EAFpBjM,EAAQkL,GAAYe,EAAO,IAa/BrF,GAAIsF,kBAAoB,CAAC7M,EAAO2H,IA2EhC,SAASmF,EAAiBpI,EAAQrF,MAC7BmK,EAAMtH,QAAQ7C,OACX,IAAIR,EAAI,EAAGA,EAAIQ,EAAQP,SAAUD,EACnCQ,EAAQR,GAAKiO,EAAiBpI,EAAQrF,EAAQR,SAE3C,GAAGmN,GAAWrC,OAAOtK,GAC1BA,EAAQ,SAAWyN,EAAiBpI,EAAQrF,EAAQ,eAC/C,GAAGmK,EAAMR,SAAS3J,GAAU,CAE9B2M,GAAWjC,YAAY1K,KACxBA,EAAQ,OAASqF,EAAOlH,MAAM6B,EAAQ,eAIlCrB,EAAOsK,OAAOtK,KAAKqB,GAASX,WAC9B,IAAIqO,EAAK,EAAGA,EAAK/O,EAAKc,SAAUiO,EAAI,OAChC9F,EAAMjJ,EAAK+O,GACN,QAAR9F,IACD5H,EAAQ4H,GAAO6F,EAAiBpI,EAAQrF,EAAQ4H,aAK/C5H,EA/FAyN,EAFPnF,EAAUA,GAAW,IACEjD,QAAU,IAAI3H,GAAiB,OACtBiD,GAiBlCuH,GAAI0E,cAAgB,CAACe,EAAIC,IAEpBD,IAAOC,OAKPjB,GAAWtC,QAAQsD,KAAOhB,GAAWtC,QAAQuD,IAC9CD,EAAG,YAAcC,EAAG,WACpBD,EAAG,WAAaC,EAAG,UACnBD,EAAG,eAAiBC,EAAG,cACvBD,EAAG,YAAcC,EAAG,eAKnBzD,EAAMR,SAASgE,IACf,QAASA,GACVxD,EAAMR,SAASiE,IACd,QAASA,IACHD,EAAG,SAAWC,EAAG,QAc5B1F,GAAI2F,qBAAuB,CAACpG,EAAGC,IAC1BD,EAAEhI,OAASiI,EAAEjI,QACN,EAEPiI,EAAEjI,OAASgI,EAAEhI,OACP,EAENgI,IAAMC,EACA,EAEDD,EAAIC,GAAM,EAAI,EC1ZxB,MAAMtH,GAAM,8CACN0N,GAAM,oCAEZrQ,OAAiB,CAEfsQ,gBAAiB,uCAEjBC,oBAAqB,uCAErB5N,IAAAA,GACA6N,SAAU7N,GAAM,OAChB8N,UAAW9N,GAAM,QACjB+N,SAAU/N,GAAM,OAChBgO,QAAShO,GAAM,MACfiO,SAAUjO,GAAM,OAChBkO,kBAAmBlO,GAAM,eACzBmO,gBAAiBnO,GAAM,aACvBoO,iBAAkBpO,GAAM,OACxBqO,WAAYrO,GAAM,SAClBD,eAAgBC,GAAM,aAEtB0N,IAAAA,GACAY,YAAaZ,GAAM,UACnBa,WAAYb,GAAM,SAClBc,YAAad,GAAM,UACnBzN,WAAYyN,GAAM,aCzBH,MAIfnQ,mBACOkR,UAAY,GAGnBC,WAAWC,SACHC,EAAO9Q,YACb8Q,EAAKC,QAAUF,EACR,kBACEC,EAAK7H,IAAI+H,MAAMF,EAAMG,sBAItBC,OACJC,EAAUnR,KAAK2Q,UAAUO,MAC1BC,SAEMtI,QAAQQ,QAAQ8H,GAIzBA,EAAUnR,KAAK2Q,UAAUO,GAAOlR,KAAK+Q,QAAQG,oBAG9BC,iBAENnR,KAAK2Q,UAAUO,MC3B5B,MAAMlH,GAAM,GACZzK,OAAiByK,GAOjBA,GAAIoH,QAAU,CACZC,OAAQ,CAEN5Q,KAAM,CACJ,OAAQ,SAAU,YAAa,OAAQ,QAAS,YAGlD6Q,MAAO,yEAETC,KAAM,CACJ9Q,KAAM,CACJ,OAAQ,WAAY,SAAU,YAAa,OAAQ,OAAQ,WAC3D,WAAY,OAAQ,OAAQ,YAAa,OAAQ,QAAS,YAG5D6Q,MAAO,4IAGXtH,GAAIwH,MAAQ,CAACC,EAAKC,WACVC,EAAS,GACT1M,EAAI+E,GAAIoH,QAAQM,GAAU,QAC1BE,EAAI3M,EAAEqM,MAAMzD,KAAK4D,OACnBnQ,EAAI2D,EAAExE,KAAKc,YACTD,KACJqQ,EAAO1M,EAAExE,KAAKa,SAAgBkC,IAAToO,EAAEtQ,GAAoB,KAAOsQ,EAAEtQ,UAIhC,UAAlBqQ,EAAOE,QAAsC,QAAhBF,EAAOG,MACnB,SAAlBH,EAAOE,QAAqC,OAAhBF,EAAOG,QACpCH,EAAOI,KAAOJ,EAAOI,KAAKlO,QAAQ,IAAM8N,EAAOG,KAAM,IACrDH,EAAOK,UAAYL,EAAOK,UAAUnO,QAAQ,IAAM8N,EAAOG,KAAM,IAC/DH,EAAOG,KAAO,MAGhBH,EAAOM,eAAiBjI,GAAIkI,kBAAkBP,EAAOjJ,MAC9CiJ,GAWT3H,GAAImI,YAAc,CAACC,EAAMC,QAEX,OAATD,SACMC,KAGNrI,GAAIsI,WAAWD,UACTA,EAILD,IAAQnG,EAAMH,SAASsG,KACzBA,EAAOpI,GAAIwH,MAAMY,GAAQ,WAIrBtE,EAAM9D,GAAIwH,MAAMa,GAGhBE,EAAY,CAChBC,SAAUJ,EAAKI,UAAY,OAGR,OAAlB1E,EAAIkE,UACLO,EAAUP,UAAYlE,EAAIkE,UAC1BO,EAAU7J,KAAOoF,EAAIpF,KACrB6J,EAAUE,MAAQ3E,EAAI2E,cAEtBF,EAAUP,UAAYI,EAAKJ,UAEX,KAAblE,EAAIpF,KACL6J,EAAU7J,KAAO0J,EAAK1J,KACL,OAAdoF,EAAI2E,MACLF,EAAUE,MAAQ3E,EAAI2E,MAEtBF,EAAUE,MAAQL,EAAKK,UAEpB,IACwB,IAA1B3E,EAAIpF,KAAK2C,QAAQ,KAElBkH,EAAU7J,KAAOoF,EAAIpF,SAChB,KAEDA,EAAO0J,EAAK1J,KAGhBA,EAAOA,EAAKgK,OAAO,EAAGhK,EAAKiK,YAAY,KAAO,IAC1CjK,EAAKnH,OAAS,GAAK6Q,EAAKJ,YAAkC,MAApBtJ,EAAKgK,QAAQ,KACrDhK,GAAQ,KAEVA,GAAQoF,EAAIpF,KAEZ6J,EAAU7J,KAAOA,EAEnB6J,EAAUE,MAAQ3E,EAAI2E,MAIV,KAAb3E,EAAIpF,OAEL6J,EAAU7J,KAAOsB,GAAIkI,kBAAkBK,EAAU7J,WAI/ChH,EAAO6Q,EAAUC,gBACM,OAAxBD,EAAUP,YACXtQ,GAAQ,KAAO6Q,EAAUP,WAE3BtQ,GAAQ6Q,EAAU7J,KACK,OAApB6J,EAAUE,QACX/Q,GAAQ,IAAM6Q,EAAUE,OAEN,OAAjB3E,EAAI8E,WACLlR,GAAQ,IAAMoM,EAAI8E,UAIR,KAATlR,IACDA,EAAO,MAGFA,GAWTsI,GAAI6I,WAAa,CAACT,EAAMC,QAEV,OAATD,SACMC,EAGLD,IAAQnG,EAAMH,SAASsG,KACzBA,EAAOpI,GAAIwH,MAAMY,GAAQ,SAIvBU,EAAO,MACM,KAAdV,EAAKL,KACNe,IAASV,EAAKI,UAAY,IAAM,MAAQJ,EAAKJ,WAAa,IAClDK,EAAIhH,QAAQ,QAEpByH,GAAQ,MAIe,IAAtBT,EAAIhH,QAAQyH,UACNT,QAIHvE,EAAM9D,GAAIwH,MAAMa,EAAIK,OAAOI,EAAKvR,SAIhCwR,EAAeX,EAAKH,eAAepP,MAAM,KACzCmQ,EAAclF,EAAImE,eAAepP,MAAM,KACvCoQ,EAAQnF,EAAI8E,UAAY9E,EAAI2E,MAAS,EAAI,OACzCM,EAAaxR,OAAS,GAAKyR,EAAYzR,OAAS0R,GACjDF,EAAa,KAAOC,EAAY,IAGnCD,EAAaG,QACbF,EAAYE,YAIVxR,EAAO,MACRqR,EAAaxR,OAAS,EAAG,CAG1BwR,EAAaI,UACT,IAAI7R,EAAI,EAAGA,EAAIyR,EAAaxR,SAAUD,EACxCI,GAAQ,aAKZA,GAAQsR,EAAYlO,KAAK,KAGR,OAAdgJ,EAAI2E,QACL/Q,GAAQ,IAAMoM,EAAI2E,OAEA,OAAjB3E,EAAI8E,WACLlR,GAAQ,IAAMoM,EAAI8E,UAIR,KAATlR,IACDA,EAAO,MAGFA,GAQTsI,GAAIkI,kBAAoBxJ,OAIH,IAAhBA,EAAKnH,aACC,SAGHkB,EAAQiG,EAAK7F,MAAM,KACnBuQ,EAAS,QAET3Q,EAAMlB,OAAS,GAAG,OAChBE,EAAOgB,EAAMyQ,QACb9R,EAAwB,IAAjBqB,EAAMlB,OAEP,MAATE,EAQS,OAATA,EASH2R,EAAO3O,KAAKhD,IARV2R,EAAOD,MACJ/R,GAEDgS,EAAO3O,KAAK,KAXXrD,GAEDgS,EAAO3O,KAAK,UAkBH,MAAZiE,EAAK,IAAc0K,EAAO7R,OAAS,GAAmB,KAAd6R,EAAO,IAChDA,EAAOnE,QAAQ,IAEI,IAAlBmE,EAAO7R,QAA8B,KAAd6R,EAAO,GACxB,IAGFA,EAAOtO,KAAK,MAOrB,MAAMuO,GAAkB,uCAWxBrJ,GAAIsI,WAAaxH,GAAKmB,EAAMH,SAAShB,IAAMuI,GAAgBpQ,KAAK6H,GAUhEd,GAAIsJ,WAAaxI,GAAKmB,EAAMH,SAAShB,uNCtOrC,OA9DA,SAAyByI,OACnB,UAAUtQ,KAAKsQ,SACb,IAAIC,UACT,0EAQIC,GAHNF,EAAMA,EAAI1P,QAAQ,SAAU,KAGLwH,QAAQ,SACX,IAAhBoI,GAAqBA,GAAc,QAChC,IAAID,UAAU,6BAIfE,EAAOH,EAAII,UAAU,EAAGF,GAAY5Q,MAAM,SAE5C+Q,EAAU,GACVC,GAAS,QACP9N,EAAO2N,EAAK,IAAM,iBACpBI,EAAW/N,MACV,IAAIzE,EAAI,EAAGA,EAAIoS,EAAKnS,OAAQD,IAChB,WAAZoS,EAAKpS,GACRuS,GAAS,GAETC,GAAY,IAAMJ,EAAKpS,GACa,IAAhCoS,EAAKpS,GAAG+J,QAAQ,cACnBuI,EAAUF,EAAKpS,GAAGqS,UAAU,KAK1BD,EAAK,IAAOE,EAAQrS,SACxBuS,GAAY,oBACZF,EAAU,kBAILG,EAAWF,EAAS,SAAW,QAC/BG,EAAOC,SAASV,EAAII,UAAUF,EAAa,IAC3CS,EAASC,OAAOC,KAAKJ,EAAMD,UAGjCG,EAAOnO,KAAOA,EACdmO,EAAOJ,SAAWA,EAGlBI,EAAON,QAAUA,EAEVM,GC3DR,MAAMG,SAACA,IAAYvK,EAKbwK,GAAK,IAAIC,QAYf,MAAMC,GASL/U,YAAYgV,EAAY,GAAIrK,EAAU,QACjCsK,EAAO,QAELC,EAAQF,EAAUG,IAAI9S,QACvBoS,SAEHA,EADGpS,aAAmBqS,OACbrS,EACC+S,YAAYC,OAAOhT,GACpBqS,OAAOC,KAAKtS,EAAQoS,OAAQpS,EAAQiT,WAAYjT,EAAQkT,YACvDlT,aAAmB+S,YACpBV,OAAOC,KAAKtS,GACXA,aAAmB0S,GACpB1S,EAEAqS,OAAOC,KAAwB,iBAAZtS,EAAuBA,EAAUoC,OAAOpC,IAIrE4S,GAAQR,EAAO3S,QAAU2S,EAAOQ,MAAQ,EACjCR,IAGFnO,OAAwBvC,IAAjB4G,EAAQrE,KAAqB,GAAK7B,OAAOkG,EAAQrE,MAAMsH,cAEpEiH,GAAGjU,IAAIL,KAAM,CACZ+F,KAAM,mBAAmB9C,KAAK8C,GAAQ,GAAKA,EAC3C2O,KAAAA,EACAC,MAAAA,sBASML,GAAGnU,IAAIH,MAAM0U,uBAObJ,GAAGnU,IAAIH,MAAM+F,yBAWboO,OAAOC,WAAWpU,KAAKiV,eAAehK,qCAWvC+I,EAAO,IAAIkB,WAAWlV,KAAK0U,UAC7BS,EAAS,YACF,MAAMC,KAASpV,KAAKqV,SAC9BrB,EAAK3T,IAAI+U,EAAOD,GAChBA,GAAUC,EAAM7T,cAGVyS,EAAKE,OASbmB,gBACQhB,GAASD,KArGlBjK,gBAAsBwK,OAChB,MAAMW,KAAQX,EACd,WAAYW,QACPA,EAAKD,eAEPC,EAgGcC,CAAKjB,GAAGnU,IAAIH,MAAM2U,QAYxChT,MAAM6T,EAAQ,EAAGC,EAAMzV,KAAK0U,KAAM3O,EAAO,UAClC2O,KAACA,GAAQ1U,SAEX0V,EAAgBF,EAAQ,EAAIlK,KAAKqK,IAAIjB,EAAOc,EAAO,GAAKlK,KAAKsK,IAAIJ,EAAOd,GACxEmB,EAAcJ,EAAM,EAAInK,KAAKqK,IAAIjB,EAAOe,EAAK,GAAKnK,KAAKsK,IAAIH,EAAKf,SAE9DoB,EAAOxK,KAAKqK,IAAIE,EAAcH,EAAe,GAC7Cf,EAAQL,GAAGnU,IAAIH,MAAM2U,MAAMtF,SAC3BoF,EAAY,OACdsB,EAAQ,MAEP,MAAMT,KAAQX,EAAO,OACnBD,EAAOG,YAAYC,OAAOQ,GAAQA,EAAKN,WAAaM,EAAKZ,QAC3DgB,GAAiBhB,GAAQgB,EAG5BA,GAAiBhB,EACjBmB,GAAenB,MACT,OACAU,EAAQE,EAAK3T,MAAM+T,EAAepK,KAAKsK,IAAIlB,EAAMmB,OACvDpB,EAAUhQ,KAAK2Q,GACfW,GAASlB,YAAYC,OAAOM,GAASA,EAAMJ,WAAaI,EAAMV,KAC9DgB,EAAgB,EAGZK,GAASD,eAMTE,EAAO,IAAIxB,GAAK,GAAI,CAACzO,KAAM7B,OAAO6B,GAAMsH,uBAC9CtC,OAAOwC,OAAO+G,GAAGnU,IAAI6V,GAAO,CAACtB,KAAMoB,EAAMnB,MAAOF,IAEzCuB,MAGHC,OAAOC,qBACJ,cAGAD,OAAOE,aAAa7S,UAE1BA,GACkB,iBAAXA,GACkB,mBAAlBA,EAAO+R,QACW,IAAzB/R,EAAO+R,OAAO9T,QACgB,mBAAvB+B,EAAO7D,aACd,gBAAgBwD,KAAKK,EAAO2S,OAAOC,eAKtCnL,OAAOqL,iBAAiB5B,GAAKxJ,UAAW,CACvC0J,KAAM,CAAC2B,YAAY,GACnBtQ,KAAM,CAACsQ,YAAY,GACnB1U,MAAO,CAAC0U,YAAY,KAGrB9W,OAAiBiV,GCjLV,MAAM8B,WAAuBnT,MACnC1D,YAAYgN,EAAS1G,SACd0G,GAENtJ,MAAMoT,kBAAkBvW,KAAMA,KAAKP,kBAE9BsG,KAAOA,oBAIL/F,KAAKP,YAAY0G,SAGpB8P,OAAOC,sBACJlW,KAAKP,YAAY0G,MCNnB,MAAMqQ,WAAmBF,GAM/B7W,YAAYgN,EAAS1G,EAAM0Q,SACpBhK,EAAS1G,GAEX0Q,SAEE1S,KAAO/D,KAAK0W,MAAQD,EAAY1S,UAChC4S,eAAiBF,EAAYG,UChBrC,MAAMC,GAAOZ,OAAOC,YASPY,GAAwBxT,GAEjB,iBAAXA,GACkB,mBAAlBA,EAAOyT,QACW,mBAAlBzT,EAAO0T,QACQ,mBAAf1T,EAAOnD,KACW,mBAAlBmD,EAAO2T,QACQ,mBAAf3T,EAAO/C,KACQ,mBAAf+C,EAAOjD,KACS,mBAAhBiD,EAAOnC,MACG,oBAAjBmC,EAAOuT,IAUIK,GAAS5T,GAEF,iBAAXA,GACuB,mBAAvBA,EAAO2R,aACS,iBAAhB3R,EAAOyC,MACW,mBAAlBzC,EAAO+R,QACgB,mBAAvB/R,EAAO7D,aACd,gBAAgBwD,KAAKK,EAAOuT,KAUvB,SAASM,GAAW7T,SAEP,iBAAXA,GACkB,mBAAlBA,EAAOyT,QACQ,mBAAfzT,EAAOjD,KACQ,mBAAfiD,EAAOnD,KACW,mBAAlBmD,EAAO2T,QACW,mBAAlB3T,EAAO0T,QACS,mBAAhB1T,EAAO7C,MACW,mBAAlB6C,EAAO+L,QACY,mBAAnB/L,EAAO8F,SACgB,mBAAvB9F,EAAO7D,aACG,aAAjB6D,EAAOuT,IAUF,MCrEDO,GAAS,IAAIC,OAAO,GACpBC,GAAiBnD,OAAOa,WAFb,QAOXuC,GAAYC,GAAa,GAAEJ,KAASI,IAAWJ,KAPpC,OAOsDC,OAAO,KAS9E,SAASI,GAAUD,EAAUrR,EAAMuR,OAC9BhK,EAAS,UAEbA,GAAW,GAAE0J,KAASI,QACtB9J,GAAW,yCAAwCvH,KAE/C+Q,GAAOQ,KACVhK,GAAW,eAAcgK,EAAMvR,YAC/BuH,GAAW,kBAAgBgK,EAAM3R,MAAQ,6BAGlC,GAAE2H,IA3BM,OA2BY2J,OAAO,KCdpC,MAAMM,GAAY1B,OAAO,kBAWV,MAAM2B,GACpBnY,YAAYoY,GAAMnD,KACjBA,EAAO,GACJ,QACC8C,EAAW,KAEF,OAATK,EAEHA,EAAO,KACGf,GAAsBe,GAEhCA,EAAO1D,OAAOC,KAAKyD,EAAK5M,YACdiM,GAAOW,IAEP1D,OAAO2D,SAASD,KAEhB5L,EAAM8L,iBAAiBF,GAEjCA,EAAO1D,OAAOC,KAAKyD,GACThD,YAAYC,OAAO+C,GAE7BA,EAAO1D,OAAOC,KAAKyD,EAAK3D,OAAQ2D,EAAK9C,WAAY8C,EAAK7C,YAC5C6C,aAAgBG,IAEhBb,GAAWU,IAErBL,EAAY,4BDjBkBS,EAAY,GAAGhN,SAAS,OCkBtD4M,EAAOG,EAAO3D,SAASD,KDZnBjK,gBAAkC+N,EAAMV,OACzC,MAAOrR,EAAMzC,KAAUwU,QACrBT,GAAUD,EAAUrR,EAAMzC,GAE5BwT,GAAOxT,SACFA,EAAM2R,eAER3R,OA9CQ,aAoDV6T,GAAUC,GCDcW,CAAiBN,EAAML,KAInDK,EAAO1D,OAAOC,KAAKlQ,OAAO2T,WAGtBF,IAAa,CACjBE,KAAAA,EACAL,SAAAA,EACAY,WAAW,EACXC,MAAO,WAEH3D,KAAOA,EAERmD,aAAgBG,GACnBH,EAAKS,GAAG,QAAS/N,UACV8N,EAAQ9N,aAAe+L,GAC5B/L,EACA,IAAIiM,GAAY,+CAA8CxW,KAAKkR,QAAQ3G,EAAIkC,UAAW,SAAUlC,QAChGoN,IAAWU,MAAQA,sBAMnBrY,KAAK2X,IAAWE,2BAIhB7X,KAAK2X,IAAWS,oCASjBlE,OAACA,EAADa,WAASA,EAATC,WAAqBA,SAAoBuD,GAAYvY,aACpDkU,EAAOvS,MAAMoT,EAAYA,EAAaC,sBASvCwD,EAAMxY,KAAKkN,SAAWlN,KAAKkN,QAAQ/M,IAAI,iBAAqBH,KAAK2X,IAAWE,MAAQ7X,KAAK2X,IAAWE,KAAK9R,MAAS,GAClH0S,QAAYzY,KAAKkU,gBAEhB,IAAIM,GAAK,CAACiE,GAAM,CACtB1S,KAAMyS,uBAUDtE,QAAeqE,GAAYvY,aAC1B0Y,KAAKlH,MAAM0C,EAAOjJ,sCASJsN,GAAYvY,OACnBiL,WAQfiJ,gBACQqE,GAAYvY,OAqBrBmK,eAAeoO,GAAYvE,MACtBA,EAAK2D,IAAWS,gBACb,IAAI5E,UAAW,0BAAyBQ,EAAK9C,QAGpD8C,EAAK2D,IAAWS,WAAY,EAExBpE,EAAK2D,IAAWU,YACbrE,EAAK2D,IAAWU,UAGnBR,KAACA,GAAQ7D,KAGA,OAAT6D,SACI1D,OAAOwE,MAAM,MAIjBzB,GAAOW,KACVA,EAAOA,EAAKxC,UAITlB,OAAO2D,SAASD,UACZA,OAIFA,aAAgBG,UACd7D,OAAOwE,MAAM,SAKfC,EAAQ,OACVC,EAAa,gBAGL,MAAMzD,KAASyC,EAAM,IAC3B7D,EAAKU,KAAO,GAAKmE,EAAazD,EAAM7T,OAASyS,EAAKU,KAAM,OACrDnK,EAAM,IAAIiM,GAAY,mBAAkBxC,EAAK9C,mBAAmB8C,EAAKU,OAAQ,kBACnFmD,EAAKiB,QAAQvO,GACPA,EAGPsO,GAAczD,EAAM7T,OACpBqX,EAAMnU,KAAK2Q,IAEX,MAAOiD,SACJA,aAAiB/B,GACd+B,EAGA,IAAI7B,GAAY,+CAA8CxC,EAAK9C,QAAQmH,EAAM5L,UAAW,SAAU4L,OAInF,IAAvBR,EAAKkB,gBAAwD,IAA9BlB,EAAKmB,eAAeC,YAWhD,IAAIzC,GAAY,4DAA2DxC,EAAK9C,gBATjF0H,EAAM1K,MAAMgL,GAAkB,iBAANA,GACpB/E,OAAOC,KAAKwE,EAAM9T,KAAK,KAGxBqP,OAAOnF,OAAO4J,EAAOC,GAC3B,MAAOR,SACF,IAAI7B,GAAY,kDAAiDxC,EAAK9C,QAAQmH,EAAM5L,UAAW,SAAU4L,IAlFlHtN,OAAOqL,iBAAiBwB,GAAK5M,UAAW,CACvC6M,KAAM,CAACxB,YAAY,GACnB8C,SAAU,CAAC9C,YAAY,GACvBpB,YAAa,CAACoB,YAAY,GAC1BL,KAAM,CAACK,YAAY,GACnB+C,KAAM,CAAC/C,YAAY,GACnBgD,KAAM,CAAChD,YAAY,KA0Fb,MAAMtW,GAAQ,CAACuZ,EAAUC,SAC3BC,EACAC,GACA5B,KAACA,GAAQyB,KAGTA,EAASH,eACN,IAAIhW,MAAM,6CAKZ0U,aAAgBG,GAAwC,mBAArBH,EAAK6B,cAE5CF,EAAK,IAAIG,EAAY,CAACJ,cAAAA,IACtBE,EAAK,IAAIE,EAAY,CAACJ,cAAAA,IACtB1B,EAAK+B,KAAKJ,GACV3B,EAAK+B,KAAKH,GAEVH,EAAS3B,IAAWE,KAAO2B,EAC3B3B,EAAO4B,GAGD5B,GAaKgC,GAAqB,CAAChC,EAAMiC,IAE3B,OAATjC,EACI,KAIY,iBAATA,EACH,2BAIJf,GAAsBe,GAClB,kDAIJX,GAAOW,GACHA,EAAK9R,MAAQ,KAIjBoO,OAAO2D,SAASD,IAAS5L,EAAM8L,iBAAiBF,IAAShD,YAAYC,OAAO+C,GACxE,KAIJA,GAAoC,mBAArBA,EAAK6B,YACf,gCAA+B7B,EAAK6B,cAGzCvC,GAAWU,GACN,iCAAgCiC,EAAQnC,IAAWH,SAIxDK,aAAgBG,EACZ,KAID,2BAYK+B,GAAgBD,UACtBjC,KAACA,GAAQiC,SAGF,OAATjC,EACI,EAIJX,GAAOW,GACHA,EAAKnD,KAITP,OAAO2D,SAASD,GACZA,EAAKtW,OAITsW,GAAsC,mBAAvBA,EAAKmC,cAChBnC,EAAKoC,gBAAkBpC,EAAKoC,iBAAmBpC,EAAKmC,gBAAkB,KAI1E7C,GAAWU,GDjST,SAA2BK,EAAMV,OACnCjW,EAAS,MAER,MAAO4E,EAAMzC,KAAUwU,EAC3B3W,GAAU4S,OAAOa,WAAWyC,GAAUD,EAAUrR,EAAMzC,IAElDwT,GAAOxT,GACVnC,GAAUmC,EAAMgR,KAEhBnT,GAAU4S,OAAOa,WAAW9Q,OAAOR,IAGpCnC,GAAU+V,UAGX/V,GAAU4S,OAAOa,WAAWuC,GAAUC,IAE/BjW,ECiRC2Y,CAAkBJ,EAAQnC,IAAWH,UAItC,MC5VF2C,GAAwD,mBAA5BC,EAAKD,mBACtCC,EAAKD,mBACLhU,QACM,0BAA0BlD,KAAKkD,GAAO,OACpCoE,EAAM,IAAIiJ,UAAW,2CAA0CrN,YACrE4E,OAAOsP,eAAe9P,EAAK,OAAQ,CAAC7G,MAAO,2BACrC6G,IAIH+P,GAA0D,mBAA7BF,EAAKE,oBACvCF,EAAKE,oBACL,CAACnU,EAAMzC,QACF,kCAAkCT,KAAKS,GAAQ,OAC5C6G,EAAM,IAAIiJ,UAAW,yCAAwCrN,aACnE4E,OAAOsP,eAAe9P,EAAK,OAAQ,CAAC7G,MAAO,qBACrC6G,IAgBM,MAAMgQ,WAAgBC,gBAOpC/a,YAAYgb,OAGPrT,EAAS,MACTqT,aAAgBF,GAAS,OACtBG,EAAMD,EAAKC,UACZ,MAAOvU,EAAMkJ,KAAWtE,OAAO3B,QAAQsR,GAC3CtT,EAAO3C,QAAQ4K,EAAOuF,IAAIlR,GAAS,CAACyC,EAAMzC,UAErC,GAAY,MAAR+W,OAEJ,CAAA,GAAoB,iBAATA,GAAsBxO,EAAM0O,iBAAiBF,SA+BxD,IAAIjH,UAAU,wIA/BiD,OAC/DoH,EAASH,EAAKxE,OAAO4E,aAEb,MAAVD,EAEHxT,EAAO3C,QAAQsG,OAAO3B,QAAQqR,QACxB,IACgB,mBAAXG,QACJ,IAAIpH,UAAU,iCAKrBpM,EAAS,IAAIqT,GACX7F,IAAIkG,OAEa,iBAATA,GAAqB7O,EAAM0O,iBAAiBG,SAE7C,IAAItH,UAAU,qDAGd,IAAIsH,KACTlG,IAAIkG,OACc,IAAhBA,EAAKvZ,aACF,IAAIiS,UAAU,qDAGd,IAAIsH,cAQf1T,EACCA,EAAO7F,OAAS,EACf6F,EAAOwN,IAAI,EAAEzO,EAAMzC,MAClByW,GAAmBhU,GACnBmU,GAAoBnU,EAAMjC,OAAOR,IAC1B,CAACQ,OAAOiC,GAAMkH,cAAenJ,OAAOR,WAE5CF,QAEI4D,GAIC,IAAI2T,MAAM/a,KAAM,CACtBG,IAAIwN,EAAQ3I,EAAGgW,UACNhW,OACF,aACA,YACG,CAACmB,EAAMzC,KACbyW,GAAmBhU,GACnBmU,GAAoBnU,EAAMjC,OAAOR,IAC1B8W,gBAAgBxP,UAAUhG,GAAGkG,KACnC8P,EACA9W,OAAOiC,GAAMkH,cACbnJ,OAAOR,SAIL,aACA,UACA,gBACGyC,IACNgU,GAAmBhU,GACZqU,gBAAgBxP,UAAUhG,GAAGkG,KACnC8P,EACA9W,OAAOiC,GAAMkH,oBAIX,aACG,KACNM,EAAOxM,OACA,IAAI+H,IAAIsR,gBAAgBxP,UAAUvK,KAAKyK,KAAKyC,IAASlN,uBAItDwa,QAAQ9a,IAAIwN,EAAQ3I,EAAGgW,WAO9B/E,OAAOC,sBACJlW,KAAKP,YAAY0G,KAGzB8E,kBACQF,OAAOC,UAAUC,SAASC,KAAKlL,MAGvCG,IAAIgG,SACGkJ,EAASrP,KAAKiX,OAAO9Q,MACL,IAAlBkJ,EAAO9N,cACH,SAGJmC,EAAQ2L,EAAOvK,KAAK,YACpB,sBAAsB7B,KAAKkD,KAC9BzC,EAAQA,EAAM2J,eAGR3J,EAGRgC,QAAQwV,OACF,MAAM/U,KAAQnG,KAAKS,OACvBya,EAASlb,KAAKG,IAAIgG,GAAOA,iBAKrB,MAAMA,KAAQnG,KAAKS,aACjBT,KAAKG,IAAIgG,kBAQX,MAAMA,KAAQnG,KAAKS,YACjB,CAAC0F,EAAMnG,KAAKG,IAAIgG,KAIvB8P,OAAO4E,mBACA7a,KAAKoJ,UAQbsR,YACQ,IAAI1a,KAAKS,QAAQ0a,OAAO,CAAC/T,EAAQsC,KACvCtC,EAAOsC,GAAO1J,KAAKiX,OAAOvN,GACnBtC,GACL,KAMH6O,OAAOmF,IAAI,uCACJ,IAAIpb,KAAKS,QAAQ0a,OAAO,CAAC/T,EAAQsC,WACjC2F,EAASrP,KAAKiX,OAAOvN,UAI1BtC,EAAOsC,GADI,SAARA,EACW2F,EAAO,GAEPA,EAAO9N,OAAS,EAAI8N,EAASA,EAAO,GAG5CjI,GACL,KAQL2D,OAAOqL,iBACNmE,GAAQvP,UACR,CAAC,MAAO,UAAW,UAAW,UAAUmQ,OAAO,CAAC/T,EAAQkH,KACvDlH,EAAOkH,GAAY,CAAC+H,YAAY,GACzBjP,GACL,KC1OJ,MAAMiU,GAAiB,IAAInS,IAAI,CAAC,IAAK,IAAK,IAAK,IAAK,MAQvCoS,GAAavX,GAClBsX,GAAe9a,IAAIwD,GCCrB4T,GAAY1B,OAAO,sBASV,MAAMsF,WAAiB3D,GACrCnY,YAAYoY,EAAO,KAAMzN,EAAU,UAC5ByN,EAAMzN,SAENoR,EAASpR,EAAQoR,QAAU,IAC3BtO,EAAU,IAAIqN,GAAQnQ,EAAQ8C,YAEvB,OAAT2K,IAAkB3K,EAAQ3M,IAAI,gBAAiB,OAC5Ckb,EAAc5B,GAAmBhC,GACnC4D,GACHvO,EAAQ6J,OAAO,eAAgB0E,QAI5B9D,IAAa,CACjBzG,IAAK9G,EAAQ8G,IACbsK,OAAAA,EACAE,WAAYtR,EAAQsR,YAAc,GAClCxO,QAAAA,EACArN,QAASuK,EAAQvK,QACjB0Z,cAAenP,EAAQmP,gCAKjBvZ,KAAK2X,IAAWzG,KAAO,uBAIvBlR,KAAK2X,IAAW6D,uBAOhBxb,KAAK2X,IAAW6D,QAAU,KAAOxb,KAAK2X,IAAW6D,OAAS,4BAI1Dxb,KAAK2X,IAAW9X,QAAU,0BAI1BG,KAAK2X,IAAW+D,gCAIhB1b,KAAK2X,IAAWzK,mCAIhBlN,KAAK2X,IAAW4B,cAQxBxZ,eACQ,IAAIwb,GAASxb,GAAMC,KAAMA,KAAKuZ,eAAgB,CACpDrI,IAAKlR,KAAKkR,IACVsK,OAAQxb,KAAKwb,OACbE,WAAY1b,KAAK0b,WACjBxO,QAASlN,KAAKkN,QACdyO,GAAI3b,KAAK2b,GACTC,WAAY5b,KAAK4b,WACjBlH,KAAM1U,KAAK0U,uBASGxD,EAAKsK,EAAS,SACxBF,GAAWE,SACT,IAAIlO,WAAW,0EAGf,IAAIiO,GAAS,KAAM,CACzBrO,QAAS,CACR2O,SAAU,IAAIC,IAAI5K,GAAKjG,YAExBuQ,OAAAA,QAIGvF,OAAOC,qBACJ,YAITnL,OAAOqL,iBAAiBmF,GAASvQ,UAAW,CAC3CkG,IAAK,CAACmF,YAAY,GAClBmF,OAAQ,CAACnF,YAAY,GACrBsF,GAAI,CAACtF,YAAY,GACjBuF,WAAY,CAACvF,YAAY,GACzBqF,WAAY,CAACrF,YAAY,GACzBnJ,QAAS,CAACmJ,YAAY,GACtBtW,MAAO,CAACsW,YAAY,KCzHd,MCeDsB,GAAY1B,OAAO,qBAQnB8F,GAAYzY,GAEE,iBAAXA,GACsB,iBAAtBA,EAAOqU,IAWD,MAAMqE,WAAgBpE,GACpCnY,YAAYgD,EAAOgY,EAAO,QACrBwB,EAGAF,GAAUtZ,GACbwZ,EAAY,IAAIH,IAAIrZ,EAAMyO,MAE1B+K,EAAY,IAAIH,IAAIrZ,GACpBA,EAAQ,QAGLmY,EAASH,EAAKG,QAAUnY,EAAMmY,QAAU,SAC5CA,EAASA,EAAOsB,eAGG,MAAbzB,EAAK5C,MAAgBkE,GAAUtZ,KAA0B,OAAfA,EAAMoV,OACzC,QAAX+C,GAA+B,SAAXA,SACf,IAAIpH,UAAU,uDAGf2I,EAAY1B,EAAK5C,KACtB4C,EAAK5C,KACJkE,GAAUtZ,IAAyB,OAAfA,EAAMoV,KAC1B9X,GAAM0C,GACN,WAEI0Z,EAAW,CAChBzH,KAAM+F,EAAK/F,MAAQjS,EAAMiS,MAAQ,UAG5BxH,EAAU,IAAIqN,GAAQE,EAAKvN,SAAWzK,EAAMyK,SAAW,OAE3C,OAAdiP,IAAuBjP,EAAQ3M,IAAI,gBAAiB,OACjDkb,EAAc5B,GAAmBsC,EAAWnc,MAC9Cyb,GACHvO,EAAQ6J,OAAO,eAAgB0E,OAI7BW,EAASL,GAAUtZ,GACtBA,EAAM2Z,OACN,QACG,WAAY3B,IACf2B,EAAS3B,EAAK2B,QAGA,OAAXA,IPRc,iBAFS9Y,EOUW8Y,IPPrB,gBAAjB9Y,EAAOuT,WOQA,IAAIrD,UAAU,mDPXMlQ,IAAAA,OOctBqU,IAAa,CACjBiD,OAAAA,EACAyB,SAAU5B,EAAK4B,UAAY5Z,EAAM4Z,UAAY,SAC7CnP,QAAAA,EACA+O,UAAAA,EACAG,OAAAA,QAIIE,YAAyB9Y,IAAhBiX,EAAK6B,YAAyC9Y,IAAjBf,EAAM6Z,OAAuB,GAAK7Z,EAAM6Z,OAAU7B,EAAK6B,YAC7FC,cAA6B/Y,IAAlBiX,EAAK8B,cAA6C/Y,IAAnBf,EAAM8Z,UAAgC9Z,EAAM8Z,SAAY9B,EAAK8B,cACvG1c,QAAU4a,EAAK5a,SAAW4C,EAAM5C,SAAW,OAC3C2c,MAAQ/B,EAAK+B,OAAS/Z,EAAM+Z,WAC5BjD,cAAgBkB,EAAKlB,eAAiB9W,EAAM8W,eAAiB,WAC7DkD,mBAAqBhC,EAAKgC,oBAAsBha,EAAMga,qBAAsB,sBAI1Ezc,KAAK2X,IAAWiD,wBAIhB8B,EAAU1c,KAAK2X,IAAWsE,gCAI1Bjc,KAAK2X,IAAWzK,8BAIhBlN,KAAK2X,IAAW0E,6BAIhBrc,KAAK2X,IAAWyE,OAQxBrc,eACQ,IAAIic,GAAQhc,UAGfiW,OAAOC,qBACJ,WAITnL,OAAOqL,iBAAiB4F,GAAQhR,UAAW,CAC1C4P,OAAQ,CAACvE,YAAY,GACrBnF,IAAK,CAACmF,YAAY,GAClBnJ,QAAS,CAACmJ,YAAY,GACtBgG,SAAU,CAAChG,YAAY,GACvBtW,MAAO,CAACsW,YAAY,GACpB+F,OAAQ,CAAC/F,YAAY,KC5If,MAAMsG,WAAmBrG,GAC/B7W,YAAYgN,EAAS1G,EAAO,iBACrB0G,EAAS1G,ICiBjB,MAAM6W,GAAmB,IAAI1T,IAAI,CAAC,QAAS,QAAS,WASrCiB,eAAe0S,GAAM3L,EAAK4L,UACjC,IAAIjU,QAAQ,CAACQ,EAASiB,WAEtBwP,EAAU,IAAIkC,GAAQ9K,EAAK4L,GAC3B1S,EFqH6B0P,CAAAA,UAC9BmC,UAACA,GAAanC,EAAQnC,IACtBzK,EAAU,IAAIqN,GAAQT,EAAQnC,IAAWzK,SAG1CA,EAAQ3M,IAAI,WAChB2M,EAAQ7M,IAAI,SAAU,WAInB0c,EAAqB,QACJ,OAAjBjD,EAAQjC,MAAiB,gBAAgB5U,KAAK6W,EAAQc,UACzDmC,EAAqB,KAGD,OAAjBjD,EAAQjC,KAAe,OACpBmF,EAAajD,GAAcD,GAEP,iBAAfkD,GAA4BC,OAAOtR,MAAMqR,KACnDD,EAAqB7Y,OAAO8Y,IAI1BD,GACH7P,EAAQ7M,IAAI,iBAAkB0c,GAI1B7P,EAAQ3M,IAAI,eAChB2M,EAAQ7M,IAAI,aAAc,cAIvByZ,EAAQyC,WAAarP,EAAQ3M,IAAI,oBACpC2M,EAAQ7M,IAAI,kBAAmB,uBAG5Bmc,MAACA,GAAS1C,EACO,mBAAV0C,IACVA,EAAQA,EAAMP,IAGV/O,EAAQ3M,IAAI,eAAkBic,GAClCtP,EAAQ7M,IAAI,aAAc,eAMrB6c,ED3MkBjB,CAAAA,OACpBA,EAAUiB,cACNjB,EAAUiB,aAGZC,EAAalB,EAAUlK,KAAKxQ,OAAS,EACrCyF,EAAOiV,EAAUjV,OAAwC,MAA/BiV,EAAUlK,KAAKoL,GAAsB,IAAM,UACvB,MAA7ClB,EAAUlK,KAAKoL,EAAanW,EAAKzF,QAAkB,IAAM,ICoMjD6b,CAAUnB,SAGF,CACtBvT,KAAMuT,EAAUoB,SAAWH,EAC3BG,SAAUpB,EAAUoB,SACpBC,SAAUrB,EAAUqB,SACpB9K,SAAUyJ,EAAUzJ,SACpBV,KAAMmK,EAAUnK,KAChB9K,KAAMiV,EAAUjV,KAChBkW,OAAQjB,EAAUiB,OAClBzK,MAAOwJ,EAAUxJ,MACjBV,KAAMkK,EAAUlK,KAChB6I,OAAQd,EAAQc,OAChB1N,QAASA,EAAQ+I,OAAOmF,IAAI,iCAC5BqB,mBAAoB3C,EAAQ2C,mBAC5BD,MAAAA,IEtLgBe,CAAsBzD,OACjC8C,GAAiBrc,IAAI6J,EAAQoI,gBAC3B,IAAIgB,UAAW,0BAAyBtC,kBAAoB9G,EAAQoI,SAAS3O,QAAQ,KAAM,6BAGzE,UAArBuG,EAAQoI,SAAsB,OAC3BwB,EAAOwJ,GAAgB1D,EAAQ5I,KAC/BuM,EAAW,IAAIlC,GAASvH,EAAM,CAAC9G,QAAS,gBAAiB8G,EAAKF,wBACpEzK,EAAQoU,SAKHC,GAA6B,WAArBtT,EAAQoI,SAAwBmL,EAAQvD,GAAMN,SACtDsC,OAACA,GAAUtC,MACb2D,EAAW,WAETG,EAAQ,WACPvF,EAAQ,IAAIsE,GAAW,8BAC7BrS,EAAO+N,GACHyB,EAAQjC,MAAQiC,EAAQjC,gBAAgBG,EAAO3D,UAClDyF,EAAQjC,KAAKiB,QAAQT,GAGjBoF,GAAaA,EAAS5F,MAI3B4F,EAAS5F,KAAKgG,KAAK,QAASxF,OAGzB+D,GAAUA,EAAO0B,oBACpBF,UAIKG,EAAmB,KACxBH,IACAI,KAIKC,EAAWP,EAAKtT,GAElBgS,GACHA,EAAO8B,iBAAiB,QAASH,SAG5BC,EAAW,KAChBC,EAASL,QACLxB,GACHA,EAAO+B,oBAAoB,QAASJ,IAItCE,EAAS3F,GAAG,QAAS/N,IACpBD,EAAO,IAAIkM,GAAY,cAAasD,EAAQ5I,uBAAuB3G,EAAIkC,UAAW,SAAUlC,IAC5FyT,MAGDC,EAAS3F,GAAG,WAAY8F,IACvBH,EAASI,WAAW,SACdnR,EN+IF,SAAwBA,EAAU,WACjC,IAAIqN,GACVrN,EAEEiO,OAAO,CAAC/T,EAAQ1D,EAAO4a,EAAOC,KAC1BD,EAAQ,GAAM,GACjBlX,EAAO3C,KAAK8Z,EAAM5c,MAAM2c,EAAOA,EAAQ,IAGjClX,GACL,IACFkF,OAAO,EAAEnG,EAAMzC,iBAEdyW,GAAmBhU,GACnBmU,GAAoBnU,EAAMjC,OAAOR,KAC1B,EACN,aACM,MMhKO8a,CAAeJ,EAAUK,eAGrCnD,GAAW8C,EAAUM,YAAa,OAE/B7C,EAAW3O,EAAQ/M,IAAI,YAGvBwe,EAA2B,OAAb9C,EAAoB,KAAO,IAAIC,IAAID,EAAU/B,EAAQ5I,YAGjE4I,EAAQuC,cACV,eACJ/R,EAAO,IAAIkM,GAAY,0EAAyEsD,EAAQ5I,IAAO,qBAC/G8M,QAEI,YAEgB,OAAhBW,MAGFzR,EAAQ7M,IAAI,WAAYse,GAEvB,MAAOtG,GACR/N,EAAO+N,aAKL,aAEgB,OAAhBsG,WAKA7E,EAAQja,SAAWia,EAAQwC,cAC9BhS,EAAO,IAAIkM,GAAY,gCAA+BsD,EAAQ5I,IAAO,sBACrE8M,UAMKY,EAAiB,CACtB1R,QAAS,IAAIqN,GAAQT,EAAQ5M,SAC7BoP,OAAQxC,EAAQwC,OAChBzc,QAASia,EAAQja,QAAU,EAC3B2c,MAAO1C,EAAQ0C,MACfD,SAAUzC,EAAQyC,SAClB3B,OAAQd,EAAQc,OAChB/C,KAAMiC,EAAQjC,KACduE,OAAQtC,EAAQsC,OAChB1H,KAAMoF,EAAQpF,aAIc,MAAzB0J,EAAUM,YAAsB5E,EAAQjC,MAAQiF,EAASjF,gBAAgBG,EAAO3D,UACnF/J,EAAO,IAAIkM,GAAW,2DAA4D,8BAClFwH,MAK4B,MAAzBI,EAAUM,aAAiD,MAAzBN,EAAUM,YAA+C,MAAzBN,EAAUM,YAA0C,SAAnB5E,EAAQc,UAC9GgE,EAAehE,OAAS,MACxBgE,EAAe/G,UAAOrU,EACtBob,EAAe1R,QAAQ8J,OAAO,mBAI/B3N,EAAQwT,GAAM,IAAIb,GAAQ2C,EAAaC,UACvCZ,OAUHI,EAAUS,KAAK,MAAO,KACjBzC,GACHA,EAAO+B,oBAAoB,QAASJ,SAIlClG,EAAOiH,EAAKV,EAAW,IAAIzE,EAAetB,IAC7C/N,EAAO+N,KAGJ0G,QAAQC,QAAU,UACrBZ,EAAU9F,GAAG,UAAWyF,SAGnBkB,EAAkB,CACvB/N,IAAK4I,EAAQ5I,IACbsK,OAAQ4C,EAAUM,WAClBhD,WAAY0C,EAAUc,cACtBhS,QAAAA,EACAwH,KAAMoF,EAAQpF,KACd7U,QAASia,EAAQja,QACjB0Z,cAAeO,EAAQP,eAIlB4F,EAAUjS,EAAQ/M,IAAI,wBAUvB2Z,EAAQyC,UAA+B,SAAnBzC,EAAQc,QAAiC,OAAZuE,GAA6C,MAAzBf,EAAUM,YAA+C,MAAzBN,EAAUM,kBACnHjB,EAAW,IAAIlC,GAAS1D,EAAMoH,QAC9B5V,EAAQoU,SASH2B,EAAc,CACnBC,MAAOC,EAAKC,aACZC,YAAaF,EAAKC,iBAIH,SAAZJ,GAAkC,WAAZA,SACzBtH,EAAOiH,EAAKjH,EAAMyH,EAAKG,aAAaL,GAAc/G,IACjD/N,EAAO+N,KAERoF,EAAW,IAAIlC,GAAS1D,EAAMoH,QAC9B5V,EAAQoU,MAKO,YAAZ0B,GAAqC,cAAZA,MAyBb,OAAZA,SACHtH,EAAOiH,EAAKjH,EAAMyH,EAAKI,yBAA0BrH,IAChD/N,EAAO+N,KAERoF,EAAW,IAAIlC,GAAS1D,EAAMoH,QAC9B5V,EAAQoU,GAKTA,EAAW,IAAIlC,GAAS1D,EAAMoH,GAC9B5V,EAAQoU,QAjCKqB,EAAKV,EAAW,IAAIzE,EAAetB,IAC9C/N,EAAO+N,KAEJwG,KAAK,OAAQzJ,IAGfyC,EADyB,IAAV,GAAXzC,EAAM,IACH0J,EAAKjH,EAAMyH,EAAKK,gBAAiBtH,IACvC/N,EAAO+N,KAGDyG,EAAKjH,EAAMyH,EAAKM,mBAAoBvH,IAC1C/N,EAAO+N,KAIToF,EAAW,IAAIlC,GAAS1D,EAAMoH,GAC9B5V,EAAQoU,QPyGgB,EAACoC,GAAOhI,KAAAA,MACvB,OAATA,EAEHgI,EAAKpK,MACKyB,GAAOW,GAEjBA,EAAKxC,SAASuE,KAAKiG,GACT1L,OAAO2D,SAASD,IAE1BgI,EAAKC,MAAMjI,GACXgI,EAAKpK,OAGLoC,EAAK+B,KAAKiG,IOlGVE,CAAc9B,EAAUnE,KCvQ1B,MAAMkG,GAAc,IAAIzL,QAOlB0L,GAAW,IAAI1L,QAQrB,SAAS2L,GAAGC,SACFC,EAAOJ,GAAY7f,IAAIggB,UAC7BE,QAAQC,OACI,MAARF,EACA,8CACAD,GAEGC,EAOX,SAASG,GAAcvM,GACS,MAAxBA,EAAKwM,gBAYJxM,EAAKmM,MAAMM,aAIhBzM,EAAK0M,UAAW,EACyB,mBAA9B1M,EAAKmM,MAAMQ,gBAClB3M,EAAKmM,MAAMQ,kBAhBY,oBAAZN,SACkB,mBAAlBA,QAAQhI,OAEfgI,QAAQhI,MACJ,qEACArE,EAAKwM,iBAyBrB,SAASI,GAAMC,EAAaV,GACxBH,GAAY3f,IAAIL,KAAM,CAClB6gB,YAAAA,EACAV,MAAAA,EACAW,WAAY,EACZC,cAAeF,EACfH,UAAU,EACVM,SAAS,EACTC,kBAAkB,EAClBT,gBAAiB,KACjBU,UAAWf,EAAMe,WAAaC,KAAKC,QAIvCrW,OAAOsP,eAAera,KAAM,YAAa,CAAE0D,OAAO,EAAO2S,YAAY,UAG/D5V,EAAOsK,OAAOtK,KAAK0f,OACpB,IAAI7e,EAAI,EAAGA,EAAIb,EAAKc,SAAUD,EAAG,OAC5BoI,EAAMjJ,EAAKa,GACXoI,KAAO1J,MACT+K,OAAOsP,eAAera,KAAM0J,EAAK2X,GAAyB3X,KAyOtE,SAAS2X,GAAyB3X,SACvB,CACH4X,aACWpB,GAAGlgB,MAAMmgB,MAAMzW,IAE1B4X,IAAI5d,GACAwc,GAAGlgB,MAAMmgB,MAAMzW,GAAOhG,GAE1B6d,cAAc,EACdlL,YAAY,GAUpB,SAASmL,GAAqB9X,SACnB,CACH4X,cACUnB,EAAQD,GAAGlgB,MAAMmgB,aAChBA,EAAMzW,GAAKsH,MAAMmP,EAAOlP,YAEnCsQ,cAAc,EACdlL,YAAY,GAmDpB,SAASoL,GAAWC,MACH,MAATA,GAAiBA,IAAU3W,OAAOC,iBAC3B4V,OAGPe,EAAU1B,GAAS9f,IAAIuhB,UACZ,MAAXC,IACAA,EA/CR,SAAuBC,EAAWF,SACxBjhB,EAAOsK,OAAOtK,KAAKihB,MACL,IAAhBjhB,EAAKc,cACEqgB,WAIFC,EAAYhB,EAAaV,GAC9ByB,EAAU1W,KAAKlL,KAAM6gB,EAAaV,GAGtC0B,EAAY7W,UAAYD,OAAO+W,OAAOF,EAAU5W,UAAW,CACvDvL,YAAa,CAAEiE,MAAOme,EAAaN,cAAc,EAAMQ,UAAU,SAIhE,IAAIzgB,EAAI,EAAGA,EAAIb,EAAKc,SAAUD,EAAG,OAC5BoI,EAAMjJ,EAAKa,QACXoI,KAAOkY,EAAU5W,WAAY,OAEzBgX,EAAqC,mBADxBjX,OAAOkX,yBAAyBP,EAAOhY,GACzBhG,MACjCqH,OAAOsP,eACHwH,EAAY7W,UACZtB,EACAsY,EACMR,GAAqB9X,GACrB2X,GAAyB3X,YAKpCmY,EAgBOK,CAAcT,GAAW1W,OAAOoX,eAAeT,IAASA,GAClEzB,GAAS5f,IAAIqhB,EAAOC,IAEjBA,EAqBJ,SAASS,GAAUjC,UACfD,GAAGC,GAAOc,iBAgCd,SAASoB,GAAmBlC,EAAOK,GACtCN,GAAGC,GAAOK,gBAAkBA,EAjXhCI,GAAM5V,UAAY,mBAMHkV,GAAGlgB,MAAMmgB,MAAMpa,0BAQfma,GAAGlgB,MAAM6gB,wCAQTX,GAAGlgB,MAAM+gB,eAMpBO,qBACUP,EAAgBb,GAAGlgB,MAAM+gB,qBACV,MAAjBA,EACO,GAEJ,CAACA,sBAQD,gCAQA,0BAQA,+BAQA,2BAQAb,GAAGlgB,MAAM8gB,YAOpBQ,wBACUtN,EAAOkM,GAAGlgB,MAEhBgU,EAAKgN,SAAU,EAC2B,mBAA/BhN,EAAKmM,MAAMmC,iBAClBtO,EAAKmM,MAAMmC,mBAQnBhB,iCACUtN,EAAOkM,GAAGlgB,MAEhBgU,EAAKgN,SAAU,EACfhN,EAAKiN,kBAAmB,EAC2B,mBAAxCjN,EAAKmM,MAAMoC,0BAClBvO,EAAKmM,MAAMoC,iDASRC,QAAQtC,GAAGlgB,MAAMmgB,MAAMsC,kCAQvBD,QAAQtC,GAAGlgB,MAAMmgB,MAAMM,aAOlCa,iBACIf,GAAcL,GAAGlgB,sCAQVkgB,GAAGlgB,MAAM0gB,gCAQT8B,QAAQtC,GAAGlgB,MAAMmgB,MAAMuC,kCAQvBxC,GAAGlgB,MAAMkhB,mCASThB,GAAGlgB,MAAM6gB,uCASTX,GAAGlgB,MAAMghB,0BAEHtd,OACRA,eAGCsQ,EAAOkM,GAAGlgB,MAEhBgU,EAAKgN,SAAU,EACwB,kBAA5BhN,EAAKmM,MAAMwC,eAClB3O,EAAKmM,MAAMwC,cAAe,6BAUtBzC,GAAGlgB,MAAM0gB,0BAELhd,GACPA,GACD6c,GAAcL,GAAGlgB,QAWzBshB,eAMJvW,OAAOsP,eAAeuG,GAAM5V,UAAW,cAAe,CAClDtH,MAAOkd,GACPW,cAAc,EACdQ,UAAU,IAIQ,oBAAXa,aAAkD,IAAjBA,OAAOhC,QAC/C7V,OAAO8X,eAAejC,GAAM5V,UAAW4X,OAAOhC,MAAM5V,WAGpDiV,GAAS5f,IAAIuiB,OAAOhC,MAAM5V,UAAW4V,2mEA0GlC,SAAmBC,EAAaV,UAE5B,IADSsB,GAAW1W,OAAOoX,eAAehC,IAC1C,CAAYU,EAAaV,gbAoB7B,SAAuBA,EAAOW,GACjCZ,GAAGC,GAAOW,WAAaA,QAUpB,SAA0BX,EAAOY,GACpCb,GAAGC,GAAOY,cAAgBA,oPC5b9B,MAAqB+B,WAAoBC,GAIrCzB,4BAEU,IAAI9N,UAAU,kEAOdsK,EAAUkF,GAAa7iB,IAAIH,SACV,kBAAZ8d,QACD,IAAItK,UACN,2DACa,OAATxT,KAAgB,cAAgBA,cAIrC8d,GAGfmF,GAAqBH,GAAY9X,UAAW,SA2B5C,MAAMgY,GAAe,IAAIzO,QAGzBxJ,OAAOqL,iBAAiB0M,GAAY9X,UAAW,CAC3C8S,QAAS,CAAEzH,YAAY,KAIL,mBAAXJ,QAAuD,iBAAvBA,OAAOC,aAC9CnL,OAAOsP,eAAeyI,GAAY9X,UAAWiL,OAAOC,YAAa,CAC7DqL,cAAc,EACd7d,MAAO,mDAjCf,iBACU0Y,EAASrR,OAAO+W,OAAOgB,GAAY9X,kBACzC+X,GAAY7X,KAAKkR,GACjB4G,GAAa3iB,IAAI+b,GAAQ,GAClBA,2CAMX,IAA4BA,EAAAA,YACS,IAA7B4G,GAAa7iB,IAAIic,KAIrB4G,GAAa3iB,IAAI+b,GAAQ,GACzBA,EAAO8G,cAAuB,CAAEnd,KAAM,siBClEsBxG,UAGvD;;MAIF4jB,EAAU,GAEVC,EAAY9U,GAEG,oBAATwC,MAAwBA,MAAQxC,KAAYwC,KAC/CA,KAIc,oBAAX8R,QAA0BA,QAAUtU,KAAYsU,OACnDA,YAGc,IAAXS,IAA0BA,IAAU/U,KAAY+U,GACnDA,GAIkB,oBAAfC,YAA8BA,WACjCA,kBAIHC,EAAmB,CACxB,UACA,UACA,WACA,iBACA,QACA,kBACA,gBAGI,MAAMjV,KAAYiV,EACtBxY,OAAOsP,eAAe8I,EAAS7U,EAAU,CACxCnO,YACOqjB,EAAeJ,EAAU9U,GACzB5K,EAAQ8f,GAAgBA,EAAalV,SACnB,mBAAV5K,EAAuBA,EAAM+f,KAAKD,GAAgB9f,WAK7D+H,EAAW/H,GAAmB,OAAVA,GAAmC,iBAAVA,EAC7CggB,EAA6D,mBAA5BP,EAAQQ,gBACzCC,EAAoD,mBAA3BT,EAAQU,eACjCC,EAA+C,mBAArBX,EAAQY,SAElCC,EAAe,CAACC,EAASC,WACxB9c,EAAS,IAAI+b,EAAQ5I,QAAQ0J,GAAW,IACxCE,EAAoBD,aAAmBf,EAAQ5I,QAC/C6J,EAAS,IAAIjB,EAAQ5I,QAAQ2J,GAAW,QAEzC,MAAOxa,EAAKhG,KAAU0gB,EACrBD,GAA+B,cAAVzgB,QAAoCF,IAAVE,EACnD0D,EAAO4P,OAAOtN,GAEdtC,EAAO/G,IAAIqJ,EAAKhG,UAIX0D,GAGFid,EAAY,IAAIC,SACjBC,EAAc,GACdrX,EAAU,OAET,MAAMkX,KAAUE,EAAS,IACzB5f,MAAMC,QAAQyf,GACX1f,MAAMC,QAAQ4f,KACnBA,EAAc,IAGfA,EAAc,IAAIA,KAAgBH,QAC5B,GAAI3Y,EAAS2Y,GAAS,KACvB,IAAK1a,EAAKhG,KAAUqH,OAAO3B,QAAQgb,GACnC3Y,EAAS/H,IAAWgG,KAAO6a,IAC9B7gB,EAAQ2gB,EAAUE,EAAY7a,GAAMhG,IAGrC6gB,EAAc,IAAIA,GAAc7a,GAAMhG,GAGnC+H,EAAS2Y,EAAOlX,WACnBA,EAAU8W,EAAa9W,EAASkX,EAAOlX,UAIzCqX,EAAYrX,QAAUA,SAGhBqX,GAGFC,EAAiB,CACtB,MACA,OACA,MACA,QACA,OACA,UAGKC,EAAgB,CACrBrL,KAAM,mBACNC,KAAM,SACNqL,SAAU,sBACVzP,YAAa,MACbe,KAAM,OAsBD2O,EAAwB,CAC7B,IACA,IACA,KAGKC,EAAO3O,OAAO,cAEd4O,UAAkB1hB,MACvB1D,YAAYge,SAIVA,EAAS/B,YACTxX,OACsB,IAApBuZ,EAASjC,QAAgBiC,EAASjC,OAClCiC,EAASjC,OAAS,gCAGhBrV,KAAO,iBACPsX,SAAWA,SAIZqH,UAAqB3hB,MAC1B1D,YAAYqa,SACL,0BACD3T,KAAO,oBACP2T,QAAUA,SAIXiL,EAAQC,GAAM,IAAInc,QAAQQ,GAAWgV,WAAWhV,EAAS2b,IAuBzDC,EAAyBxiB,GAAS+hB,EAAeU,SAASziB,GAASA,EAAMyZ,cAAgBzZ,EAEzF0iB,EAAsB,CAC3BC,MAAO,EACPC,QA9EoB,CACpB,MACA,MACA,OACA,SACA,UACA,SAyEAC,YAtEwB,CACxB,IACA,IACA,IACA,IACA,IACA,IACA,KAgEAC,iBAAkBZ,GAGba,EAAwB,CAACC,EAAQ,SACjB,iBAAVA,QACH,IACHN,EACHC,MAAOK,MAILA,EAAMJ,UAAY3gB,MAAMC,QAAQ8gB,EAAMJ,eACnC,IAAIliB,MAAM,qCAGbsiB,EAAMH,cAAgB5gB,MAAMC,QAAQ8gB,EAAMH,mBACvC,IAAIniB,MAAM,4CAGV,IACHgiB,KACAM,EACHF,iBAAkBZ,UAOde,EACLjmB,YAAYgD,EAAO2H,EAAU,YACvBub,YAAc,OACdC,OAASnjB,OACTojB,SAAW,CAEfC,YAAa9lB,KAAK4lB,OAAOE,aAAe,iBACrC1b,EACH8C,QAAS8W,EAAahkB,KAAK4lB,OAAO1Y,QAAS9C,EAAQ8C,SACnD6Y,MAAO1B,EAAU,CAChB2B,cAAe,GACfC,YAAa,GACbC,cAAe,IACb9b,EAAQ2b,OACXnL,OAAQqK,EAAuB7a,EAAQwQ,QAAU5a,KAAK4lB,OAAOhL,QAC7DuL,UAAWjiB,OAAOkG,EAAQ+b,WAAa,IACvCV,MAAOD,EAAsBpb,EAAQqb,OACrCW,iBAA6C,IAA5Bhc,EAAQgc,gBACzBC,aAAoC,IAApBjc,EAAQic,QAA0B,IAAQjc,EAAQic,QAClExJ,MAAOzS,EAAQyS,OAASsG,EAAQtG,OAGN,iBAAhB7c,KAAK4lB,UAAyB5lB,KAAK4lB,kBAAkB9J,KAAO9b,KAAK4lB,kBAAkBzC,EAAQnH,eAC/F,IAAIxI,UAAU,gDAGjBxT,KAAK6lB,SAASM,WAAoC,iBAAhBnmB,KAAK4lB,OAAqB,IAC3D5lB,KAAK4lB,OAAO5f,WAAW,WACpB,IAAI7C,MAAM,8DAGZnD,KAAK6lB,SAASM,UAAUG,SAAS,YAChCT,SAASM,WAAa,UAGvBP,OAAS5lB,KAAK6lB,SAASM,UAAYnmB,KAAK4lB,UAG1ClC,SACE6C,gBAAkB,IAAIpD,EAAQQ,gBAC/B3jB,KAAK6lB,SAASzJ,aACZyJ,SAASzJ,OAAO8B,iBAAiB,QAAS,UACzCqI,gBAAgB3I,eAIlBiI,SAASzJ,OAASpc,KAAKumB,gBAAgBnK,aAGxCtC,QAAU,IAAIqJ,EAAQnH,QAAQhc,KAAK4lB,OAAQ5lB,KAAK6lB,UAEjD7lB,KAAK6lB,SAASW,aAAc,OACzBA,EAAe,IAAM,IAAIhM,gBAAgBxa,KAAK6lB,SAASW,cAAcvb,WACrEiG,EAAMlR,KAAK8Z,QAAQ5I,IAAIrN,QAAQ,oBAAqB2iB,KAGpD1C,GAAoB9jB,KAAK6lB,SAAShO,gBAAgBsL,EAAQY,UAAa/jB,KAAK6lB,SAAShO,gBAAgB2C,kBAAsBxa,KAAK6lB,SAAS3Y,SAAWlN,KAAK6lB,SAAS3Y,QAAQ,sBAC1K4M,QAAQ5M,QAAQ8J,OAAO,qBAGxB8C,QAAU,IAAIqJ,EAAQnH,QAAQ,IAAImH,EAAQnH,QAAQ9K,EAAKlR,KAAK8Z,SAAU9Z,KAAK6lB,eAGtDriB,IAAvBxD,KAAK6lB,SAASzM,YACZyM,SAAShO,KAAOa,KAAK+N,UAAUzmB,KAAK6lB,SAASzM,WAC7CU,QAAQ5M,QAAQ7M,IAAI,eAAgB,yBACpCyZ,QAAU,IAAIqJ,EAAQnH,QAAQhc,KAAK8Z,QAAS,CAACjC,KAAM7X,KAAK6lB,SAAShO,cAGjE6O,EAAKvc,aACNnK,KAAK6lB,SAASQ,QAxEE,iBAyEb,IAAI/Y,WAAY,gEAGjByX,EAAM,OACRtH,QAAiBzd,KAAK2mB,aAErB,MAAMC,KAAQ5mB,KAAK6lB,SAASE,MAAMG,cAAe,OAE/CW,QAAyBD,EAC9B5mB,KAAK8Z,QACL9Z,KAAK6lB,SACL7lB,KAAK8mB,kBAAkBrJ,EAAS1d,UAG7B8mB,aAA4B1D,EAAQ5H,WACvCkC,EAAWoJ,WAIRC,kBAAkBrJ,IAElBA,EAAS9B,IAAM3b,KAAK6lB,SAASO,sBAC3B,IAAIvB,EAAUpH,MAKjBzd,KAAK6lB,SAASkB,mBAAoB,IACW,mBAArC/mB,KAAK6lB,SAASkB,yBAClB,IAAIvT,UAAU,0DAGhBoQ,QACE,IAAIzgB,MAAM,sFAGVnD,KAAKgnB,QAAQvJ,EAAS1d,QAASC,KAAK6lB,SAASkB,2BAG9CtJ,GAIFrW,EADoBpH,KAAK6lB,SAASJ,MAAMJ,QAAQH,SAASllB,KAAK8Z,QAAQc,OAAOvN,eAChDrN,KAAKinB,OAAOP,GAAMA,QAEhD,MAAO3gB,EAAMmhB,KAAanc,OAAO3B,QAAQqb,GAC7Crd,EAAOrB,GAAQoE,eACT2P,QAAQ5M,QAAQ7M,IAAI,SAAUL,KAAK8Z,QAAQ5M,QAAQ/M,IAAI,WAAa+mB,SAEnEzJ,SAAkBrW,GAAQrH,WAEnB,SAATgG,EAAiB,IACI,MAApB0X,EAASjC,aACL,MAGJpR,EAAQ+c,iBACJ/c,EAAQ+c,gBAAgB1J,EAASpE,eAInCoE,EAAS1X,aAIXqB,EAGRggB,qBAAqB/O,WACfsN,cAED3lB,KAAK2lB,YAAc3lB,KAAK6lB,SAASJ,MAAML,SAAW/M,aAAiByM,GAAe,IACjFzM,aAAiBwM,EAAW,KAC1B7kB,KAAK6lB,SAASJ,MAAMH,YAAYJ,SAAS7M,EAAMoF,SAASjC,eACrD,QAGF6L,EAAahP,EAAMoF,SAASvQ,QAAQ/M,IAAI,kBAC1CknB,GAAcrnB,KAAK6lB,SAASJ,MAAMF,iBAAiBL,SAAS7M,EAAMoF,SAASjC,QAAS,KACnF8L,EAAQrK,OAAOoK,UACfpK,OAAOtR,MAAM2b,GAChBA,EAAQnG,KAAK3P,MAAM6V,GAAclG,KAAKC,MAEtCkG,GAAS,SAGuC,IAAtCtnB,KAAK6lB,SAASJ,MAAM8B,eAAiCD,EAAQtnB,KAAK6lB,SAASJ,MAAM8B,cACpF,EAGDD,KAGsB,MAA1BjP,EAAMoF,SAASjC,cACX,QAIc,GACE,IAAMxb,KAAK2lB,YAAc,GAAM,WAGlD,EAGRmB,kBAAkBrJ,UACbzd,KAAK6lB,SAASsB,YACjB1J,EAASrE,KAAOjP,SACRnK,KAAK6lB,SAASsB,gBAAgB1J,EAASpE,SAIzCoE,eAGKiJ,oBAEEA,IACZ,MAAOrO,SACF2M,EAAK1Z,KAAKsK,IAAI5V,KAAKonB,qBAAqB/O,GAhM1B,eAiMT,IAAP2M,GAAYhlB,KAAK2lB,YAAc,EAAG,OAC/BZ,EAAMC,OAEP,MAAM4B,KAAQ5mB,KAAK6lB,SAASE,MAAME,qBAEbW,EAAK,CAC7B9M,QAAS9Z,KAAK8Z,QACd1P,QAASpK,KAAK6lB,SACdxN,MAAAA,EACAmP,WAAYxnB,KAAK2lB,gBAICf,gBAKb5kB,KAAKinB,OAAOP,MAGhB1mB,KAAK6lB,SAASO,sBACX/N,sBAMH,MAAMuO,KAAQ5mB,KAAK6lB,SAASE,MAAMC,cAAe,OAE/C5e,QAAewf,EAAK5mB,KAAK8Z,QAAS9Z,KAAK6lB,aAEzCze,aAAkB4U,QAAS,MACzBlC,QAAU1S,WAIZA,aAAkBmU,gBACdnU,SAIqB,IAA1BpH,KAAK6lB,SAASQ,QACVrmB,KAAK6lB,SAAShJ,MAAM7c,KAAK8Z,QAAQ/Z,SAjS3B,EAAC+Z,EAASyM,EAAiBnc,IAC1C,IAAIvB,QAAQ,CAACQ,EAASiB,WACfmd,EAAYpJ,WAAW,KACxBkI,GACHA,EAAgB3I,QAGjBtT,EAAO,IAAIwa,EAAahL,KACtB1P,EAAQic,SAGXjc,EAAQyS,MAAM/C,GACZ4N,KAAKre,GACLse,MAAMrd,GACNod,KAAK,KACLE,aAAaH,OAqRRpB,CAAQrmB,KAAK8Z,QAAQ/Z,QAASC,KAAKumB,gBAAiBvmB,KAAK6lB,UAIjEmB,QAAQvJ,EAAUsJ,SACX/J,EAAaC,OAAOQ,EAASvQ,QAAQ/M,IAAI,oBAAsB,MACjE0nB,EAAmB,SAEhB,IAAI1E,EAAQ5H,SAClB,IAAI4H,EAAQU,eAAe,CAC1BrO,MAAMsS,SACCC,EAAStK,EAAS5F,KAAKmQ,YAEzBjB,GACHA,EAAmB,CAACkB,QAAS,EAAGJ,iBAAkB,EAAG7K,WAAAA,GAAa,IAAI9H,2BAGxDK,UACRnU,KAACA,EAADsC,MAAOA,SAAeqkB,EAAOxS,OAC/BnU,EACH0mB,EAAWI,SAIRnB,IACHc,GAAoBnkB,EAAMsR,WAE1B+R,EAAmB,CAACkB,QADW,IAAfjL,EAAmB,EAAI6K,EAAmB7K,EAC7B6K,iBAAAA,EAAkB7K,WAAAA,GAAatZ,IAG7DokB,EAAWK,QAAQzkB,GACnB6R,KAGDA,cAOC6S,EAAmB,IAAI9D,SACvB,MAAMF,KAAUE,OACd7Y,EAAS2Y,IAAW1f,MAAMC,QAAQyf,UAA8B,IAAXA,QACpD,IAAI5Q,UAAU,mDAIf6Q,EAAU,MAAOC,IAGnB+D,EAAiBC,UAChBC,EAAK,CAAC9lB,EAAO2H,IAAY,IAAIsb,EAAGjjB,EAAO2lB,EAAiBE,EAAUle,QAEnE,MAAMwQ,KAAU4J,EACpB+D,EAAG3N,GAAU,CAACnY,EAAO2H,IAAY,IAAIsb,EAAGjjB,EAAO2lB,EAAiBE,EAAUle,EAAS,CAACwQ,OAAAA,YAGrF2N,EAAG1D,UAAYA,EACf0D,EAAGzD,aAAeA,EAClByD,EAAGzG,OAAS0G,GAAeH,EAAeD,EAAiBI,IAC3DD,EAAGE,OAASD,GAAeH,EAAeD,EAAiBE,EAAUE,IACrED,EAAG3D,KAAOA,EAEH2D,UAGIF,IAphBoEK,uCCyBjF,GApBKrF,GAAOxG,QACXwG,GAAOxG,MAAQ,CAAC3L,EAAK9G,IAAYyS,GAAM3L,EAAK,CAACqI,cAHxB,OAGyDnP,KAG1EiZ,GAAO9I,UACX8I,GAAO9I,QAAUsC,GAAMtC,SAGnB8I,GAAOrH,UACXqH,GAAOrH,QAAUa,GAAMb,SAGnBqH,GAAO9H,WACX8H,GAAO9H,SAAWsB,GAAMtB,UAGpB8H,GAAOM,kBACXN,GAAOM,gBAAkBA,KAGrBN,GAAOQ,mBAEVR,GAAOQ,eAAiB/Z,EACvB,MAAO6e,KAGVppB,OAAiBuK;;;GC3BV,MAAM8e,GAAkB,CAC7Bpb,OAAQ,yCAGJ+a,GAAKM,GAAW/G,OAAO,CAAC5U,QAAS0b,KAEjCE,GAAe,IAAI5f,IAAI,CAC3B,MAAO,OAAQ,OAAQ,QAAS,OAAQ,WAkB1CiB,eAAe4e,GAAgBpb,EAAQqb,EAASC,OAC1CxL,MAEFA,QAAiB9P,EAAOqD,MAAMgY,EAASC,GACvC,MAAMlf,UAcVI,eAA4BJ,OAEtBA,EAAE0T,cACa,oBAAd1T,EAAE0C,UACH1C,EAAE0C,QAAa1C,EAAE0C,QAAJ,0BAET1C,EAIRA,EAAEyR,OAASzR,EAAE0T,SAASjC,aAEhBC,EAAc1R,EAAE0T,SAASvQ,QAAQ/M,IAAI,mBACxCsb,GAAeA,EAAYyJ,SAAS,QAAS,OACxCgE,QAAkBnf,EAAE0T,SAASrE,OAGnCrP,EAAE0C,QAAUyc,EAAUzc,SAAW1C,EAAE0C,QACnC1C,EAAEiK,KAAOkV,QAELnf,EAjCGof,CAAapf,SAEhBqf,UAACA,GAAY,GAAQH,EAAK,IAAM,MACnCG,EAAW,OAEN3N,EAAcgC,EAASvQ,QAAQ/M,IAAI,gBACtCsb,GAAeA,EAAYyJ,SAAS,UACrCzH,EAASzJ,WAAayJ,EAASrE,eAG5BqE,EA0BT,OAAe,YAxDW,IAAI1C,MAAMwN,GAAI,CACtCvX,MAAO+X,GACP5oB,IAAIwN,EAAQ0b,SACJC,EAAY3b,EAAO0b,UAGrBP,GAAavoB,IAAI8oB,GAGdlf,wBACE4e,GAAgBO,EAAWtpB,KAAMiR,YAHjCqY,KAmDXf,GAAIM,GACJD,gBAAAA,ICpEF,MAAMnb,gBAACA,GAADR,aAAkBA,IAAgBnD,IAClCgG,oBAACA,IAAuBhG,gBAGvBqI,IAAerI,IAChByf,WAACA,IAAczf,GAsBrBvK,OAAiB,EACfiqB,OAAAA,EACAC,UAAAA,GAAY,EACZC,aAAAA,GAAe,EACfxc,QAAAA,EAAU,GACVyc,UAAAA,EACAC,WAAAA,GACE,CAACH,WAAW,EAAMC,cAAe,EAAGxc,QAAS,OAG1C,eAFLA,EAAUD,GAAaC,MAGrBA,EAAUnC,OAAOwC,OAAO,GAAIL,EAAS,cACrB,qBAGZkN,EAAOtQ,SAEC,IAAI+f,IACLjZ,YAAW,SAASM,yBAIlB4Y,EAAa5Y,EAAK6Y,SACzBC,EAAS9Y,EAAIlL,WAAW,SACxBikB,EAAU/Y,EAAIlL,WAAW,cAC3BgkB,IAAWC,QACP,IAAI7b,GACR,6EAEA,oBAAqB,CAACrK,KAAM,0BAA2BmN,IAAAA,OAExDsY,IAAWS,QACN,IAAI7b,GACR,8FAEA,oBAAqB,CAACrK,KAAM,0BAA2BmN,IAAAA,QAGvDgZ,EAAM,QACC,OAARA,SACMA,MAGLC,EAAY,WAEVC,IAACA,EAADvS,KAAMA,SAqFhB1N,gBAAsB+G,IAACA,EAADhE,QAAMA,EAANuc,UAAeA,EAAfE,UAA0BA,EAA1BC,WAAqCA,cAEjDxf,EAAU,CAAC8C,QAAAA,EAASmP,SAAU,UACpBnL,EAAIlL,WAAW,UAE7BoE,EAAQoS,MACNoN,GAAc,IAAIjM,EAAM0M,MAAM,CAACC,mBAAoBb,IAElDE,IACDvf,EAAQoS,MAAQmN,SAGdS,QAAYb,GAAWppB,IAAI+Q,EAAK9G,SAC/B,CAACggB,IAAAA,EAAKvS,KAAMuS,EAAIpW,MACvB,MAAMjK,MAGHA,EAAE0T,eACI,CAAC2M,IAAKrgB,EAAE0T,SAAU5F,KAAM,YAE3B,IAAIzJ,GACR,oDACA,2BACA,CAACrK,KAAM,0BAA2BmN,IAAAA,EAAKqZ,MAAOxgB,KA5GtB4c,CAAO,CAC/BzV,IAAAA,EAAKhE,QAAAA,EAASuc,UAAAA,EAAWE,UAAAA,EAAWC,WAAAA,IAEtCM,EAAM,CAACM,WAAY,KAAMC,YAAavZ,EAAKwZ,SAAU7S,GAAQ,YAEvD6D,EAAatB,EAAKuQ,aAAaP,EAAI5O,WACtC4O,EAAI5O,QAAU,UACT,IAAIpN,GACP,QAAO8C,iCAAmCwK,IAC3C,oBAAqB,CACnB3X,KAAM,0BACNmN,IAAAA,EACA0Z,eAAgBR,EAAI5O,eAGpBqP,EAAOT,EAAIld,QAAQ/M,IAAI,QACvBsb,EAAc2O,EAAIld,QAAQ/M,IAAI,mBAEjC0qB,GAAwB,wBAAhBpP,EAAuC,OAE1CqP,EAAcrd,GAAgBod,GAC9BE,EAAgBD,EAAYhb,OAC/BpL,MAAMC,QAAQomB,SACT,IAAI3c,GACR,mFAEA,oBACA,CAACrK,KAAM,gCAAiCmN,IAAAA,IAEzC6Z,IACDb,EAAIM,WAAaO,EAAcpd,QAIjCwc,EAAYW,EAAW,UACpBX,GACiB,uBAAlBA,EAAUpkB,QACR0V,GAAe,IACdvY,MAAM,gCACTknB,EAAIld,QAAQ7M,IAAI,WAAY8R,GAAYjB,EAAKiZ,EAAUxc,eAGrDkO,EAAWuO,EAAIld,QAAQ/M,IAAI,gBAE7BgqB,GACFC,EAAI5O,QAAU,KAAO4O,EAAI5O,OAAS,MAAQK,EAAU,IACjDkO,EAAUxoB,SAAWmoB,QAChB,IAAItb,GACR,gEACA,0BAA2B,CACzBrK,KAAM,0BACNmN,IAAAA,EACA0Z,eAAgBR,EAAI5O,OACpBuO,UAAAA,QAGyB,IAA5BA,EAAU1e,QAAQ6F,SACb,IAAI9C,GACR,oEACA,kCAAmC,CACjCrK,KAAM,8BACNmN,IAAAA,EACA0Z,eAAgBR,EAAI5O,OACpBuO,UAAAA,WAGNA,EAAUtlB,KAAKyM,GACR4Y,EAAajO,EAAUkO,UAIhCA,EAAUtlB,KAAKyM,GAURgZ,EA3GAJ,CAAa5Y,EAAK,QC7C7B,MAAMlH,GAAM,GACZzK,OAAiByK,GAOjBA,GAAIghB,qBAAuB,SAASC,GAClCA,EAAOC,gBAAgBC,KAAOC,GAE9BH,EAAOI,kBAAkB,SAS3BrhB,GAAIshB,aAAe,SAASL,KC1B5B1rB,OCAiBgsB,GAKjB,SAASA,GAAStqB,OACZ6P,EAAO9Q,QACL8Q,aAAgBya,KACpBza,EAAO,IAAIya,IAGbza,EAAK0a,KAAO,KACZ1a,EAAK2a,KAAO,KACZ3a,EAAKvP,OAAS,EAEVN,GAAgC,mBAAjBA,EAAKyE,QACtBzE,EAAKyE,SAAQ,SAAUgmB,GACrB5a,EAAKrM,KAAKinB,WAEP,GAAIza,UAAU1P,OAAS,MACvB,IAAID,EAAI,EAAGqqB,EAAI1a,UAAU1P,OAAQD,EAAIqqB,EAAGrqB,IAC3CwP,EAAKrM,KAAKwM,UAAU3P,WAIjBwP,EAoVT,SAAS8a,GAAQ9a,EAAMqa,EAAMznB,OACvBmoB,EAAWV,IAASra,EAAK2a,KAC3B,IAAIK,GAAKpoB,EAAO,KAAMynB,EAAMra,GAC5B,IAAIgb,GAAKpoB,EAAOynB,EAAMA,EAAK1pB,KAAMqP,UAEb,OAAlB+a,EAASpqB,OACXqP,EAAK0a,KAAOK,GAEQ,OAAlBA,EAASE,OACXjb,EAAK2a,KAAOI,GAGd/a,EAAKvP,SAEEsqB,EAGT,SAASpnB,GAAMqM,EAAM4a,GACnB5a,EAAK0a,KAAO,IAAIM,GAAKJ,EAAM5a,EAAK0a,KAAM,KAAM1a,GACvCA,EAAK2a,OACR3a,EAAK2a,KAAO3a,EAAK0a,MAEnB1a,EAAKvP,SAGP,SAAS0N,GAAS6B,EAAM4a,GACtB5a,EAAK2a,KAAO,IAAIK,GAAKJ,EAAM,KAAM5a,EAAK2a,KAAM3a,GACvCA,EAAK0a,OACR1a,EAAK0a,KAAO1a,EAAK2a,MAEnB3a,EAAKvP,SAGP,SAASuqB,GAAMpoB,EAAOqoB,EAAMtqB,EAAMR,QAC1BjB,gBAAgB8rB,WACb,IAAIA,GAAKpoB,EAAOqoB,EAAMtqB,EAAMR,QAGhCA,KAAOA,OACPyC,MAAQA,EAETqoB,GACFA,EAAKtqB,KAAOzB,UACP+rB,KAAOA,QAEPA,KAAO,KAGVtqB,GACFA,EAAKsqB,KAAO/rB,UACPyB,KAAOA,QAEPA,KAAO,KA/ZhB8pB,GAAQO,KAAOA,GACfP,GAAQzJ,OAASyJ,GAyBjBA,GAAQvgB,UAAUghB,WAAa,SAAUb,MACnCA,EAAKlqB,OAASjB,WACV,IAAImD,MAAM,wDAGd1B,EAAO0pB,EAAK1pB,KACZsqB,EAAOZ,EAAKY,YAEZtqB,IACFA,EAAKsqB,KAAOA,GAGVA,IACFA,EAAKtqB,KAAOA,GAGV0pB,IAASnrB,KAAKyrB,YACXA,KAAOhqB,GAEV0pB,IAASnrB,KAAKwrB,YACXA,KAAOO,GAGdZ,EAAKlqB,KAAKM,SACV4pB,EAAK1pB,KAAO,KACZ0pB,EAAKY,KAAO,KACZZ,EAAKlqB,KAAO,KAELQ,GAGT8pB,GAAQvgB,UAAUihB,YAAc,SAAUd,MACpCA,IAASnrB,KAAKyrB,MAIdN,EAAKlqB,MACPkqB,EAAKlqB,KAAK+qB,WAAWb,OAGnBM,EAAOzrB,KAAKyrB,KAChBN,EAAKlqB,KAAOjB,KACZmrB,EAAK1pB,KAAOgqB,EACRA,IACFA,EAAKM,KAAOZ,QAGTM,KAAON,EACPnrB,KAAKwrB,YACHA,KAAOL,QAET5pB,WAGPgqB,GAAQvgB,UAAUkhB,SAAW,SAAUf,MACjCA,IAASnrB,KAAKwrB,MAIdL,EAAKlqB,MACPkqB,EAAKlqB,KAAK+qB,WAAWb,OAGnBK,EAAOxrB,KAAKwrB,KAChBL,EAAKlqB,KAAOjB,KACZmrB,EAAKY,KAAOP,EACRA,IACFA,EAAK/pB,KAAO0pB,QAGTK,KAAOL,EACPnrB,KAAKyrB,YACHA,KAAON,QAET5pB,WAGPgqB,GAAQvgB,UAAUvG,KAAO,eAClB,IAAInD,EAAI,EAAGqqB,EAAI1a,UAAU1P,OAAQD,EAAIqqB,EAAGrqB,IAC3CmD,GAAKzE,KAAMiR,UAAU3P,WAEhBtB,KAAKuB,QAGdgqB,GAAQvgB,UAAUiE,QAAU,eACrB,IAAI3N,EAAI,EAAGqqB,EAAI1a,UAAU1P,OAAQD,EAAIqqB,EAAGrqB,IAC3C2N,GAAQjP,KAAMiR,UAAU3P,WAEnBtB,KAAKuB,QAGdgqB,GAAQvgB,UAAUmI,IAAM,cACjBnT,KAAKwrB,UAINpB,EAAMpqB,KAAKwrB,KAAK9nB,kBACf8nB,KAAOxrB,KAAKwrB,KAAKO,KAClB/rB,KAAKwrB,UACFA,KAAK/pB,KAAO,UAEZgqB,KAAO,UAETlqB,SACE6oB,IAGTmB,GAAQvgB,UAAUkI,MAAQ,cACnBlT,KAAKyrB,UAINrB,EAAMpqB,KAAKyrB,KAAK/nB,kBACf+nB,KAAOzrB,KAAKyrB,KAAKhqB,KAClBzB,KAAKyrB,UACFA,KAAKM,KAAO,UAEZP,KAAO,UAETjqB,SACE6oB,IAGTmB,GAAQvgB,UAAUtF,QAAU,SAAUghB,EAAIyF,GACxCA,EAAQA,GAASnsB,SACZ,IAAIosB,EAASpsB,KAAKyrB,KAAMnqB,EAAI,EAAc,OAAX8qB,EAAiB9qB,IACnDolB,EAAGxb,KAAKihB,EAAOC,EAAO1oB,MAAOpC,EAAGtB,MAChCosB,EAASA,EAAO3qB,MAIpB8pB,GAAQvgB,UAAUqhB,eAAiB,SAAU3F,EAAIyF,GAC/CA,EAAQA,GAASnsB,SACZ,IAAIosB,EAASpsB,KAAKwrB,KAAMlqB,EAAItB,KAAKuB,OAAS,EAAc,OAAX6qB,EAAiB9qB,IACjEolB,EAAGxb,KAAKihB,EAAOC,EAAO1oB,MAAOpC,EAAGtB,MAChCosB,EAASA,EAAOL,MAIpBR,GAAQvgB,UAAU7K,IAAM,SAAUmsB,OAC3B,IAAIhrB,EAAI,EAAG8qB,EAASpsB,KAAKyrB,KAAiB,OAAXW,GAAmB9qB,EAAIgrB,EAAGhrB,IAE5D8qB,EAASA,EAAO3qB,QAEdH,IAAMgrB,GAAgB,OAAXF,SACNA,EAAO1oB,OAIlB6nB,GAAQvgB,UAAUuhB,WAAa,SAAUD,OAClC,IAAIhrB,EAAI,EAAG8qB,EAASpsB,KAAKwrB,KAAiB,OAAXY,GAAmB9qB,EAAIgrB,EAAGhrB,IAE5D8qB,EAASA,EAAOL,QAEdzqB,IAAMgrB,GAAgB,OAAXF,SACNA,EAAO1oB,OAIlB6nB,GAAQvgB,UAAU4J,IAAM,SAAU8R,EAAIyF,GACpCA,EAAQA,GAASnsB,aACboqB,EAAM,IAAImB,GACLa,EAASpsB,KAAKyrB,KAAiB,OAAXW,GAC3BhC,EAAI3lB,KAAKiiB,EAAGxb,KAAKihB,EAAOC,EAAO1oB,MAAO1D,OACtCosB,EAASA,EAAO3qB,YAEX2oB,GAGTmB,GAAQvgB,UAAUwhB,WAAa,SAAU9F,EAAIyF,GAC3CA,EAAQA,GAASnsB,aACboqB,EAAM,IAAImB,GACLa,EAASpsB,KAAKwrB,KAAiB,OAAXY,GAC3BhC,EAAI3lB,KAAKiiB,EAAGxb,KAAKihB,EAAOC,EAAO1oB,MAAO1D,OACtCosB,EAASA,EAAOL,YAEX3B,GAGTmB,GAAQvgB,UAAUmQ,OAAS,SAAUuL,EAAI+F,OACnCC,EACAN,EAASpsB,KAAKyrB,QACdxa,UAAU1P,OAAS,EACrBmrB,EAAMD,MACD,CAAA,IAAIzsB,KAAKyrB,WAIR,IAAIjY,UAAU,8CAHpB4Y,EAASpsB,KAAKyrB,KAAKhqB,KACnBirB,EAAM1sB,KAAKyrB,KAAK/nB,UAKb,IAAIpC,EAAI,EAAc,OAAX8qB,EAAiB9qB,IAC/BorB,EAAMhG,EAAGgG,EAAKN,EAAO1oB,MAAOpC,GAC5B8qB,EAASA,EAAO3qB,YAGXirB,GAGTnB,GAAQvgB,UAAU2hB,cAAgB,SAAUjG,EAAI+F,OAC1CC,EACAN,EAASpsB,KAAKwrB,QACdva,UAAU1P,OAAS,EACrBmrB,EAAMD,MACD,CAAA,IAAIzsB,KAAKwrB,WAIR,IAAIhY,UAAU,8CAHpB4Y,EAASpsB,KAAKwrB,KAAKO,KACnBW,EAAM1sB,KAAKwrB,KAAK9nB,UAKb,IAAIpC,EAAItB,KAAKuB,OAAS,EAAc,OAAX6qB,EAAiB9qB,IAC7CorB,EAAMhG,EAAGgG,EAAKN,EAAO1oB,MAAOpC,GAC5B8qB,EAASA,EAAOL,YAGXW,GAGTnB,GAAQvgB,UAAU4hB,QAAU,mBACtBC,EAAM,IAAInoB,MAAM1E,KAAKuB,QAChBD,EAAI,EAAG8qB,EAASpsB,KAAKyrB,KAAiB,OAAXW,EAAiB9qB,IACnDurB,EAAIvrB,GAAK8qB,EAAO1oB,MAChB0oB,EAASA,EAAO3qB,YAEXorB,GAGTtB,GAAQvgB,UAAU8hB,eAAiB,mBAC7BD,EAAM,IAAInoB,MAAM1E,KAAKuB,QAChBD,EAAI,EAAG8qB,EAASpsB,KAAKwrB,KAAiB,OAAXY,EAAiB9qB,IACnDurB,EAAIvrB,GAAK8qB,EAAO1oB,MAChB0oB,EAASA,EAAOL,YAEXc,GAGTtB,GAAQvgB,UAAUrJ,MAAQ,SAAUyS,EAAM2Y,IACxCA,EAAKA,GAAM/sB,KAAKuB,QACP,IACPwrB,GAAM/sB,KAAKuB,SAEb6S,EAAOA,GAAQ,GACJ,IACTA,GAAQpU,KAAKuB,YAEXyrB,EAAM,IAAIzB,MACVwB,EAAK3Y,GAAQ2Y,EAAK,SACbC,EAEL5Y,EAAO,IACTA,EAAO,GAEL2Y,EAAK/sB,KAAKuB,SACZwrB,EAAK/sB,KAAKuB,YAEP,IAAID,EAAI,EAAG8qB,EAASpsB,KAAKyrB,KAAiB,OAAXW,GAAmB9qB,EAAI8S,EAAM9S,IAC/D8qB,EAASA,EAAO3qB,UAEA,OAAX2qB,GAAmB9qB,EAAIyrB,EAAIzrB,IAAK8qB,EAASA,EAAO3qB,KACrDurB,EAAIvoB,KAAK2nB,EAAO1oB,cAEXspB,GAGTzB,GAAQvgB,UAAUiiB,aAAe,SAAU7Y,EAAM2Y,IAC/CA,EAAKA,GAAM/sB,KAAKuB,QACP,IACPwrB,GAAM/sB,KAAKuB,SAEb6S,EAAOA,GAAQ,GACJ,IACTA,GAAQpU,KAAKuB,YAEXyrB,EAAM,IAAIzB,MACVwB,EAAK3Y,GAAQ2Y,EAAK,SACbC,EAEL5Y,EAAO,IACTA,EAAO,GAEL2Y,EAAK/sB,KAAKuB,SACZwrB,EAAK/sB,KAAKuB,YAEP,IAAID,EAAItB,KAAKuB,OAAQ6qB,EAASpsB,KAAKwrB,KAAiB,OAAXY,GAAmB9qB,EAAIyrB,EAAIzrB,IACvE8qB,EAASA,EAAOL,UAEA,OAAXK,GAAmB9qB,EAAI8S,EAAM9S,IAAK8qB,EAASA,EAAOL,KACvDiB,EAAIvoB,KAAK2nB,EAAO1oB,cAEXspB,GAGTzB,GAAQvgB,UAAUkiB,OAAS,SAAU1X,EAAO2X,KAAgBC,GACtD5X,EAAQxV,KAAKuB,SACfiU,EAAQxV,KAAKuB,OAAS,GAEpBiU,EAAQ,IACVA,EAAQxV,KAAKuB,OAASiU,OAGnB,IAAIlU,EAAI,EAAG8qB,EAASpsB,KAAKyrB,KAAiB,OAAXW,GAAmB9qB,EAAIkU,EAAOlU,IAChE8qB,EAASA,EAAO3qB,SAGdurB,EAAM,OACD1rB,EAAI,EAAG8qB,GAAU9qB,EAAI6rB,EAAa7rB,IACzC0rB,EAAIvoB,KAAK2nB,EAAO1oB,OAChB0oB,EAASpsB,KAAKgsB,WAAWI,GAEZ,OAAXA,IACFA,EAASpsB,KAAKwrB,MAGZY,IAAWpsB,KAAKyrB,MAAQW,IAAWpsB,KAAKwrB,OAC1CY,EAASA,EAAOL,UAGTzqB,EAAI,EAAGA,EAAI8rB,EAAM7rB,OAAQD,IAChC8qB,EAASR,GAAO5rB,KAAMosB,EAAQgB,EAAM9rB,WAE/B0rB,GAGTzB,GAAQvgB,UAAUqiB,QAAU,mBACtB5B,EAAOzrB,KAAKyrB,KACZD,EAAOxrB,KAAKwrB,KACPY,EAASX,EAAiB,OAAXW,EAAiBA,EAASA,EAAOL,KAAM,KACzD/mB,EAAIonB,EAAOL,KACfK,EAAOL,KAAOK,EAAO3qB,KACrB2qB,EAAO3qB,KAAOuD,cAEXymB,KAAOD,OACPA,KAAOC,EACLzrB,MA2DT,KDraiB,SAAUurB,GACzBA,EAAQvgB,UAAUiL,OAAO4E,UAAY,gBAC9B,IAAIuR,EAASpsB,KAAKyrB,KAAMW,EAAQA,EAASA,EAAO3qB,WAC7C2qB,EAAO1oB,OCoajBoG,CAAyByhB,IACzB,MAAO+B,ICpaT,MAAMC,GAAMtX,OAAO,OACbuX,GAASvX,OAAO,UAChBwX,GAAoBxX,OAAO,oBAC3ByX,GAAczX,OAAO,cACrB0X,GAAU1X,OAAO,UACjB2X,GAAU3X,OAAO,WACjB4X,GAAoB5X,OAAO,kBAC3B6X,GAAW7X,OAAO,WAClB8X,GAAQ9X,OAAO,SACf+X,GAAoB/X,OAAO,kBAE3BgY,GAAc,IAAM,EAkP1B,MAAM9tB,GAAM,CAAC2Q,EAAMpH,EAAKwkB,WAChB/C,EAAOra,EAAKid,IAAO5tB,IAAIuJ,MACzByhB,EAAM,OACFgD,EAAMhD,EAAKznB,SACb0qB,GAAQtd,EAAMqd,OAChBE,GAAIvd,EAAMqa,IACLra,EAAK4c,IACR,YAEEQ,IACEpd,EAAKkd,MACP7C,EAAKznB,MAAM0d,IAAMD,KAAKC,OACxBtQ,EAAKgd,IAAU7B,YAAYd,WAGxBgD,EAAIzqB,QAIT0qB,GAAU,CAACtd,EAAMqd,SAChBA,IAASA,EAAIG,SAAWxd,EAAK6c,IAChC,OAAO,QAEHY,EAAOpN,KAAKC,MAAQ+M,EAAI/M,WACvB+M,EAAIG,OAASC,EAAOJ,EAAIG,OAC3Bxd,EAAK6c,KAAaY,EAAOzd,EAAK6c,KAG9Ba,GAAO1d,OACPA,EAAK0c,IAAU1c,EAAKyc,QACjB,IAAInB,EAAStb,EAAKgd,IAAUtC,KAC/B1a,EAAK0c,IAAU1c,EAAKyc,KAAmB,OAAXnB,GAAkB,OAIxCL,EAAOK,EAAOL,KACpBsC,GAAIvd,EAAMsb,GACVA,EAASL,IAKTsC,GAAM,CAACvd,EAAMqa,QACbA,EAAM,OACFgD,EAAMhD,EAAKznB,MACboN,EAAK8c,KACP9c,EAAK8c,IAASO,EAAIzkB,IAAKykB,EAAIzqB,OAE7BoN,EAAK0c,KAAWW,EAAI5sB,OACpBuP,EAAKid,IAAO/W,OAAOmX,EAAIzkB,KACvBoH,EAAKgd,IAAU9B,WAAWb,KAI9B,MAAMsD,GACJhvB,YAAaiK,EAAKhG,EAAOnC,EAAQ6f,EAAKkN,QAC/B5kB,IAAMA,OACNhG,MAAQA,OACRnC,OAASA,OACT6f,IAAMA,OACNkN,OAASA,GAAU,GAI5B,MAAMI,GAAc,CAAC5d,EAAM4V,EAAIyE,EAAMgB,SAC/BgC,EAAMhD,EAAKznB,MACX0qB,GAAQtd,EAAMqd,KAChBE,GAAIvd,EAAMqa,GACLra,EAAK4c,MACRS,OAAM3qB,IAEN2qB,GACFzH,EAAGxb,KAAKihB,EAAOgC,EAAIzqB,MAAOyqB,EAAIzkB,IAAKoH,IAGvCvR,OAnTA,MACEE,YAAa2K,MACY,iBAAZA,IACTA,EAAU,CAAEuL,IAAKvL,IAEdA,IACHA,EAAU,IAERA,EAAQuL,MAA+B,iBAAhBvL,EAAQuL,KAAoBvL,EAAQuL,IAAM,GACnE,MAAM,IAAInC,UAAU,qCAEVxT,KAAKutB,IAAOnjB,EAAQuL,KAAOgZ,EAAAA,QAEjCC,EAAKxkB,EAAQ7I,QAAU0sB,WACxBR,IAAoC,mBAAPmB,EAAqBX,GAAcW,OAChElB,IAAetjB,EAAQykB,QAAS,EACjCzkB,EAAQkkB,QAAoC,iBAAnBlkB,EAAQkkB,OACnC,MAAM,IAAI9a,UAAU,gCACjBma,IAAWvjB,EAAQkkB,QAAU,OAC7BV,IAAWxjB,EAAQ0kB,aACnBjB,IAAqBzjB,EAAQ2kB,iBAAkB,OAC/Cf,IAAqB5jB,EAAQ4kB,iBAAkB,OAC/CC,gBAIEC,MACW,iBAAPA,GAAmBA,EAAK,EACjC,MAAM,IAAI1b,UAAU,0CAEjB+Z,IAAO2B,GAAMP,EAAAA,EAClBH,GAAKxuB,uBAGEA,KAAKutB,mBAGE4B,QACTzB,MAAiByB,0BAGfnvB,KAAK0tB,eAGF0B,MACQ,iBAAPA,EACT,MAAM,IAAI5b,UAAU,6CAEjBma,IAAWyB,EAChBZ,GAAKxuB,0BAGEA,KAAK2tB,yBAIQ0B,GACF,mBAAPA,IACTA,EAAKpB,IAEHoB,IAAOrvB,KAAKytB,WACTA,IAAqB4B,OACrB7B,IAAU,OACVM,IAAUpoB,QAAQyoB,IACrBA,EAAI5sB,OAASvB,KAAKytB,IAAmBU,EAAIzqB,MAAOyqB,EAAIzkB,UAC/C8jB,KAAWW,EAAI5sB,UAGxBitB,GAAKxuB,oCAE0BA,KAAKytB,wBAEfztB,KAAKwtB,2BACFxtB,KAAK8tB,IAAUvsB,OAEzC+tB,SAAU5I,EAAIyF,GACZA,EAAQA,GAASnsB,SACZ,IAAIosB,EAASpsB,KAAK8tB,IAAUtC,KAAiB,OAAXY,GAAkB,OACjDL,EAAOK,EAAOL,KACpB2C,GAAY1uB,KAAM0mB,EAAI0F,EAAQD,GAC9BC,EAASL,GAIbrmB,QAASghB,EAAIyF,GACXA,EAAQA,GAASnsB,SACZ,IAAIosB,EAASpsB,KAAK8tB,IAAUrC,KAAiB,OAAXW,GAAkB,OACjD3qB,EAAO2qB,EAAO3qB,KACpBitB,GAAY1uB,KAAM0mB,EAAI0F,EAAQD,GAC9BC,EAAS3qB,GAIbhB,cACST,KAAK8tB,IAAUlB,UAAUhY,IAAIhT,GAAKA,EAAE8H,KAG7C2F,gBACSrP,KAAK8tB,IAAUlB,UAAUhY,IAAIhT,GAAKA,EAAE8B,OAG7CurB,QACMjvB,KAAK4tB,KACL5tB,KAAK8tB,KACL9tB,KAAK8tB,IAAUvsB,aACZusB,IAAUpoB,QAAQyoB,GAAOnuB,KAAK4tB,IAASO,EAAIzkB,IAAKykB,EAAIzqB,aAGtDqqB,IAAS,IAAInuB,SACbkuB,IAAY,IAAIvC,QAChBiC,IAAU,EAGjB+B,cACSvvB,KAAK8tB,IAAUlZ,IAAIuZ,IACxBC,GAAQpuB,KAAMmuB,IAAe,CAC3BvsB,EAAGusB,EAAIzkB,IACPoB,EAAGqjB,EAAIzqB,MACPqG,EAAGokB,EAAI/M,KAAO+M,EAAIG,QAAU,KAC3B1B,UAAUtgB,OAAOc,GAAKA,GAG7BoiB,iBACSxvB,KAAK8tB,IAGdztB,IAAKqJ,EAAKhG,EAAO4qB,OACfA,EAASA,GAAUtuB,KAAK2tB,MAEQ,iBAAXW,EACnB,MAAM,IAAI9a,UAAU,iCAEhB4N,EAAMkN,EAASnN,KAAKC,MAAQ,EAC5BqO,EAAMzvB,KAAKytB,IAAmB/pB,EAAOgG,MAEvC1J,KAAK+tB,IAAOxtB,IAAImJ,GAAM,IACpB+lB,EAAMzvB,KAAKutB,WACbc,GAAIruB,KAAMA,KAAK+tB,IAAO5tB,IAAIuJ,KACnB,QAIHgiB,EADO1rB,KAAK+tB,IAAO5tB,IAAIuJ,GACXhG,aAId1D,KAAK4tB,MACF5tB,KAAK6tB,KACR7tB,KAAK4tB,IAASlkB,EAAKgiB,EAAKhoB,QAG5BgoB,EAAKtK,IAAMA,EACXsK,EAAK4C,OAASA,EACd5C,EAAKhoB,MAAQA,OACR8pB,KAAWiC,EAAM/D,EAAKnqB,OAC3BmqB,EAAKnqB,OAASkuB,OACTtvB,IAAIuJ,GACT8kB,GAAKxuB,OACE,QAGHmuB,EAAM,IAAIM,GAAM/kB,EAAKhG,EAAO+rB,EAAKrO,EAAKkN,UAGxCH,EAAI5sB,OAASvB,KAAKutB,KAChBvtB,KAAK4tB,KACP5tB,KAAK4tB,IAASlkB,EAAKhG,IAEd,SAGJ8pB,KAAWW,EAAI5sB,YACfusB,IAAU7e,QAAQkf,QAClBJ,IAAO1tB,IAAIqJ,EAAK1J,KAAK8tB,IAAUrC,MACpC+C,GAAKxuB,OACE,GAGTO,IAAKmJ,OACE1J,KAAK+tB,IAAOxtB,IAAImJ,GAAM,OAAO,QAC5BykB,EAAMnuB,KAAK+tB,IAAO5tB,IAAIuJ,GAAKhG,aACzB0qB,GAAQpuB,KAAMmuB,GAGxBhuB,IAAKuJ,UACIvJ,GAAIH,KAAM0J,GAAK,GAGxBgmB,KAAMhmB,UACGvJ,GAAIH,KAAM0J,GAAK,GAGxByJ,YACQgY,EAAOnrB,KAAK8tB,IAAUtC,YACvBL,GAGLkD,GAAIruB,KAAMmrB,GACHA,EAAKznB,OAHH,KAMX2qB,IAAK3kB,GACH2kB,GAAIruB,KAAMA,KAAK+tB,IAAO5tB,IAAIuJ,IAG5BimB,KAAM9C,QAECoC,cAEC7N,EAAMD,KAAKC,UAEZ,IAAIuK,EAAIkB,EAAItrB,OAAS,EAAGoqB,GAAK,EAAGA,IAAK,OAClCwC,EAAMtB,EAAIlB,GACViE,EAAYzB,EAAIpkB,GAAK,KACT,IAAd6lB,OAEGvvB,IAAI8tB,EAAIvsB,EAAGusB,EAAIrjB,OACjB,OACGwjB,EAASsB,EAAYxO,EAEvBkN,EAAS,QACNjuB,IAAI8tB,EAAIvsB,EAAGusB,EAAIrjB,EAAGwjB,KAM/BuB,aACO9B,IAAOroB,QAAQ,CAAChC,EAAOgG,IAAQvJ,GAAIH,KAAM0J,GAAK,MCrPvDnK,OAAiB,MAMfE,aAAYirB,SAACA,SACNA,SAAWA,OAGXoF,MAAQ,IAAIC,GAAI,CAACpa,IAZE,KAe1Bqa,aAAaC,UACJjwB,KAAK8vB,MAAM3vB,IAAI8vB,GAGxBC,aAAaD,EAAWE,QACjBL,MAAMzvB,IAAI4vB,EAAWE,KCtB9B,MACExrB,QAASyrB,GACT3kB,SAAU4kB,GACVvkB,SAAUwkB,IACRxmB,GAEFkD,QAASujB,IACPzmB,gBACGqI,IAAerI,GAMtBvK,OAAiB,MAMfE,aAAY+wB,YAACA,SACNC,WAAa,IAAI7wB,SACjB4wB,YAAcA,iBAGPP,UACZA,EADYS,QACDA,EADCC,eACQA,EADRve,KACwBA,EADxBwe,OAC8BA,EAAS,IAAI1nB,MAGpDwnB,GAAWL,GAAUK,IAAYA,EAAQ,cAC1CA,EAAUA,EAAQ,aAIpBA,EAAUH,GAASG,SAGbG,EAAc,OAChB,MAAMC,KAAOJ,EAAS,IACrBJ,GAAUQ,GAAM,KAEbC,EAAW/wB,KAAKgxB,KAAKF,GACrBC,IAEFA,QAAiB/wB,KAAKixB,sBACpB,CAAChB,UAAAA,EAAW/e,IAAK4f,EAAKH,eAAAA,EAAgBve,KAAAA,EAAMwe,OAAAA,KAI7CR,GAASW,GACVF,EAAYpsB,QAAQssB,GAEpBF,EAAYpsB,KAAKssB,eAIV,OAARD,EAAc,CAEfD,EAAYpsB,KAAK,IAAIysB,GAAgB,CAACxG,SAAU,iBAG9C2F,GAAUS,IACZK,GAA0BT,SAGtBhnB,EAAMgP,KAAK+N,UAAUqK,OACvBC,EAAW/wB,KAAKgxB,KAAKtnB,GACrBqnB,IAEFA,EAAW,IAAIG,GAAgB,CAACxG,SAAUoG,SACrCM,sBAAsB,CAAC1nB,IAAAA,EAAKqnB,SAAAA,EAAUM,IAAK,YAElDR,EAAYpsB,KAAKssB,UAGZF,EAGTG,KAAKtnB,OAGCqnB,EAAW/wB,KAAKywB,WAAWtwB,IAAIuJ,OAC/BqnB,EAAU,OAENO,EAAStxB,KAAKwwB,YAAYrwB,IAAIuJ,GACjC4nB,IACDP,EAAWO,EAAOnxB,IAAI,UACnB4wB,QACIN,WAAWpwB,IAAIqJ,EAAKqnB,WAIxBA,EAGTK,uBAAsB1nB,IAACA,EAADqnB,SAAMA,EAANM,IAAgBA,YAC/BZ,WAAWpwB,IAAIqJ,EAAKqnB,QACdvtB,IAAR6tB,EAAmB,KAChBC,EAAStxB,KAAKwwB,YAAYrwB,IAAIuJ,GAC9B4nB,IACFA,EAAS,IAAI1xB,SACR4wB,YAAYnwB,IAAIqJ,EAAK4nB,IAE5BA,EAAOjxB,IAAIgxB,EAAKN,UAEXA,+BAGmBd,UAACA,EAAD/e,IAAYA,EAAZyf,eAAiBA,EAAjBve,KAAiCA,EAAjCwe,OAAuCA,IAEjE1f,EAAMiB,GAAYC,EAAMlB,SAClBwf,QAACA,EAADa,UAAUA,SAAmBvxB,KAAKwxB,cACtC,CAACvB,UAAAA,EAAW/e,IAAAA,EAAKyf,eAAAA,EAAgBC,OAAAA,KA4GvC,SAASa,GAAoBf,QAACA,EAADte,KAAUA,QACjCse,eAIEI,EAAMJ,EAAQ,eAEjBJ,GAAUQ,eACXJ,EAAQ,YAAcve,GAAYC,EAAM0e,OAIvCV,GAASU,GAAM,KACZ,IAAIxvB,EAAI,EAAGA,EAAIwvB,EAAIvvB,SAAUD,EAAG,OAC5BQ,EAAUgvB,EAAIxvB,GACjBgvB,GAAUxuB,GACXgvB,EAAIxvB,GAAK6Q,GAAYC,EAAMtQ,GAG1BuuB,GAAUvuB,IACX2vB,EAAoB,CAACf,QAAS,YAAa5uB,GAAUsQ,KAAAA,eAMvDie,GAAUS,cAMV,MAAMY,KAAQZ,EAChBW,EAAoB,CAACf,QAASI,EAAIY,GAAOtf,KAAAA,KAzIzCqf,CAAoB,CAACf,QAAAA,EAASte,KAD9BA,EAAOmf,EAAU9G,aAAevZ,UAI1B6f,QAAiB/wB,KAAKqJ,QAC1B,CAAC4mB,UAAAA,EAAWS,QAAAA,EAASC,eAAAA,EAAgBve,KAAAA,EAAMwe,OAAAA,gBACxCQ,sBAAsB,CAAC1nB,IAAKwH,EAAK6f,SAAAA,EAAUM,IAAKE,EAAUF,MACxDN,uBAGWd,UAACA,EAAD/e,IAAYA,EAAZyf,eAAiBA,EAAjBC,OAAiCA,OAEhDA,EAAOlc,KAnHW,SAoHb,IAAItG,GACR,4CACA,yBACA,CACErK,KAAmC,gBAA7BksB,EAAU0B,eACd,gCACA,mBACFhc,IA3He,QAiIlBib,EAAOrwB,IAAI2Q,SACN,IAAI9C,GACR,mCACA,yBACA,CACErK,KAAmC,gBAA7BksB,EAAU0B,eACd,8BACA,mBACFzgB,IAAAA,QAOFwf,EACAa,EAHJX,EAAO3nB,IAAIiI,OAMTqgB,QAAkBZ,EAAezf,GACjCwf,EAAUa,EAAU7G,UAAY,KAE7B4F,GAAUI,KACXA,EAAUhY,KAAKlH,MAAMkf,IAEvB,MAAM3mB,SACA,IAAIqE,GACR,iUAMA,oBACA,CAACrK,KAAM,gCAAiCmN,IAAAA,EAAKqZ,MAAOxgB,QAIpDsmB,GAAUK,SACN,IAAItiB,GACR,kHAEA,oBAAqB,CAACrK,KAAM,yBAA0BmN,IAAAA,WAOxDwf,EAHG,aAAcA,EAGP,YAAaA,EAAQ,aAFrB,YAAa,IAMtBa,EAAU/G,aACP4F,GAASM,EAAQ,eACnBA,EAAQ,YAAc,CAACA,EAAQ,cAEjCA,EAAQ,YAAYjsB,KAAK8sB,EAAU/G,aAG9B,CAACkG,QAAAA,EAASa,UAAAA,KAIrB,SAASJ,GAA0BL,SAC3B,IAAI1iB,GACR,sDACA,qBAAsB,CACpBrK,KAAM,wBAAyB2sB,QAASI,IChN9CvxB,OAAiBuK,EAAwBtH,OCEzC,MACEmC,QAASyrB,GACT3kB,SAAU4kB,GACVvkB,SAAUwkB,GACVvkB,YAAa6lB,IACX9nB,GAGFwI,WAAYuf,GACZve,WAAYwe,GAFR3f,YAGJA,IACErI,IAGFkD,QAASujB,GACT5gB,qBAAsBoiB,IACpBjoB,GAEEkoB,GAAwB,IAAIpyB,IAE5BqyB,GAAkB,eAElBjoB,GAAM,GACZzK,OAAiByK,GAm7BjB,SAASkoB,GAAWjC,EAAWvsB,EAAOyuB,EAAYC,EAAUC,EAASjoB,MAEtD,OAAV1G,IAAmB4sB,GAAU5sB,IAAUsG,GAAIsoB,UAAU5uB,UAC/CA,KAINA,EAAMR,MAAM+uB,WACN,QAING,GAAYA,EAASrkB,eAAerK,KACd,IAAvB2uB,EAAQlyB,IAAIuD,IACZsG,GAAIuoB,qBAAqB,CACvBtC,UAAAA,EAAWmC,SAAAA,EAAUV,KAAMhuB,EAAO2uB,QAAAA,EAASjoB,QAAAA,KAI/C+nB,EAAaA,GAAc,IACbK,MAAO,OACbC,EAAUxC,EAAUyC,SAASvyB,IAAIuD,MAGxB,OAAZ+uB,SACM,QAGNpC,GAAUoC,IAAY,QAASA,SAEzBA,EAAQ,aAKbE,EAAQjvB,EAAM2H,QAAQ,QACzBsnB,EAAQ,EAAG,OACNjzB,EAASgE,EAAMgP,OAAO,EAAGigB,GACzBC,EAASlvB,EAAMgP,OAAOigB,EAAQ,MAItB,MAAXjzB,GAA2C,IAAzBkzB,EAAOvnB,QAAQ,aAC3B3H,EAIN0uB,GAAYA,EAASrkB,eAAerO,IACrCsK,GAAIuoB,qBAAqB,CACvBtC,UAAAA,EAAWmC,SAAAA,EAAUV,KAAMhyB,EAAQ2yB,QAAAA,EAASjoB,QAAAA,UAK1CqoB,EAAUxC,EAAUyC,SAASvyB,IAAIT,MACpC+yB,GAAWA,EAAQI,eACbJ,EAAQ,OAASG,KAIvBf,GAAenuB,UACTA,KAKRyuB,EAAWK,OAAS,WAAYvC,SAC1BA,EAAU,UAAYvsB,KAI5ByuB,EAAW/f,MAAQ,UAAW6d,MAC5BA,EAAU,gBAEJ9d,GAAYA,GAAY/H,EAAQgI,KAAM6d,EAAU,UAAWvsB,QAE/D,GAAGyuB,EAAW/f,YACZD,GAAY/H,EAAQgI,KAAM1O,UAG5BA,EAr/BTsG,GAAI+U,QAAU5U,OACZ8lB,UAAAA,EAAWmC,SAAAA,EAAUhoB,QAAAA,EACrB0oB,UAAAA,GAAY,EACZC,kBAAAA,GAAoB,EACpBnC,OAAAA,EAAS,IAAI1nB,QAGVmnB,GAAU+B,IAAa,aAAcA,GACtChC,GAASgC,EAAS,eAClBA,EAAWA,EAAS,gBAKH,IAHN7B,GAAS6B,GAGd7wB,cACC0uB,QAIHc,QAAiB3mB,EAAQ4oB,gBAAgB3pB,QAAQ,CACrD4mB,UAAAA,EACAS,QAAS0B,EACTzB,eAAgBvmB,EAAQumB,eACxBve,KAAMhI,EAAQgI,OAIbie,GAAUU,EAAS,GAAGrG,WACuB,kBAAvCqG,EAAS,GAAGrG,SAAS,gBAE5BoI,EAAY/B,EAAS,GAAGrG,SAAS,mBAK/BhpB,EAAOuuB,EAIP6C,GAAcpxB,EAAKuxB,kBAErBvxB,EAAOA,EAAK3B,QACZ2B,EAAKuxB,gBAAkBhD,OAGrB,MAAMiD,KAAmBnC,EAAU,KAChCrG,SAAUoG,GAAOoC,KAGtBjD,EAAYvuB,EAGD,OAARovB,EAAc,KAGXiC,GAC0C,IAA5ChoB,OAAOtK,KAAKwvB,EAAUkD,WAAW5xB,OAAc,OACzC6xB,EAAiBhpB,GAAWA,EAAQgpB,eAAkB,WACvC,UAAlBA,QACK,IAAIhlB,GACR,gFAEA,qBACA,CAACrK,KAAM,kCACJ,GAAqB,SAAlBqvB,EAA0B,CAElC/S,QAAQgT,KAAK,gDAGPC,EAAYJ,EAAgBlD,aAAaC,MAC5CqD,EAAW,CACZ5xB,EAAOuuB,EAAYqD,iBAIfC,EAAetD,EAErBvuB,EAAOuuB,EAAYjmB,GAAIwpB,kBAAkBppB,GAASrK,YAC9C,MAAO2xB,EAAM+B,KACf1oB,OAAO3B,QAAQmqB,EAAaJ,WACzBM,IACDxD,EAAUyC,SAAShB,GACjBgC,GAAK3zB,MAAMwzB,EAAab,SAAShB,KAGvCzB,EAAUkD,UAAYO,GAAK3zB,MAAMwzB,EAAaJ,WAG9CD,EAAgBhD,aAAaqD,EAAc7xB,kBAGvC,IAAI0M,GACR,yBACA,qBACA,CAACrK,KAAM,yBAA0B2sB,QAAS0B,EAAUgB,cAAAA,IAExD1xB,EAAOuuB,EAAYjmB,GAAIwpB,kBAAkBppB,GAASrK,uBAK9CuzB,EAAYJ,EAAgBlD,aAAaC,MAC5CqD,EAAW,CACZ5xB,EAAOuuB,EAAYqD,cAKlBjD,GAAUS,IAAQ,aAAcA,IACjCA,EAAMA,EAAI,cAIRT,GAAUS,SACN,IAAI1iB,GACR,sDACA,qBAAsB,CAACrK,KAAM,wBAAyB2sB,QAASI,IAOnEpvB,EAAOA,EAAK3B,cAGNsyB,EAAU,IAAIzyB,OAGjB,aAAckxB,EAAK,IACG,MAApBA,EAAI,kBACC,IAAI1iB,GACR,gCAAkC0iB,EAAI,YACtC,4BACA,CAAC/sB,KAAM,yBAA0B2sB,QAASI,OAE3Cb,EAAU0B,gBACkB,gBAA7B1B,EAAU0B,qBACJ,IAAIvjB,GACR,aAAe0iB,EAAI,YAAc,wBACjCb,EAAU0B,eACV,gCACA,CAAC5tB,KAAM,2BAA4B2sB,QAASI,IAEhDpvB,EAAKiwB,eAAiB,cACtBjwB,EAAK,YAAcovB,EAAI,YACvBuB,EAAQhyB,IAAI,YAAY,MAI1BqB,EAAKiwB,eACHjwB,EAAKiwB,gBAAkB1B,EAAU0B,eAGhC,UAAWb,EAAK,KACb1e,EAAO0e,EAAI,YAEH,OAAT1e,GAAiByf,GAAezf,QAE5B,CAAA,IAAG0f,GAAe1f,SAGjB,IAAIhE,GACR,+GAEA,qBAAsB,CAACrK,KAAM,mBAAoB2sB,QAASI,IAL5D1e,EAAOD,GAAYzQ,EAAK,SAAU0Q,GAQpC1Q,EAAK,SAAW0Q,EAChBigB,EAAQhyB,IAAI,SAAS,MAIpB,WAAYywB,EAAK,OACZptB,EAAQotB,EAAI,aACL,OAAVptB,SACMhC,EAAK,cACP,CAAA,IAAI4uB,GAAU5sB,SACb,IAAI0K,GACR,wFAEA,qBAAsB,CAACrK,KAAM,wBAAyB2sB,QAASI,IAC5D,IAAIe,GAAenuB,IAAUsG,GAAI2nB,eAAejwB,EAAM,SACrD,IAAI0M,GACR,uFAEA,qBAAsB,CAACrK,KAAM,wBAAyB2sB,QAASI,IAEjEpvB,EAAK,UAAYwwB,GAAWxwB,EAAMgC,EAAO,CAAC8uB,OAAO,EAAMpgB,MAAM,QAC3D5O,OAAWA,EAAW4G,GAE1BioB,EAAQhyB,IAAI,UAAU,MAIrB,cAAeywB,EAAK,OACfptB,EAAQotB,EAAI,gBACL,OAAVptB,SACMhC,EAAK,iBACP,CAAA,IAAI4uB,GAAU5sB,SACb,IAAI0K,GACR,2FAEA,qBACA,CAACrK,KAAM,2BAA4B2sB,QAASI,IAE9CpvB,EAAK,aAAegC,EAAM2J,cAE5BglB,EAAQhyB,IAAI,aAAa,MAIxB,eAAgBywB,EAAK,OAChBptB,EAAQotB,EAAI,iBACc,gBAA7Bb,EAAU0B,qBACL,IAAIvjB,GACR,0DACA6hB,EAAU0B,eACV,qBACA,CAAC5tB,KAAM,yBAA0B2sB,QAASI,OAEjC,OAAVptB,SACMhC,EAAK,kBACP,CAAA,GAAa,QAAVgC,GAA6B,QAAVA,QACrB,IAAI0K,GACR,iGAEA,qBACA,CAACrK,KAAM,yBAA0B2sB,QAASI,IAE5CpvB,EAAK,cAAgBgC,EAEvB2uB,EAAQhyB,IAAI,cAAc,MAKzB,eAAgBywB,EAAK,OAChBptB,EAAQotB,EAAI,iBACc,gBAA7Bb,EAAU0B,qBACL,IAAIvjB,GACR,0DACA6hB,EAAU0B,eACV,qBACA,CAAC5tB,KAAM,wBAAyB2sB,QAASI,OAEzB,kBAAVptB,QACF,IAAI0K,GACR,8DACA,qBACA,CAACrK,KAAM,2BAA4B2sB,QAAS0B,IAEhDC,EAAQhyB,IAAI,cAAc,MAIzB,YAAaywB,EAAK,OACbptB,EAAQotB,EAAI,cACc,gBAA7Bb,EAAU0B,qBACL,IAAIvjB,GACR,uDACA6hB,EAAU0B,eACV,qBACA,CAAC5tB,KAAM,wBAAyB2sB,QAASI,QAEzCR,GAAU5sB,SACN,IAAI0K,GACR,oDACA,qBACA,CAACrK,KAAM,wBAAyB2sB,QAAS0B,UAIvCuB,QAAuBvpB,EAAQ4oB,gBAAgB3pB,QAAQ,CAC3D4mB,UAAAA,EACAS,QAAShtB,EACTitB,eAAgBvmB,EAAQumB,eACxBve,KAAMhI,EAAQgI,UAEa,IAA1BuhB,EAAepyB,aACV,IAAI6M,GACR,mEACA,qBACA,CAACrK,KAAM,yBAA0B2sB,QAAS0B,UAExCwB,EAAkBD,EAAe,GAAG3D,aAAaC,MACpD2D,EAID9C,EAAM8C,MACD,OACCC,EAAYF,EAAe,GAAGjJ,YACjC,YAAamJ,QACR,IAAIzlB,GACR,qEAEA,qBACA,CAACrK,KAAM,wBAAyB2sB,QAAS0B,QAIzC,MAAM1oB,KAAOmqB,EACX/C,EAAI/iB,eAAerE,KACrBonB,EAAIpnB,GAAOmqB,EAAUnqB,IAQzBiqB,EAAe,GAAGzD,aAAaD,EAAWa,GAG5CuB,EAAQhyB,IAAI,WAAW,GAMzBgyB,EAAQhyB,IAAI,aAAcywB,EAAI,gBAAiB,OAG3C,MAAMpnB,KAAOonB,KACf9mB,GAAIuoB,qBAAqB,CACvBtC,UAAWvuB,EACX0wB,SAAUtB,EACVY,KAAMhoB,EACN2oB,QAAAA,EACAjoB,QAAAA,EACA2oB,kBAAAA,IAGC1C,GAAUS,EAAIpnB,KAAS,aAAconB,EAAIpnB,GAAM,OAC1CoqB,EAAShD,EAAIpnB,GAAK,gBACpBqV,GAAU,KACXuR,GAAUwD,GAAS,OACd5iB,EAAMiB,GAAY/H,EAAQgI,KAAM0hB,GAEnClD,EAAOrwB,IAAI2Q,GACZ6N,GAAU,EAEV6R,EAAO3nB,IAAIiI,MAIZ6N,YAEO/U,GAAI+U,QAAQ,CAChBkR,UAAWvuB,EAAK3B,QAChBqyB,SAAUtB,EAAIpnB,GAAK,YACnBqpB,mBAAmB,EACnB3oB,QAAAA,EACAwmB,OAAAA,IAEF,MAAM7mB,SACA,IAAIqE,GACR,kDACA,qBACA,CACErK,KAAM,yBACN2sB,QAASI,EAAIpnB,GAAK,YAClBgoB,KAAMhoB,KAQlBwpB,EAAgBhD,aAAaD,EAAWvuB,UAGnCA,GAiBTsI,GAAIuoB,qBAAuB,EACzBtC,UAAAA,EACAmC,SAAAA,EACAV,KAAAA,EACAW,QAAAA,EACAjoB,QAAAA,EACA2oB,kBAAAA,GAAoB,SAEjBV,EAAQ9xB,IAAImxB,GAAO,IAEjBW,EAAQlyB,IAAIuxB,gBAIT,IAAItjB,GACR,wCACA,yBACA,CAACrK,KAAM,qBAAsB2sB,QAAS0B,EAAUV,KAAAA,QAOhDhuB,KAHJ2uB,EAAQhyB,IAAIqxB,GAAM,GAIfU,EAASrkB,eAAe2jB,KACzBhuB,EAAQ0uB,EAASV,IAGP,UAATA,GACArB,GAAU3sB,IAC0B,UAAnCA,EAAM,eAAiB,SACxBsG,GAAI2nB,eAAe1B,EAAW,KAAM,OAE/B8D,EAAY,CAAC,aAAc,MAAO,cAClCtzB,EAAOsK,OAAOtK,KAAKiD,MACN,IAAhBjD,EAAKc,QAAgBd,EAAK0M,KAAKvL,IAAMmyB,EAAU7O,SAAStjB,UACnD,IAAIwM,GACR,yDACA,qBACA,CAACrK,KAAM,uBAAwB2sB,QAAS0B,EAAUV,KAAAA,QAEjD,CAAA,GAAG1nB,GAAIsoB,UAAUZ,SAChB,IAAItjB,GACR,yDACA,qBACA,CAACrK,KAAM,uBAAwB2sB,QAAS0B,EAAUV,KAAAA,IAC/C,GAAGA,EAAKxuB,MAAM+uB,gBAEnB5R,QAAQgT,KAAK,4EACoB,CAAC3B,KAAAA,IAE7B,GAAY,KAATA,QACF,IAAItjB,GACR,4DACA,qBACA,CAACrK,KAAM,0BAA2B2sB,QAAS0B,UAIzC4B,EAAkB/D,EAAUyC,SAASvyB,IAAIuxB,GAG5CzB,EAAUyC,SAASnyB,IAAImxB,IACxBzB,EAAUyC,SAAS1b,OAAO0a,OAIxBuC,GAAa,MACd3D,GAAU5sB,IAAoB,OAAVA,KACrBuwB,GAAa,EACbvwB,EAAQ,OAAQA,KAGd2sB,GAAU3sB,SACN,IAAI0K,GACR,2EAEA,qBACA,CAACrK,KAAM,0BAA2B2sB,QAAS0B,UAIzCK,EAAU,GAChBxC,EAAUyC,SAASryB,IAAIqxB,EAAMe,GAC7BA,EAAQpF,SAAU,QAGZ0G,EAAY,CAAC,aAAc,MAAO,YAAa,WAAY,SAG9D/pB,GAAI2nB,eAAe1B,EAAW,MAC/B8D,EAAUtvB,KACR,WAAY,aAAc,SAAU,QAAS,UAAW,kBAGxD,MAAMyvB,KAAMxwB,MACVqwB,EAAU7O,SAASgP,SACf,IAAI9lB,GACR,8DAAgE8lB,EAChE,qBACA,CAACnwB,KAAM,0BAA2B2sB,QAAS0B,UAM3CO,EAAQjB,EAAKrmB,QAAQ,QAC3BonB,EAAQ0B,cAAiBxB,EAAQ,EAE9B,aAAcjvB,EAAO,IACnB,QAASA,QACJ,IAAI0K,GACR,2EACgB,qBAChB,CAACrK,KAAM,2BAA4B2sB,QAAS0B,OAE7C,UAAW1uB,QACN,IAAI0K,GACR,6EACkB,qBAClB,CAACrK,KAAM,2BAA4B2sB,QAAS0B,UAE1C/E,EAAU3pB,EAAM,gBAClB4sB,GAAUjD,SACN,IAAIjf,GACR,sEACA,qBAAsB,CAACrK,KAAM,sBAAuB2sB,QAAS0B,QAG7DpoB,GAAIsoB,UAAUjF,IAAYA,EAAQnqB,MAAM+uB,WAE1C5R,QAAQgT,KAAK,6EACoB,CAAChG,QAAAA,SAC/B2G,EACD/D,EAAUyC,SAASryB,IAAIqxB,EAAMsC,GAE7B/D,EAAUyC,SAAS1b,OAAO0a,UAMxB/qB,EAAKurB,GACTjC,EAAW5C,EAAS,CAACmF,OAAO,EAAMpgB,MAAM,GAAQggB,EAAUC,EAC1DjoB,OACEynB,GAAelrB,SACX,IAAIyH,GACR,wGAEA,qBAAsB,CAACrK,KAAM,sBAAuB2sB,QAAS0B,IAGjEK,EAAQ,OAAS9rB,EACjB8rB,EAAQpF,SAAU,OACb,GAAG,QAAS3pB,EAAO,KACpBiD,EAAKjD,EAAM,UACZiD,IAAO2pB,GAAU3pB,SACZ,IAAIyH,GACR,wFAEA,qBAAsB,CAACrK,KAAM,sBAAuB2sB,QAAS0B,OAEvD,OAAPzrB,EAED8rB,EAAQ,OAAS,SACZ,CAAA,IAAIzoB,GAAIsoB,UAAU3rB,IAAOA,EAAGzD,MAAM+uB,WAEvC5R,QAAQgT,KAAK,6EACoB,CAAC1sB,GAAAA,SAC/BqtB,EACD/D,EAAUyC,SAASryB,IAAIqxB,EAAMsC,GAE7B/D,EAAUyC,SAAS1b,OAAO0a,IAGvB,GAAG/qB,IAAO+qB,EAAM,IAErB/qB,EAAKurB,GACHjC,EAAWtpB,EAAI,CAAC6rB,OAAO,EAAMpgB,MAAM,GAAQggB,EAAUC,EAASjoB,IAC5DynB,GAAelrB,KAAQqD,GAAIsoB,UAAU3rB,SACjC,IAAIyH,GACR,+GAEA,qBACA,CAACrK,KAAM,sBAAuB2sB,QAAS0B,OAIxCV,EAAKxuB,MAAM,gBAAiB,IAEbgvB,GACdjC,EAAWyB,EAAM,CAACc,OAAO,EAAMpgB,MAAM,GACrCggB,EAHkB,IAAIxyB,IAAIyyB,GAAShyB,IAAIqxB,GAAM,GAGtBtnB,KACVzD,QACP,IAAIyH,GACR,yEAEA,qBACA,CAACrK,KAAM,sBAAuB2sB,QAAS0B,IAI7CK,EAAQ,OAAS9rB,EAEjB8rB,EAAQI,QAAWoB,IAChBxB,EAAQ0B,eACTxtB,EAAGzD,MAAM,yBAIV,QAASuvB,MAETA,EAAQ0B,cAAe,OAClBz0B,EAASgyB,EAAKhf,OAAO,EAAGigB,MAC3BP,EAASrkB,eAAerO,IAEzBsK,GAAIuoB,qBAAqB,CACvBtC,UAAAA,EAAWmC,SAAAA,EAAUV,KAAMhyB,EAAQ2yB,QAAAA,EAASjoB,QAAAA,IAI7C6lB,EAAUyC,SAASnyB,IAAIb,GAAS,OAE3BkzB,EAASlB,EAAKhf,OAAOigB,EAAQ,GACnCF,EAAQ,OAASxC,EAAUyC,SAASvyB,IAAIT,GAAQ,OAASkzB,OAGzDH,EAAQ,OAASf,OAEd,GAAY,UAATA,EAERe,EAAQ,OAASf,MACZ,MAEA,WAAYzB,SACT,IAAI7hB,GACR,6DACA,qBACA,CAACrK,KAAM,sBAAuB2sB,QAAS0B,EAAUV,KAAAA,IAGrDe,EAAQ,OAASxC,EAAU,UAAYyB,OAKhB,IAAxBhuB,EAAM,gBACwB,IAA9B2uB,EAAQlyB,IAAI,gBAAkD,IAAxBuD,EAAM,iBAC7CusB,EAAUkD,UAAUzB,IAAQ,EAC5Be,EAAQU,WAAY,GAItBd,EAAQhyB,IAAIqxB,GAAM,GAEf,UAAWhuB,EAAO,KACfqC,EAAOrC,EAAM,aACb4sB,GAAUvqB,SACN,IAAIqI,GACR,oEACA,qBACA,CAACrK,KAAM,uBAAwB2sB,QAAS0B,OAG/B,UAATrsB,GAA6B,UAATA,MACnBiE,GAAI2nB,eAAe1B,EAAW,SACzB,IAAI7hB,GAEP,gEAAGrI,0BACJ,qBACA,CAAChC,KAAM,uBAAwB2sB,QAAS0B,SAEvC,GAAY,QAATrsB,GAA2B,WAATA,EAAmB,IAE7CA,EAAOmsB,GACLjC,EAAWlqB,EAAM,CAACysB,OAAO,EAAMpgB,MAAM,GAAQggB,EAAUC,EACvDjoB,IACEynB,GAAe9rB,SACX,IAAIqI,GACR,2EAEA,qBACA,CAACrK,KAAM,uBAAwB2sB,QAAS0B,OAElB,IAAvBrsB,EAAKsF,QAAQ,YACR,IAAI+C,GACR,+FAEA,qBACA,CAACrK,KAAM,uBAAwB2sB,QAAS0B,IAK9CK,EAAQ,SAAW1sB,KAGlB,eAAgBrC,EAAO,OAElB0wB,EAAY9D,GAAU5sB,EAAM,eAChC,CAACA,EAAM,eAAkBA,EAAM,eAAiB,GAC5C2wB,EAAkB,CAAC,QAAS,OAAQ,SAAU,iBAChDC,GAAU,QACRC,EAASH,EAAUlP,SAAS,WAG/Blb,GAAI2nB,eAAe1B,EAAW,KAAM,IACrCoE,EAAgB5vB,KAAK,SAAU,MAAO,SAGnC2vB,EAAUlP,SAAS,aACI,IAArBkP,EAAU7yB,aACL,IAAI6M,GACR,mFAEA,qBACA,CAACrK,KAAM,4BAA6B2sB,QAAS0B,SAE5C,GAAGgC,EAAUlP,SAAS,cACxBkP,EAAUjnB,KAAKzD,GACR,WAARA,GAA4B,QAARA,GAAyB,WAARA,GAC7B,SAARA,SACM,IAAI0E,GACR,qHAEA,qBACA,CAACrK,KAAM,4BAA6B2sB,QAAS0B,SAIjDkC,GAAWF,EAAU7yB,SAAWgzB,EAAS,EAAI,MAG5CH,EAAUlP,SAAS,WAGpBuN,EAAQ,SAAWA,EAAQ,UAAY,OAGnC,CAAC,MAAO,UAAUvN,SAASuN,EAAQ,iBAC/B,IAAIrkB,GACR,+EAEA,qBACA,CAACrK,KAAM,uBAAwB2sB,QAAS0B,SAM9CkC,IAAYlE,GAAS1sB,EAAM,eAG3B4wB,GAAWF,EAAU7yB,QAAU,KAIjC+yB,GAAWF,EAAUlmB,MAAMgL,GAAKmb,EAAgBnP,SAAShM,IAGzDob,KAAaC,GAAUH,EAAUlP,SAAS,WAEtCoP,QACI,IAAIlmB,GACR,mFAC2BimB,EAAgBvvB,KAAK,MAChD,qBACA,CAACf,KAAM,4BAA6B2sB,QAAS0B,OAG9CK,EAAQpF,UACR+G,EAAUlmB,MAAMgL,GAAK,CAAC,SAAU,QAAQgM,SAAShM,UAC5C,IAAI9K,GACR,2GAC2C,qBAC3C,CAACrK,KAAM,2BAA4B2sB,QAAS0B,IAIhDK,EAAQ,cAAgB2B,KAIvB,WAAY1wB,EAAO,MACf,eAAgBA,KAAW+uB,EAAQ,cAAcvN,SAAS,gBACvD,IAAI9W,GAEP,iEAAG1K,EAAM,uBAAuBguB,MAAU,qBAC3C,CAAC3tB,KAAM,0BAA2B2sB,QAAS0B,QAE3C9B,GAAU5sB,EAAM,YAA+C,IAAjCA,EAAM,UAAU2H,QAAQ,WAClD,IAAI+C,GAEP,0DAAG1K,EAAM,uBAAuBguB,MAAU,qBAC3C,CAAC3tB,KAAM,0BAA2B2sB,QAAS0B,IAE/CK,EAAQ,UAAY/uB,EAAM,aAIzB,aAAcA,IACf+uB,EAAQ,YAAc/uB,EAAM,aAG3B,cAAeA,KAAW,UAAWA,GAAQ,KAC1CE,EAAWF,EAAM,gBACL,OAAbE,IAAsB0sB,GAAU1sB,SAC3B,IAAIwK,GACR,6EACqB,qBACrB,CAACrK,KAAM,2BAA4B2sB,QAAS0B,IAIhC,OAAbxuB,IACDA,EAAWA,EAASyJ,eAEtBolB,EAAQ,aAAe7uB,KAItB,YAAaF,EAAO,IAClBguB,EAAKxuB,MAAM,cACN,IAAIkL,GACR,sEACA,qBACA,CAACrK,KAAM,0BAA2B2sB,QAAS0B,OAE5CpoB,GAAIsoB,UAAUG,EAAQ,cACjB,IAAIrkB,GACR,+DACA,qBACA,CAACrK,KAAM,0BAA2B2sB,QAAS0B,OAEhB,kBAArB1uB,EAAM,iBAGR,IAAI0K,GACR,qEACA,qBACA,CAACrK,KAAM,wBAAyB2sB,QAAS0B,IAL3CK,EAAQI,SAA+B,IAArBnvB,EAAM,cASzB,eAAgBA,EAAO,OAClB8wB,EAAY9wB,EAAM,iBACP,OAAd8wB,GAAoC,QAAdA,GAAqC,QAAdA,QACxC,IAAIpmB,GACR,0EAEA,qBACA,CAACrK,KAAM,yBAA0B2sB,QAAS0B,IAE9CK,EAAQ,cAAgB+B,KAGvB,UAAW9wB,EAAO,OACb+wB,EAAO/wB,EAAM,aACf4sB,GAAUmE,IAAmB,UAATA,GAA0C,IAAtBA,EAAKppB,QAAQ,WACjD,IAAI+C,GACR,yGAEA,qBACA,CAACrK,KAAM,sBAAuB2sB,QAAS0B,IAE3CK,EAAQ,SAAWgC;MAIf9tB,EAAK8rB,EAAQ,UACT,aAAP9rB,GAA4B,cAAPA,QAChB,IAAIyH,GACR,oEACA,qBAAsB,CAACrK,KAAM,wBAAyB2sB,QAAS0B,OAIhE4B,GAAmBA,EAAgBb,YAAcJ,IAGlD9C,EAAUkD,UAAUzB,IAAQ,EAC5Be,EAAQU,WAAY,GA4fxB,SAASuB,EAAaC,EAAIC,OAElBD,GAAoB,iBAAPA,IACbC,GAAoB,iBAAPA,SACVD,IAAOC,QAGVC,EAAUnwB,MAAMC,QAAQgwB,MAC3BE,IAAYnwB,MAAMC,QAAQiwB,UACpB,KAENC,EAAS,IACPF,EAAGpzB,SAAWqzB,EAAGrzB,cACX,MAEL,IAAID,EAAI,EAAGA,EAAIqzB,EAAGpzB,SAAUD,MAC1BozB,EAAaC,EAAGrzB,GAAIszB,EAAGtzB,WAClB,SAGJ,QAGHwzB,EAAM/pB,OAAOtK,KAAKk0B,GAClBI,EAAMhqB,OAAOtK,KAAKm0B,MACrBE,EAAIvzB,SAAWwzB,EAAIxzB,cACb,MAEL,MAAMyzB,KAAML,EAAI,KACdllB,EAAKklB,EAAGK,GACRtlB,EAAKklB,EAAGI,MAEF,eAAPA,GACEtwB,MAAMC,QAAQ8K,IAAO/K,MAAMC,QAAQ+K,KACpCD,EAAKA,EAAG9N,QAAQR,OAChBuO,EAAKA,EAAG/N,QAAQR,SAGhBuzB,EAAajlB,EAAIC,UACZ,SAGJ,EAriBDglB,CAAaV,EAAiBvB,IAAU,OACpCW,EAAiBhpB,GAAWA,EAAQgpB,eAAkB,WACvC,UAAlBA,QACK,IAAIhlB,GACP,8CAA6CsjB,gCAE9C,qBACA,CAAC3tB,KAAM,8BAA+B2sB,QAAS0B,EAAUV,KAAAA,IACtD,GAAqB,SAAlB0B,cAER/S,QAAQgT,KAAK,uCAAwC,CAAC3B,KAAAA,UAGlD,IAAItjB,GACR,yBACA,qBACA,CAACrK,KAAM,yBAA0B2sB,QAAS0B,EAAUV,KAAAA,EAClD0B,cAAAA,MAmBVppB,GAAIirB,UAAY,CAAChF,EAAWvsB,EAAOyuB,EAAY/nB,IACtC8nB,GAAWjC,EAAWvsB,EAAOyuB,OAAY3uB,OAAWA,EACzD4G,GAgHJJ,GAAIwpB,kBAAoBppB,UAChBV,EAAMgP,KAAK+N,UAAU,CAACkL,eAAgBvnB,EAAQunB,iBAC9CuD,EAASlD,GAAsB7xB,IAAIuJ,MACtCwrB,SACMA,QAGHC,EAAiB,CACrBxD,eAAgBvnB,EAAQunB,eACxBe,SAAU,IAAI9yB,IACdw1B,QAAS,KACTC,4BAqBMpF,EAAYjwB,QAGfiwB,EAAUmF,eACJnF,EAAUmF,cAEbA,EAAUnF,EAAUmF,QAAU,GAG9BE,EAAerF,EAAUqF,aAAe,GACxCC,EAAc,GAGdC,GAAmBvF,EAAU,cAAgB,SAAS5iB,cAGtDooB,EAAmBxF,EAAU,cAI7ByC,EAAWzC,EAAUyC,SACrBgD,EAAQ,IAAIhD,EAASjyB,QAAQU,KAAK4wB,QACpC,MAAML,KAAQgE,EAAO,OACjBjD,EAAUC,EAASvyB,IAAIuxB,MACd,OAAZe,eAIC2B,EAAY3B,EAAQ,eAAiB,WACzC2B,EAAY,GAAGplB,OAAOolB,GAAWjzB,OAAO2D,KAAK,IAEvB,OAAnB2tB,EAAQ,sBAILkD,EAAMpF,GAASkC,EAAQ,YACzB,MAAMpgB,KAAOsjB,EAAK,KAChBC,EAAQR,EAAQ/iB,SACdigB,EAAYtoB,GAAIsoB,UAAUjgB,MAE5BujB,EAcOtD,GAAcG,EAAQ0B,eAE/BoB,EAAYljB,GAAK5N,KAAKitB,WAdtB0D,EAAQ/iB,GAAOujB,EAAQ,IAEnBtD,IAAcG,EAAQ0B,cAAe,CAEvCoB,EAAYljB,GAAO,CAACqf,SACdmE,EAAiB,CAACxjB,IAAAA,EAAKqjB,MAAOH,EAAYljB,IAC7CA,EAAI,KAAMijB,EACXA,EAAajjB,EAAI,IAAI5N,KAAKoxB,GAE1BP,EAAajjB,EAAI,IAAM,CAACwjB,MAS1BD,EAAMxB,KACRwB,EAAMxB,GAAa,aACJ,WACJ,UACD,KAGZwB,EAAQA,EAAMxB,GACd0B,EAAkBpE,EAAMkE,EAAM,QAAS,SAEpCnD,EAAQpF,QAETyI,EAAkBpE,EAAMkE,EAAM,SAAU,iBACnC,GAAwB,UAArBnD,EAAQ,SAChBqD,EAAkBpE,EAAMkE,EAAM,QAAS,SACvCE,EAAkBpE,EAAMkE,EAAM,aAAc,SAC5CE,EAAkBpE,EAAMkE,EAAM,SAAU,cACnC,GAAG,UAAWnD,EAEnBqD,EAAkBpE,EAAMkE,EAAM,SAAUnD,EAAQ,eAC3C,GAAG,cAAeA,GAAW,eAAgBA,EAAS,OAErD7uB,EAAW6uB,EAAQ,aACnB+B,EAAY/B,EAAQ,cAExBqD,EAAkBpE,EAAMkE,EAAM,aAD7BhyB,GAAY4wB,EAEV,GAAE5wB,KAAY4wB,IAAYnnB,cACrBzJ,EACoCA,EAASyJ,cAC7CmnB,EACqC,IAAGA,EAEJ,aAEtC,cAAe/B,EACvBqD,EAAkBpE,EAAMkE,EAAM,cAC3BnD,EAAQ,cAAgB,SAASplB,eAC5B,eAAgBolB,EACrBA,EAAQ,cACTqD,EAAkBpE,EAAMkE,EAAM,aAC3B,IAAGnD,EAAQ,eAEdqD,EAAkBpE,EAAMkE,EAAM,aAAc,SAEtCH,GACRK,EAAkBpE,EAAMkE,EAAM,aAAe,IAAGH,GAChDK,EAAkBpE,EAAMkE,EAAM,aAAc,SAC5CE,EAAkBpE,EAAMkE,EAAM,SAAU,WAGxCE,EAAkBpE,EAAMkE,EAAM,aAAcJ,GAC5CM,EAAkBpE,EAAMkE,EAAM,aAAc,SAC5CE,EAAkBpE,EAAMkE,EAAM,SAAU,eAM1C,MAAMlsB,KAAO4rB,EACfS,EAAaT,EAAc5rB,EAAK,UAG3B0rB,GA9IPr1B,uBAwMMi2B,EAAQ,GACdA,EAAMtD,SAAWgB,GAAK3zB,MAAMC,KAAK0yB,UACjCsD,EAAMj2B,MAAQC,KAAKD,MACnBi2B,EAAMZ,QAAU,KAChBY,EAAMX,WAAar1B,KAAKq1B,WACxBW,EAAM7C,UAAYO,GAAK3zB,MAAMC,KAAKmzB,WAC/BnzB,KAAKizB,kBACN+C,EAAM/C,gBAAkBjzB,KAAKizB,gBAAgBlzB,SAE/Ci2B,EAAMC,wBAA0Bj2B,KAAKi2B,wBAClC,UAAWj2B,OACZg2B,EAAM,SAAWh2B,KAAK,UAErB,cAAeA,OAChBg2B,EAAM,aAAeh2B,KAAK,cAEzB,WAAYA,OACbg2B,EAAM,UAAYh2B,KAAK,kBAElBg2B,GA1NPC,uCAkOIj2B,KAAKizB,uBACAjzB,YAEFA,KAAKizB,gBAAgBlzB,SApO5BozB,UAAW,WAhiCwB,MAmiClCnB,GAAsBtd,MAGvBsd,GAAsBkE,QAExBlE,GAAsB3xB,IAAIqJ,EAAKyrB,GACxBA,WA8IEY,EAAaI,EAAQzsB,EAAK0sB,SAC3BhtB,EAAU+sB,EAAOzsB,GACjBjI,EAAO00B,EAAOzsB,GAAO,OAEvB2I,EACAgkB,MACA,MAAMT,KAASxsB,EACjBiJ,EAAMujB,EAAMvjB,IAEVgkB,EADCD,GAAO/jB,EAAI9Q,OACH,GAEA8Q,EAAI+jB,GAEZC,KAAU50B,EACXA,EAAK40B,GAAQ5xB,KAAKmxB,GAElBn0B,EAAK40B,GAAU,CAACT,OAIhB,MAAMlsB,KAAOjI,EACJ,KAARiI,GAGHqsB,EAAat0B,EAAMiI,EAAK0sB,EAAM,YAWzBN,EAAkBpE,EAAMkE,EAAOU,GAClCV,EAAM7nB,eAAeuoB,KACvBV,EAAMU,GAAuB5E,KAuDnC1nB,GAAIusB,gBAAkB,CAACzF,EAAKpnB,EAAK3D,QAEpB,OAAR2D,EAAc,IACH,aAAT3D,gBAGI,QAIN+qB,EAAI4B,SAASnyB,IAAImJ,GAAM,OAClBksB,EAAQ9E,EAAI4B,SAASvyB,IAAIuJ,MAE5BkoB,GAAa7rB,UAEP6vB,KAENA,EAAM7nB,eAAehI,UAEf6vB,EAAM7vB,SAKL,cAATA,GAAwBA,KAAQ+qB,GAKvB,eAAT/qB,GAAyBA,KAAQ+qB,EAJ3BA,EAAI/qB,GAQD,aAATA,EAGI,aAWTiE,GAAI2nB,eAAiB,CAAC1B,EAAWjR,IAC5BA,EAAQ/T,YAAc,OACfglB,EAAU0B,gBAChB1B,EAAU0B,gBAAkB,WAAa3S,EAAQ/T,WAEf,gBAA7BglB,EAAU0B,eAWrB3nB,GAAIsoB,UAAYxnB,QACVwlB,GAAUxlB,IAAe,MAATA,EAAE,UACb,SAEFA,OACA,YACA,iBACA,eACA,eACA,iBACA,aACA,gBACA,aACA,UACA,gBACA,aACA,YACA,gBACA,YACA,YACA,YACA,mBACA,cACA,gBACA,iBACA,kBACA,eACA,WACA,YACA,aACA,eACA,gBACI,SAEJ,GCx4CT,MACEnG,QAASyrB,GACT3kB,SAAU4kB,GACV7kB,cAAegrB,GACf1qB,SAAUwkB,GACVvkB,YAAa6lB,IACX9nB,GAGFsC,OAAQqqB,GACRtqB,QAASuqB,GACTrqB,QAASsqB,GACT3qB,UAAW4qB,IACT9sB,IAGFmrB,UAAW/C,GACXqE,gBAAiBM,GACjBvE,UAAWwE,GACX/X,QAASgY,GACTpF,eAAgBqF,IACdltB,IAGFwI,WAAYuf,IACV/nB,IAGF6E,SAAUsoB,GACVjqB,QAASujB,GACTrhB,UAAWgoB,GACXlpB,kBAAmBmpB,IACjBrtB,GAEEE,GAAM,GACZzK,OAAiByK,GACjB,MAAMotB,GAAc,sCA62BpB,SAASC,IAAapH,UAACA,EAADqH,eAAYA,EAAZ5zB,MAA4BA,EAA5B0G,QAAmCA,OAEpD1G,MAAAA,SACM,WAIH6zB,EAAmBrF,GACvBjC,EAAWqH,EAAgB,CAAC9E,OAAO,GAAOpoB,MACpB,QAArBmtB,SACMrF,GAAWjC,EAAWvsB,EAAO,CAAC0O,MAAM,GAAOhI,GAC7C,GAAwB,UAArBmtB,SACDrF,GAAWjC,EAAWvsB,EAAO,CAAC8uB,OAAO,EAAMpgB,MAAM,GAAOhI,SAI3DrE,EAAO8wB,GAAiB5G,EAAWqH,EAAgB,aAG5C,QAATvxB,GAAuC,WAArBwxB,IAAkCjH,GAAU5sB,SACzD,OAAQwuB,GAAWjC,EAAWvsB,EAAO,CAAC0O,MAAM,GAAOhI,OAGhD,WAATrE,GAAqBuqB,GAAU5sB,SACzB,OACEwuB,GAAWjC,EAAWvsB,EAAO,CAAC8uB,OAAO,EAAMpgB,MAAM,GAAOhI,OAKhE0sB,GAAWS,UACL7zB,QAGHhC,EAAO,MAEVqE,IAAS,CAAC,MAAO,SAAU,SAASmf,SAASnf,GAE9CrE,EAAK,SAAWqE,OACX,GAAGuqB,GAAU5sB,GAAQ,OAEpBE,EAAWizB,GAAiB5G,EAAWqH,EAAgB,aAC7C,OAAb1zB,IACDlC,EAAK,aAAekC,SAEhB4wB,EAAYqC,GAAiB5G,EAAWqH,EAAgB,cAC7C,OAAd9C,IACD9yB,EAAK,cAAgB8yB,SAIrB,CAAC,UAAW,SAAU,UAAUtP,gBAAgBxhB,KAClDA,EAAQA,EAAMuH,YAEhBvJ,EAAK,UAAYgC,EAEVhC,EAaT,SAAS81B,GAAmBvH,EAAWwH,EAAajD,EAAWpqB,SACvD1I,EAAO,GACPjB,EAAOsK,OAAOtK,KAAKg3B,GAAat2B,WAClC,MAAMuI,KAAOjJ,EAAM,OACfi3B,EAAcxF,GAAWjC,EAAWvmB,EAAK,CAAC8oB,OAAO,GAAOpoB,OAC1DoE,EAAMipB,EAAY/tB,GAClB0mB,GAAS5hB,KACXA,EAAM,CAACA,QAEL,MAAMkd,KAAQld,EAAK,IACT,OAATkd,eAIC4E,GAAU5E,SACN,IAAItd,GACR,+DACA,qBACA,CAACrK,KAAM,6BAA8B0zB,YAAAA,UAEnCjpB,EAAM,UAAWkd,GACJ,UAAhBgM,IACDlpB,EAAI,aAAe9E,EAAI2D,eAEtBmnB,IACDhmB,EAAI,cAAgBgmB,GAEtB9yB,EAAK+C,KAAK+J,WAGP9M,EAGTyI,eAAewtB,IACb1H,UAACA,EAAD7lB,QAAYA,EAAZktB,eAAqBA,EAArB5zB,MAAqCA,EAArCk0B,aAA4CA,EAA5CC,QAA0DA,EAA1DC,SACEA,EADFC,cACYA,UACNr2B,EAAO,GACPjB,EAAOsK,OAAOtK,KAAKiD,GAAOvC,OAC1B62B,EAA2B,UAAbF,MAChB,IAAIpuB,KAAOjJ,EAAM,IAEhBu3B,EAAa,OACRlH,EAAM+F,GAAiB5G,EAAWvmB,EAAK,YACzCkoB,GAAad,KACfb,QAAkB8G,GAAgB,CAChC9G,UAAAA,EACAmC,SAAUtB,EACVgC,WAAW,EACX1oB,QAAAA,SAqBFstB,EAhBAlpB,EAAM9K,EAAMgG,GACZ0mB,GAAS5hB,KACXA,EAAM,CAACA,IAGTA,QAAYxE,GAAIiuB,OAAO,CACrBhI,UAAAA,EACAqH,eAAAA,EACAx1B,QAAS0M,EACTpE,QAAAA,EACA8tB,YAAY,EACZC,aAAa,EACbP,aAAAA,IAOEF,EAFDK,EACU,UAARruB,EACa,QAEA2tB,GACZ,CAACpH,UAAAA,EAAWqH,eAAgBQ,EAAUp0B,MAAOgG,EAAKU,QAAAA,IAGxC8nB,GAAWjC,EAAWvmB,EAAK,CAAC8oB,OAAO,GAAOpoB,GAG1C,QAAb0tB,EAEDpuB,EAAMwoB,GAAWjC,EAAWvmB,EAAK,CAAC0I,MAAM,GAAOhI,GACvC4tB,IACRtuB,EAAMguB,OAGJ,IAAIhM,KAAQld,EAAK,IAEhBqpB,IAAYlB,GAASjL,KACtBA,EAAO,UAAW,CAACA,KAEL,UAAboM,EACkB,UAAhBJ,IAEOhM,EAAK,SACbA,EAAK,SAAW,CAAChiB,GAAKsF,OAAO0c,EAAK,UAElCA,EAAK,SAAW,CAAChiB,QAEd,CAAA,GAAGgtB,GAAShL,KAChB,CAAC,YAAa,QAAS,UAAUxG,SAAS4S,SACrC,IAAI1pB,GAEP,wEAAW0pB,MACZ,qBACA,CAAC/zB,KAAM,uBAAwBL,MAAOgoB,IAChCqM,EAGW,UAAhBL,GAEDT,GAAUvL,EAAMqM,EAAeL,EAAa,CAC1C9oB,iBAAiB,EACjBG,cAAc,IAGM,UAAhB2oB,GAA6BI,KAAYpM,IACjDA,EAAKoM,GAAYpuB,GAEnBhI,EAAK+C,KAAKinB,WAGPhqB,EAthCTsI,GAAIiuB,OAAS9tB,OACX8lB,UAAAA,EACAqH,eAAAA,EAAiB,KACjBx1B,QAAAA,EACAsI,QAAAA,EAAU,GACV8tB,WAAAA,GAAa,EACbC,YAAAA,GAAc,EACdC,kBAAAA,EAAoB,KACpBR,aAAAA,EAAe,gBAGZ91B,MAAAA,SACM,QAIa,aAAnBw1B,IACDltB,EAAUW,OAAOwC,OAAO,GAAInD,EAAS,CAAC6D,SAAS,MAG7CmiB,GAAStuB,KAAauuB,GAAUvuB,GAAU,KAExCo2B,IAAkC,OAAnBZ,GAEF,WADfpF,GAAWjC,EAAWqH,EAAgB,CAAC9E,OAAO,GAC5CpoB,IAAwB,OACpBiuB,QAAeT,EAAa,CAChCU,cAAex2B,EACfmuB,UAAAA,EACAqH,eAAAA,EACAltB,QAAAA,EACA8tB,WAAAA,gBAEY10B,IAAX60B,EACM,KAEFA,SAIFhB,GAAa,CAACpH,UAAAA,EAAWqH,eAAAA,EAAgB5zB,MAAO5B,EAASsI,QAAAA,OAI/DgmB,GAAStuB,GAAU,KAChBJ,EAAO,SACL0yB,EAAYyC,GAChB5G,EAAWqH,EAAgB,eAAiB,GAC9CY,EAAaA,GAAc9D,EAAUlP,SAAS,aAC1C,IAAI5jB,EAAI,EAAGA,EAAIQ,EAAQP,SAAUD,EAAG,KAElCyI,QAAUC,GAAIiuB,OAAO,CACvBhI,UAAAA,EACAqH,eAAAA,EACAx1B,QAASA,EAAQR,GACjB8I,QAAAA,EACAwtB,aAAAA,EACAO,YAAAA,EACAC,kBAAAA,IAECF,GAAc9H,GAASrmB,KACxBA,EAAI,SAAUA,IAGP,OAANA,IACDA,QAAU6tB,EAAa,CACrBU,cAAex2B,EAAQR,GACvB2uB,UAAAA,EACAqH,eAAAA,EACAiB,OAAQz2B,EACRwc,MAAOhd,EACP8I,QAAAA,EACAouB,eAAgB92B,EAChBw2B,WAAAA,SAEO10B,IAANuG,KAKFqmB,GAASrmB,GACVrI,EAAOA,EAAKsN,OAAOjF,GAEnBrI,EAAK+C,KAAKsF,WAGPrI,QAMH+2B,EAAyBvG,GAC7BjC,EAAWqH,EAAgB,CAAC9E,OAAO,GAAOpoB,GAGtCsuB,EACJ7B,GAAiB5G,EAAWqH,EAAgB,YAM9Cc,EAAoBA,IACjBnI,EAAUgD,gBAAkBhD,EAAY,UACvCxvB,EAAOsK,OAAOtK,KAAKqB,GAASX,OAC5Bw3B,GAAcR,KACfQ,GAAcP,GAAqB33B,EAAKc,QAAU,IAClDd,EAAKykB,SAAS,gBACX,MAAMxb,KAAOjJ,EAAM,OACf82B,EAAmBrF,GACvBkG,EAAmB1uB,EAAK,CAAC8oB,OAAO,GAAOpoB,MACjB,WAArBmtB,EAA+B,CAEhCoB,GAAa,EACb1I,EAAYmI,WAGU,QAArBb,GAA8C,IAAhB92B,EAAKc,OAAc,CAElDo3B,GAAa,SAMhBA,IAED1I,EAAYA,EAAUgG,2BAIpBrE,GAAa8G,KACfzI,QAAkB8G,GAAgB,CAChC9G,UAAAA,EACAmC,SAAUsG,EACV5F,WAAW,EACXC,mBAAmB,EACnB3oB,QAAAA,KAKD,aAActI,IACfmuB,QAAkB8G,GAChB,CAAC9G,UAAAA,EAAWmC,SAAUtwB,EAAQ,YAAasI,QAAAA,KAI/CguB,EAAoBnI,MAGhB2I,EAAU,SAGV,MAAMlvB,KAAOjJ,EAAM,IAEG,UADCyxB,GAAWjC,EAAWvmB,EAAK,CAAC8oB,OAAO,GAAOpoB,GAClC,CAG/BwuB,EAAUA,GAAWlvB,QACfhG,EAAQ5B,EAAQ4H,GAChBuC,EACJvH,MAAMC,QAAQjB,GACXA,EAAMnC,OAAS,EAAImC,EAAM/B,QAAQR,OAASuC,EAAS,CAACA,OACrD,MAAMqC,KAAQkG,EAAO,OACjB6kB,EAAM+F,GAAiBuB,EAAmBryB,EAAM,YAClD6rB,GAAad,KACfb,QAAkB8G,GAAgB,CAChC9G,UAAAA,EACAmC,SAAUtB,EACV1mB,QAAAA,EACA0oB,WAAW,WAQjBpxB,EAAO,SAgKbyI,eAAe0uB,GAAc5I,UAC3BA,EAD2BqH,eAE3BA,EAF2BmB,uBAG3BA,EAH2B32B,QAI3BA,EAJ2B02B,eAK3BA,EAL2BpuB,QAM3BA,EAAU,GANiB8tB,WAO3BA,EAP2BU,QAQ3BA,EAR2BR,kBAS3BA,EAT2BR,aAU3BA,UAEMn3B,EAAOsK,OAAOtK,KAAKqB,GAASX,OAC5B23B,EAAQ,OACVC,QAGEC,EAAal3B,EAAQ82B,IAGK,UAF9B1G,GAAWjC,EACRG,GAAStuB,EAAQ82B,IAAY92B,EAAQ82B,GAAS,GAAK92B,EAAQ82B,GAC5D,CAACpG,OAAO,GAAOpoB,OAEf,MAAMV,KAAOjJ,EAAM,KAEjBw4B,EADAv1B,EAAQ5B,EAAQ4H,MAIT,aAARA,eAKC6tB,EAAmBrF,GAAWjC,EAAWvmB,EAAK,CAAC8oB,OAAO,GAAOpoB,OAGzC,OAArBmtB,IACC1F,GAAe0F,KAAqBT,GAAWS,MAEjDA,EAAmBK,EAAa,CAC9BsB,iBAAkBxvB,EAClBumB,UAAAA,EACAqH,eAAAA,EACAiB,OAAQz2B,EACRsI,QAAAA,EACA8tB,WAAAA,EACAx0B,MAAAA,EACA80B,eAAAA,SAEsBh1B,IAArB+zB,eAKFT,GAAWS,GAAmB,IACD,aAA3BkB,QACK,IAAIrqB,GACR,2EACa,qBACb,CAACrK,KAAM,+BAAgCL,MAAAA,OAExC6zB,KAAoBiB,GACC,cAArBjB,GACqB,UAArBA,QACK,IAAInpB,GACR,uDACA,qBACA,CAACrK,KAAM,qBAAsBo1B,QAAS5B,OAKpB,QAArBA,EAA4B,KACzBjH,GAAU5sB,GAAQ,KAChB0G,EAAQ6D,cACJ,IAAIG,GACR,qDACA,qBAAsB,CAACrK,KAAM,oBAAqBL,MAAAA,OAEnD2sB,GAAU3sB,QAEP8yB,GAAe9yB,SACX,IAAI0K,GACR,sFAEA,qBAAsB,CAACrK,KAAM,oBAAqBL,MAAAA,QAEjD,CAAA,IAAG0sB,GAAS1sB,SAQX,IAAI0K,GACR,sFAEA,qBAAsB,CAACrK,KAAM,oBAAqBL,MAAAA,QAVhDA,EAAMwK,MAAMpD,GAAKwlB,GAAUxlB,UACvB,IAAIsD,GACR,sFAEA,qBAAsB,CAACrK,KAAM,oBAAqBL,MAAAA,KAU1DuzB,GACEuB,EAAgB,MAChBjI,GAAS7sB,GAAOkR,IAAI9J,GAClBwlB,GAAUxlB,GAAKonB,GAAWjC,EAAWnlB,EAAG,CAACsH,MAAM,GAAOhI,GAAWU,GACnE,CAAC8D,gBAAiBxE,EAAQ6D,sBAIN,UAArBspB,EAA8B,CAG5BlH,GAAU3sB,KACXA,EAAQqH,OAAOquB,YAAYruB,OAAO3B,QAAQ1F,GAAOkR,IAAI,EAAEhT,EAAGkJ,KAAO,CAC/DonB,GAAWkG,EAAmBx2B,EAAG,CAAC4wB,OAAO,IACzCjC,GAASzlB,GAAG8J,IAAIzG,GACd+jB,GAAWkG,EAAmBjqB,EAAI,CAACiE,MAAM,EAAMogB,OAAO,SAI5D2E,GAAmBzzB,EAAO0G,EAAQ6D,SAClCgpB,GACEuB,EAAgB,QAChBjI,GAAS7sB,GAAOkR,IAAI9J,GAClBwlB,GAAUxlB,GACRonB,GAAWkG,EAAmBttB,EAC5B,CAACsH,MAAM,EAAMogB,OAAO,GAAOpoB,GAAWU,GAC5C,CAAC8D,gBAAiBxE,EAAQ6D,sBAON,cAArBspB,GAAoCP,GAAgB/G,EAAW,KAAM,OAChEoJ,EAAiB9I,SAAevmB,GAAIiuB,OAAO,CAC/ChI,UAAAA,EACAqH,eAAAA,EACAx1B,QAAS4B,EACT0G,QAAAA,EACAwtB,aAAAA,SAIEyB,EAAenrB,MAAMpD,GAAK8rB,GAAW9rB,UACjC,IAAIsD,GACR,2EAEA,qBAAsB,CAACrK,KAAM,0BAA2BL,MAAAA,IAG5DuzB,GACEuB,EAAgB,YAAaa,EAAgB,CAACzqB,iBAAiB,gBAK3C,WAArB2oB,IACClH,GAAU3sB,KAAU0sB,GAAS1sB,SACzB,IAAI0K,GACR,4EAEA,qBAAsB,CAACrK,KAAM,uBAAwBL,MAAAA,OAGjC,WAArB6zB,EAA+B,CAGhCwB,EAAkBr1B,EACfs1B,GAAchC,GAAgB/G,EAAW,KAE1CuI,EAAe,UAAY90B,EAE3BuzB,GACEuB,EAAgB,SAAU90B,EAAO,CAACkL,gBAAiBxE,EAAQ6D,sBAOzC,cAArBspB,EAAkC,IACtB,OAAV7zB,eAIC4sB,GAAU5sB,KAAW0G,EAAQ6D,cACzB,IAAIG,GACR,8DACA,qBACA,CAACrK,KAAM,iCAAkCL,MAAAA,IAG7CA,EAAQ6sB,GAAS7sB,GAAOkR,IAAI9J,GAAKwlB,GAAUxlB,GAAKA,EAAEuC,cAAgBvC,OAG9D,MAAMwuB,KAAQ51B,EACb4sB,GAAUgJ,KAAUA,EAAKp2B,MAAMk0B,KAChC/W,QAAQgT,KAAM,kCAAiCiG,GAInDrC,GACEuB,EAAgB,YAAa90B,EAAO,CAACkL,gBAAiBxE,EAAQ6D,sBAK1C,eAArBspB,EAAmC,KAChCjH,GAAU5sB,KAAW0G,EAAQ6D,cACzB,IAAIG,GACR,+DACA,qBACA,CAACrK,KAAM,yBAA0BL,MAAAA,IAGrCA,EAAQ6sB,GAAS7sB,OAGb,MAAMrC,KAAOqC,KACZ4sB,GAAUjvB,IAAgB,QAARA,GAAyB,QAARA,QAC9B,IAAI+M,GACR,+DACA,qBACA,CAACrK,KAAM,yBAA0BL,MAAAA,IAIvCuzB,GACEuB,EAAgB,aAAc90B,EAC9B,CAACkL,gBAAiBxE,EAAQ6D,sBAKN,WAArBspB,EAA+B,KAC5BjH,GAAU5sB,SACN,IAAI0K,GACR,2DACA,qBACA,CAACrK,KAAM,uBAAwBL,MAAAA,IAEnCuzB,GAAUuB,EAAgB,SAAU90B,eAKd,aAArB6zB,EAAiC,KAC9BlH,GAAU3sB,SACN,IAAI0K,GACR,8DACA,qBAAsB,CAACrK,KAAM,yBAA0BL,MAAAA,OAG3Du1B,QAAsBjvB,GAAIiuB,OAAO,CAC/BhI,UAAAA,EACAqH,eACA,WACAx1B,QAAS4B,EACT0G,QAAAA,EACAwtB,aAAAA,IAGC,aAAcqB,MACX,MAAM3qB,KAAY2qB,EAAc,YAClChC,GACEuB,EAAgBlqB,EAAU2qB,EAAc,YAAY3qB,GACpD,CAACM,iBAAiB,QAMpB2qB,EAAaf,EAAe,aAAe,SAC3C,MAAMlqB,KAAY2qB,EAAe,IACnB,aAAb3qB,WAGe,OAAfirB,IACDA,EAAaf,EAAe,YAAc,IAE5CvB,GAAUsC,EAAYjrB,EAAU,GAAI,CAACM,iBAAiB,UAChD4qB,EAAQP,EAAc3qB,OACxB,IAAImrB,EAAK,EAAGA,EAAKD,EAAMj4B,SAAUk4B,EAAI,OACjC/N,EAAO8N,EAAMC,MAChB/C,GAAShL,IAAS+K,GAAQ/K,SACrB,IAAItd,GACR,6EACuB,qBACvB,CAACrK,KAAM,iCAAkCL,MAAOu1B,IAEpDhC,GAAUsC,EAAYjrB,EAAUod,EAAM,CAAC9c,iBAAiB,iBAQtC,UAArB2oB,EAA8B,CAC/BuB,EAAMr0B,KAAKiF,gBAKTgwB,EAAUzJ,QACRa,EAAM+F,GAAiB5G,EAAWvmB,EAAK,YACzCkoB,GAAad,KACf4I,QAAgB3C,GAAgB,CAC9B9G,UAAAA,EACAmC,SAAUtB,EACVgC,WAAW,EACXC,mBAAmB,EACnB3oB,QAAAA,WAIEgqB,EAAYyC,GAAiB6C,EAAShwB,EAAK,eAAiB,MAE/D0qB,EAAUlP,SAAS,cAAgBmL,GAAU3sB,GAAQ,OAChD8wB,EAAYqC,GAAiB6C,EAAShwB,EAAK,cAEjDuvB,EAAgBzB,GAAmBkC,EAASh2B,EAAO8wB,EAAWpqB,QACzD,GAAGgqB,EAAUlP,SAAS,WAAamL,GAAU3sB,GAAQ,OAEpDm0B,EAAUzD,EAAUlP,SAAS,UAC7B4S,EAAWjB,GAAiB6C,EAAShwB,EAAK,WAAa,SACvDquB,EAA6B,WAAbD,GACpB5F,GAAWjC,EAAW6H,EAAU,CAACtF,OAAO,GAAOpoB,GAEjD6uB,QAAsBtB,GAAgB,CACpC1H,UAAWyJ,EACXtvB,QAAAA,EACAktB,eAAgB5tB,EAChBhG,MAAAA,EACAk0B,aAAAA,EACAC,QAAAA,EACAC,SAAAA,EACAC,cAAAA,SAEG,GAAG3D,EAAUlP,SAAS,QAAUmL,GAAU3sB,GAAQ,OAEjDm0B,EAAUzD,EAAUlP,SAAS,UACnC+T,QAAsBtB,GAAgB,CACpC1H,UAAWyJ,EACXtvB,QAAAA,EACAktB,eAAgB5tB,EAChBhG,MAAAA,EACAk0B,aAAAA,EACAC,QAAAA,EACAC,SAAU,aAEP,GAAG1D,EAAUlP,SAAS,UAAYmL,GAAU3sB,GAEjDu1B,QAAsBtB,GAAgB,CAEpC1H,UAAWyJ,EAAQzD,0BACnB7rB,QAAAA,EACAktB,eAAgB5tB,EAChBhG,MAAAA,EACAk0B,aAAAA,EACAC,SAAS,EACTC,SAAU,cAEP,OAEC1rB,EAA+B,UAArBmrB,KACbnrB,GAA+B,SAArBmrB,EAA6B,KACpCoC,EAAqBrC,EACtBlrB,GAAqC,WAA3BqsB,IACXkB,EAAqB,MAEvBV,QAAsBjvB,GAAIiuB,OAAO,CAC/BhI,UAAWyJ,EACXpC,eAAgBqC,EAChB73B,QAAS4B,EACT0G,QAAAA,EACA8tB,WAAY9rB,EACZwrB,aAAAA,SAIFqB,EAD8C,UAA9CpC,GAAiB5G,EAAWvmB,EAAK,SACjB,SACL,iBACChG,SAIUsG,GAAIiuB,OAAO,CAC/BhI,UAAWyJ,EACXpC,eAAgB5tB,EAChB5H,QAAS4B,EACT0G,QAAAA,EACA8tB,YAAY,EACZN,aAAAA,OAMe,OAAlBqB,GAA+C,WAArB1B,IAE3B0B,EAAgBrB,EAAa,CAC3BU,cAAe50B,EACf6zB,iBAAAA,EACAtH,UAAWyJ,EACXpC,eAAAA,EACAiB,OAAQz2B,EACRsI,QAAAA,EACA8tB,WAAAA,EACAxuB,IAAAA,EACA8uB,eAAAA,SAEmBh1B,IAAlBy1B,MAMmB,UAArB1B,IAAiCd,GAAQwC,IAC1C7E,EAAUlP,SAAS,WAEnB+T,EAAgB,SAAU1I,GAAS0I,KAMlC7E,EAAUlP,SAAS,YACnBkP,EAAUjnB,KAAKzD,GAAe,QAARA,GAAyB,WAARA,KAExCuvB,EAAgB1I,GAAS0I,GACtBrkB,IAAI9J,cAAiBylB,GAASzlB,OAKhC4uB,EAAQhH,SAASnyB,IAAImJ,IAAQgwB,EAAQhH,SAASvyB,IAAIuJ,GAAK2jB,eAClDkM,EACJf,EAAe,YAAcA,EAAe,aAAe,GAC7DS,EAAgB1I,GAAS0I,OACrB,IAAIQ,EAAK,EAAGA,EAAKR,EAAc13B,SAAUk4B,EAAI,OACzC/N,EAAOuN,EAAcQ,MACxB/C,GAAShL,IAAS+K,GAAQ/K,SACrB,IAAItd,GACR,6EACuB,qBACvB,CAACrK,KAAM,iCAAkCL,MAAOu1B,IAEpDhC,GAAUsC,EAAYhC,EAAkB7L,EAAM,CAAC9c,iBAAiB,UAOpEqoB,GAAUuB,EAAgBjB,EAAkB0B,EAAe,CACzDrqB,iBAAiB,OAMlB,WAAY4pB,KACkB,UAA5BA,EAAe,UAAwBxB,GAAgB/G,EAAW,WAG9D,IAAII,GAAU0I,IAAoB3I,GAAS2I,MAC/C3uB,EAAQ6D,cACH,IAAIG,GACR,4EAEA,qBACA,CAACrK,KAAM,6BAA8BL,MAAOq1B,QAK9C,MAAMrvB,KAAOovB,EAAO,OAChBc,EAAexJ,GAAStuB,EAAQ4H,IAAQ5H,EAAQ4H,GAAO,CAAC5H,EAAQ4H,QAClE,MAAMmwB,KAAMD,EAAc,KACxBvJ,GAAUwJ,IAAO9uB,OAAOtK,KAAKo5B,GAAI1sB,KAAKvL,GACa,WAArDswB,GAAWjC,EAAWruB,EAAG,CAAC4wB,OAAO,GAAOpoB,UAClC,IAAIgE,GACR,8DACA,qBACA,CAACrK,KAAM,sBAAuBL,MAAOm2B,UAEnChB,EAAc,CAClB5I,UAAAA,EACAqH,eAAAA,EACAmB,uBAAAA,EACA32B,QAAS+3B,EACTrB,eAAAA,EACApuB,QAAAA,EACA8tB,WAAAA,EACAE,kBAAAA,EACAQ,QAAAA,EACAhB,aAAAA,MAjpBAiB,CAAc,CAClB5I,UAAAA,EACAqH,eAAAA,EACAmB,uBAAAA,EACA32B,QAAAA,EACA02B,eAAgB92B,EAChB0I,QAAAA,EACA8tB,WAAAA,EACAU,QAAAA,EACAR,kBAAAA,EACAR,aAAAA,IAGFn3B,EAAOsK,OAAOtK,KAAKiB,OACfo4B,EAAQr5B,EAAKc,UAEd,WAAYG,EAAM,IAEhB,UAAWA,IAAS,cAAeA,GAAQ,eAAgBA,SACtD,IAAI0M,GACR,8HAEA,qBAAsB,CAACrK,KAAM,uBAAwBjC,QAASJ,QAE9Dq4B,EAAaD,EAAQ,KACtB,UAAWp4B,IACZq4B,GAAc,GAEb,WAAYr4B,IACbq4B,GAAc,GAEb,cAAer4B,IAChBq4B,GAAc,GAEb,eAAgBr4B,IACjBq4B,GAAc,GAEE,IAAfA,QACK,IAAI3rB,GACR,8JAGA,qBAAsB,CAACrK,KAAM,uBAAwBjC,QAASJ,UAE5D2N,EAA4B,OAAnB3N,EAAK,UAAqB,GAAK6uB,GAAS7uB,EAAK,WACtDuK,EAAQirB,GAAWx1B,EAAM,YAG5Bs1B,GAAgB/G,EAAW,MAAQhkB,EAAMiZ,SAAS,UAClC,IAAjBjZ,EAAM1K,aAED,GAAqB,IAAlB8N,EAAO9N,OAAc,OACvB82B,QAAeT,EAAa,CAChCU,cAAe52B,EACfuuB,UAAAA,EACAqH,eAAAA,EACAx1B,QAAAA,EACAsI,QAAAA,EACA8tB,WAAAA,IAGAx2B,OADY8B,IAAX60B,EACMA,EAEA,SAEJ,CAAA,IAAIhpB,EAAOnB,MAAMpD,GAAMwlB,GAAUxlB,IAAM0rB,GAAe1rB,KAC3D,cAAepJ,QAET,IAAI0M,GACR,+DACA,qBACA,CAACrK,KAAM,gCAAiCjC,QAASJ,IAC9C,IAAIuK,EAAMiC,MAAM8rB,GACpBnI,GAAemI,MAAQ1J,GAAU0J,IAA0B,IAApBA,EAAE3uB,QAAQ,QAClDmrB,GAAewD,UACT,IAAI5rB,GACR,yHAEA,qBAAsB,CAACrK,KAAM,sBAAuBjC,QAASJ,UAE5D,GAAG,UAAWA,IAAS0uB,GAAS1uB,EAAK,UAE1CA,EAAK,SAAW,CAACA,EAAK,eACjB,GAAG,SAAUA,GAAQ,UAAWA,EAAM,IAExCo4B,EAAQ,IAAiB,IAAVA,KAAe,WAAYp4B,UACrC,IAAI0M,GACR,0IAEa,qBACb,CAACrK,KAAM,6BAA8BjC,QAASJ,IAG/C,SAAUA,IACXA,EAAOA,EAAK,QACZjB,EAAOsK,OAAOtK,KAAKiB,GACnBo4B,EAAQr5B,EAAKc,aAEV,GAAa,IAAVu4B,GAAe,cAAep4B,EAAM,OAEtC22B,QAAeT,EAAal2B,EAAM,CACtC42B,cAAe52B,EACfuuB,UAAAA,EACAqH,eAAAA,EACAx1B,QAAAA,EACAsI,QAAAA,EACA8tB,WAAAA,IAGAx2B,OADY8B,IAAX60B,EACMA,EAEA,QAMRhI,GAAU3uB,KACV0I,EAAQ6vB,wBAA0B/B,IACf,OAAnBZ,GAAsD,WAA3BmB,KAEf,IAAVqB,GAAe,WAAYp4B,GAAQ,UAAWA,GACpC,IAAVo4B,GAAe,QAASp4B,GAAO,OAC1B22B,QAAeT,EAAa,CAChCU,cAAe52B,EACfuuB,UAAAA,EACAqH,eAAAA,EACAx1B,QAAAA,EACAsI,QAAAA,EACA8tB,WAAAA,IAGAx2B,OADY8B,IAAX60B,EACMA,EAEA,YAKN32B,GC7XT,gBAAO4wB,IAAaxoB,GAMdE,GAAM,GACZzK,OAAiByK,GAWjBA,GAAIkwB,oBAAsB,CAACz3B,EAAO2H,WAI1BjD,GAHNiD,EAAUA,GAAW,IAGEjD,QAAU,IAAIusB,GAAKl0B,iBAAiB,OACrDmD,EAAS,YAAa,WAC5BqH,GAAImwB,cAAc13B,EAAOE,EAAQ,WAAYwE,GAGtC6C,GAAIowB,cAAcz3B,IAc3BqH,GAAImwB,cAAgB,CAAC13B,EAAOE,EAAQY,EAAO4D,EAAQhB,EAAMlF,QAEpDgL,EAAMtH,QAAQlC,GAAQ,KACnB,MAAM0oB,KAAQ1oB,EAChBuH,GAAImwB,cAAchP,EAAMxoB,EAAQY,EAAO4D,OAAQ3D,EAAWvC,cAM1DgL,EAAMR,SAAShJ,eACdxB,GACDA,EAAKwD,KAAKhC,OAMXgM,GAAWtC,QAAQ1J,GAAQ,IACzB,UAAWA,EAAO,KACfsD,EAAOtD,EAAM,SAES,IAAvBsD,EAAKsF,QAAQ,QACd5I,EAAM,SAAWsD,EAAOoB,EAAOlH,MAAM8F,gBAGtC9E,GACDA,EAAKwD,KAAKhC,IAGP,GAAGxB,GAAQwN,GAAWrC,OAAO3J,GAAQ,OACpC43B,EAAQ,UACdrwB,GAAImwB,cAAc13B,EAAM,SAAUE,EAAQY,EAAO4D,EAAQhB,EAAMk0B,QAC/Dp5B,EAAKwD,KAAK,SAAU41B,OAOnB,UAAW53B,EAAO,OACbwJ,EAAQxJ,EAAM,aAChB,MAAMsD,KAAQkG,EACU,IAAvBlG,EAAKsF,QAAQ,OACdlE,EAAOlH,MAAM8F,GAMhBkG,EAAMF,YAAY5F,KACnBA,EAAOsI,GAAWjC,YAAY/J,GAC5B0E,EAAOlH,MAAMwC,EAAM,QAAUA,EAAM,QAIpCxB,GACDA,EAAKwD,KAAK,OAAQ0B,UAIdm0B,EAAW33B,EAAOY,GAClBH,EAAUk3B,EAASn0B,GAAQm0B,EAASn0B,IAAS,GACnD/C,EAAQ,OAAS+C,QACXo0B,EAAaxvB,OAAOtK,KAAKgC,GAAOtB,WAClC,IAAImN,KAAYisB,EAAY,IAEd,QAAbjsB,cAKa,aAAbA,EAAyB,OACpBksB,EAAiB,OAAQr0B,GACzBozB,EAAa92B,EAAM,gBACrB,MAAMg4B,KAAmBlB,EAAY,OACjCC,EAAQD,EAAWkB,OACrB,MAAM/O,KAAQ8N,EAAO,KACnBkB,EAAWhP,EAAK,OACjBjd,GAAWjC,YAAYkf,KACxBgP,EAAWvzB,EAAOlH,MAAMy6B,IAE1B1wB,GAAImwB,cAAczO,EAAM/oB,EAAQY,EAAO4D,EAAQuzB,GAC/ChH,GAAK/kB,SACH2rB,EAASI,GAAWD,EAAiBD,EACrC,CAAC5rB,iBAAiB,EAAME,gBAAgB,iBAOhC,WAAbR,EAAuB,CAEnBnI,KAAQxD,IACXA,EAAOwD,GAAQ,IAEjB6D,GAAImwB,cAAc13B,EAAM6L,GAAW3L,EAAQwD,EAAMgB,eAKnC,cAAbmH,EAA0B,CAC3BtE,GAAImwB,cAAc13B,EAAM6L,GAAW3L,EAAQY,EAAO4D,eAKpC,UAAbmH,GAAwBgkB,GAAUhkB,GAAW,IAC9B,WAAbA,GAAyBA,KAAYlL,IACrCX,EAAM6L,KAAclL,EAAQkL,IAC7B7L,EAAM6L,GAAU,SAAWlL,EAAQkL,GAAU,cACvC,IAAIF,GACR,gEACA,qBACA,CAACrK,KAAM,sBAAuBX,QAAAA,IAElCA,EAAQkL,GAAY7L,EAAM6L,kBAKtBqsB,EAAUl4B,EAAM6L,MAGQ,IAA3BA,EAASjD,QAAQ,QAClBiD,EAAWnH,EAAOlH,MAAMqO,IAIJ,IAAnBqsB,EAAQp5B,WAIP,IAAI0D,KAAK01B,KACK,UAAbrsB,IAEDrJ,EAAyB,IAApBA,EAAEoG,QAAQ,MAAelE,EAAOlH,MAAMgF,GAAKA,GAI/CwJ,GAAWzC,UAAU/G,IAAMwJ,GAAWvC,mBAAmBjH,GAAI,IAE3D,QAASA,IAAMA,EAAE,sBAKd0B,EAAK8H,GAAWjC,YAAYvH,GAChCkC,EAAOlH,MAAMgF,EAAE,QAAUA,EAAE,OAG7ByuB,GAAK/kB,SACHvL,EAASkL,EAAU,OAAQ3H,GAC3B,CAACiI,iBAAiB,EAAME,gBAAgB,IAC1C9E,GAAImwB,cAAcl1B,EAAGtC,EAAQY,EAAO4D,EAAQR,QACvC,GAAG8H,GAAWtC,QAAQlH,GAC3ByuB,GAAK/kB,SACHvL,EAASkL,EAAUrJ,EACnB,CAAC2J,iBAAiB,EAAME,gBAAgB,SACrC,GAAGL,GAAWrC,OAAOnH,GAAI,OAExBo1B,EAAQ,GACdrwB,GAAImwB,cAAcl1B,EAAE,SAAUtC,EAAQY,EAAO4D,EAAQhB,EAAMk0B,GAC3Dp1B,EAAI,SAAUo1B,GACd3G,GAAK/kB,SACHvL,EAASkL,EAAUrJ,EACnB,CAAC2J,iBAAiB,EAAME,gBAAgB,SAG1C9E,GAAImwB,cAAcl1B,EAAGtC,EAAQY,EAAO4D,EAAQhB,GAC5CutB,GAAK/kB,SACHvL,EAASkL,EAAUrJ,EAAG,CAAC2J,iBAAiB,EAAME,gBAAgB,SAzClE4kB,GAAK/kB,SAASvL,EAASkL,EAAU,GAAI,CAACM,iBAAiB,MAuD7D5E,GAAI4wB,mBAAqBj4B,UACjBk4B,EAAS,OACX,MAAM10B,KAAQ4E,OAAOtK,KAAKkC,GAAQxB,WAChC,MAAMwF,KAAMoE,OAAOtK,KAAKkC,EAAOwD,IAAOhF,OAAQ,OAC1CgqB,EAAOxoB,EAAOwD,GAAMQ,GACrBA,KAAMk0B,IACTA,EAAOl0B,GAAM,OAAQA,UAEjBm0B,EAAaD,EAAOl0B,OAEtB,MAAM2H,KAAYvD,OAAOtK,KAAK0qB,GAAMhqB,UACnCmxB,GAAUhkB,IAA0B,UAAbA,EAExBwsB,EAAWxsB,GAAYolB,GAAK3zB,MAAMorB,EAAK7c,aAGnC,MAAM5K,KAASynB,EAAK7c,GACtBolB,GAAK/kB,SACHmsB,EAAYxsB,EAAUolB,GAAK3zB,MAAM2D,GACjC,CAACkL,iBAAiB,EAAME,gBAAgB,WAO7C+rB,GAGT7wB,GAAIowB,cAAgBz3B,UAEZo4B,EAAep4B,EAAO,YACtBq4B,EAAajwB,OAAOtK,KAAKkC,GAAQxB,WACnC,MAAMsE,KAAau1B,EAAY,IAChB,aAAdv1B,iBAGGw1B,EAAUt4B,EAAO8C,OACnBrC,EAAU23B,EAAat1B,GACvBrC,EAKQ,WAAYA,IACtBA,EAAQ,UAAY,IALpB23B,EAAat1B,GAAarC,EAAU,OAC3BqC,WACG,UAKRlC,EAAQH,EAAQ,cAClB,MAAMuD,KAAMoE,OAAOtK,KAAKw6B,GAAS95B,OAAQ,OACrCgqB,EAAO8P,EAAQt0B,GAEjB8H,GAAWvC,mBAAmBif,IAChC5nB,EAAMkB,KAAK0mB,WAIV4P,GC3RT,MACE7uB,mBAAoBgvB,IAClBpxB,IAGFowB,oBAAqBiB,IACnBrxB,GAEEE,GAAM,GACZzK,OAAiByK,GASjBA,GAAIoxB,QAAU34B,UACNs4B,EAAeI,GAAqB14B,GAGpC44B,EAAY,GACZ56B,EAAOsK,OAAOtK,KAAKs6B,GAAc55B,WACnC,IAAIqO,EAAK,EAAGA,EAAK/O,EAAKc,SAAUiO,EAAI,OAChC2b,EAAO4P,EAAat6B,EAAK+O,IAE3B0rB,GAAoB/P,IACtBkQ,EAAU52B,KAAK0mB,UAGZkQ,GCzBT,MAAMtrB,SAEJA,aACAC,YACAC,WACAC,YACAC,oBAGAG,eAKAE,cACAC,eACAC,cACAvO,IACE2H,GAEEstB,GAAc,sCAEdptB,GAAM,GACZzK,OAAiByK,GAsPjB,SAASsxB,GAAar2B,EAAGs2B,EAAgBC,MAEpCv2B,EAAExB,SAAS6iB,SAAS,cACd,OAAQrhB,EAAEvB,aAIbhC,EAAO,UAAWuD,EAAEvB,UAGvBuB,EAAErB,SACHlC,EAAK,aAAeuD,EAAErB,aACjB,KACDmC,EAAOd,EAAEtB,SAASD,SAClBqC,IACFA,EAAO5D,IAEN4D,IAASuK,GAAkB,CAC5BvK,EAAO,YAELrE,EAAK,UAAYgX,KAAKlH,MAAM9P,EAAK,WACjC,MAAMqI,SACA,IAAIqE,GACR,oCACA,4BACA,CAACrK,KAAM,uBAAwBL,MAAOhC,EAAK,UAAW6oB,MAAOxgB,QAIhEwxB,EAAgB,IACdx1B,IAASyK,GACY,SAAnB9O,EAAK,UACNA,EAAK,WAAY,EACU,UAAnBA,EAAK,YACbA,EAAK,WAAY,QAEd,GAAGuK,EAAMP,UAAUhK,EAAK,cAC1BqE,IAAS2K,GAAa,OACjBpP,EAAI8C,SAAS1C,EAAK,UAAW,IAChCJ,EAAEm6B,QAAQ,KAAO/5B,EAAK,YACvBA,EAAK,UAAYJ,QAEXyE,IAAS0K,KACjB/O,EAAK,UAAYkK,WAAWlK,EAAK,YAIjC,CAAC8O,GAAaE,GAAaD,GAAYtO,IAAY+iB,SAASnf,KAC9DrE,EAAK,SAAWqE,QAEb,GAAoB,kBAAjBy1B,GACRz1B,EAAKC,WAAW,+BAAgC,QACvCpC,EAAU4wB,GAAazuB,EAAKlD,MAAM,QACxCe,EAASrC,OAAS,IACnBG,EAAK,aAAekC,EAChBA,EAASV,MAAMk0B,KACjB/W,QAAQgT,KAAM,kCAAiCzvB,IAGnDlC,EAAK,cAAgB8yB,OACbzuB,IAAS5D,KACjBT,EAAK,SAAWqE,UAIbrE,EA7STsI,GAAI0xB,QAAUvxB,MACZzH,GAEEi5B,WAAAA,GAAa,EACbJ,eAAAA,GAAiB,EACjBC,aAAAA,EAAe,eAGXT,EAAe,GACfa,EAAW,YAAab,GACxBc,EAAiB,OAEnB,MAAMt5B,KAAQG,EAAS,OAEnByD,EAAgC,iBAAxB5D,EAAKgB,MAAME,SACvB,WAAalB,EAAKgB,MAAMG,MACrByC,KAAQy1B,IACXA,EAASz1B,GAAQ,IAEP,aAATA,GAAyBA,KAAQ40B,IAClCA,EAAa50B,GAAQ,OAAQA,UAGzB80B,EAAUW,EAASz1B,GAGnBpB,EAAIxC,EAAKa,QAAQM,MACjBsB,EAAIzC,EAAKc,UAAUK,MACnBuB,EAAI1C,EAAKe,OAEVyB,KAAKk2B,IACRA,EAAQl2B,GAAK,OAAQA,UAEjBomB,EAAO8P,EAAQl2B,GAEf+2B,EAAe72B,EAAExB,SAAS6iB,SAAS,WACtCwV,KAAkB72B,EAAEvB,SAASu3B,KAC9BA,EAAQh2B,EAAEvB,OAAS,OAAQuB,EAAEvB,QAG5BsB,IAAMmL,KAAawrB,GAAcG,EAAc,CAChDpI,GAAK/kB,SAASwc,EAAM,QAASlmB,EAAEvB,MAAO,CAACkL,iBAAiB,mBAIpDlL,EAAQ43B,GAAar2B,EAAGs2B,EAAgBC,MAC9C9H,GAAK/kB,SAASwc,EAAMnmB,EAAGtB,EAAO,CAACkL,iBAAiB,IAI7CktB,KACE72B,EAAEvB,QAAUwM,GAAS,OAEhB5M,EAAS23B,EAAQh2B,EAAEvB,OACpB,WAAYJ,IACfA,EAAOy4B,OAAS,IAElBz4B,EAAOy4B,OAAOt3B,KAAK,CACjB0mB,KAAAA,EACA7c,SAAUtJ,EACVtB,MAAAA,SAEMuB,EAAEvB,SAASm4B,EAEnBA,EAAe52B,EAAEvB,QAAS,EAG1Bm4B,EAAe52B,EAAEvB,OAAS,CACxBynB,KAAAA,EACA7c,SAAUtJ,EACVtB,MAAAA,OAwEJ,MAAMyC,KAAQy1B,EAAU,OACpBI,EAAcJ,EAASz1B,QAGxB+J,MAAW8rB,kBAKVC,EAAMD,EAAY9rB,OACpB+rB,EAAIF,YAGJ,IAAIG,KAASD,EAAIF,OAAQ,KACvB5Q,EAAO+Q,EAAM/Q,KACb7c,EAAW4tB,EAAM5tB,SACjBmd,EAAOyQ,EAAMx4B,YACXzC,EAAO,GACPk7B,EAAY,OAQdC,EAAerxB,OAAOtK,KAAK0qB,GAAM5pB,YAC/B+M,IAAa2B,IACjBhE,EAAMR,SAASowB,EAAe1Q,EAAK,UACnClf,EAAMtH,QAAQwmB,EAAKnb,MAA0C,IAA3Bmb,EAAKnb,IAAWzO,QAClD0K,EAAMtH,QAAQwmB,EAAKlb,MAAwC,IAA1Bkb,EAAKlb,IAAU1O,SAC9B,IAAjB66B,GACmB,IAAjBA,GAAsBnwB,EAAMtH,QAAQwmB,EAAK,WACjB,IAAzBA,EAAK,SAAS5pB,QAAgB4pB,EAAK,SAAS,KAAOpb,MACrD9O,EAAKwD,KAAK0mB,EAAKnb,IAAW,IAC1BmsB,EAAU13B,KAAK0mB,EAAK,QAGpB+Q,EAAQL,EAAe1Q,EAAK,QAC5BA,EAAO+Q,EAAM/Q,KACb7c,EAAW4tB,EAAM5tB,SACjBmd,EAAOyQ,EAAMx4B,MACb04B,EAAerxB,OAAOtK,KAAK0qB,GAAM5pB,OAG7BkN,GAAWjC,YAAY2e,aAMtBM,EAAK,OACZA,EAAK,SAAWxqB,EAAKosB,cACjB,MAAMgP,KAAYF,SACbH,EAAYK,UAIhBJ,EAAIF,cAGP30B,EAAS,GACTkzB,EAAWvvB,OAAOtK,KAAKs6B,GAAc55B,WACvC,MAAMiC,KAAWk3B,EAAU,OACvBnP,EAAO4P,EAAa33B,MACvBA,KAAWw4B,EAAU,OAChBr4B,EAAQ4nB,EAAK,UAAY,GACzB6Q,EAAcJ,EAASx4B,GACvBk5B,EAAgBvxB,OAAOtK,KAAKu7B,GAAa76B,WAC3C,MAAMo7B,KAAgBD,EAAe,OACjCnR,EAAO6Q,EAAYO,GAErB9tB,GAAWvC,mBAAmBif,IAChC5nB,EAAMkB,KAAK0mB,IAKb1c,GAAWvC,mBAAmBif,IAChC/jB,EAAO3C,KAAK0mB,UAIT/jB,GCxQT,MAAM+yB,cAACA,IAAiBrwB,cACjBwoB,IAAaxoB,IAMdkG,UAGJA,GAHIC,SAIJA,GAJIC,QAKJA,GALIC,SAMJA,GANIG,iBASJA,GATIrO,eAWJA,GAXIuO,YAcJA,GAdIC,WAeJA,GAfIC,YAgBJA,GAhBIvO,WAiBJA,IACE2H,IAGFwI,WAAYuf,IACV/nB,GAEEE,GAAM,GACZzK,OAAiByK,GAkDjB,SAASwyB,GAAY95B,EAASa,EAAOk5B,EAAWt1B,EAAQiD,SAChDurB,EAAM5qB,OAAOtK,KAAK8C,GAAOpC,WAC3B,MAAMwF,KAAMgvB,EAAK,OACbxK,EAAO5nB,EAAMoD,GACb4zB,EAAaxvB,OAAOtK,KAAK0qB,GAAMhqB,WACjC,IAAImN,KAAYisB,EAAY,OACxBf,EAAQrO,EAAK7c,MACH,UAAbA,EACDA,EAAW6B,QACN,GAAGmiB,GAAUhkB,gBAIhB,MAAMod,KAAQ8N,EAAO,OAEjBp2B,EAAU,CACdK,SAAUkD,EAAGX,WAAW,MAAQ,YAAc,YAC9CtC,MAAOiD,OAILkrB,GAAelrB,kBAKbtD,EAAY,CAChBI,SAAU6K,EAAStI,WAAW,MAAQ,YAAc,YACpDtC,MAAO4K,OAILujB,GAAevjB,eAKO,cAAvBjL,EAAUI,WACV2G,EAAQsyB,qCAKLp5B,EACJq5B,GAAajR,EAAMvkB,EAAQzE,EAAS+5B,EAAWryB,EAAQoxB,cAEtDl4B,GACDZ,EAAQ+B,KAAK,CACXrB,QAAAA,EACAC,UAAAA,EACAC,OAAAA,EACAC,MAAOk5B,OA8EnB,SAASE,GAAajR,EAAMvkB,EAAQzE,EAAS+5B,EAAWjB,SAChDl4B,EAAS,MAGZmL,GAAWtC,QAAQuf,GAAO,CAC3BpoB,EAAOG,SAAW,UAClBH,EAAOI,WAAQF,EACfF,EAAOK,SAAW,CAChBF,SAAU,iBAERC,EAAQgoB,EAAK,gBACX/nB,EAAW+nB,EAAK,UAAY,QAGlB,UAAb/nB,EACDL,EAAOI,MCnOI,SAASk5B,EAAWt5B,UACpB,OAAXA,GAAqC,iBAAXA,GAAwC,MAAjBA,EAAOu5B,OACnDnkB,KAAK+N,UAAUnjB,GAGpBoB,MAAMC,QAAQrB,GACT,IAAMA,EAAO6X,OAAO,CAAC6e,EAAG8C,EAAIC,IAG1B/C,GAFc,IAAP+C,EAAW,GAAK,KAEXH,OADEp5B,IAAPs5B,GAAkC,iBAAPA,EAAkB,KAAOA,GAEjE,IAAM,IAGJ,IAAM/xB,OAAOtK,KAAK6C,GAAQnC,OAAOga,OAAO,CAAC6e,EAAG8C,EAAIC,aAClCv5B,IAAfF,EAAOw5B,IACe,iBAAfx5B,EAAOw5B,UACT9C,SAGFA,GADoB,IAAbA,EAAEz4B,OAAe,GAAK,KACjBq7B,EAAUE,GAAM,IAAMF,EAAUt5B,EAAOw5B,KACzD,IAAM,ID+MUE,CAAiBt5B,GAChCJ,EAAOK,SAASD,MAAQ4M,QACnB,GAAGrE,EAAMpB,UAAUnH,GACxBJ,EAAOI,MAAQA,EAAMuH,WACrB3H,EAAOK,SAASD,MAAQC,GAAY6M,QAC/B,GAAGvE,EAAMd,SAASzH,IAAUC,IAAa8M,GAC1CxE,EAAMd,SAASzH,KACjBA,EAAQkI,WAAWlI,IAGrBJ,EAAOI,MAAQA,EAAMu5B,cAAc,IAAIp5B,QAAQ,aAAc,OAC7DP,EAAOK,SAASD,MAAQC,GAAY8M,QAC/B,GAAGxE,EAAMb,SAAS1H,GACvBJ,EAAOI,MAAQA,EAAM+3B,QAAQ,GAC7Bn4B,EAAOK,SAASD,MAAQC,GAAY+M,QAC/B,GAAoB,kBAAjB8qB,GACR,eAAgB9P,EAAM,OAChB/nB,EAAW,+BACd+nB,EAAK,cAAgB,IACrB,IAAGA,EAAK,cACXpoB,EAAOK,SAASD,MAAQC,EACxBL,EAAOI,MAAQA,MACP,cAAegoB,GACvBpoB,EAAOI,MAAQA,EACfJ,EAAOK,SAASD,MAAQC,GAAY1B,GACpCqB,EAAOM,SAAW8nB,EAAK,eAEvBpoB,EAAOI,MAAQA,EACfJ,EAAOK,SAASD,MAAQC,GAAYxB,SAEjC,GAAGsM,GAAWrC,OAAOsf,GAAO,OAC3B2O,EAzGV,SAAoBp5B,EAAMkG,EAAQzE,EAAS+5B,EAAWjB,SAC9C0B,EAAQ,CAACz5B,SAAU,YAAaC,MAAOsM,IACvCmtB,EAAO,CAAC15B,SAAU,YAAaC,MAAOuM,IACtCgsB,EAAM,CAACx4B,SAAU,YAAaC,MAAOwM,IAErC+C,EAAOhS,EAAKkS,MAEZ/L,EAAS6L,EAAO,CAACxP,SAAU,YAAaC,MAAOyD,EAAOlH,SAAWg8B,MACnE74B,EAAUgE,MAEV,MAAMskB,KAAQzqB,EAAM,OAChBqC,EAASq5B,GAAajR,EAAMvkB,EAAQzE,EAAS+5B,EAAWjB,GACxD/5B,EAAO,CAACgC,SAAU,YAAaC,MAAOyD,EAAOlH,SACnDyC,EAAQ+B,KAAK,CACXrB,QAAAA,EACAC,UAAW65B,EACX55B,OAAAA,EACAC,MAAOk5B,IAET/5B,EAAQ+B,KAAK,CACXrB,QAAAA,EACAC,UAAW85B,EACX75B,OAAQ7B,EACR8B,MAAOk5B,IAETr5B,EAAU3B,KAITwR,EAAM,OACD3P,EAASq5B,GAAa1pB,EAAM9L,EAAQzE,EAAS+5B,EAAWjB,GAC9D94B,EAAQ+B,KAAK,CACXrB,QAAAA,EACAC,UAAW65B,EACX55B,OAAAA,EACAC,MAAOk5B,IAET/5B,EAAQ+B,KAAK,CACXrB,QAAAA,EACAC,UAAW85B,EACX75B,OAAQ24B,EACR14B,MAAOk5B,WAIJr1B,EA6DHg2B,CAAW1R,EAAK,SAAUvkB,EAAQzE,EAAS+5B,EAAWjB,GACxDl4B,EAAOG,SAAW42B,EAAM52B,SACxBH,EAAOI,MAAQ22B,EAAM32B,UAChB,OAECiD,EAAKsF,EAAMR,SAASigB,GAAQA,EAAK,OAASA,EAChDpoB,EAAOG,SAAWkD,EAAGX,WAAW,MAAQ,YAAc,YACtD1C,EAAOI,MAAQiD,QAIM,cAApBrD,EAAOG,UAA6BouB,GAAevuB,EAAOI,OAItDJ,EAHE,KApOX0G,GAAIqzB,MAAQ,CAAC56B,EAAO2H,WAEZjD,EAAS,IAAIusB,GAAKl0B,iBAAiB,OACnCy7B,EAAU,YAAa,IAC7Bd,GAAc13B,EAAOw4B,EAAS,WAAY9zB,SAEpCzE,EAAU,GACVs4B,EAAajwB,OAAOtK,KAAKw6B,GAAS95B,WACpC,MAAMsE,KAAau1B,EAAY,KAC7ByB,KACa,aAAdh3B,EACDg3B,EAAY,CAACh5B,SAAU,eAAgBC,MAAO,QACzC,CAAA,IAAGmuB,GAAepsB,YAErBg3B,EADCh3B,EAAUO,WAAW,MACV,CAACvC,SAAU,aAEX,CAACA,SAAU,aAEzBg5B,EAAU/4B,MAAQ+B,EAKpB+2B,GAAY95B,EAASu4B,EAAQx1B,GAAYg3B,EAAWt1B,EAAQiD,UAGvD1H,GEpET,MAAM4vB,UAACA,IAAaxoB,IAOlBqwB,cAAemD,GACf1C,mBAAoB2C,IAClBzzB,GAEEE,GAAM,GACZzK,OAAiByK,GAyWjB,SAASwzB,GAAqBC,SACtBC,EAAQ,OACV,MAAMh0B,KAAO+zB,OACGj6B,IAAfi6B,EAAM/zB,KACPg0B,EAAM,IAAMh0B,GAAO,CAAC+zB,EAAM/zB,WAGvB,CAACg0B,GAaV,SAASC,GAA0BC,EAAgBr6B,EAAOs6B,OACpD,IAAIv8B,EAAIu8B,EAAat8B,OAAS,EAAGD,GAAK,IAAKA,EAAG,OAC1C8B,EAAUy6B,EAAav8B,MAC1B8B,EAAQG,QAAUA,GACnBH,EAAQA,QAAQ,SAAWw6B,EAAe,cACnC,SAGJ,EAYT,SAASE,GAAcJ,EAAOtzB,EAASjE,SAC/B43B,EAAO,IAAM53B,MACfzE,EAAQq8B,KAAQL,EAAQA,EAAMK,GAAM,GAAK3zB,EAAQjE,MACzC,UAATA,MAKW,IAATzE,EACDA,EAAO,aACF,IAAY,IAATA,EACRA,EAAO,cACF,GAAY,YAATA,GAA+B,WAATA,GAA8B,UAATA,GAC1C,WAATA,GAA8B,UAATA,GAA6B,UAATA,QACnC,IAAI0M,GACR,mDACA,qBAAsB,CAACrK,KAAM,uBAAwB25B,MAAAA,WAGpDh8B,EAQT,SAASs8B,GAAeN,OAClBzxB,EAAMtH,QAAQ+4B,IAA2B,IAAjBA,EAAMn8B,SAAiB0K,EAAMR,SAASiyB,EAAM,UAChE,IAAItvB,GACR,mEACA,qBAAsB,CAACsvB,MAAAA,OAGxB,QAASA,EAAM,OACZ,MAAM/2B,KAAM+sB,GAAK1mB,QAAQ0wB,EAAM,GAAG,YAE/BzxB,EAAMR,SAAS9E,KAAOuK,GAAIoB,WAAW3L,IACvCsF,EAAMH,SAASnF,IAA4B,IAArBA,EAAG0E,QAAQ,YAC5B,IAAI+C,GACR,gDACA,qBAAsB,CAACrK,KAAM,gBAAiB25B,MAAAA,OAKnD,UAAWA,EAAM,OACd,MAAM33B,KAAQ2tB,GAAK1mB,QAAQ0wB,EAAM,GAAG,cAEjCzxB,EAAMR,SAAS1F,KAASmL,GAAIoB,WAAWvM,IACzCkG,EAAMH,SAAS/F,IAAgC,IAAvBA,EAAKsF,QAAQ,YAChC,IAAI+C,GACR,kDACA,qBAAsB,CAACrK,KAAM,gBAAiB25B,MAAAA,IA8CxD,SAASO,GAAeC,EAAO96B,EAASs6B,EAAOD,OAEzCU,GAAW,EACXC,GAAc,MAEd,MAAM10B,KAAOg0B,EAAO,KAClBW,GAAY,QACVC,EAAa5K,GAAKxkB,UAAU9L,EAASsG,GACrC60B,EAAgD,IAAtC7K,GAAKxkB,UAAUwuB,EAAOh0B,GAAKnI,UAEhC,QAARmI,MAEEuC,EAAMT,cAAckyB,EAAM,OAAO,IAAM,IACxCW,GAAY,EACJX,EAAM,OAAOn8B,QAAU,IAC/B88B,EAAYX,EAAM,OAAOxY,SAASoZ,EAAW,MAE3Cb,EAAMe,kBACDH,OAEJ,GAAW,UAAR30B,EAAiB,IAGzBy0B,GAAW,EACRI,EAAS,IACPD,EAAW/8B,OAAS,SAEd,EAET88B,GAAY,OACP,GAA6B,IAA1BX,EAAM,SAASn8B,QACvB0K,EAAMT,cAAckyB,EAAM,SAAS,IAEnCW,EAAYC,EAAW/8B,OAAS,WAG5B,MAAMwE,KAAQ23B,EAAM,SAGpBW,KAFCpyB,EAAMR,SAAS1F,MAAS,aAAcA,MAI3Bs4B,GAAaC,EAAWnxB,KAAKsxB,GAAMA,IAAO14B,QAIxD03B,EAAMe,kBACDH,MAEJ,CAAA,GAAG/L,GAAU5oB,YAEb,OAECg1B,EAAYhL,GAAKxkB,UAAUwuB,EAAOh0B,GAAK,OACzCi1B,GAAa,KACdD,IACDV,GAAe,CAACU,IAChBC,EAAa,aAAcD,GAI7BP,GAAW,EAIc,IAAtBG,EAAW/8B,QAAgBo9B,cAK3BL,EAAW/8B,OAAS,GAAKg9B,SACnB,UAGQ/6B,IAAdk7B,EAAyB,IAGvBJ,EAAW/8B,OAAS,SACd,EAET88B,GAAY,UAET5vB,GAAWrC,OAAOsyB,GAAY,OACzBE,EAAYF,EAAU,SAAS,MAClCjwB,GAAWrC,OAAOkyB,EAAW,IAAK,OAC7BO,EAAiBP,EAAW,GAAG,SAElC7vB,GAAWtC,QAAQyyB,GAEpBP,EAAYQ,EAAe1xB,KAAK2xB,GAAMC,GAAYH,EAAWE,KACrDrwB,GAAWzC,UAAU4yB,IAC7BnwB,GAAWvC,mBAAmB0yB,MAC9BP,EAAYQ,EAAe1xB,KAAK2xB,GAAME,GACpCd,EAAOU,EAAWE,EAAIrB,WAI5BY,EADQ5vB,GAAWtC,QAAQuyB,GACfJ,EAAWnxB,KAAK0sB,GAAMkF,GAAYL,EAAW7E,IACjDprB,GAAWvC,mBAAmBwyB,GAEpCJ,EAAWnxB,KAAK0sB,GAAMmF,GAAWd,EAAOQ,EAAW7E,EAAI4D,MACjDxxB,EAAMR,SAASizB,IACXJ,EAAW/8B,OAAS,OAQlC88B,GAAaZ,EAAMe,kBACd,EAGTJ,EAAcA,GAAeC,SAIxBF,GAAYC,EASrB,SAASa,GAAaf,EAAOv3B,SAErBu4B,EAAShB,EAAMiB,aAAajB,EAAM36B,OAClC67B,EAAQF,EAAOv4B,GACf4xB,EAAS6G,EAAM7G,OACfjqB,EAAW8wB,EAAM9wB,SAGjBlL,EAAU,OAAQuD,MAGrBsF,EAAMtH,QAAQ4zB,QAEX,IAAIj3B,EAAI,EAAGA,EAAIi3B,EAAOh3B,SAAUD,KAC/BoyB,GAAKhlB,cAAc6pB,EAAOj3B,GAAI8B,GAAU,CACzCm1B,EAAOj3B,GAAK8B,aAIX,OAECi8B,EAAWpzB,EAAMtH,QAAQ4zB,EAAOjqB,IACtColB,GAAKtkB,YAAYmpB,EAAQjqB,EAAUlL,EAAS,CAACwL,gBAAiBywB,IAC9D3L,GAAK/kB,SAAS4pB,EAAQjqB,EAAUlL,EAAS,CAACwL,gBAAiBywB,UAIvDC,EAAmB34B,UAEjBgvB,EAAM5qB,OAAOtK,KAAKy+B,OACpB,MAAMz9B,KAAQk0B,EACbl0B,KAAQy9B,GAAUjzB,EAAMR,SAASyzB,EAAOz9B,GAAM82B,SAC/C2G,EAAOz9B,GAAM82B,OAAO,SAAW5xB,WACxBu4B,EAAOz9B,GACd69B,EAAiB79B,KAIvB69B,EAAiB34B;;;;;;;;GAwEnB,SAAS44B,GAAgBhH,EAAQjqB,EAAU8E,GACtCnH,EAAMR,SAAS8sB,GAChB7E,GAAK/kB,SAAS4pB,EAAQjqB,EAAU8E,EAAQ,CAACxE,iBAAiB,IAE1D2pB,EAAO9zB,KAAK2O,GAYhB,SAAS4rB,GAAWd,EAAOsB,EAAS97B,EAAO+5B,QACpC,QAAS/5B,UACL,QAEH+7B,EAAavB,EAAM5D,SAAS52B,EAAM,eACjC+7B,GAAcxB,GAAeC,EAAOuB,EAAYD,EAAS/B,GAkBlE,SAASsB,GAAYS,EAAS97B,SACtB+L,EAAK/L,EAAM,UACXuC,EAAKvC,EAAM,SACXg8B,EAAKh8B,EAAM,aACXgM,EAAK8vB,EAAQ,UAChBvzB,EAAMtH,QAAQ66B,EAAQ,WACrBA,EAAQ,UAAY,CAACA,EAAQ,WAC/B,GACIt5B,EAAKs5B,EAAQ,SAChBvzB,EAAMtH,QAAQ66B,EAAQ,UACrBA,EAAQ,SAAW,CAACA,EAAQ,UAC9B,GACIG,EAAKH,EAAQ,aAChBvzB,EAAMtH,QAAQ66B,EAAQ,cACrBA,EAAQ,aAAe,CAACA,EAAQ,cAClC,UAEe,IAAd9vB,EAAGnO,QAA8B,IAAd2E,EAAG3E,QAA8B,IAAdo+B,EAAGp+B,WAGvCmO,EAAGwV,SAASzV,KAAOxD,EAAMT,cAAckE,EAAG,WAGzCzJ,GAAoB,IAAdC,EAAG3E,QAAgB2E,EAAGgf,SAASjf,IAAOA,GAChDgG,EAAMT,cAActF,EAAG,UAGnBw5B,GAAoB,IAAdC,EAAGp+B,QAAgBo+B,EAAGza,SAASwa,IAAOA,GAChDzzB,EAAMT,cAAcm0B,EAAG,MAxxB3B31B,GAAI41B,qBAAuB,CAACn9B,EAAOi7B,EAAOtzB,WAElC8zB,EAAQ,CACZ9zB,QAAAA,EACAy1B,UAAU,EACVt8B,MAAO,WACPq4B,SAAU,YAAa,IACvBiC,aAAc,GACdhT,KAAM,GACNiV,SAAU,IAKN34B,EAAS,IAAIusB,GAAKl0B,iBAAiB,OACzC89B,GAAe76B,EAAOy7B,EAAMtC,SAAU,WAAYz0B,GAC/CiD,EAAQywB,SACTqD,EAAMtC,SAAS,WAAa2B,GAAoBW,EAAMtC,UACtDsC,EAAM36B,MAAQ,WAEhB26B,EAAM5D,SAAW4D,EAAMtC,SAASsC,EAAM36B,aAGhCw8B,EAAS,UACf/1B,GAAI0zB,MAAMQ,EAAOnzB,OAAOtK,KAAKy9B,EAAM5D,UAAUn5B,OAAQu8B,EAAOqC,GAGzD31B,EAAQ41B,4BAET51B,EAAQ61B,cACNl1B,OAAOtK,KAAKy9B,EAAM4B,UAAUxzB,OAAO3F,GAAoC,IAA9Bu3B,EAAM4B,SAASn5B,GAAIpF;AAIhE6I,EAAQygB,KAAO,GAsnBjB,SAASqV,EAAiBz9B,EAAO2H,MAE5B6B,EAAMtH,QAAQlC,UACRA,EAAMmS,IAAIlR,GAASw8B,EAAiBx8B,EAAO0G,OAGjD6B,EAAMR,SAAShJ,GAAQ;;GAErB,cAAeA,SACTA,EAAM,aAAa,MAIzBgM,GAAWtC,QAAQ1J,UACbA,KAINgM,GAAWrC,OAAO3J,UACnBA,EAAM,SAAWy9B,EAAiBz9B,EAAM,SAAU2H,GAC3C3H,KAIN,QAASA,EAAO,OACXkE,EAAKlE,EAAM,UACd2H,EAAQygB,KAAK9c,eAAepH,GAAK,OAC5ByvB,EAAMhsB,EAAQygB,KAAKlkB,GAAI0E,QAAQ5I,OACzB,IAAT2zB,SAEMhsB,EAAQygB,KAAKlkB,GAAIyvB,GAG1BhsB,EAAQygB,KAAKlkB,GAAIlC,KAAKhC,QAGtB2H,EAAQygB,KAAKlkB,GAAM,CAAClE,OAKpB,MAAM09B,KAAQ19B,EAEJ,QAAT09B,GAAkB/1B,EAAQ61B,cAAc/a,SAASziB,EAAM09B,WACjD19B,EAAM,OAIfA,EAAM09B,GAAQD,EAAiBz9B,EAAM09B,GAAO/1B,UAGzC3H,EAxqBAy9B,CAAiBH,EAAQ31B,IAYlCJ,GAAI0zB,MAAQ,CAACQ,EAAO5D,EAAUoD,EAAOnF,EAAQjqB,EAAW,QAEtD0vB,GAAeN,GACfA,EAAQA,EAAM,SAGRtzB,EAAU8zB,EAAM9zB,QAChBqzB,EAAQ,CACZ2B,MAAOtB,GAAcJ,EAAOtzB,EAAS,SACrCg2B,SAAUtC,GAAcJ,EAAOtzB,EAAS,YACxCo0B,WAAYV,GAAcJ,EAAOtzB,EAAS,eAIxC8zB,EAAMrT,KAAK9c,eAAemwB,EAAM36B,SAClC26B,EAAMrT,KAAKqT,EAAM36B,OAAS,UAEtBsnB,EAAOqT,EAAMrT,KAAKqT,EAAM36B,OAGxB88B,EAwYR,SAAyBnC,EAAO5D,EAAUoD,EAAOD,SAEzC/7B,EAAO,OACT,MAAMiF,KAAM2zB,EAAU,OAClBl3B,EAAU86B,EAAMtC,SAASsC,EAAM36B,OAAOoD,GACzCs3B,GAAeC,EAAO96B,EAASs6B,EAAOD,KACvC/7B,EAAKiF,GAAMvD,UAGR1B,EAjZS4+B,CAAgBpC,EAAO5D,EAAUoD,EAAOD,GAGlD9H,EAAM5qB,OAAOtK,KAAK4/B,GAASl/B,WAC7B,MAAMwF,KAAMgvB,EAAK,OACbvyB,EAAUi9B,EAAQ15B,MAKR,OAAb2H,EACD4vB,EAAMiB,aAAe,EAAEjB,EAAM36B,OAAQ,IAErC26B,EAAMiB,aAAajB,EAAM36B,OAAS26B,EAAMiB,aAAajB,EAAM36B,QAAU,GAGpD,UAAhBk6B,EAAM2B,OAAqBz4B,KAAMkkB,EAAM,CAMxC0U,GAAgBhH,EAAQjqB,EAAUuc,EAAKlkB,mBAKnCyM,EAAS,OAAQzM,MACC,IAArBA,EAAG0E,QAAQ,OACZqoB,GAAK/kB,SAASuvB,EAAM4B,SAAUn5B,EAAIyM,EAAQ,CAACxE,iBAAiB,IAE9Dic,EAAKlkB,GAAMyM,GAGS,WAAhBqqB,EAAM2B,OAAsC,UAAhB3B,EAAM2B,QAAsBlB,EAAMqC,WAC1D,IAAInyB,GACR,mDACA,qBAAsB,CAACrK,KAAM,uBAAwB25B,MAAAA,OAGrDQ,EAAM2B,WAAY3B,EAAMiB,aAAajB,EAAM36B,OAAOwK,eAAepH,OAUlEu3B,EAAM2B,UACU,WAAhBpC,EAAM2B,QACPzB,GAA0Bv6B,EAAS86B,EAAM36B,MAAO26B,EAAML,kBAMrDK,EAAM2B,UACU,UAAfpC,EAAM2B,OAAoC,SAAf3B,EAAM2B,QAClClB,EAAMiB,aAAajB,EAAM36B,OAAOwK,eAAepH,OAM/B,UAAhB82B,EAAM2B,OAEJz4B,KAAMu3B,EAAMiB,aAAajB,EAAM36B,QAChC07B,GAAaf,EAAOv3B,GAIxBu3B,EAAMiB,aAAajB,EAAM36B,OAAOoD,GAAM,CAAC4xB,OAAAA,EAAQjqB,SAAAA,GAG/C4vB,EAAML,aAAap5B,KAAK,CAACrB,QAAAA,EAASG,MAAO26B,EAAM36B,QAG5CoD,KAAMu3B,EAAMtC,SAAU,KACnB4E,GAAU,EACVC,EAAW,KACV,WAAY/C,GAIf+C,EAAW/C,EAAM,UAAU,GAC3B8C,IAAmB,YAAP75B,GAA2B,aAAPA,GAC5BsF,EAAMR,SAASg1B,KACjBA,EAAW,MANbD,EAA0B,YAAhBtC,EAAM36B,MAChBk9B,EAAW,IASVD,GAEDx2B,GAAI0zB,MACF,IAAIQ,EAAO36B,MAAOoD,EAAIk5B,UAAU,GAChC90B,OAAOtK,KAAKy9B,EAAMtC,SAASj1B,IAAKxF,OAAQ,CAACs/B,GAAWrtB,EAAQ,UAK/D,cAAesqB,GAChB1zB,GAAI0zB,MACF,IAAIQ,EAAO2B,UAAU,GACrBvF,EAAUoD,EAAM,aAActqB,EAAQ,iBAItC,MAAM+sB,KAAQp1B,OAAOtK,KAAK2C,GAASjC,UAElCmxB,GAAU6N,OACX/sB,EAAO+sB,GAAQzM,GAAK3zB,MAAMqD,EAAQ+8B,IAEtB,UAATA,MAEG,MAAMp6B,KAAQ3C,EAAQ,SACE,IAAvB2C,EAAKsF,QAAQ,OACdqoB,GAAK/kB,SACHuvB,EAAM4B,SAAU/5B,EAAMqN,EAAQ,CAACxE,iBAAiB,aAQvD6uB,EAAM2C,UAAcD,KAAQzC,MAK3B,MAAMz4B,KAAK7B,EAAQ+8B,GAAO,OACtBM,EAAYN,KAAQzC,EACxBA,EAAMyC,GAAQ3C,GAAqBC,MAGlChvB,GAAWrC,OAAOnH,GAAI,OACjBw7B,EACH/C,EAAMyC,IAASzC,EAAMyC,GAAM,IAAMzC,EAAMyC,GAAM,GAAG,SAC/CzC,EAAMyC,GAAM,GAAG,SACf3C,GAAqBC,GAGnBx8B,EAAO,SAAU,IACvBs+B,GAAgBnsB,EAAQ+sB,EAAMl/B,SAGxBy/B,EAAMz7B,EAAE,aACV,MAAM07B,KAAMD,EACXjyB,GAAWvC,mBAAmBy0B,GAE/B32B,GAAI0zB,MACF,IAAIQ,EAAO2B,UAAU,GACrB,CAACc,EAAG,QAASF,EAAUx/B,EAAM,SAG/Bs+B,GAAgBt+B,EAAM,QAASyyB,GAAK3zB,MAAM4gC,SAGtClyB,GAAWvC,mBAAmBjH,GAEtC+E,GAAI0zB,MACF,IAAIQ,EAAO2B,UAAU,GACrB,CAAC56B,EAAE,QAASw7B,EAAUrtB,EAAQ+sB,GACxBpB,GAAY0B,EAAS,GAAIx7B,IAEjCs6B,GAAgBnsB,EAAQ+sB,EAAMzM,GAAK3zB,MAAMkF,QAM3C,MAAMk7B,KAAQp1B,OAAOtK,KAAKi9B,GAAOv8B,OAAQ,IAE/B,UAATg/B,OACGl0B,EAAMR,SAASiyB,EAAMyC,GAAM,OAC1B,aAAczC,EAAMyC,GAAM,kBAI1B,GAAG7N,GAAU6N,kBAMd1+B,EAAOi8B,EAAMyC,GAAM,IAAM,OACTrC,GAAcr8B,EAAM2I,EAAS,kBAC5B+1B,KAAQ/sB,GAAS,KAClCwtB,EAAW,QACZ,aAAcn/B,IACfm/B,EAAWlN,GAAK3zB,MAAM0B,EAAK,cAEzBwK,EAAMtH,QAAQi8B,KAChBA,EAAW,CAACA,IAEdxtB,EAAO+sB,GAAQ,CAAC,aAAcS,SAM9B,MAAMC,KAAe91B,OAAOtK,KAAKi9B,EAAM,aAAe,IAAIv8B,OAAQ,OAC9Ds/B,EAAW/C,EAAM,YAAYmD,OAC/B,MAAMz9B,KAAW2H,OAAOtK,KAAKy9B,EAAM5D,UAAW,CAE9C5G,GAAKxkB,UAAUgvB,EAAM5D,SAASl3B,GAAUy9B,GAC5B1zB,KAAKrC,GAAKA,EAAE,SAAWnE,KAEnCyM,EAAO,YAAcA,EAAO,aAAe,GAC3CsgB,GAAK/kB,SACHyE,EAAO,YAAaytB,EAAa,GAAI,CAACjyB,iBAAiB,IACzD5E,GAAI0zB,MACF,IAAIQ,EAAO2B,UAAU,GACrB,CAACz8B,GAAUq9B,EAAUrtB,EAAO,YAAYytB,GACxCvyB,KAMRixB,GAAgBhH,EAAQjqB,EAAU8E,GAGlC8qB,EAAML,aAAa1qB,WApKjBosB,GAAgBhH,EAAQjqB,EAAU8E,QARlCmsB,GAAgBhH,EAAQjqB,EAAU8E,KAwLxCpJ,GAAI82B,YAAc,CAACr+B,EAAO2H,QAErB6B,EAAMtH,QAAQlC,GAAQ,QACPA,EAAMmS,IAAI9J,GAAKd,GAAI82B,YAAYh2B,EAAGV,IACnCkC,OAAOxB,GAAKA,MAGhB,UAAVrI,SACM,QAGNwJ,EAAMR,SAAShJ,GAAQ,IAErB,QAASA,EAAO,OACXkE,EAAKlE,EAAM,UACd2H,EAAQygB,KAAK9c,eAAepH,GAAK,OAC5ByvB,EAAMhsB,EAAQygB,KAAKlkB,GAAI0E,QAAQ5I,OACzB,IAAT2zB,SAEMhsB,EAAQygB,KAAKlkB,GAAIyvB,GAG1BhsB,EAAQygB,KAAKlkB,GAAIlC,KAAKhC,QAGtB2H,EAAQygB,KAAKlkB,GAAM,CAAClE,OAIpB,MAAMiH,KAAOjH,EACfA,EAAMiH,GAAOM,GAAI82B,YAAYr+B,EAAMiH,GAAMU,UAGtC3H,GCtWT,MACEkC,QAASyrB,GACT3kB,SAAU4kB,GACVvkB,SAAUwkB,GACVvkB,YAAa6lB,IACX9nB,GAGFsC,OAAQqqB,GACRtqB,QAASuqB,GACTrqB,QAASsqB,GACTpqB,cAAew0B,GACf70B,mBAAoBgvB,IAClBpxB,IAGFmrB,UAAW/C,GACXqE,gBAAiBM,GACjBvE,UAAWwE,GACX/X,QAASgY,GACTpF,eAAgBqF,IACdltB,IAGF+I,WAAYmuB,GACZ7uB,YAAa8uB,IACXn3B,IAGF6E,SAAUsoB,GACVjqB,QAASujB,GACT5gB,qBAAsBoiB,IACpBjoB,GAEEE,GAAM,GACZzK,OAAiByK,GAwmCjB,SAASk3B,GAAmBjR,EAAWkR,EAAc/2B,MACgB,UAAhE8nB,GAAWjC,EAAWkR,EAAc,CAAC3O,OAAO,GAAOpoB,SAC9C,IAAIgE,GACR,sFAEA,qBAAsB,CAACrK,KAAM,wBA9lCnCiG,GAAIo3B,QAAUj3B,OACZ8lB,UAAAA,EACAqH,eAAAA,EAAiB,KACjBx1B,QAAAA,EACAsI,QAAAA,EAAU,GACVi3B,cAAAA,EAAgB,gBAGbjR,GAAStuB,GAAU,KAChBJ,EAAO,OACP,IAAIJ,EAAI,EAAGA,EAAIQ,EAAQP,SAAUD,EAAG,KAElCggC,QAAkBt3B,GAAIo3B,QAAQ,CAChCnR,UAAAA,EACAqH,eAAAA,EACAx1B,QAASA,EAAQR,GACjB8I,QAAAA,EACAi3B,cAAAA,IAEe,OAAdC,IACDA,QAAkBD,EAAc,CAC9B/I,cAAex2B,EAAQR,GACvB2uB,UAAAA,EACAqH,eAAAA,EACAiB,OAAQz2B,EACRwc,MAAOhd,EACP8I,QAAAA,SAEe5G,IAAd89B,IAIL5/B,EAAK+C,KAAK68B,MAETl3B,EAAQm3B,eAAiC,IAAhB7/B,EAAKH,OAAc,CAIrB,KAFNs1B,GAChB5G,EAAWqH,EAAgB,eAAiB,IACjC/1B,SACXG,EAAOA,EAAK,WAGTA,QAIHovB,EAAM+F,GAAiB5G,EAAWqH,EAAgB,eACpD1F,GAAad,KACfb,QAAkB8G,GAAgB,CAChC9G,UAAAA,EACAmC,SAAUtB,EACVgC,WAAW,EACXC,mBAAmB,EACnB3oB,QAAAA,KAKDimB,GAAUvuB,GAAU,IAClBsI,EAAQygB,MAAQ,QAAS/oB,GAC1BsI,EAAQygB,KAAK9c,eAAejM,EAAQ,QAAS,OAEvC0/B,EAASp3B,EAAQygB,KAAK/oB,EAAQ,YAChC,IAAIR,EAAI,EAAGA,EAAIkgC,EAAOjgC,SAAUD,KAC/BkgC,EAAOlgC,GAAGmgC,WAAa3/B,SACjB0/B,EAAOlgC,GAAGggC,aAMpB5K,GAAS50B,IAAYo5B,GAAoBp5B,GAAU,OAC9CJ,EACJsI,GAAI03B,aAAa,CAACzR,UAAAA,EAAWqH,eAAAA,EAAgB5zB,MAAO5B,EAASsI,QAAAA,WAC5DA,EAAQygB,MAAQqQ,GAAoBp5B,KAEhCsI,EAAQygB,KAAK9c,eAAejM,EAAQ,UACvCsI,EAAQygB,KAAK/oB,EAAQ,QAAU,IAEjCsI,EAAQygB,KAAK/oB,EAAQ,QAAQ2C,KAAK,CAACg9B,SAAU3/B,EAASw/B,UAAW5/B,KAE5DA,KAKN+0B,GAAQ30B,GAAU,KACD+0B,GAChB5G,EAAWqH,EAAgB,eAAiB,IACjCpS,SAAS,gBACblb,GAAIo3B,QAAQ,CACjBnR,UAAAA,EACAqH,eAAAA,EACAx1B,QAASA,EAAQ,SACjBsI,QAAAA,EACAi3B,cAAAA,UAMAM,EAAoC,aAAnBrK,EAEjB51B,EAAO,GAGPkgC,EAAW3R,EAIbyG,GAAS50B,IAAao5B,GAAoBp5B,KAC5CmuB,EAAYA,EAAUgG,iCAIlByC,EACJ7B,GAAiB+K,EAAUtK,EAAgB,YACzC1F,GAAa8G,KACfzI,QAAkB8G,GAAgB,CAChC9G,UAAAA,EACAmC,SAAUsG,EACV5F,WAAW,EACXC,mBAAmB,EACnB3oB,QAAAA,KAIDA,EAAQygB,MAAQ,QAAS/oB,IAEtBsI,EAAQygB,KAAK9c,eAAejM,EAAQ,UACtCsI,EAAQygB,KAAK/oB,EAAQ,QAAU,IAEjCsI,EAAQygB,KAAK/oB,EAAQ,QAAQ2C,KAAK,CAACg9B,SAAU3/B,EAASw/B,UAAW5/B,SAM/DuK,EAAQnK,EAAQ,UAAY,GAC7BmK,EAAM1K,OAAS,IAChB0K,EAAQvH,MAAM0P,KAAKnI,GAAO9K,cAItB0gC,EAAc5R,MAChB,MAAMlqB,KAAQkG,EAAO,OACjB61B,EAAgB93B,GAAI+3B,WACxB,CAAC9R,UAAW4R,EAAaxvB,IAAKtM,EAAMosB,WAAY,CAACK,OAAO,KAGpD1B,EAAM+F,GAAiB+K,EAAUE,EAAe,YAClDlQ,GAAad,KACfb,QAAkB8G,GAAgB,CAChC9G,UAAAA,EACAmC,SAAUtB,EACV1mB,QAAAA,EACA0oB,WAAW,WAMXryB,EAAOsK,OAAOtK,KAAKqB,GAASX,WAC9B,MAAMo2B,KAAoB92B,EAAM,OAC5Bw4B,EAAgBn3B,EAAQy1B,MAGN,QAArBA,KAqBqB,UAArBA,KA6BqB,aAArBA,KAsCqB,cAArBA,KAiBqB,WAArBA,KAoBqB,WAArBA,GAAsD,UAArBA,GACb,cAArBA,GACAT,GAAWS,UAELyK,EAAQh4B,GAAI+3B,WAAW,CAC3B9R,UAAAA,EACA5d,IAAKklB,EACLpF,WAAY,CAACK,OAAO,KAEtByE,GAAUv1B,EAAMsgC,EAAO/I,YAKrB7I,GAAS6I,SACL,IAAI7qB,GACR,4DACA,yBAIwB,IAAzB6qB,EAAc13B,OAAc,OACvB0gC,EAAqBj4B,GAAI+3B,WAAW,CACxC9R,UAAAA,EACA5d,IAAKklB,EACL7zB,MAAOu1B,EACP9G,WAAY,CAACK,OAAO,GACpBnF,QAASsU,IAELR,EAAelR,EAAUyC,SAASnyB,IAAI0hC,GAC1ChS,EAAUyC,SAASvyB,IAAI8hC,GAAoB,SAAW,SACpDC,EAAaxgC,EACdy/B,IACDD,GAAmBjR,EAAWkR,EAAc/2B,GACxCimB,GAAU3uB,EAAKy/B,MACjBz/B,EAAKy/B,GAAgB,IAEvBe,EAAaxgC,EAAKy/B,IAEpBlK,GACEiL,EAAYD,EAAoBhJ,EAAe,CAC7CrqB,iBAAiB,QAKnB,MAAMuzB,KAAgBlJ,EAAe,OAEjCgJ,EAAqBj4B,GAAI+3B,WAAW,CACxC9R,UAAAA,EACA5d,IAAKklB,EACL7zB,MAAOy+B,EACPhQ,WAAY,CAACK,OAAO,GACpBnF,QAASsU,IAKLR,EAAelR,EAAUyC,SAASnyB,IAAI0hC,GAC1ChS,EAAUyC,SAASvyB,IAAI8hC,GAAoB,SAAW,SACpDC,EAAaxgC,EACdy/B,IACDD,GAAmBjR,EAAWkR,EAAc/2B,GACxCimB,GAAU3uB,EAAKy/B,MACjBz/B,EAAKy/B,GAAgB,IAEvBe,EAAaxgC,EAAKy/B,UAGd/M,EAAYyC,GAChB5G,EAAWgS,EAAoB,eAAiB,GAG5C51B,EAAUsqB,GAASwL,GACnB/1B,EAASqqB,GAAQ0L,OACnBC,EACDh2B,EACDg2B,EAAQD,EAAa,SACb91B,IACR+1B,EAAQD,EAAa,eAInBE,QAAsBr4B,GAAIo3B,QAAQ,CACpCnR,UAAAA,EACAqH,eAAgB2K,EAChBngC,QAAUsK,GAAUC,EAAW+1B,EAAQD,EACvC/3B,QAAAA,EACAi3B,cAAAA,OAICj1B,EAAQ,IAELgkB,GAASiS,KACXA,EAAgB,CAACA,IAGfjO,EAAUlP,SAAS,SAkBhB,CACL+R,GAAUiL,EAAYD,EAAoBI,EAAe,CACvDxzB,cAAc,EACdC,gBAAgB,aAnBlBuzB,EAAgB,EACbr4B,GAAI+3B,WAAW,CACd9R,UAAAA,EACA5d,IAAK,QACL8f,WAAY,CAACK,OAAO,MACjB6P,GAIJ,WAAYF,IACbE,EAAcr4B,GAAI+3B,WAAW,CAC3B9R,UAAAA,EACA5d,IAAK,SACL8f,WAAY,CAACK,OAAO,MAChB2P,EAAa,cAYtB91B,KACE+nB,EAAUlP,SAAS,YAAckP,EAAUlP,SAAS,QACrDkP,EAAUlP,SAAS,WAAa6b,GAAeoB,IAAgB,KAE3DG,EACDJ,EAAWn0B,eAAek0B,GAC3BK,EAAYJ,EAAWD,GAEvBC,EAAWD,GAAsBK,EAAY,SAIzC54B,GAAO0qB,EAAUlP,SAAS,OAC9Bid,EAAa,OAASA,EAAa,YACnCn4B,GAAI+3B,WAAW,CAAC9R,UAAAA,EAAW5d,IAAK,QAC9B8f,WAAY,CAACK,OAAO,KAIxByE,GACEqL,EAAW54B,EAAK24B,EAAe,CAC7BzzB,iBACIxE,EAAQm3B,eAAiBnN,EAAUlP,SAAS,eAE5CkP,EAAUlP,SAAS,WAC3B6b,GAAeoB,IAKZ/R,GAASiS,IAAkBA,EAAc9gC,OAAS,IACnD8gC,EAAgB,aAAcA,IAEhCpL,GACEiL,EAAYD,EAAoBI,EAAe,CAC7CzzB,iBACIxE,EAAQm3B,eAAiBnN,EAAUlP,SAAS,YAKjDkL,GAASiS,IAA2C,IAAzBA,EAAc9gC,QAC1C6I,EAAQm3B,gBACRc,EAAgBA,EAAc,IAEhCA,EAAgB,EACbr4B,GAAI+3B,WAAW,CACd9R,UAAAA,EACA5d,IAAK,SACL8f,WAAY,CAACK,OAAO,MACjB6P,GAIJ,QAASF,IACVE,EAAcr4B,GAAI+3B,WAAW,CAC3B9R,UAAAA,EACA5d,IAAK,MACL8f,WAAY,CAACK,OAAO,MAChB2P,EAAa,QAIlB,WAAYA,IACbE,EAAcr4B,GAAI+3B,WAAW,CAC3B9R,UAAAA,EACA5d,IAAK,SACL8f,WAAY,CAACK,OAAO,MAChB2P,EAAa,WAErBlL,GACEiL,EAAYD,EAAoBI,EAAe,CAC7CzzB,iBACIxE,EAAQm3B,eAAiBnN,EAAUlP,SAAS,gBAGjD,GAAGkP,EAAUlP,SAAS,cAC3BkP,EAAUlP,SAAS,WAAakP,EAAUlP,SAAS,QACnDkP,EAAUlP,SAAS,SAAU,KAGzBod,EAOA54B,KANDw4B,EAAWn0B,eAAek0B,GAC3BK,EAAYJ,EAAWD,GAEvBC,EAAWD,GAAsBK,EAAY,GAI5ClO,EAAUlP,SAAS,aAGjBwR,GAAS2L,KACVA,EAAgBA,EAAc,WAEhC34B,EAAMy4B,EAAa,kBACd,GAAG/N,EAAUlP,SAAS,UAAW,OAChC4S,EAAWjB,GACf5G,EAAWgS,EAAoB,WAAa,SACxCM,EAAev4B,GAAI+3B,WACvB,CAAC9R,UAAAA,EAAW5d,IAAKylB,EAAU3F,WAAY,CAACK,OAAO,QACjC,WAAbsF,EACDpuB,EAAMy4B,EAAa,iBACZE,EAAcE,OAChB,KACDC,MACH94B,KAAQ84B,GAAUjS,GAAS8R,EAAcvK,IAAa,IACnDxH,GAAU5mB,UAIL84B,EAAOjhC,aACP,SACI8gC,EAAcvK,cAElB,EACHuK,EAAcvK,GAAY0K,EAAO,iBAGjCH,EAAcvK,GAAY0K,OAV9B94B,EAAM,WAeL,GAAG0qB,EAAUlP,SAAS,OAAQ,OAC7Bud,EAAQz4B,GAAI+3B,WAAW,CAAC9R,UAAAA,EAAW5d,IAAK,MAC5C8f,WAAY,CAACK,OAAO,KACtB9oB,EAAM24B,EAAcI,UACbJ,EAAcI,QAChB,GAAGrO,EAAUlP,SAAS,SAAU,OAC/B0T,EAAU5uB,GAAI+3B,WAAW,CAC7B9R,UAAAA,EACA5d,IAAK,QACL8f,WAAY,CAACK,OAAO,SAElBvmB,UACHvC,KAAQuC,GAASskB,GAAS8R,EAAczJ,IAAY,IAC9C3sB,EAAM1K,aACN,SACI8gC,EAAczJ,cAElB,EACHyJ,EAAczJ,GAAW3sB,EAAM,iBAG/Bo2B,EAAczJ,GAAW3sB,EAMY,IAAtClB,OAAOtK,KAAK4hC,GAAe9gC,QAC5B,QAAS4gC,IACTE,QAAsBr4B,GAAIo3B,QAAQ,CAChCnR,UAAAA,EACAqH,eAAgB2K,EAChBngC,QAAS,OAAQqgC,EAAa,QAC9B/3B,QAAAA,EACAi3B,cAAAA,KAMF33B,IACFA,EAAMM,GAAI+3B,WAAW,CAAC9R,UAAAA,EAAW5d,IAAK,QACpC8f,WAAY,CAACK,OAAO,MAIxByE,GACEqL,EAAW54B,EAAK24B,EAAe,CAC7BzzB,gBAAiBwlB,EAAUlP,SAAS,cAEnC,OAICvgB,GAAYyF,EAAQm3B,eACxBnN,EAAUlP,SAAS,SAAWkP,EAAUlP,SAAS,UAChDkL,GAASiS,IAA2C,IAAzBA,EAAc9gC,QACrB,UAArBg2B,GAAqD,WAArBA,EAGlCN,GACEiL,EAAYD,EAAoBI,EAChC,CAACzzB,gBAAiBjK,eA1UJkyB,GAChB5G,EAAWqH,EAAgB,eAAiB,IACjCpS,SAAS,yBAKhB8c,EAAQh4B,GAAI+3B,WAAW,CAC3B9R,UAAAA,EACA5d,IAAKklB,EACLpF,WAAY,CAACK,OAAO,KAEtByE,GAAUv1B,EAAMsgC,EAAO/I,cA7BjByJ,QAAuB14B,GAAIo3B,QAAQ,CACvCnR,UAAAA,EACAqH,eAAAA,EACAx1B,QAASm3B,EACT7uB,QAAAA,EACAi3B,cAAAA,IAGGjR,GAASsS,IAA6C,IAA1BA,EAAenhC,QAC9C01B,GAAUv1B,EAAM61B,EAAkBmL,cA/C9BA,QAAuB14B,GAAIo3B,QAAQ,CACvCnR,UAAAA,EACAqH,eAAgB,WAChBx1B,QAASm3B,EACT7uB,QAAAA,EACAi3B,cAAAA,QAIE,MAAMsB,KAAqBD,KAC1BzS,EAAUyC,SAASnyB,IAAIoiC,IACxB1S,EAAUyC,SAASvyB,IAAIwiC,GAAmBtV,QAAS,OAC7C3pB,EAAQg/B,EAAeC,GAGvBtD,GAFYxI,GAChB5G,EAAW0S,EAAmB,eAAiB,IAErCzd,SAAS,UAAY9a,EAAQm3B,cACzCtK,GACEv1B,EAAMihC,EAAmBj/B,EAAO,CAACkL,gBAAiBywB,WAC7CqD,EAAeC,MAIvB53B,OAAOtK,KAAKiiC,GAAgBnhC,OAAS,EAAG,OAEnCygC,EAAQh4B,GAAI+3B,WAAW,CAC3B9R,UAAAA,EACA5d,IAAKklB,EACLpF,WAAY,CAACK,OAAO,KAEtByE,GAAUv1B,EAAMsgC,EAAOU,aA3DrBA,EAAiBnS,GAAS0I,GAAerkB,IAC3CguB,GAAe54B,GAAI+3B,WAAW,CAC5B9R,UAAW2R,EACXvvB,IAAKuwB,EACLzQ,WAAY,CAACK,OAAO,MAEK,IAA1BkQ,EAAenhC,SAChBmhC,EAAiBA,EAAe,UAI5BV,EAAQh4B,GAAI+3B,WAChB,CAAC9R,UAAAA,EAAW5d,IAAK,QAAS8f,WAAY,CAACK,OAAO,KAQ1C7tB,GAPYkyB,GAChB5G,EAAW+R,EAAO,eAAiB,IAIzB9c,SAAS,SACnB8R,GAAgB/G,EAAW,MAEbG,GAASsS,IAA4C,IAAzBzJ,EAAc13B,OAC1D01B,GAAUv1B,EAAMsgC,EAAOU,EAAgB,CAAC9zB,gBAAiBjK,aA5CrD+9B,EAAiBnS,GAAS0I,GAAerkB,IAC3CguB,GAAe54B,GAAI+3B,WAAW,CAC5B9R,UAAAA,EACA5d,IAAKuwB,EACLzQ,WAAY,CAACK,OAAO,GACpBpgB,KAAMhI,EAAQgI,QAEW,IAA1BswB,EAAenhC,SAChBmhC,EAAiBA,EAAe,IAOlChhC,EAHcsI,GAAI+3B,WAChB,CAAC9R,UAAAA,EAAW5d,IAAK,MAAO8f,WAAY,CAACK,OAAO,MAEhCkQ,UA0aXhhC,SAIFI,GAiBTkI,GAAI+3B,WAAa,EACf9R,UAAAA,EACA5d,IAAAA,EACA3O,MAAAA,EAAQ,KACRyuB,WAAAA,EAAa,CAACK,OAAO,GACrBnF,QAAAA,GAAU,EACVjb,KAAAA,EAAO,YAGI,OAARC,SACMA,EAKN4d,EAAU4S,sBAAwB5S,EAAUgD,kBAC7ChD,EAAYA,EAAUgD,uBAGlB6P,EAAa7S,EAAUoF,gBAG1ByB,GAAWzkB,IACZA,KAAOywB,GACP,UAAWA,EAAWzwB,IACtB,UAAWywB,EAAWzwB,GAAK,UAC3B,UAAWywB,EAAWzwB,GAAK,SAAS,gBAC7BywB,EAAWzwB,GAAK,SAAS,SAAS,YAIxC8f,EAAWK,OAASngB,KAAOywB,EAAY,OAClCtN,EAAkBvF,EAAU,cAAgB,QAG5C8S,EAAa,GAChB1S,GAAU3sB,IAAU,WAAYA,KAAW,WAAYA,IACxDq/B,EAAWt+B,KAAK,SAAU,cAIzB4rB,GAAU3sB,IAAU,cAAeA,IACpCA,EAAQA,EAAM,aAAa,IAK1BizB,GAASjzB,IAEP,WAAYA,GACbq/B,EAAWt+B,KACT,eAAgB,mBAAoB,SAAU,cAG/C,QAASf,GACVq/B,EAAWt+B,KACT,YAAa,iBAEjBs+B,EAAWt+B,KAAK,SAAU,aAAc,QAEnC,WAAYf,GACfq/B,EAAWt+B,KACT,eAAgB,mBAAoB,SAAU,cAG7C,QAASf,GACZq/B,EAAWt+B,KAAK,YAAa,kBAEvB4rB,GAAU3sB,KAAWgzB,GAAShzB,IACtCq/B,EAAWt+B,KAAK,MAAO,UAAW,QAAS,iBAIzCu+B,EAAiB,YACjB1M,EAAsB,WAEvBjJ,EACD2V,EAAiB,QACjB1M,EAAsB,WACtByM,EAAWt+B,KAAK,aACX,GAAGgyB,GAAQ/yB,GAAQ,CAGnB,WAAYA,GACfq/B,EAAWt+B,KAAK,eAEZxD,EAAOyC,EAAM,YACA,IAAhBzC,EAAKM,OAGNyhC,EAAiB,OACjB1M,EAAsB,YACjB,KACD2M,EAAkC,IAAhBhiC,EAAKM,OAAgBi0B,EAAkB,KACzD0N,EAAa,SACb,IAAI5hC,EAAI,EAAGA,EAAIL,EAAKM,SAAUD,EAAG,OAC7BoqB,EAAOzqB,EAAKK,OACd6hC,EAAe,QACfC,EAAW,WACZ1M,GAAShL,MACP,eAAgBA,EAAM,CAGvByX,EAAgB,IAFFzX,EAAK,cAAgB,IAAIre,iBAC3Bqe,EAAK,oBAET,cAAeA,EACvByX,EAAezX,EAAK,aAAare,cACzB,UAAWqe,EACnB0X,EAAW1X,EAAK,SAGhByX,EAAe,aAGjBC,EAAW,SAES,OAAnBH,EACDA,EAAiBE,EACTA,IAAiBF,GAAkBvM,GAAShL,KACpDuX,EAAiB,SAED,OAAfC,EACDA,EAAaE,EACLA,IAAaF,IACrBA,EAAa,SAIO,UAAnBD,GAA6C,UAAfC,QAInCD,EAAiBA,GAAkB,QACnCC,EAAaA,GAAc,QACT,UAAfA,GACDF,EAAiB,QACjB1M,EAAsB4M,GAEtB5M,EAAsB2M,OAGrB,IACFvM,GAAShzB,MACP,cAAeA,KAAW,WAAYA,GAAQ,CAC/Cq/B,EAAWt+B,KAAK,YAAa,iBAC7B6xB,EAAsB5yB,EAAM,mBACtBrC,EAAMqC,EAAM,cACfrC,IACDi1B,EAAuB,GAAEA,KAAuBj1B,SAE1C,eAAgBqC,KAAW,WAAYA,GAC/C4yB,EAAuB,IAAG5yB,EAAM,cACxB,UAAWA,IACnBs/B,EAAiB,QACjB1M,EAAsB5yB,EAAM,eAG9Bs/B,EAAiB,QACjB1M,EAAsB,MAExByM,EAAWt+B,KAAK,QAIlBs+B,EAAWt+B,KAAK,SAIb4rB,GAAU3sB,MAAY,WAAYA,IAEnCq/B,EAAWt+B,KAAK,SAAU,cAIzBiyB,GAAShzB,IAAwC,IAA9BqH,OAAOtK,KAAKiD,GAAOnC,QAEvCwhC,EAAWt+B,KAAK,YAAa,uBAGzBitB,EA2OV,SACEzB,EAAW5d,EAAK3O,EAAOq/B,EAAYC,EAAgB1M,GACxB,OAAxBA,IACDA,EAAsB,eAIlB+M,EAAQ,OAGc,QAAxB/M,GAAyD,aAAxBA,IACnCjG,GAAU3sB,IAAU,QAASA,EAAO,CAET,aAAxB4yB,GACD+M,EAAM5+B,KAAK,kBAGPitB,EAAO1nB,GAAI+3B,WACf,CAAC9R,UAAAA,EAAW5d,IAAK3O,EAAM,OAAQyuB,WAAY,CAACK,OAAO,KAClDvC,EAAUyC,SAASnyB,IAAImxB,IACxBzB,EAAUyC,SAASvyB,IAAIuxB,IACvBzB,EAAUyC,SAASvyB,IAAIuxB,GAAM,SAAWhuB,EAAM,OAE9C2/B,EAAM5+B,KAAKuM,MAAMqyB,EAAO,CAAC,SAAU,QAGnCA,EAAM5+B,KAAKuM,MAAMqyB,EAAO,CAAC,MAAO,eAE7B,CACLA,EAAM5+B,KAAK6xB,SAGLgN,EAAUD,EAAME,KAAKC,GAAMA,EAAGte,SAAS,MAC1Coe,GAEDD,EAAM5+B,KAAK6+B,EAAQz/B,QAAQ,UAAW,MAG1Cw/B,EAAM5+B,KAAK,eAELg/B,EAAexT,EAAUmF,QAAQ/iB,OACnC,MAAM+hB,KAAa2O,EAAY,MAE5B3O,KAAaqP,kBAIZC,EAAyBD,EAAarP,GAAW4O,OACnD,MAAMW,KAAQN,KAEXM,KAAQD,SAKNA,EAAuBC,UAI3B,KAtSQC,CACX3T,EAAW5d,EAAK3O,EAAOq/B,EAAYC,EAAgB1M,MACzC,OAAT5E,SACMA,KAKRS,EAAWK,OACT,WAAYvC,EAAW,OAElBuC,EAAQvC,EAAU,aACE,IAAvB5d,EAAIhH,QAAQmnB,IAAgBngB,IAAQmgB,EAAO,OAEtCI,EAASvgB,EAAIK,OAAO8f,EAAMjxB,YAC5B0uB,EAAUyC,SAASnyB,IAAIqyB,UAClBA,OAOXiR,EAAS,WAEPC,EAAiB,OACnB3N,EAASlG,EAAUqF,mBAGjByO,EAAmB1xB,EAAI9Q,OAAS,MAClC,IAAID,EAAI,EAAGA,EAAIyiC,GAAoB1xB,EAAI/Q,KAAM60B,IAAU70B,EACzD60B,EAASA,EAAO9jB,EAAI/Q,IACjB,KAAM60B,GACP2N,EAAer/B,KAAK0xB,EAAO,IAAI,QAI/B,IAAI70B,EAAIwiC,EAAeviC,OAAS,EAAGD,GAAK,IAAKA,EAAG,OAC5Cs0B,EAAQkO,EAAexiC,GACvBo0B,EAAQE,EAAMF,UAChB,MAAMhE,KAAQgE,EAAO,OAKjBsO,EAAQtS,EAAO,IAAMrf,EAAIK,OAAOkjB,EAAMvjB,IAAI9Q,QACzB0uB,EAAUyC,SAASvyB,IAAIuxB,GAAMmB,WAChD5C,EAAUyC,SAASnyB,IAAIyjC,IACd,OAAVtgC,GAAkBusB,EAAUyC,SAASvyB,IAAI6jC,GAAO,SAAW3xB,KAI9B,OAAXwxB,GACnB9R,GAAsBiS,EAAOH,GAAU,KACvCA,EAASG,OAMD,OAAXH,SACMA,MAKL,MAAOnS,EAAMuS,KAAOhU,EAAUyC,YAC7BuR,GAAMA,EAAGpR,SAAWxgB,EAAIrM,WAAW0rB,EAAO,WACrC,IAAItjB,GACP,iBAAgBiE,4BAA8Bqf,MAC/C,qBACA,CAAC3tB,KAAM,2BAA4B2sB,QAAST,WAK9CkC,EAAWK,MAcRngB,EAbF,UAAW4d,EACRA,EAAU,SAIL+Q,GAAYC,GAAa7uB,EAAM6d,EAAU,UAAW5d,GAFpDA,EAKF2uB,GAAY5uB,EAAMC,IAmB/BrI,GAAI03B,aAAe,EAAEzR,UAAAA,EAAWqH,eAAAA,EAAgB5zB,MAAAA,EAAO0G,QAAAA,SAElDssB,GAAShzB,GAAQ,OAEZqC,EAAO8wB,GAAiB5G,EAAWqH,EAAgB,SACnD1zB,EAAWizB,GAAiB5G,EAAWqH,EAAgB,aACvD9C,EAAYqC,GAAiB5G,EAAWqH,EAAgB,cACxDlD,EACJyC,GAAiB5G,EAAWqH,EAAgB,eAAiB,GAGzD4M,EAAgB,WAAYxgC,IAAU0wB,EAAUlP,SAAS,cAG3Dgf,GAA0B,UAATn+B,EAAkB,IAElCrC,EAAM,WAAaqC,SACbrC,EAAM,aAEZ,cAAeA,GAASA,EAAM,eAAiBE,GAC/C,eAAgBF,GAASA,EAAM,gBAAkB8wB,SAC3C9wB,EAAM,aAEZ,cAAeA,GAASA,EAAM,eAAiBE,SACzCF,EAAM,aAEZ,eAAgBA,GAASA,EAAM,gBAAkB8wB,SAC3C9wB,EAAM,gBAQXygC,EAAWp5B,OAAOtK,KAAKiD,GAAOnC,OAC9B6iC,EAA+B,IAAbD,GACR,IAAbA,GAAkB,WAAYzgC,IAAUwgC,EACrCG,EAAsB,cAAepU,EACrCqU,EAAgBhU,GAAU5sB,EAAM,WAChC6gC,EAAkBtU,EAAUyC,SAASnyB,IAAI+2B,IACW,OAAxDrH,EAAUyC,SAASvyB,IAAIm3B,GAAgB,gBACtC8M,GACQ,UAATr+B,KACEs+B,IAAuBC,GAAiBC,UACnC7gC,EAAM,gBAGThC,EAAO,UAGVwiC,IACDxiC,EAAKsI,GAAI+3B,WAAW,CAClB9R,UAAAA,EACA5d,IAAK,SACL8f,WAAY,CAACK,OAAO,MAChB9uB,EAAM,WAGX,UAAWA,EAEZhC,EAAKsI,GAAI+3B,WAAW,CAClB9R,UAAAA,EACA5d,IAAK,QACL8f,WAAY,CAACK,OAAO,MAChBxoB,GAAI+3B,WACR,CAAC9R,UAAAA,EAAW5d,IAAK3O,EAAM,SAAUyuB,WAAY,CAACK,OAAO,KAC/C,cAAe9uB,IAEvBhC,EAAKsI,GAAI+3B,WAAW,CAClB9R,UAAAA,EACA5d,IAAK,YACL8f,WAAY,CAACK,OAAO,MAChB9uB,EAAM,cAGX,eAAgBA,IAEjBhC,EAAKsI,GAAI+3B,WAAW,CAClB9R,UAAAA,EACA5d,IAAK,aACL8f,WAAY,CAACK,OAAO,MAChB9uB,EAAM,eAIdhC,EAAKsI,GAAI+3B,WAAW,CAClB9R,UAAAA,EACA5d,IAAK,SACL8f,WAAY,CAACK,OAAO,MAChB9uB,EAAM,UAELhC,QAIH61B,EAAmBrF,GAAWjC,EAAWqH,EAAgB,CAAC9E,OAAO,GACrEpoB,GACIrE,EAAO8wB,GAAiB5G,EAAWqH,EAAgB,SACnDgK,EAAYt3B,GAAI+3B,WAAW,CAC/B9R,UAAAA,EACA5d,IAAK3O,EAAM,OACXyuB,WAAY,CAACK,MAAgB,WAATzsB,GACpBqM,KAAMhI,EAAQgI,aAGJ,QAATrM,GAA2B,WAATA,GAA0C,WAArBwxB,EACjC+J,EAGF,EACJt3B,GAAI+3B,WAAW,CACd9R,UAAAA,EACA5d,IAAK,MACL8f,WAAY,CAACK,OAAO,MACjB8O;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrhCT,MAAM9hC,GAAmBk0B,GAAKl0B,kBAKvBy4B,OAAQuM,IAAW16B,IACnBsxB,QAASqJ,IAAY36B,IACrB4xB,QAASgJ,IAAY56B,IACrBuzB,MAAOsH,IAAU76B,IAGtB81B,qBAAsBgF,GACtB9D,YAAa+D,IACX/6B,IAGFnF,QAASyrB,GACT3kB,SAAU4kB,GACVvkB,SAAUwkB,IACRxmB,GAGFoC,mBAAoBgvB,IAClBpxB,IAGFmrB,UAAW/C,GACXsB,kBAAmBsR,GACnB/lB,QAASgY,GACTpF,eAAgBqF,IACdltB,IAGFs3B,QAAS2D,GACThD,WAAYiD,IACVl7B,IAGFqwB,cAAemD,GACfpD,oBAAqBiB,GACrBf,cAAe6K,IACbn7B,GAIE6X,GAAU,SAASsJ,SAGnBia,EAAc,GAKdC,EAAwB,IAAIpV,GAAI,CAACpa,IADC,eAg5B/ByvB,EAAah7B,GAASumB,eAC7BA,EAAiB1F,EAAO0F,kBACrBrI,WAEIvd,OAAOwC,OAAO,GAAI,CAACojB,eAAAA,GAAiBrI,EAAUle,UAl3BvD6gB,EAAOmW,QAAUj3B,eAAe1H,EAAOquB,EAAK1mB,MACvC6G,UAAU1P,OAAS,QACd,IAAIiS,UAAU,4CAGX,OAARsd,QACK,IAAI1iB,GACR,2CACA,sBAAuB,CAACrK,KAAM,6BAIrB,OAAVtB,SACM,SAyBLg/B,GArBJr3B,EAAUg7B,EAAah7B,EAAS,CAC9BgI,KAAMke,GAAU7tB,GAASA,EAAQ,GACjC8+B,eAAe,EACf8D,mBAAmB,EACnB9hC,OAAO,EACP+hC,eAAe,EACfza,MAAM,EACN1jB,OAAQ,IAAI3H,GAAiB,OAC7BwzB,gBAAiB,IAAIuS,GACnB,CAAC/U,YAAa2U,OAEPta,OAGTzgB,EAAQk7B,eAAgB,GAEtBl7B,EAAQi7B,0BACHj7B,EAAQgI,KAMfqvB,EADCr3B,EAAQk7B,cACE7iC,QAEMwoB,EAAOgN,OAAOx1B,EAAO2H,SAIlC6lB,QAAkBhF,EAAOua,eAC7BV,GAAmB16B,GAAU0mB,EAAK1mB,OAGhCk3B,QAAkByD,GAAS,CAC7B9U,UAAAA,EACAnuB,QAAS2/B,EACTr3B,QAAAA,EACAi3B,cAAej3B,EAAQi3B,gBAItBj3B,EAAQm3B,gBAAkBn3B,EAAQ7G,OAAS6sB,GAASkR,GAC7B,IAArBA,EAAU//B,OAEX+/B,EAAYA,EAAU,GACO,IAArBA,EAAU//B,SAElB+/B,EAAY,IAENl3B,EAAQ7G,OAAS8sB,GAAUiR,KAEnCA,EAAY,CAACA,IAIZjR,GAAUS,IAAQ,aAAcA,IACjCA,EAAMA,EAAI,aAIZA,EAAM4C,GAAK3zB,MAAM+wB,GACbV,GAASU,KACXA,EAAM,CAACA,UAGH2U,EAAM3U,EACZA,EAAM,OACF,IAAIxvB,EAAI,EAAGA,EAAImkC,EAAIlkC,SAAUD,IAC3B+uB,GAAUoV,EAAInkC,KAAOyJ,OAAOtK,KAAKglC,EAAInkC,IAAIC,OAAS,IACpDuvB,EAAIrsB,KAAKghC,EAAInkC,UAKXokC,EAAc5U,EAAIvvB,OAAS,KACf,IAAfuvB,EAAIvvB,SACLuvB,EAAMA,EAAI,IAITV,GAASkR,GAAY,OAEhBqE,EAAaX,GAAY,CAC7B/U,UAAAA,EAAW5d,IAAK,SAAU8f,WAAY,CAACK,OAAO,KAE1CjvB,EAAQ+9B,EACdA,EAAY,GACToE,IACDpE,EAAU,YAAcxQ,GAE1BwQ,EAAUqE,GAAcpiC,OACnB,GAAG8sB,GAAUiR,IAAcoE,EAAY,OAEtCniC,EAAQ+9B,EACdA,EAAY,YAAaxQ,OACrB,MAAMpnB,KAAOnG,EACf+9B,EAAU53B,GAAOnG,EAAMmG,UAIpB43B,GAqBTrW,EAAOgN,OAAS9tB,eAAe1H,EAAO2H,MACjC6G,UAAU1P,OAAS,QACd,IAAIiS,UAAU,yCASM,KAL5BpJ,EAAUg7B,EAAah7B,EAAS,CAC9B6vB,uBAAuB,EACvBjH,gBAAiB,IAAIuS,GACnB,CAAC/U,YAAa2U,OAEPvN,eACTxtB,EAAQwtB,kBAAep0B,SAInBoiC,EAAY,GAGZC,EAAoB,MAGvB,kBAAmBz7B,EAAS,OACvB07B,EAAgBpS,GAAK3zB,MAAMqK,EAAQ07B,eACtCzV,GAAUyV,IAAkB,aAAcA,EAC3CF,EAAUE,cAAgBA,EAE1BF,EAAUE,cAAgB,YAAaA,GAEzCD,EAAkBphC,KAAKmhC,EAAUE,mBAI/BC,KACAzV,GAAU7tB,GAGP,OAEC8uB,QAAkBtG,EAAO9qB,IAAIsC,EAAO2H,GAC1C27B,EAAcxU,EAAU9G,YACxBmb,EAAUnjC,MAAQ8uB,EAAU7G,SACzB6G,EAAU/G,aAEXob,EAAUI,cAAgB,YAAazU,EAAU/G,YACjDqb,EAAkBphC,KAAKmhC,EAAUI,qBATnCJ,EAAUnjC,MAAQixB,GAAK3zB,MAAM0C,GAc1B,SAAU2H,IACbA,EAAQgI,KAAO2zB,GAAe,QAI5B9V,EAAY6U,GAAmB16B,OAC/B,MAAMgoB,KAAYyT,EACpB5V,QAAkB8G,GAAgB,CAAC9G,UAAAA,EAAWmC,SAAAA,EAAUhoB,QAAAA,QAItDq3B,QAAiB+C,GAAQ,CAC3BvU,UAAAA,EACAnuB,QAAS8jC,EAAUnjC,MACnB2H,QAAAA,EACAwtB,aAAcxtB,EAAQwtB,sBAIrBvH,GAAUoR,IAAc,WAAYA,GACJ,IAAjC12B,OAAOtK,KAAKghC,GAAUlgC,OACtBkgC,EAAWA,EAAS,UACC,OAAbA,IACRA,EAAW,IAITrR,GAASqR,KACXA,EAAW,CAACA,IAGPA,GAgBTxW,EAAOmQ,QAAUjxB,eAAe1H,EAAOquB,EAAK1mB,MACvC6G,UAAU1P,OAAS,SACb,IAAIiS,UAAU,yCAIrBsd,EADgB,mBAARA,EACF,KAEAA,GAAO,KAIf1mB,EAAUg7B,EAAah7B,EAAS,CAC9BgI,KAAMke,GAAU7tB,GAASA,EAAQ,GACjCuwB,gBAAiB,IAAIuS,GACnB,CAAC/U,YAAa2U,YAIZ1D,QAAiBxW,EAAOgN,OAAOx1B,EAAO2H,GAGtCixB,EAAYoJ,GAAShD,MAEhB,OAAR3Q,SAEMuK,EAITjxB,EAAQ7G,OAAQ,EAChB6G,EAAQk7B,eAAgB,QAClBhE,QAAkBrW,EAAOmW,QAAQ/F,EAAWvK,EAAK1mB,UAEhDk3B,GAqBTrW,EAAOyS,MAAQvzB,eAAe1H,EAAOi7B,EAAOtzB,MACvC6G,UAAU1P,OAAS,QACd,IAAIiS,UAAU,0CAItBpJ,EAAUg7B,EAAah7B,EAAS,CAC9BgI,KAAMke,GAAU7tB,GAASA,EAAQ,GACjC28B,MAAO,QACPgB,UAAU,EACV5B,YAAY,EACZyH,aAAa,EACbhG,cAAe,GACfjN,gBAAiB,IAAIuS,GACnB,CAAC/U,YAAa2U,MAIf7U,GAAUoN,GAAQ,OAEbnM,QAAkBtG,EAAO9qB,IAAIu9B,EAAOtzB,MAC1CszB,EAAQnM,EAAU7G,SAEf6G,EAAU/G,WAAY,KAEnBsG,EAAM4M,EAAM,YACZ5M,EAEMV,GAASU,GACjBA,EAAIrsB,KAAK8sB,EAAU/G,YAEnBsG,EAAM,CAACA,EAAKS,EAAU/G,YAJtBsG,EAAMS,EAAU/G,WAMlBkT,EAAM,YAAc5M,SAIlBoV,EAAexI,GAAQA,EAAM,aAAoB,GAGjDzN,QAAkBhF,EAAOua,eAC7BV,GAAmB16B,GAAU87B,EAAc97B,GAGzCA,EAAQ2D,eAAe,eACzB3D,EAAQ+7B,UAAYnP,GAAgB/G,EAAW,MAE7C7lB,EAAQ2D,eAAe,+BACzB3D,EAAQ41B,0BAA4BhJ,GAAgB/G,EAAW,YAI3DwR,QAAiBxW,EAAOgN,OAAOx1B,EAAO2H,GAGtCg8B,EAAO,IAAIh8B,GACjBg8B,EAAKn4B,SAAU,EACfm4B,EAAKnM,uBAAwB,QACvBoM,QAAsBpb,EAAOgN,OAAOyF,EAAO0I,GAI3CE,EAAYv7B,OAAOtK,KAAKi9B,GAC3B9oB,IAAIlL,GAAOwoB,GAAWjC,EAAWvmB,EAAK,CAAC8oB,OAAO,KACjD4T,EAAKvL,QAAUyL,EAAUphB,SAAS,UAClCkhB,EAAK7F,KAAOvJ,GAAgB/G,EAAW,WAGjC8P,EAAS6E,GAAsBnD,EAAU4E,EAAeD,GAE9DA,EAAK7iC,OAAS6G,EAAQ+7B,UACtBC,EAAKd,eAAgB,EACrBc,EAAKvb,KAAO,GACZub,EAAKG,SAAU,MACXjF,QAAkBrW,EAAOmW,QAAQrB,EAAQmG,EAAcE,UAG3DA,EAAKvb,KAAO,GACZyW,EAAYuD,GAAavD,EAAW8E,GAE7B9E,GAkBTrW,EAAOJ,KAAO1gB,eAAe1H,EAAOquB,EAAK1mB,SAGjCszB,EAAQ,UACX5M,IACD4M,EAAM,YAAc5M,GAEtB4M,EAAM,UAAY,QACXzS,EAAOyS,MAAMj7B,EAAOi7B,EAAOtzB,IA2BpC6gB,EAAOub,UAAYvb,EAAO/gB,SAAWC,eAAe1H,EAAO2H,MACtD6G,UAAU1P,OAAS,QACd,IAAIiS,UAAU,6CAWnB,gBAPHpJ,EAAUg7B,EAAah7B,EAAS,CAC9BgI,KAAMke,GAAU7tB,GAASA,EAAQ,GACjC/B,UAAW,YACX4kC,eAAe,EACftS,gBAAiB,IAAIuS,GACnB,CAAC/U,YAAa2U,OAEW,IACA,wBAAxB/6B,EAAQq8B,aACe,uBAAxBr8B,EAAQq8B,kBACF,IAAIr4B,GACR,yCACA,8BAGEs4B,EAAclkC,GAAOgP,MAAM/O,UAG1ByH,EAASA,SAASw8B,EAAat8B,SAIlCg8B,EAAO,IAAIh8B,UACVg8B,EAAKO,OACZP,EAAK1J,uBAAwB,QACvBh6B,QAAgBuoB,EAAOoS,MAAM56B,EAAO2jC,UAGnCl8B,EAASA,SAASxH,EAAS0H,IAmBpC6gB,EAAOyQ,QAAUvxB,eAAezH,EAAS0H,MACpC6G,UAAU1P,OAAS,QACd,IAAIiS,UAAU,kDAItBpJ,EAAUg7B,EAAah7B,EAAS,CAC9Bu8B,OAAQrW,GAAU5tB,GAAW,2BAAwBc,UAGjDmjC,OAACA,GAAUv8B,MACbw8B,UAACA,GAAax8B,KAGfu8B,MAEDC,EAAYA,GAAa1B,EAAYyB,IACjCC,QACI,IAAIx4B,GACR,wBACA,uBAAwB,CAACu4B,OAAAA,SAI7BC,EAAY,IAAMlkC,QAIdmkC,QAAsBD,EAAUlkC,UAC/BgiC,GAASmC,EAAez8B,IAqBjC6gB,EAAOoS,MAAQlzB,eAAe1H,EAAO2H,MAChC6G,UAAU1P,OAAS,QACd,IAAIiS,UAAU,oDAYlBiuB,EAEFA,GAVFr3B,EAAUg7B,EAAah7B,EAAS,CAC9BgI,KAAMke,GAAU7tB,GAASA,EAAQ,GACjC6iC,eAAe,EACftS,gBAAiB,IAAIuS,GACnB,CAAC/U,YAAa2U,OAKPG,cACE7iC,QAGMwoB,EAAOgN,OAAOx1B,EAAO2H,SAIlC1H,EAAUiiC,GAAOlD,EAAUr3B,MAC9BA,EAAQu8B,OAAQ,IACK,wBAAnBv8B,EAAQu8B,QACU,uBAAnBv8B,EAAQu8B,cACDnkC,GAAOo6B,UAAUl6B,SAEpB,IAAI0L,GACR,yBACA,uBAAwB,CAACu4B,OAAQv8B,EAAQu8B,gBAGtCjkC,GAmBTuoB,EAAOkP,cAAgBhwB,eAAe1H,EAAO2H,MACxC6G,UAAU1P,OAAS,QACd,IAAIiS,UAAU,iDAItBpJ,EAAUg7B,EAAah7B,EAAS,CAC9BgI,KAAMke,GAAU7tB,GAASA,EAAQ,GACjCuwB,gBAAiB,IAAIuS,GACnB,CAAC/U,YAAa2U,YAIZ1D,QAAiBxW,EAAOgN,OAAOx1B,EAAO2H,UAErC+wB,GAAqBsG,EAAUr3B,IAwBxC6gB,EAAO6b,MAAQ38B,eAAe48B,EAAMjW,EAAK1mB,MACpC6G,UAAU1P,OAAS,QACd,IAAIiS,UAAU,2CAElB4c,GAAS2W,SACL,IAAIvzB,UAAU,6CAIpBsd,EADgB,mBAARA,EACF,KAEAA,GAAO,KAIf1mB,EAAUg7B,EAAah7B,EAAS,CAC9B4oB,gBAAiB,IAAIuS,GACnB,CAAC/U,YAAa2U,YAIZ1D,QAAiB54B,QAAQC,IAAIi+B,EAAKnyB,IAAIsV,UACpCkc,EAAO,IAAIh8B,UACV6gB,EAAOgN,OAAO/N,EAAKkc,UAGxBY,GAAa,EACd,eAAgB58B,IACjB48B,EAAa58B,EAAQ48B,kBAGjB7/B,EAASiD,EAAQjD,QAAU,IAAI3H,GAAiB,OAChDmD,EAAS,YAAa,QAExB,IAAIrB,EAAI,EAAGA,EAAImgC,EAASlgC,SAAUD,EAAG,OAEjC4oB,EAAMwJ,GAAKpkB,kBAAkBmyB,EAASngC,GAAI,CAC9C6F,OAAQ,IAAI3H,GAAiB,MAAQ8B,EAAI,OAKrC2lC,EAAWD,GAAoB,IAAN1lC,EAAWqB,EAAS,YAAa,OAChE26B,GAAepT,EAAK+c,EAAS,WAAY9/B,GAEtC8/B,IAAYtkC,MAET,MAAM8C,KAAawhC,EAAS,OACxBC,EAAWD,EAAQxhC,QACpBA,KAAa9C,GAAS,CACzBA,EAAO8C,GAAayhC,iBAGhBjM,EAAUt4B,EAAO8C,OACnB,MAAMiE,KAAOw9B,EACVx9B,KAAOuxB,IACVA,EAAQvxB,GAAOw9B,EAASx9B,WAQ5BqxB,EAAekK,GAAetiC,GAG9B04B,EAAY,GACZ56B,EAAOsK,OAAOtK,KAAKs6B,GAAc55B,WACnC,IAAIqO,EAAK,EAAGA,EAAK/O,EAAKc,SAAUiO,EAAI,OAChC2b,EAAO4P,EAAat6B,EAAK+O,IAE3B0rB,GAAoB/P,IACtBkQ,EAAU52B,KAAK0mB,MAIR,OAAR2F,SACMuK,EAITjxB,EAAQ7G,OAAQ,EAChB6G,EAAQk7B,eAAgB,QAClBhE,QAAkBrW,EAAOmW,QAAQ/F,EAAWvK,EAAK1mB,UAEhDk3B,GAUTv2B,OAAOsP,eAAe4Q,EAAQ,iBAAkB,CAC9C9qB,IAAK,IAAM8qB,EAAOkc,gBAClB9mC,IAAKyK,GAAKmgB,EAAOkc,gBAAkBr8B,IAGrCmgB,EAAO0F,eAAiBxmB,MAAAA,UAChB,IAAIiE,GACR,yFACkC,2BAClC,CAACrK,KAAM,0BAA2BmN,IAAAA,KAatC+Z,EAAO9qB,IAAMgK,eAAe+G,EAAK9G,OAC3BulB,EAEFA,EADmC,mBAA3BvlB,EAAQumB,eACTvmB,EAAQumB,eAER1F,EAAO0F,qBAGVY,QAAkB5B,EAAKze,WAGvBqgB,EAAU7G,eACN,IAAItc,GACR,6CACA,6BAEDkiB,GAAUiB,EAAU7G,YACrB6G,EAAU7G,SAAWhS,KAAKlH,MAAM+f,EAAU7G,WAE5C,MAAM3gB,SACA,IAAIqE,GACR,sDACA,2BAA4B,CAC1BrK,KAAM,0BACNwmB,MAAOxgB,EACPwnB,UAAAA,WAICA,GAeTtG,EAAOua,eAAiBr7B,eACtB8lB,EAAWmC,EAAUhoB,UAErBA,EAAUg7B,EAAah7B,EAAS,CAC9BgI,KAAM,GACN4gB,gBAAiB,IAAIuS,GACnB,CAAC/U,YAAa2U,MAIF,OAAb/S,EACM0S,GAAmB16B,IAI5BgoB,EAAWsB,GAAK3zB,MAAMqyB,GACjB/B,GAAU+B,IAAa,aAAcA,IACxCA,EAAW,YAAaA,IAGnB2E,GAAgB,CAAC9G,UAAAA,EAAWmC,SAAAA,EAAUhoB,QAAAA,MAI/C6gB,EAAOsL,gBAAkBzsB,GAAqBysB,gBAK9CtL,EAAOC,gBAAkB,GASzBD,EAAOI,kBAAoB,SAAStlB,QAC7BA,KAAQklB,EAAOC,uBACZ,IAAI9c,GACR,kCAAoCrI,EAAO,IAC3C,+BACA,CAACA,KAAAA,IAILklB,EAAO0F,eAAiB1F,EAAOC,gBAAgBnlB,GAAMiL,MACnDia,EAAQvmB,MAAMsG,UAAUrJ,MAAMuJ,KAAK+F,UAAW,KAalDga,EAAOmc,kBAAoB,SAAS3rB,EAAa/J,GAC/CwzB,EAAYzpB,GAAe/J,GAQ7BuZ,EAAOoc,oBAAsB,SAAS5rB,UAC7BypB,EAAYzpB,IAIrBwP,EAAOmc,kBAAkB,sBAAuB5kC,GAAOgP,OACvDyZ,EAAOmc,kBAAkB,qBAAsB5kC,GAAOgP,OAGtDyZ,EAAO/Z,IAAMpH,GAGbmhB,EAAOyI,KAAOA,GAEd3oB,OAAOwC,OAAO0d,EAAQyI,IAGtBzI,EAAOqc,SAAWrc,EAGlBA,EAAOpB,aAAe/f,GAGtBmhB,EAAOsc,gBCj+BUtc,CAAAA,UACTsc,EACJt8B,iBACS,mCAGXF,OAAOsP,eAAektB,EAAiB,YAAa,CAClDxlB,UAAU,EACV1L,YAAY,IAEdtL,OAAOsP,eAAektB,EAAgBv8B,UAAW,cAAe,CAC9D+W,UAAU,EACV1L,YAAY,EACZkL,cAAc,EACd7d,MAAO6jC,IASTA,EAAgBnG,QAAU,SAAS3+B,EAAOquB,UACrC7f,UAAU1P,OAAS,EACbsH,QAAQyB,OACb,IAAIkJ,UAAU,0CAEXyX,EAAOmW,QAAQ3+B,EAAOquB,IAE/ByW,EAAgBtP,OAAS,SAASx1B,UAC7BwO,UAAU1P,OAAS,EACbsH,QAAQyB,OACb,IAAIkJ,UAAU,yCAEXyX,EAAOgN,OAAOx1B,IAEvB8kC,EAAgBnM,QAAU,SAAS34B,UAC9BwO,UAAU1P,OAAS,EACbsH,QAAQyB,OACb,IAAIkJ,UAAU,0CAEXyX,EAAOmQ,QAAQ34B,IAGjB8kC,GDo7BgBz9B,CAA6BmhB,GAEtDuc,GAASlc,aAAaL,GACtBuc,GAASxc,qBAAqBC,GAUvBA,GAMDvC,GAAU,kBACP/G,IAAQ,kBACN+G,SAKX/G,GAAQ+G,IAERnpB,OAAiBmpB,uBElgCjB,SAAW5V,OAOH20B,EAAU,KAGL,QACA,QACA,QACA,QACA,SACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,SACA,SACA,QACA,QACA,QACA,QACA,SACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,SACA,QACA,SAKA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,SACA,QACA,SACA,QACA,QACA,QACA,SACA,QACA,SACA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,UACA,UACA,UAGA,QACA,SACA,QACA,SACA,QACA,QAGA,QACA,SACA,QACA,SACA,QACA,SACA,OAGA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGA,QACA,SACA,QACA,SACA,SACA,QACA,SACA,SACC,SACD,SACA,QACA,SACA,QACA,SACA,SACA,QACA,SACA,QACA,SACA,QACA,QACA,SACA,QACA,SACA,QACA,QACA,SACA,QACA,QACA,SACA,QACA,SACA,QAEA,QACA,SACA,SACC,UACA,UACD,QAEA,QACA,SACA,QACA,SACA,QACA,SACA,YACG,SACH,SAEA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAEA,OACA,OACA,OAGA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGA,QACA,SACA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,SACA,SACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,SACA,SACA,SACA,SACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,SACA,QACA,SACA,QACA,SACA,QACA,SACA,QACA,SACA,OAIA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,QACA,QAGA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGA,QAEA,QACA,QACA,QACA,QACA,QACA,QAEA,QAEA,QAEA,QACA,QACA,QACA,QACA,QACA,QAEA,QAIA,SACA,SACA,SACA,SACA,SACA,UACC,UACA,SAGD,QACA,QACA,QACA,QACA,QAEA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGA,SACA,QACA,SACA,QACA,SACA,QACA,SACA,QAGA,QACA,QACA,QACA,QAGA,QACA,QACA,QACA,QAKA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,SACA,SACA,SACA,OACA,QACA,OACA,QACA,SACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,QACA,SACA,SACA,SACA,OACA,QACA,OACA,QACA,SACA,SAGA,SACA,QAGA,QACA,SACA,SACA,QAGA,QACA,SAGA,QACA,QACA,QACA,QACA,QACA,QAGA,QACA,QACA,QACA,QAOA,QACA,QAGA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SAEA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SAEA,QACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SAEA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAEA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGA,QACA,QACA,QACA,QACA,QACA,QACA,WACA,UACA,SACA,SACA,UACA,QACA,WACA,UACA,QACA,QACA,QACA,QACA,QACA,MAGA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,WACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,SACA,UACA,UACA,WACC,UACD,UACA,UACA,YACE,WACD,UACD,UACA,OASLC,EAAqB,UAYrBC,EAAa,KAGR,QACA,QACA,QACA,QACA,QACA,SACC,QACD,QACA,WACG,YACF,WACC,UACD,WACC,SACF,SACC,YACE,aACA,WACF,YACE,cACA,YACF,UACA,SACA,WACC,YACA,WACA,WACA,UACD,WACE,WACD,WACD,WACC,WACA,YACA,WACA,UACD,WACC,YACA,WACA,aACE,WACH,WACC,YACA,WACA,UACD,WACE,UACF,SACD,UACC,WACA,WAGC,WACA,MAOPC,EAAc,IACR,MAEA,KACG,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGH,KACG,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGH,KAGG,QACA,QACA,QACA,QAGH,KACG,QACA,QAGA,QACA,QAGA,QACA,QACA,QACA,QAGH,KACG,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGH,KACG,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGH,KACG,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGH,KAGG,QACA,QACA,QACA,QAGH,KACG,QACA,QAGH,KACG,SACA,SACA,SACA,SACA,SACA,SAGH,KACG,QACA,QACA,QACA,MASTC,EAAY,IACN,KACG,YACA,gBACA,UACA,SACA,SACA,eACA,gBACA,aACA,WAGH,MAEA,KACG,YACA,cACA,WACA,QACA,QACA,gBACA,cACA,gBACA,aAGH,KACG,YACA,gBACA,YACA,QACA,WACA,gBACA,gBACA,aACA,WAGH,KACG,YACA,gBACA,YACA,UACA,WACA,kBACA,mBACA,gBACA,eAGH,KACG,YACA,gBACA,YACA,UACA,aACA,mBACA,mBACA,aACA,aAGH,KACG,YACA,eACA,WACA,UACA,SACA,gBACA,mBACA,UACA,eAGH,KACG,YACA,eACA,WACA,QACA,QACA,gBACA,cACA,kBACA,aAGH,KACG,YACA,iBACA,YACA,SACA,SACA,gBACA,iBACA,cACA,YAGH,KACG,YACA,kBACA,cACA,SACA,UACA,oBACA,oBACA,YACA,eAGH,KACG,YACA,iBACA,YACA,SACA,SACA,gBACA,mBACA,gBACA,cAGH,KACG,YACA,iBACA,gBACA,SACA,SACA,cACA,WACA,WACA,aAGH,MAEA,KACG,YACA,eACA,eACA,SACA,WACA,kBACA,mBACA,aACA,cAGH,KACG,YACA,eACA,YACA,QACA,QACA,gBACA,kBACA,YACA,aAGH,KACG,YACA,eACA,YACA,SACA,SACA,iBACA,kBACA,WACA,cAGH,KACG,YACA,gBACA,gBACA,SACA,UACA,iBACA,mBACA,YACA,aAGH,KACG,iBACA,gBACA,cACA,WACA,UACA,cACA,cACA,cACA,cAGH,MAEA,KACG,YACA,eACA,aACA,SACA,SACA,kBACA,iBACA,UACA,aAGH,KACG,YACA,qBACA,aACA,QACA,UACA,mBACA,kBACA,WACA,aAGH,KACG,YACA,eACA,WACA,QACA,SACA,gBACA,gBACA,WACA,YAGH,KACG,YACA,cACA,eACA,SACA,UACA,iBACA,kBACA,WACA,aAGH,KACG,YACA,kBACA,YACA,QACA,UACA,aACA,aACA,YACA,cAGH,KACG,YACA,gBACA,YACA,QACA,YACA,gBACA,eACA,YACA,WAGH,MAEA,KACG,YACA,gBACA,UACA,SACA,WACA,eACA,eACA,aACA,kBAGH,KACG,YACA,oBACA,YACA,QACA,UACA,aACA,aACA,WACA,cAGH,KACG,YACA,aACA,UACA,SACA,WACA,cACA,cACA,WACA,YAITC,EAAY,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KAAKhjC,KAAK,IAEpEijC,EAAmB,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KAAKjjC,KAAK,IAEtEkjC,EAAY,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KAAKljC,KAAK,IASrDmjC,EAAU,SAAiBxlC,EAAO2jC,OAM9B8B,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACApnC,EACAqnC,EACAhd,EACAid,EACAC,EAlBAC,EAAY,IACZ1hC,EAAS,GACT2hC,EAAgB,GAChBC,GAAiB,EACjBC,EAAqB,GAerBC,EAAe,MAEE,iBAAVzmC,QACA,MAGS,iBAAT2jC,IACP0C,EAAY1C,GAGhBoC,EAASX,EAAUsB,GACnBV,EAAWb,EAAYuB,GAEH,iBAAT/C,MA6DFuC,KA5DLT,EAAe9B,EAAK8B,eAAgB,EACpCe,EAAsB7C,EAAKgD,QAAiC,iBAAhBhD,EAAKgD,OAAuBhD,EAAKgD,OAASH,EACtFb,GAAahC,EAAKgC,SAAW,GAAKhC,EAAKgC,WAAa,EACpDC,EAAWjC,EAAKiD,OAAQ,EACxBf,EAAkBlC,EAAKkD,cAAe,EACtCf,EAAWnC,EAAKmD,OAAQ,EACxBP,GAAmC,IAAjB5C,EAAKoD,UAAmC,IAAdpD,EAAK9M,KACjDwP,EAAY1C,EAAK0C,WAAaA,EAE1BT,IACAa,GAAgBpB,GAGhBQ,IACAY,GAAgBnB,GAGhBQ,IACAW,GAAgBlB,GAGpBQ,EAAUpC,EAAK9M,MAAQuO,EAAUzB,EAAK9M,OAAS0P,EAC3CnB,EAAUzB,EAAK9M,MAAS0P,EAAiBnB,EAAUsB,GAAK,GAE5DV,EAAYrC,EAAK9M,MAAQsO,EAAYxB,EAAK9M,MACtCsO,EAAYxB,EAAK9M,OACH,IAAd8M,EAAK9M,OAAgC,IAAd8M,EAAK9M,KAAgB,GAAKsO,EAAYuB,GAG7D/C,EAAK+B,WAA8C,iBAA1B/B,EAAK+B,UAAU5mC,QAAuBmD,MAAMsG,UAAUC,SAASC,KAAKk7B,EAAK+B,YAClG/B,EAAK+B,UAAUziC,SAAQ,SAAUoF,GAC7Bm+B,EAAmBn+B,EAAI,IAAMA,EAAI,MAGrCq9B,GAAY,GAEZA,IAAc/B,EAAK+B,UAInB/B,EAAKgD,QAAwC,iBAAvBhD,EAAKgD,OAAO7nC,QAAuBmD,MAAMsG,UAAUC,SAASC,KAAKk7B,EAAKgD,SAC5FhD,EAAKgD,OAAO1jC,SAAQ,SAAUoF,GAC1Bm+B,EAAmBn+B,EAAI,IAAMA,EAAI,MAKzCC,OAAOtK,KAAKwoC,GAAoBvjC,SAAQ,SAAUoF,OAC1C2+B,EAGAA,EADA3+B,EAAEvJ,OAAS,EACP,IAAIe,OAAO,MAAQonC,EAAY5+B,GAAK,MAAO,MAE3C,IAAIxI,OAAOonC,EAAY5+B,GAAI,MAGnCrI,EAAQA,EAAMoB,QAAQ4lC,EAAGR,EAAmBn+B,OAIrCm+B,EACPC,GAAgBP,MAOxBO,EAAeQ,EAHfR,GAAgBJ,GAQhBF,GAAoB,EACpBC,GAAqB,EAEhBvnC,EAAI,EAAGqqB,GALZlpB,EAAQA,EAAMoB,QAAQ,eAAgB,KAKhBtC,OAAQD,EAAIqqB,EAAGrqB,IACjCqnC,EAAKlmC,EAAMnB,GAEPqoC,EAAqBhB,EAAIM,GAEzBL,GAAoB,EACbH,EAASE,IAEhBA,EAAKC,GAAqBH,EAASE,GAAIzlC,MAAM,eAAiB,IAAMulC,EAASE,GAAMF,EAASE,GAE5FC,GAAoB,GACbD,KAAMlB,GAETnmC,EAAI,EAAIqqB,GAAK+b,EAAmBr8B,QAAQ5I,EAAMnB,EAAI,KAAO,GACzDynC,GAAiBJ,EACjBA,EAAK,KACyB,IAAvBE,GACPF,EAAKhB,EAAWoB,GAAiBtB,EAAQkB,GACzCI,EAAgB,IAGhBJ,EAAKC,GAAqBnB,EAAQkB,GAAIzlC,MAAM,eAAiB,IAAMukC,EAAQkB,GAAMlB,EAAQkB,GAG7FC,GAAoB,EACpBC,GAAqB,GACdF,KAAMhB,GACboB,GAAiBJ,EACjBA,EAAK,GAEDrnC,IAAMqqB,EAAI,IACVgd,EAAKhB,EAAWoB,IAEpBF,GAAqB,IAGrBL,EAAOG,IAASN,IACM,IADMP,EACvBz8B,QAAQs9B,IAAiBL,IAER,IAF2BP,EAE5C18B,QAAQs9B,KAMc,IAAvBE,GACAF,EAAKhB,EAAWoB,GAAiBJ,EACjCI,EAAgB,GAChBF,GAAqB,GACdD,IAAsB,cAAc3lC,KAAK0lC,IAAOvhC,EAAOsL,QAAQ,GAAGxP,MAAM,iBAE/EylC,EAAK,IAAMA,GAEfC,GAAoB,IAbpBD,EAAKC,GAAqBxhC,EAAOsL,QAAQ,GAAGxP,MAAM,eAAiB4lC,EAAYN,EAAOG,GAAMH,EAAOG,GACnGA,QAAuB,IAAjBlmC,EAAMnB,EAAI,IAAiBmB,EAAMnB,EAAI,GAAG4B,MAAM,eAAiB4lC,EAAY,GAEjFF,GAAoB,GAcxBxhC,GAAUuhC,EAAG9kC,QAAQ,IAAIvB,OAAO,WAAa4mC,EAAe,MAAO,KAAMJ,UAGzEX,IACA/gC,EAASA,EAAOvD,QAAQ,cAAc,SAAU8kB,EAAGrnB,EAAGmoC,OAC9CG,EAAItoC,EAAE4a,eAAuB,OAANutB,EAAaA,EAAI,WACpC1+B,OAAOtK,KAAKwoC,GAAoB59B,QAAQu+B,EAAEv8B,eAAiB,EAAKu8B,EAAIA,EAAEv8B,kBAOtFjG,EAASA,EAAOvD,QAAQ,OAAQilC,GAC3BjlC,QAAQ,IAAIvB,OAAO,KAAOwmC,EAAY,IAAK,KAAMA,GACjDjlC,QAAQ,IAAIvB,OAAO,OAASwmC,EAAY,OAASA,EAAY,MAAO,KAAM,IAE3EV,GAAYhhC,EAAO7F,OAAS6mC,IAC5BM,EAAQthC,EAAOyiC,OAAOzB,KAAcU,EACpC1hC,EAASA,EAAOzF,MAAM,EAAGymC,GAEpBM,IACDthC,EAASA,EAAOzF,MAAM,EAAGyF,EAAOuL,YAAYm2B,MAI/CZ,GAAiBC,IAClB/gC,EAASA,EAAOiG,eAGbjG,GAQP0iC,EAAa,SAAoB1D,UAO1B,SAA2B3jC,UACvBwlC,EAAQxlC,EAAO2jC,KAQ1BsD,EAAc,SAAqBjnC,UAC5BA,EAAMoB,QAAQ,yBAA0B,SAQ/C8lC,EAAuB,SAAUhB,EAAIM,OAChC,IAAI/vB,KAAK+vB,KACNA,EAAmB/vB,KAAOyvB,SACnB,MAKkBppC,EAAOwqC,QAGxCxqC,UAAiB0oC,EACjB1oC,qBAA4BuqC,cAWpBh3B,EAAKm1B,SAAWn1B,EAAKg3B,gBACf,qDAENh3B,EAAKm1B,QAAUA,EACfn1B,EAAKg3B,WAAaA,EAExB,MAAO//B,KAtpDjB,CAwpDG/J,qBCxpDHT,OAAiBuK,2gfCIXkgC,GAAiB,gBAAGC,IAAAA,cAAeC,IAAAA,SAAUC,IAAAA,SAAahN,aACvB,IAAnCiN,EAAMC,SAASvQ,MAAMqQ,SACjB,IAAIhnC,MAAM,sDAIoBmnC,EAAUJ,EAAUD,EAAe,CAAEM,UAAWN,IAAxEO,IAANx2B,cAAkBy2B,QAGfL,uBAAKM,MAAO,CAAEC,UAAW,IAAKP,gBAACQ,SAC9BJ,EAKVJ,gBAACS,MAAoBC,UAAWZ,EAAUa,OAAQP,EAAYpmB,OAAO,SAAY+Y,GAC9EgN,GALI,oDCZLa,GAA2B,gBAAG5mB,IAAAA,OAAQ2mB,IAAAA,OAAQD,IAAAA,UAAWX,IAAAA,SAAahN,aACnC,IAAnCiN,EAAMC,SAASvQ,MAAMqQ,SACjB,IAAIhnC,MAAM,iEAGb4nC,GAAWA,EAAO3mB,GAGrBgmB,gBAACJ,MAAeE,SAAUY,EAAWb,cAAec,EAAO3mB,IAAa+Y,GACrEgN,GAJkC,MASzCa,GAAyBC,aAAe,CACtCC,UAAU,OCfNC,GAAgB,SAACC,OACbC,EAAaC,IAAbD,aACkBE,EAAS,OAA5B/R,OAAOgS,WACgBD,GAAS,MAAhCd,OAASgB,WACYF,GAAS,MAA9BG,OAAQC,WACWJ,GAAS,MAA5BlzB,OAAOuzB,OAER3B,EAAgB4B,GAAQ,cACxBT,EAAgB,IACdA,EAAeplC,WAAW,eACrBolC,QACF,GAAIC,MAAAA,GAAAA,EAAUS,iBACZT,MAAAA,aAAAA,EAAUS,8BAAVC,EAAsBX,MAGhC,CAACC,EAAUD,IAERvuB,EAAQmvB,6BAAY,sGACnB/B,mDAELwB,GAAW,GACLv+B,EAAU,IAAIqN,QAAQ,CAC1B/M,OAAQ,sBACRy+B,cAAe,UAAYC,aAAaC,QAAQ,WAGlDC,EACGC,UAAUpC,EAAe,CAAE/8B,QAAAA,IAC3Bwa,MAAK,gBAAGtO,IAAAA,KACHA,GAAQA,EAAKogB,MACfgS,EAASpyB,EAAKogB,OAEdgS,EAAS,IAEXI,GAAS,GACTD,GAAU,GACVF,GAAW,aAEN,WACLG,GAAS,GACTD,GAAU,GACVF,GAAW,iDAEd,CAACD,EAAUG,EAAWF,EAAYG,EAAU3B,WAE/CqC,GAAU,WACH7B,GAAYiB,GAAWrzB,GAC1BwE,MAED,CAACA,EAAO4tB,EAASiB,EAAQrzB,IAErB,CAAEmhB,MAAAA,EAAOiR,QAAAA,EAASiB,OAAAA,EAAQrzB,MAAAA,EAAOk0B,QAAS1vB,EAAO3L,IAAK+4B,EAAeuC,MAAOnB,MAAAA,SAAAA,EAAU1kC,KClDzF8lC,GAAW,eACPpB,EAAaC,IAAbD,SAEFqB,EAAWb,GAAQ,oBACnBR,MAAAA,GAAAA,EAAUS,iBACLT,MAAAA,aAAAA,EAAUS,8BAAVC,EAAqBY,QAE7B,CAACtB,IAEEuB,EAAiBf,GAAQ,sBACzBR,MAAAA,GAAAA,EAAUS,iBACLT,MAAAA,aAAAA,EAAUS,kCAAVe,EAAqBC,8BAArBC,EAAiC,yBAEzC,CAAC1B,UAoDG,CAAExuB,MAlDKmvB,8CACZ,mHAASgB,IAAAA,QACFJ,GAAmBF,0DAElBO,EAAQf,aAAaC,QAAQ,SAC7Be,EAAmBC,GAAsB,CAAC,cAE5CC,EAAoB,GACpBJ,GACFjiC,OAAOtK,KAAKusC,GAAStnC,SAAQ,SAACrC,MACxB2pC,EAAQ3pC,GAAY,KAChBC,EAAS0pC,EAAQ3pC,GAAW2C,WAAW,mBAAcgnC,EAAQ3pC,QAAgB2pC,EAAQ3pC,GAC3F+pC,iBAA4B/pC,cAAaC,YAKzCmP,2HAIFy6B,EAAiBG,wDAGhBX,gGAGDU,uBACAF,EAAiBI,mCAIElB,EAAWC,UAAUO,EAAgB,CAC1DhyB,OAAQ,OACR/C,KAAMpF,EACNvF,QAAS,IAAIqN,QAAQ,CACnB/M,OAAQ,sBACRy+B,cAAe,UAAYgB,4BALvB7zB,IAAAA,MASC,oDACAA,EAAK,4CAEL,wGAGX,CAACwzB,EAAgBF,IAGHx7B,IAAKw7B,EAAUF,MAAOnB,MAAAA,SAAAA,EAAU1kC,KCjE5C4mC,GAAY,eACRlC,EAAaC,IAAbD,SAEFmC,EAAY3B,GAAQ,oBACpBR,MAAAA,GAAAA,EAAUS,iBACLT,MAAAA,aAAAA,EAAUS,8BAAVC,EAAqB0B,SAE7B,CAACpC,IAEEuB,EAAiBf,GAAQ,sBACzBR,MAAAA,GAAAA,EAAUS,iBACLT,MAAAA,aAAAA,EAAUS,kCAAVe,EAAqBC,8BAArBC,EAAiC,yBAEzC,CAAC1B,UA6DG,CAAEqC,KA1DI1B,8CACX,WAAO2B,oGACCV,EAAQf,aAAaC,QAAQ,2BAEPC,EAAWC,UAAUmB,EAAW,CACxD5yB,OAAQ,OACR/C,KAAMa,KAAK+N,wBACG,yCACTknB,IAELzgC,QAAS,IAAIqN,QAAQ,gBACH,sBAChB0xB,+BAAyBgB,8BARrB//B,IAAAA,0BAWDA,EAAQ/M,IAAI,uEAEZ,kHAGX,CAACqtC,IAsCY3wB,MAnCDmvB,6BAAY,8GACnBY,GAAmBY,0DAElBP,EAAQf,aAAaC,QAAQ,SAC7Be,EAAmBC,GAAsB,CAAC,cAE1C16B,2HAIAy6B,EAAiBG,wDAGhBG,8DAEDN,EAAiBI,kCAIAlB,EAAWC,UAAUO,EAAgB,CAC1DhyB,OAAQ,OACR/C,KAAMpF,EACNvF,QAAS,IAAIqN,QAAQ,CACnB/M,OAAQ,sBACRy+B,cAAe,UAAYgB,2BALvB7zB,IAAAA,MASC,oDACAA,EAAK,4CAEL,kDAER,CAACwzB,EAAgBY,IAEEt8B,IAAKs8B,EAAWhB,MAAOnB,MAAAA,SAAAA,EAAU1kC,KC3EnDinC,GAAe,iBAoBZ,CAAE/wB,MAlBKmvB,8CAAY,WAAOrlC,kHAEHA,EAAG9D,MAAM,cAA3BgrC,OAAUC,OACdt7B,EAAWs7B,EAAK5oB,SAAS,KAAO,OAAS,QAEzC6oB,YAAkBv7B,gBAAcs7B,kDAA4CD,cAAYC,qBAGrE1B,EAAWC,UAAU0B,0BAApC30B,IAAAA,KAEFyR,EAAOzR,EAAK40B,MAAMzK,MAAK,SAAC5X,SAAiB,8BAAXA,EAAE5lB,0BAE/B8kB,EAAOA,EAAK9Y,KAAO,iEAEnB,sHAER"}